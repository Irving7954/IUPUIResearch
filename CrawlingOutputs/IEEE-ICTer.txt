412
Chaos theory based cryptography in digital image distribution
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
The amount of visual information available in digital format has grown exponentially in recent years due to the wide availability of digital equipments, changes in the way people socially interact by setting up community web pages, wide spread use of the Internet in all types of personal and business activities, pay-after-trial services of digital multimedia and developments in high speed transmission of digital images with high reliability. However, the wide accessibility of the Internet and its connected hosts and availability of technology to capture network traffic or penetrate hosts have made digital images vulnerable to unauthorized access while in storage and during transmission over a network. Hence users of the Internet and application that use or process digital images need to address security issues to protect commercial value of images and also ensure user privacy and other issues. The objective of the research presented in this paper focused on proposing an image encryption technique which is capable of encrypting an image effectively and securely with a predefined visibility level. The stipulated objective is achieved by employing 2D chaotic map called the Kaplan-Yorke map.
[Chaos, community Web page, pay after trial service, Chaos theory based cryptography, Encryption, multimedia computing, Convolution, high speed transmission, authorisation, image encryption technique, Kernel, digital image distribution, visual information, business activity, image processing, chaos theory, chaos, 2D chaotic map, digital equipment, Kaplan Yorke Map, cryptography, digital multimedia, Equations, network traffic, Kaplan-Yorke map, user privacy, social networking (online), Internet, digital format, security issue, Pixel]
EME: An emergent model of emotions
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Throughout the history of artificial intelligence (AI) various attempts have been made to incorporate emotional support in intelligent systems. Still some potential paths are left untraveled. This study presents an attempt to model emotions as a complex system based on the hypothesis that mind state can be considered as an emergent phenomena resulting from autonomous, interactive, elementary entities called emotions. Our approach is based on Buddhist philosophical concepts about thought formation by combination of emotions. Multi Agent Systems (MAS) technology has been used for the realization of above emotional model since interactions and emergence are intrinsic features of MAS. Capabilities of the model are exposed via a virtual agent application called EME who perceives, understands, uses and expresses emotions. Other potential applications incorporating the model are also introduced.
[multi-agent systems, emotional support, cognition, emergent emotion model, intelligent systems, complex system, artificial intelligence, Buddhist philosophical concepts, virtual agent application, emergent systems, emotion, psychology, cognitive architecture, decision making, human computer interaction, multiagent system technology, EME]
Facial muscle anatomy based approach for forensic facial reconstruction in Sri Lanka
International Conference on Advances in ICT for Emerging Regions
None
2012
Forensic facial reconstruction is still at its infancy in Sri Lanka and is yet to utilize the advanced technologies of other countries. Hence introducing a more efficient multimedia based technique to the local forensic officials in order to improve the efficiency and the accuracy of the reconstructions is the aim of this study. In contrast to the other mechanisms used for facial reconstruction by others, this paper adopts a novel approach of muscle based facial reconstruction which goes hand in hand with the manual reconstruction process. The adopted process involved, acquiring a 3D model of the skull and digitally sculpting muscles in a 3D environment, followed by adding different facial features to improve identification. The research also encompassed a tissue thickness analysis that is conducted for the first time on Sri Lankans as well as a facial component analysis, both of which were needed to improve the accuracy of the final output. This procedure was attempted on cases of the age category 20-30 and of medium weight. The outputs and the process were evaluated with different parties such as general public, forensic officials, lawyers and CID all of which are to be benefited from this application. The ultimate goal of conducting the study was to understand and overcome the challenges faced in developing this novel application for the Sri Lankan Forensic officials and to establish the first unit for facial reconstruction in Sri Lanka.
[Solid modeling, muscle-anatomy, general public, Sri Lanka, tissue thickness, facial muscle anatomy based approach, 3D model, multimedia based technique, tissue thickness analysis, image forensics, facial components, digital sculpting, local forensic officials, Sri Lankan, manual reconstruction process, Lead, face recognition, muscle based facial reconstruction, facial component analysis, forensic facial reconstruction, CID]
Facial image classification based on age and gender
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Automatic face identification and verification from facial images attain good accuracy with large sets of training data while face attribute recognition from facial images still remain challengeable. We propose a methodology for automatic age and gender classification based on feature extraction from facial, images, namely, primary and secondary features. Our methodology &#x00B7; includes three main iterations: Preprocessing, Feature extraction and Classification. Our solution is able to classify images in different lighting conditions and different illumination conditions. Classification is done using Artificial Neural Networks according to the different shape and texture variations of wrinkles on face images.
[face identification, image classification, age classification, facial image classification, secondary feature, face verification, Classification algorithms, Texture, wrinkles, Accuracy, Image color analysis, feature extraction, Nose, Mouth, Wrinkles, face recognition, lighting conditions, shape variation, image preprocessing, Face, face attribute recognition, illumination conditions, Age classification, gender classification, lighting, texture variation, Gender classification, image texture, artificial neural networks, primary feature, Feature extraction, neural nets]
Invited talks: Developing secure mobile applications
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Summary form only given. In the rapidly growing mobile eco-system, mobile application security is an important aspect for many stakeholders. Mobile application development incorporates new design principles that require developers to pay attention to new methods for ensuring data security. Proper design of mobile applications and associated frastructure with alignment to security can be an effective way to increase the long-term success of your solutions.
[mobile computing, security of data, data security, mobile eco-system, secure mobile applications development]
Contour tracing for isolated Sinhala handwritten character recognition
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Sinhala is the language of the Sinhalese. Most Sinhala language characters have a complex shape. As a result, many writing styles are used in Sinhala writing which makes recognition difficult. In this paper, a contour tracing technique is applied for isolated Sinhala handwritten character recognition. To improve the recognition rate, distance profiles have been incorporated. The proposed technique was tested for 35 commonly used characters in the Sinhala alphabet. Handwritten samples are collected from three different writers. A maximum recognition rate of 100%, a minimum of 9.1%, median of 48.5% and a mean of 53% was achieved with this technique.
[distance profiles, handwritten character recognition, Shape, Sinhala Handwritten Character Recognition, Contour Tracing, contour tracing technique, Handwriting recognition, median, mean, Sinhala handwritten character recognition, shape recognition, Sinhala alphabet, Distance Profile]
Framework for Sinhala Sign Language recognition and translation using a wearable armband
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Sign Language is the main communication method of hearing &amp; speaking impaired people and their main obstacle in the general society is the communication difficulty with normal hearing people. The aim of this research is to bridge above gap by proposing a framework for recognize Sinhala sign language gestures and translate them in to natural language. In order to preserve both functional and usability aspects of the solution, this study has used a non-invasive wearable gesture recognition armband. The approach is to use a combination of gestural data (surface Electromyography) that measures the muscle activity and spatial data (accelerometer, gyroscope &amp; orientation) that measures hand movements for the sign recognition. The mapping has been done by implementing multiple artificial neural networks under the supervised machine learning technique. As a result, the study provided 100% accuracy for person dependent (personalized) study and 94.4% accuracy for person independent (generalized) study.
[Performance evaluation, supervised machine learning, spatial data, handicapped aids, surface electromyography, Sinhala sign language gesture recognition, Sinhala sign language translation, Inertial Measurement Units (IMU), communication difficulty, accelerometer, Electromyography, Sensors, learning (artificial intelligence), sign language recognition, Surface Electromyography (sEMG), Accelerometers, hearing &amp; speaking impaired people, Assistive technology, Gesture recognition, gyroscopes, gyroscope, wearable computers, hand movement measurement, Supervised Learning, artificial neural networks, MYO Gesture Recognition Armband, electromyography, Auditory system, accelerometers, natural languages, muscle activity, Sinhala Sign Language, noninvasive wearable gesture recognition armband, neural nets]
Constructing and analyzing gene regulatory networks in leaf senescence of arabidopsis thalina
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Aging or senescence in plant is a highly regulated and a complex process. Since vulnerability to diseases increases with age, studying aging is of high importance. Analysis of gene expression or sequence data has been crucial for investigating aging, which limits the studies of their genes and proteins by isolation, ignoring their interactions. This research concerns the modelling of Gene Regulatory Networks (GRNs) for the process of leaf senescence in Arabidopsis thaliana to be used as an example, to uncover the cell mechanisms that are responsible for aging. The networks were obtained considering the gene expression values of up regulated and down regulated genes occurred in the process of leaf senescence using Dynamic Bayesian Network model. We obtained six Dynamic Bayesian Networks which can be used to study the behavioural changes of leaves with time. Our dynamic GRNs predict a number of valid gene-gene interactions which we believe directly impact leaf senescence of Arabidopsis. Up regulated and down regulated gene networks at different time periods were then analysed and compared. Several number of sensitive measures in network topologies were applied to the obtained dynamic Senescence specific GRNs. Results illustrate that there are significant changes in local topologies of networks than global properties highlighting the loss of connectivity in genes in the activation of visible senescence of a leaf. The Gene Ontology (GO) enrichment analysis reveals certain genes in signalling pathways which regulate in leaf senescence. We successfully validated number of Senescence Associated Genes (SAGs) in our study and several gene-gene interaction predictions were derived from our network inference phase.
[Dynamic Bayesian Networks, dynamic Senescence specific GRNs, Gene Regulatory Networks, dynamic GRNs, Senescence Associated Genes, Network topology, genetics, gene regulatory networks, biology computing, network topological analysis, Aging, genomics, gene-gene interaction predictions, belief networks, gene expression values, network inference phase, gene-gene interactions, Sparse Candidate Algorithm, regulated regulated genes, Topology, Gene expression, Gene Ontology enrichment analysis, down regulated gene networks, leaf senescence, Dynamic Bayesian Network model, network topologies, ontologies (artificial intelligence), Data models, arabidopsis thalina, Bayes methods, aging, Bayesian networks, molecular biophysics]
Adaptation analysis of Agile Project Management for managing IT projects in Sri Lanka
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
The dynamic business environment today has created immense pressure on the delivery of IT projects. Traditional methods of managing projects are no longer applicable and effective to manage certain IT projects as they are unable to cope with the rapid organizational and business level changes. Agile project management has caught the attention of many project managers as a means of facing these challenges and to overcome the limitations of managing IT projects. This study reports the results of an adaptation analysis done on Agile Project Management in managing IT projects in Sri Lanka. The awareness level of agile project management and what factors affect the awareness are discussed in this study. The agile project management implementation challenges and recommendations discussed in this study will help Sri Lankan organizations to successfully adopt agile project management.
[Industries, project management, Traditional Project Management, information technology, Sri Lanka, Project management, Awareness, Companies, Programming, adaptation analysis, business level change, awareness level, Agile Project Management, IT project management, agile project management, Software, business data processing, organisational aspects, rapid organizational change]
Women empowerment in rural areas through the usage of telecentres - a Sri Lankan case study
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
Information and Communication Technologies can have a strong impact on the development of a region: telecentre networks are in particular interesting model for e-learning dissemination to rural areas. The focus area of our investigation is Sri Lanka: the country has a long tradition in terms of gender equality - as it promotes an inclusive education system - and the use of ICTs is widespread. So far 600 of the planned 1000 telecentres have been started following the Nenasala network model. This paper is based upon observations and interviews of women and men working in different roles (owner, manager, operator and user) at telecentres in rural Sri Lanka. The aim of the study is to analyze and discuss the role of telecentres in rural areas and their impact on women empowerment. Findings show that telecentres open up new channels of information and create career opportunities for women in rural areas. Through telecentres, women can improve their life and be active participants in the rural development. However there still exists a need for further improvements and support for females in the Sri Lankan telecentre network.
[region development, gender equality, Nenasala network model, Women Empowerment, Sri Lanka, telecentre networks, education system, Telecentres, Education for all, e-learning, rural development, women empowerment, Lead, career opportunities, Sri Lankan case study, information and communication technologies, computer aided instruction, Internet, gender issues, government data processing, CT4D]
On cloud computing deployment architecture
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
Cloud computing is the provision of providing dynamically scalable and often virtualized resources as a service over the Internet. It is a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources that can be rapidly provisioned and released with minimal management effort and cloud provider interaction. Enterprises across the world are moving their business infrastructure from on-premise to the cloud. The lack of reliability and inter-portability in the current cloud deployment architecture makes this transition much slower than expected. The most of existing cloud providers are using 2-tiered cloud deployment architecture. This paper presents a 3-tiered cloud deployment architecture which ensures the improved reliability and inter-portability in the cloud environment.
[virtualized resource, Cloud computing, Google, Clouds, Outage, virtualization, on demand network access, Service oriented architecture, minimal management, Servers, interportability, business infrastructure, configurable computing resource, 2-tiered cloud deployment architecture, Inter-portability, software architecture, cloud provider interaction, Cloud Computing, cloud computing deployment architecture, Computer architecture, Internet, Reliability, 3-tiered cloud deployment architecture, business data processing]
A language independent algorithm to send secret messages using steganography
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
The radical growth of internet &amp; cybercrime during the last few years has forced us to think about how to improve information security efficiently during communication. Protecting the information during communication via the internet is the major challenge against eavesdropper. Encryption is a widely used technique to ensure secure communication; however, sending encrypted messages often draws an eavesdropper's attention. Steganography is a method of writing secret messages in a way that nobody, except for the sender and the recipient, suspects the existence of a hidden message. In this paper a new steganographic technique is proposed to transmit concealed messages in multi-language or combination of languages, which can be represented in Unicode. Use of inter-character spacing technique is proposed as the steganographic technique and a prototype implementation has been done with Rich Text Format (RTF) documents. An additional optimized compression technique is also proposed with enhanced user defined codes, to support Unicode language. Another advantage is that the secret message (hidden) can be in a different language than which is transmitted through the communication channel.
[Unicode, codes, cybercrime, rich text format document, document compression technique, electronic messaging, information security, cryptography, language independent algorithm, Encoding, Decoding, Encryption, Unicode language, Security, Steganography, message authentication, steganography, computer crime, Writing, Internet]
E-governance service delivery - an assessment of Community Information Centre Model in India
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
There exists relationship between the Governance and Information &amp; Communication Technology [ICT]. For the digital revolution in the rural areas in developing countries like India, governmental intervention was done in the form implementation of a Community Information Centre Model [CIC] of ICT project to reach the people. Hence, an assessment of e-governance through CIC Model was done. The scope of the study was to analyse the activities of CICs in one of the districts in India. The district has its rural and tribal character and unique distinction of ISO 9001:2000 certificate for integrated citizen centric services. The study investigated the demand-supply matching of e-governance services rendered under the CIC model from the perspective of the providers, users and community people. The study necessitated the developing a new evaluation methodology and use of Empirical Research Design, structured questionnaire, multi stage stratified random sampling technique, primary data along and Descriptive statistics and Non-Parametric testes for hypotheses testing. The study observed that there is gap between the level of demand and the level of supply in respect of e-governance service by CICs, as perceived by the Service Providers, Service Users and Community People. To fulfil the gap between the levels of delivery of the e-governance service, views of the target population should be considered more. The positive message is that there exists high level of demand for e-governance service in the rural as well as tribal areas. The study also mentioned scope of the future research.
[empirical research design, community information centre model, information &amp; communication technology, Communities, descriptive statistics, ISO standards, governmental intervention, structured questionnaire, e-Governance, community people, digital revolution, Communications technology, rural areas, nonparametric tests, Electronic government, Biological system modeling, demand-supply matching, Information technology, India, Information &amp; Communication Technology, integrated citizen centric services, e-governance service delivery, multi stage stratified random sampling technique, ISO 9001:2000 certificate, Community Information Centre, service users, government data processing]
Game interaction state graphs for evaluation of user engagement in explorative and experience-based training games
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
There is an increasing interest to use computer games for non-traditional education, such as for training purposes. For training education, simulators are considered as offering more realistic learning environments to experience situations that are similar to real world. This type of learning is more beneficial for practicing critical situations which are difficult or impossible in real world training, for instance experience the consequences of unsafe driving. However, the effectiveness of simulation-based learning of this nature is dependent upon the learner's engagement and explorative behaviour. Most current learner evaluation systems are unable to capture this type of learning. Therefore, in this paper we introduce the concept of game interaction state graphs (GISGs) to capture the engagement in explorative and experience-based training tasks. These graphs are constructed based on rules which capture psychologically significant learner behaviours and situations. Simple variables reflecting game state and learner's controller actions provide the ingredients to the rules. This approach eliminates the complexity involved with other similar approaches, such as constructing a full-fledged cognitive model for the learner. GISGs, at minimum, can be used to evaluate the explorative behaviour, the training performance and personal preferences of a learner.
[Computers, virtual reality, learner behaviour, engagement, driving simulator training, explorative training game, Psychology, digital simulation, explorative behaviour, Training, graphs, computer based training, computer games, experience based training game, learner evaluation system, serious games, Driver circuits, cognitive systems, Computational modeling, cognition, learning systems, game interaction state graph, Games, game interaction, experience-based systems, simulation based learning, behavioural sciences computing]
Performance analysis of user scheduling schemes in next generation wireless systems with MIMO links
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
Future wireless communication systems like 3GPP Long Term Evolution are required to support extreme high speed packet data transmission. Due to the limitation of available spectrum resource, high spectrum efficiency technologies are needed to be explored for different OSI layers. Over last decades, many technologies have been investigated to achieve this target. Multiple-input multiple-output (MIMO) system and channel-aware scheduling are two promising schemes proposed for that achievement. In this paper, we investigate the impact of MIMO and scheduling in the increasing of the system throughput of next generation mobile wireless systems when transmitting on different channels for several transmission modes. A cross-layer approach in resource allocation and scheduling schemes is emphasized.
[3GPP LTE, next generation mobile wireless systems, spectrum efficiency technologies, Conferences, Noise, 3G mobile communication, MIMO links, Throughput, cross-layer approach, channel-aware scheduling, Wireless communication, user scheduling schemes, resource allocation problem, resource allocation, 3GPP long term evolution, Scheduling schemes, MIMO-OFDMA, scheduling, multiple input multiple output system, MIMO, throughput, Round robin, MIMO communication]
Identification of learning styles and learning domains in Sri Lanka in the development of e-learning content
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
The nature of the human being is extremely variable as far as lifelong learning is concerned. With the advent of new technologies such as information technology with e-learning concepts they will get a pretty good learning environment. Different techniques are always being used for learning. That is the temperament of the people. It differs from person to person with respect to the learning purpose, behavior, life style, culture, age, profession and so on. In this the era of e-learning concepts and techniques we should be able to facilitate their learning style and domains. The awareness of learning styles and domain is important in the Sri Lankan context to ease the development of the e-learning content and to enhance the quality of the materials. The focus of this paper however, is on an identification of learning styles and domains within the Sri Lankan community to develop e-learning content to confer the maximum benefit to the end users. Since Sri Lanka is a multi-ethnic country a research has been done considering the above as well. Anyhow one's learning should be oriented towards a common goal what ever the nationality one belongs to. The University of Colombo School of Computing (UCSC) was the pioneer center which focused on e-learning content development in Sri Lanka. It has received a massive grant from JICA with their expertise and their knowledge to develop and train the trainers in the field of e-learning content development in Sri Lanka and the Asian region. The Learner must be able to study more content and also adhere to the self learning style because the country needs more self motivated and confident learners for its future development. This paper will describe the key learning styles and domains within the Sri Lankan community to develop e-learning content for all.
[Identification of learning styles and learning domains in Sri Lanka in the development of e-learning content, learning styles identification, self learning style, information technology, Sri Lanka, multiethnic country, Asian region, behavioural sciences, Materials, Educational institutions, e-learning content development, distance learning, Training, Electronic learning, computer based training, Analysis of variance]
Towards designing a routing protocol for opportunistic networks
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
Intermittently connected opportunistic networks experience frequent disconnections and shorter contact durations. Therefore routing of messages towards their destinations needs to be handled from various points of view. Predictability and connectedness are two information which can be determined by participating mobile nodes of an opportunistic content distribution network using their past contacts. Epidemic or probabilistic routing protocols do not fully utilize these information to route messages towards their destinations. In this paper we describe the routing algorithm, implementation details, experiment design and the performance validation of a new, adaptive routing protocol which utilizes the predictability and connectedness information to route messages efficiently. Simulation based comparative studies show that the proposed routing protocol outperforms existing Epidemic and probabilistic routing protocols in delivering messages.
[opportunistic content distribution network, mobile radio, queueing theory, Peer to peer computing, intermittently connected opportunistic network, Adaptation model, network contact duration, Probabilistic logic, Routing, message routing, History, adaptive routing protocol, MANET, network disconnection, routing algorithm, routing protocols, mobile node, message delivery, MOFO queuing policy, Routing protocols, routing protocol design]
Statistical machine translation of systems for Sinhala - Tamil
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
One of the most promising and leading machine translation strategies would be Statistical Translation Approach. Being pertinent even to structurally dissimilar language pairs, it has confirmed its suitability for large text translation. Rising demand is present for automatic translation between Sinhala and Tamil for quite a lot of decades. Statistical approach is the best preference to resolve the unavailability of a machine translation tool for the languages concerned. Because of language similarity, statistical approach could thrive agreeably, exclusive of more concern on linguistic knowledge. A basic translation system has been modelled and implemented in this research, with the preparation of parallel corpora from parliament order papers. This paper demonstrates only the preliminary system runs of the research, devoid of various parameter refinements and actual design and evaluation strategies. Language Model, Translation Model and Decoder Configurations are done consistent with recent literature. To facilitate the improvement of output quality, MERT technique is integrated to tune the decoder. To stay away from sole dependence on BLEU, two other automatic metrics namely TER and NIST are utilised for the evaluation in different aspects. In addition, directions to future research are also recognized and specified for the refinements of this system.
[Measurement, text analysis, automatic metrics, large text translation, Sinhala-Tamil translation, Training, linguistic knowledge, machine translation, decoder configuration, statistical machine translation, natural language processing, BLEU, language model, Decoding, language similarity, Tuning, Tamil, translation model, MERT technique, Hidden Markov models, structurally dissimilar language pairs, Sinhala, NIST, Data models, automatic translation, language translation]
Myanmar language search engine
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
With the enormous growth of the World Wide Web, search engines play a critical role in retrieving information from the borderless Web. Although many search engines are available for the major languages, but they are not much proficient for the less computerized languages including Myanmar. The main reason is that those search engines are not considering the specific features of those languages. A search engine which is capable of searching the Web documents written in those languages is highly needed, especially when more and more Web sites are coming up with localized content in multiple languages. In this study, the design and the architecture of language specific search engine for Myanmar language is proposed. The main features of the system are, (1) it can search the multiple encodings of the Myanmar Web page, (2) it is designed to comply with the specific features of the Myanmar language. Finally the experiment has been done to prove whether it meets the design requirements.
[Myanmar, search engines, search engine, Web document, information retrieval, borderless Web, World Wide Web, Encoding, Indexes, Compounds, encoding, Web pages, Web page, Non-standard encodings, Search engines, Writing, Myanmar language, natural languages, Internet, Web sites, Web site, Web search, computerized language, Indexing]
A case study approach: eT Guide - assisting the eTransformation journey
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
eTransformation, the ability to select and implement appropriate Information and Communication Technologies (ICT) based on company's goals, objectives and operations is essential for the businesses today. This paper identifies how an online system - eTranformation Guide (eT Guide) allows companies especially Small to Medium Enterprises (SMEs) to track, measure and guide their eTransformation journey. In particular this paper outlines how three companies from different industry sectors namely: Manufacturing - Staircase Design, Service - Finance and Accounting Services and Tourism and Hospitality - Boat Cruise have travelled the eTransformation journey over the period of last year. Furthermore, the study highlights that eT Guide Recommendations are important indicators to the companies in terms of identifying into which Dimension they should be investing into next and what changes they should be making for the future benefits of their eTransformation journey. Moreover, the findings also benefit the research community that is investigating how best companies can undertake the eTransformation journey.
[Industries, accounting services, Companies, tourism, Electronic mail, accounting, SMEs, Investments, eT Guide, hospitality, Book reviews, information systems, Information and Communication Technology, eTranformation Guide, company operations, information management, staircase design, Finance, manufacturing industry, small-to-medium enterprises, ICT selection, manufacturing data processing, eTransformation, company goals, company objectives, travel industry, finance services, ICT implementation, boat cruise, online system, business data processing]
Virtual learning model for metaverses
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
Virtual learning environments have been increasingly utilized in the domain of eLearning recently. Virtual worlds such as SecondLife and OpenSimulator have opened up great opportunities in this front. The major issue with virtual worlds with respect to education is lack of models that consistently describe the entire learning process. Most of the prior work was focused on building tools to extend real world learning tasks to virtual worlds rather than building virtual world based learning models which consistently describe the virtual world based learning itself. The ongoing work presented here is focused on filling the void in virtual world based learning models.
[Solid modeling, SecondLife, virtual reality, Computational modeling, learning process, building tool, Learning Model, Educational institutions, VLE, distance learning, metaverse, e-learning, OpenSimulator, Three dimensional displays, Second Life, computer aided instruction, Internet, Joining processes, real world learning, Virtual Worlds, virtual learning model]
Scalable fault tolerant architecture for complex event processing systems
2010 International Conference on Advances in ICT for Emerging Regions
None
2010
Complex Event Processing (CEP) is one of the fastest emerging fields in computer science. Modern CEP systems which are critical for organizations to maintain their business processes and to achieve excellence through operational responsiveness should be scalable and fault tolerant. The research project epZilla is to build a highly scalable, highly available, real time, fault tolerant distributed architecture for CEP systems.
[Scalability, Nominations and elections, distributed processing, business processes, Dynamic Service Discovery, Servers, Distributed Systems, operational responsiveness, STM, CEP, Fault tolerance, Computer architecture, Lead, Software, fault tolerant computing, Stratification, business data processing, complex event processing system, epZilla, scalable fault tolerant distributed architecture]
Message from the conference chair
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
The International Conference on Advances in ICT for Emerging Regions (ICTer) is the successor to the International IT Conference, the major IT Conference in Sri Lanka since 1998. It is a forum for the sharing of knowledge through the presentation of research carried out on various aspects of ICT in the region. This year particular effort was made to attract papers from the international community in addition to those from local research group and academia.
[]
Organizing team
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Provides a listing of current committee members and society officers.
[]
Program Committee
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
The conference offers a note of thanks and lists its reviewers.
[]
Logistics Committee
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Provides a listing of current committee members.
[]
Location aware queries for sensor network
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Wireless sensor networking is a rapidly merging research area. There are many areas where Wireless Sensor Network (WSN) applications are very important such as military, healthcare, agricultural and transportation. In WSN applications, power consumption is foremost crucial. Therefore reducing power consumption is a focal concern when developing WSN applications. Majority of power in WSN environment is used for communication purpose. As such the facility to acquire data based on location only from sensor node at required location would save power consumption. However this type of data acquisition has not been possible due to the unavailability of spatial queries. The acquisitional queries should be enhanced with the location aspect and moreover each sensor node should also be made aware of its location. This will enable user to specify queries based on the location and only the corresponding nodes respond by acquiring data. Thus main objective of this research is to come up with this enhancement. We have purposed spatial query syntaxes which have similar features as in Relational database spatial queries and main target of that approach is to increase the user friendliness. Other than that sensor nodes in the sensor network are capable to identify its location based on the GPS value. We evaluate these issues in the context of TikiriDB, a distributed, shared WSN, query processor for smart sensor devices, and show how acquisitional data based on location can provide significant reductions in power consumption on our sensor devices.
[Mesh routing, wireless sensor networks, relational database spatial queries, GPS, TikiriDB, telecommunication computing, healthcare, Temperature sensors, query processing, agricultural, RDBMS, location aware queries, communication purpose, PostGIS, military, GPS value, spatial query syntaxes, Europe, Spatial databases, smart sensor devices, Grammar, Spatial queries, relational databases, wireless sensor network applications, transportation, SQL, Temperature measurement, query processor, Wireless sensor networks, acquisitional queries, Wireless ad-hoc and sensor networks, power consumption reduction, Database abstractions, sensor node]
A framework for managing persistence in distributed systems
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Enterprise applications today have acquired the need to be distributed due various demanding reasons. Such systems are developed with focus on distributed concerns than on the application logic. This diverted the developers from the functional requirement of the system and burdened them with the responsibility of developing and maintaining code related to distributed concerns. The main intention of this research is to facilitate development of distributed systems without any consideration for distributed concerns. We suggest a way where the application is initially designed without them and later enabled by integrating the framework proposed in this research. We confine our interest in separating persistence and replication among other distributed concerns. The motivation for this research comes by recognizing the fact that such a framework drastically reduces the code and complexity involved to make a distributed application resilient to failures and thereby to minimize the effort necessary to debug, deploy and maintain.
[enterprise application, code maintenance, Peer to peer computing, distributed processing, distributed system, software management, Servers, software maintenance, software fault tolerance, distributed computing, FreePastry, JGroups, peer to peer overlay, failure resilience, group communication framework, debugging, Robustness, persistence management, Indexing, functional requirement]
Architectural description based Overlay Networks
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Overlay Networks are heavily used in Distributed computing applications. They often have heterogeneous architectures, such as Client Server, Peer to Peer or Hybrid. In this work, we try to abstract the Architecture of an Overlay Network into a document called an Architectural Description (AD). The Architectural Description document may contain the Roles and the Relationships of a particular Overlay Architecture. The Architectural Description documents may be exchanged among the nodes and parsed by the nodes themselves, enabling the nodes to adopt different roles and relationships. By introducing a new AD, a new Overlay Network can be formed dynamically. AD based Overlay Networks may open many new possibilities in Overlay Networking. This approach would allow heterogeneous Overlays to work collaboratively, while maintaining their respective Security settings using 'Security Roles'. It would also allow multiple overlays to be dynamically 'super-imposed' on top of each other. Apart from that, the AD based approach would allow the same set of nodes to switch between heterogeneous overlays at different time intervals. Architectural Descriptions can also be used as an efficient means of Security key management. A prototype framework was developed to explore these features, using sample distributed file sharing applications. Moreover, the possible enhancements and future directions of AD based approach in developing Overlay Networks are also discussed.
[architectural description document, FTP, Peer to peer computing, distributed processing, Encryption, network architecture, distributed computing, P2P, Architectural Description, heterogeneous overlays, security of data, overlay architecture, XML, overlay networking, Computer architecture, architectural description based overlay network, security role, Robustness, security key management, Overlay Network]
Computational model of grammar for English to Sinhala Machine Translation
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Development of the computational model of grammar for highly inflected language is a complex task and it is also essential to develop rule-based machine translation systems. This paper presents a computational model of grammar for Sinhala language by considering the Morphology and the Syntax of the Sinhala language. Finite State Transducers (FST) and Context-free grammar (CFG) have been used to describe the computational grammar for Sinhala. The grammar has been tested through the English to Sinhala Machine Translation System. The translation system successfully translates English sentences with simple or complex subjects and objects with most commonly used patterns of the tenses including active and passive voice forms.
[English language, Sinhala language, rule-based machine translation system, Instruments, natural language processing, finite state transducer, CFG, FST, Machine Translation, Sinhala Languages, Generators, Grammar, finite state machines, context-free grammar, Context-free grammar, context-free grammars, Conjugation, IP networks, computational grammar, language translation]
Age progression for elderly people using image morphing
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Aging is an inevitable process and its effects cause major variations in the appearance of human faces. Human face identification has a significant amount of information depend on his age, gender, ethnicity and etc. In addition, facial expression and facial gestures often reveal the emotional state of an individual. Consequently human facial analysis has received considerable attention and has led to the development of novel approaches to perform face recognition, facial expression characterization, face modeling, etc. Facial aging is attributed by changes in facial features, shape and texture and other biological factors like weight loss/gain, facial hair, etc. Age seems to be the main cause of the facial change and it has become forefront. Human life cycle can be classified in to four main stages with the age. Those are babies, children, young adults and elderly. Significant amount of facial changes can be identified in each of these stages. This paper introduces a methodology for elderly facial shape changes using morphing. Paper discusses some key landmarks of elderly aging progression techniques from the existing research pool as well.
[image morphing, Image Warping, emotion recognition, Automatic Age Estimation, Runtime, Forehead, Image color analysis, facial aging, Texture Enhancement, face recognition, Graph based Image Representation, Face, facial expression recognition, Hair, Compositional and Dynamic Model, age progression techniques, facial gestures, Image Morphing, Wrinkle Transformation, image texture, Age Progression Techniques, texture enhancement, Senior citizens, human facial analysis, Software, human face identification, human life cycle]
An automated vision based recognition system for Sri Lankan Tamil sign language finger spelling
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
As computers become more and more pervasive in human lives, the need for natural and effective Human Computer Interaction (HCI) becomes more important than ever. Speech recognising and voice commanding remain to play an important role in the HCI field. However, these systems are restricted for deaf community. In Sri Lanka, the native language of the deaf community is Sri Lankan sign language, which defines set of vocabulary of gestures corresponding to frequently used words. If a word is not defined, they are spelt out the word using gestures that correspond to the letters in the Sinhala or Tamil alphabet. In this paper, authors investigate as regards Sri Lankan Tamil sign language finger spelling alphabet, problem of recognising Sri Lankan Tamil finger spelling from vision based recognition and technical challenges behind it.
[Image recognition, Sign Language Recognition, Handicapped aids, Sri Lanka, Humans, Tamil Finger spelling Recognition, Optical imaging, Gesture Recognition, Tamil sign language, gesture recognition, speech recognition, Artificial Neural Network, Sri Lankan Sign Language, voice command, computer vision, sign language finger spelling, deaf community, human computer interaction, vision based recognition system, gesture vocabulary, Computer Vision]
Two Dimensional Audio Environment for the Visually Impaired
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Two Dimensional Audio Environment for the Visually Impaired, hereinafter TDAEVI is an audio based computer interface with positional information. It provides layout and tabular structures in application interfaces. A prototype system is implemented in order to test the concept. Both qualitative and quantitative evaluations were carried out with users who have an average level of computer skills. Finally the results were analyzed using statistical methods. Position identification of the home page and feedback taken for the questionnaire provided exceptionally positive results towards the concept.
[handicapped aids, application interfaces, Visually impaired, tabular structures, feedback, quantitative evaluations, two dimensional audio environment, computer skills, layout structures, Navigation, audio based computer interface, qualitative evaluation, Audio based environment, Human computer interaction, Sound positioning, Interfaces, audio user interfaces, positional information, TDAEVI, prototype system, Layout, home page, Speech, human computer interaction, statistical analysis, visually impaired, statistical methods]
Pattern independent fiducial marker detection for an interactive public display
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
The use of keyboard and mouse introduced with the advent of the first GUI operating system is a proven way of interaction with interfaces based on window, icon, menu and pointer (WIMP) paradigm, which has prevailed for few decades. Traditional input devices have limitations as they are originally designed to support two dimensional interfaces in single user environment, thus increasing interest on interactive software and use of novel ways of interaction. As a result, interaction using tangible real objects that can eliminate cumbersome intermediate input devices to provide natural interaction is deemed as an important approach for developing alternative interaction paradigms. This research attempts to develop an alternative interaction methodology to enable interaction using tangible real world objects with fiducial marker detection and using commonly available hardware such as webcam. The research explores two novel capabilities of using fiducial markers. First it attempts to enable pattern independent marker detection that can replicate mouse interface and finally it exploits multiple marker detection along with a multi-user driver to construct an interactive public display. Tests prove that both the attempts of the authors are applicable in practice and they promise to make human computer interaction more entertaining.
[window-icon-menu-pointer paradigm, keyboard, Fiducial Markers, graphical user interfaces, keyboards, GUI operating system, Virtual and Augmented Reality, Approximation methods, pattern independent fiducial marker detection, interactive public display, computer displays, interactive systems, operating systems (computers), multiuser driver, human computer interaction, tangible real objects, mouse interface, interaction methodology, Computer Vision, WIMP paradigm, Interface: Interaction Devices and Tools]
Proposing a port decision system approach for dynamic integration of South American sea ports
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
The integration of regional infrastructure is essential for the economic wellbeing of nations, including developing countries. This project is particularly concerned with addressing regional port-to-port integration in the South American context. Towards this goal of integration, this paper proposes an initial interdisciplinary theoretical model to assist computer-based decision-making for port authorities. The approach is based on a review of the factors affecting the integration of not only ports but other nodes such as cities and regions. We also consider current computational decision-making models used to describe the dynamics of sea ports in anticipation that in the future there will be a need for integration between two or more regional sea ports which also takes into account their international role and local socio-economic responsibility.
[port-to-port integration, Computational modeling, Decision making, interdisciplinary approach, computational decision-making models, knowledge management]
From eTransformation to mTransformation: Designing mobile information systems for empowerment
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Today over 90% of the world population is covered by a mobile signal and over 76% have a mobile phone. Mobile devices enable us to access information often in multimedia format at anytime from anywhere as well as share any information that we have with others. Further most mobile phones are equipped with global positioning systems which enable the applications to find out the location of the mobile user. These features enable us to create new types of context aware applications for mobile devices that may not be optimal for computers with wired connectivity.
[mobile information systems, information retrieval, multimedia format, multimedia computing, mTransformation, Global Positioning System, empowerment, mobile computing, eTransformation, mobile user, mobile phone, information access, mobile devices, context awareness, information systems, global positioning systems, mobile handsets]
Mobile service portal for rural fisher community development
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Emerging technological advancements are with the potential of delivering numerous services for betterment of local SMEs, entrepreneurs and rural community in general. However, the necessity of high-tech, sophisticated and high cost equipments to access these services has created digital division between socioeconomic layers as well as between rural and communities in cities. In this work, we have illustrated possibilities of adoption of affordable mobile telephony for trade facilitation and information service provisioning in compliance with global standards such as UN/CEFACT's recommendations. We have demonstrated application of a mobile service portal in particular for fisher communities concentrated mainly in rural costal cities.
[mobile service portal, Mobile communication, UN-CEFACT recommendation, technological forecasting, mobile computing, Databases, digital division, high cost equipment, socioeconomic layer, socio-economic effects, Meteorology, Mobile Service Portal, small-to-medium enterprises, information service provisioning, SME, information services, aquaculture, rural fisher community development, trade facilitation, UMM, Collaboration, high tech sophisticated equipment, mobile telephony, technological advancement, Trading Collaboration, rural costal city]
The Kenyan &#x2018;Digital Villages Project&#x2019; from a behavioural perspective
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
This reflective paper sheds light on the Kenyan Government's DigitalVillages Project. The project strives to decrease the disparities between urban and rural environments across the country using information and communications technologies. The structure of the project is inspired by the Capability Maturity Model. This paper proposes the use of behavioural archaeology instead. The use of behavioural archaeology enables important aspects and results of the project to be illuminated and captured. In addition a specific focus is placed upon the political implications of the project and their effect on rural Kenya.
[Economics, Kenyan government, Capability Maturity Model, behavioural perspective, models, CMM, behavioural archaeology, urban environment, Government, information and communications technologies, rural environment, telecentre, Coordinate measuring machines, Education, digital villages project, archaeology, behavioural sciences computing]
Hidden in the clouds: The impact on data security and forensic investigation
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
The world is fast embracing cloud computing. Gartner describes cloud computing as &#x201C;a style of computing where scalable and elastic IT capabilities are provided as a service to multiple customers using Internet technologies&#x201D;. Many analysts attribute the renewed interest in virtualisation to the economic depression in the period 2008-2010 that led to shrinking IT procurement and maintenance budgets. The opportunity to save money by outsourcing computing services and the ability to exploit associated efficiencies have driven the cloud computing industry to what it is today. A number of service providers such as Amazon, Microsoft, Google, and IBM, who exploited the large scale virtualisation of services have built very successful cloud computing platforms. VMWare has become one of the most successful virtualisation software platforms and claim that 100% of Fortune 100 companies trust VMWare as their infrastructure virtualisation platform. Forrester research forecasts that the cloud computing market will be more than $300 billion by 2011. It is estimated that of the Fortune 500 companies have moved their data on to the cloud. Those who move on to the cloud clearly understand the economic benefits. However they do not know where their data on the cloud is or if the cloud provider will provide water tight guarantees that their data is safe.
[maintenance budgets, Google, virtualisation software platform, IT procurement, data security, virtualisation, large scale virtualisation, computing services, VMWare, IBM, forensic investigation, Microsoft, cloud computing platform, Internet, infrastructure virtualisation platform, cloud computing, Amazon, computer forensics, economic depression]
NoSQL query processing system for wireless ad-hoc and sensor networks
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
TinyDB and TikiriDB are query processing systems, which have been used successfully in wireless sensor networks (WSN). These query processing systems provide a SQL query interface to extract data from sensors and it has proven to be a convenient programming interface in these environments. However, a relational database model that guarantees ACID properties is not a good match for a wireless sensor network since consistent connectivity or the uninterrupted operation of the sensor nodes cannot be expected. We noted that the NoSQL approach which does not rely on the ACID properties is a better match for a query processing systems for WASNs. We developed a NoSQL based query processing system on the Contiki operating system that is popular among the WSN community.
[Mesh routing, wireless sensor networks, ACID properties, wireless ad hoc networks, user interfaces, TinyDB, TikiriDB, relational database model, telecommunication computing, query processing, sensor nodes, Databases, NoSQL, RDBMS, Contiki operating system, ACID, Artificial neural networks, Ad hoc networks, relational databases, SQL, Wireless sensor networks, Query processing, Wireless ad-hoc and sensor networks, operating systems (computers), ad hoc networks, NoSQL query processing system, programming interface, Database abstractions, SQL query interface]
Knowledge extraction for semantic web using web mining
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Semantic web, the future of all web technologies has its roots on ontologies. At present most of the ontologies are manually constructed, which is a time consuming, tedious task where significant domain knowledge is required. The manual nature of ontology development has given rise to the well known knowledge engineering bottleneck which hinders the rapid growth of semantic web. This paper investigates the problem of extracting knowledge from large number of web documents in order to develop ontologies. This research introduces web usage patterns as a novel source of semantics in ontology learning. The proposed methodology combines web content mining with web usage mining in the knowledge extraction process. Therefore, both the web user's and web author's perspectives are captured with respect to the web content, which ultimately leads to extraction of more realistic set of conceptual relationships. The evaluation results prove the effectiveness of the proposed methodology. This solution is intended to be usable for transformation of large web corpuses to semantic web and also it could be used to develop cross domain ontologies.
[knowledge engineering, semantic Web, Manuals, Ontologies, HTML, web usage mining and Ontology, Semantic web, web content mining, Web usage mining, knowledge extraction, Web mining, Web content mining, ontologies (artificial intelligence), Web documents, ontology learning, Web usage patterns]
An automated tool to generate test cases for performing basis path testing
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Basis Path Testing is a more rigorous software testing criterion typically used for program unit testing. Although it can simply be used to assure the quality of the individual program units, a major issue that the tester experiences is how to determine test cases. The tester requires enough test cases to uphold the thoroughness of testing, but not many that all the limited testing resources are used up. In most cases, the tester has to determine test cases manually. However, when program has a complex branching structure, it becomes very difficult to determine test cases manually. This makes the automated test case generation a need. However, the usual practices such as use of dynamic program analyzers to guide the test case generation process are inadequate to address this problem. In previous work, we proposed a method to generate test cases for performing basis path testing. In this paper, we discuss how the proposed method can be used to develop a tool to automate the test case generation process. The paper also outlines few limitations of our tool and provides some general guidelines for its further improvement.
[white-box testing, complex branching structure, program testing, Input variables, software testing, Basis path testing, Artificial neural networks, unit testing, Flowcharts, program unit testing, software testing criterion, testing tools, test case generation, basis path testing, dynamic program analyzers, Testing]
Bag-of-keypoints approach for Tamil handwritten character recognition using SVMs
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
In this paper, the bag-of-keypoints approach for the off-line recognition of Tamil handwritten characters is investigated. Various pre-processing operations are performed on the digitised image to enhance the quality of an image. In the proposed method each pre-processed character image is represented by a set of local-invariant SIFT feature vectors. From a set of reference vectors, the key idea is to create a codebook for each character using K-means clustering algorithm. Then, the bag-of-keypoints are computed for the total number of character images. These features are used to train a linear support vector machine. A target character is predicted to exactly one of the twenty character classes. An average recognition rate of 81.62% on the character level has been achieved in experiments using six thousand training and two thousand testing images of twenty selected character classes. These results clearly demonstrate that the method produces good recognition accuracy on the handwritten Tamil character database and can be extended with more characters and more samples being recognised.
[K-means, Emotion recognition, handwritten character recognition, SIFT, support vector machines, Image edge detection, Random access memory, Tamil Handwritten characters, K-means clustering algorithm, Support Vector Machine, scale invariant feature transform, Training, Handwriting recognition, Image segmentation, local-invariant SIFT feature vectors, Mood, image enhancement, pattern clustering, feature extraction, Character Recognition, bag-of-keypoints approach, Tamil handwritten character recognition]
Case study on adaptability to ICT enabled childhood education in Sri Lanka
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Ministry of Education, Sri Lanka is piloting One Laptop per Child (OLPC) project in selected primary schools in the country. In this context a remote school participating in the project in Badulla district was selected for this study. ICT enabled teaching and learning is very new concept for teaching children and also a need to adjust to new learning styles of children. We need to study the adaptability to ICT enabled education environment. For this a mixed approach quantitative and qualitative method is used to gather data by questionnaire and interviewing of teachers, children and parents of the school. Firstly, questioning teachers led to the second step of discussing and observing children and to the third step of speaking with parents. The results obtained using the method shows that activities using OLPC increase innovation and creativity of children in drawing, audio recording and video capturing compared to traditional existing primary school pedagogy based on books. Further it helped them to share knowledge, explore required learning beyond the curriculum. From the parental views, this OLPC led satisfactory learning and created curiosity. Creativity, sharing, collaboration, independent learning, formal mathematic learning are seems to be increased. Parents expressed proudness and privilege of having free OLPC while identified negative impacts like addiction to the OLPC use and neglecting physical game during off school time.
[Electronic publishing, knowledge sharing, Childhood education, Encyclopedias, Adaptability, HTML, teaching, video capturing, laptop computers, Ministry of Education, Badulla district, laptop per child project, ICT enabled learning, Sri Lanka, primary school pedagogy, primary schools, remote school, Educational institutions, ICT enabled childhood education, informal learning worldview, OLPC, parental view, educational courses, formal learning, Internet, computer aided instruction, educational institutions, audio recording, ICT enabled teaching, independent learning, formal mathematic learning]
Towards next generation mobile applications for MOPS: Investigating emerging patterns to derive future requirements
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Summary form only given. Abstracts are presented for three keynote presentations along with the biographies of their respective authors.
[Middle of the Pyramid (MOP), micro blog aggregation, Mobile applications]
Networked shared storage (NSS)
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Summary form only given. During the last few years, there has been an explosive increase in demand for Smartphones with ever increasing capabilities, features and performance. Entertainment features, and mobile connectivity anywhere, anytime has become an accepted norm. There is a very competitive landscape driven by insatiable consumer demands, Operating System wars and chip level performance enhancements. There are numerous hardware challenges associated with this demand.
[Networked Shared Storage (NSS), Distributed Storage, Wide Area Network (WAN), Local Area Network (LAN)]
A performance comparison of hypervisors
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Summary form only given. The main reasons hindering the wide spread deployment of passive RFID tags are high cost and limited range. The present work focuses on developing a sub-cent RFID capable of operating from a reasonable distance, though with some compromise on the information content. Since there are ample applications of read-only RFID with limited information content, the present technology is expected to fill a substantial part of the niche of sub-cent tags. A metal patch on a metallic ground plane, separated by a dielectric, acts like a microstrip patch antenna and has scattering characteristic defined by poles and zeros depending on the dimensions of the patch. Such resonating structures can be used to create tags, with a purpose of storing information in the various resonant frequencies. Multiple patches, either stacked on top of each other, or located transversely, can be used to increase information content. The challenge is to retrieve these resonant frequencies - from single or multiple patches - in presence of clutter (unwanted scatter) from surrounding objects without the use of any non-linear elements. The situation becomes especially difficult in presence of large metallic objects creating significant amounts of clutter. We have used soft-computing techniques to analyze the nature of the clutter signal. Multilayer Perceptron trained with error back propagation could deliver very accurate estimation of the resonant frequencies in realtime. We discuss in detail the experimental set-up, data collection and analysis methodology and demonstrate the stability of the results for signals measured at a distance, even in presence for of impairments.
[Performance Comparison of Hypervisors, Xen vs Esxi, Quantitative analysis on hypervisors]
AskME: A database abstraction for ad-hoc networks
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Summary form only given. Despite recent advancements in the areas of machine learning and data mining, there are still areas where human effort cannot be easily replicated by software systems. The rise of crowdsourcing systems such as Amazon Turk help fills this void by enabling the mobilization of human effort for large-scale computing tasks. Like many new techniques or systems, crowdsourcing systems are a double-edged sword capable of being used for either "good" or "evil." In this talk, I will take a closer look at the impact of crowdsourcing on the security of web-services. I will focus on both positive and negative implications of crowdsourcing systems for the future. First, I will discuss how crowdsourcing can help us address difficult problems in dealing with fake online identities in online social networks. I will describe recent work studying crowdsourced Sybil detection, using a large user study and several ground-truth datasets of fake and real users. Results show that in the right conditions, human workers can be highly accurate in identifying real and fake identities. In fact, we can build scalable systems for crowdsourced Sybil detection, and data from user studies show that it can provide highly accurate results with very low cost. Second, I will discuss the negative implications of crowdsourcing, and describe a detailed measurement study on malicious "crowdturfing" systems, where users sign up to perform tasks such as spreading rumors, writing fake reviews, and creating fake online identities. Through both large scale data measurements and experiments, our study shows that these systems are highly scalable, and growing exponentially in both jobs and revenue, and pose a new type of threat to the security of today's online communities.
[Distributed Databases, Wireless Networks, Android]
Comparison of &#x201C;P&#x201D; and &#x201C;PID&#x201D; control algorithms implemented on non holonomic multi-agent mobile robots
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Summary form only given. These invited talks discuss the following: STG Decomposition and Its Correctness; Asynchronous Network-On-Chip and its Potential.
[]
A buddy-file-system to improve block level sharing of disk images in virtualization environments
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
We evaluate how existing problems in virtualization environments can be rectified by exploiting common data blocks. BuddyFS is a new file-system which identifies common blocks and recreates the disk images with fewer disk block exchanges between the hosting environment and the remote machine. We have also discussed how semantic information can be used to enable new levels of sharing. The idea is to avoid transferring data blocks from remote servers if equivalent data exist in the hosting environment. It is the system data such as the kernel pages, library pages that are most likely to reside in the hosting machines. In order to achieve this main goal, we needed a method to identify data that are equivalent in disk images and to evaluate whether the commonalities amongst disk images can effectively reduce the amount of data that has to be transferred to create the virtual machine. Then using this comparison, a controlling module needs to map the disk image blocks and produce a structured view for the virtualization environment. Even though sharing is the main focus, unique data alterations by different users must be saved. These are the main design requirements and considerations. The fundamental approach was to build a file-system to reuse client-side cached blocks and transmit less number of disk image blocks. The results suggest that introducing this concept in the hosting environment is a plausible optimization when transferring and storing data in a virtualization environment. When creating virtual machines it is possible to identify reusable common blocks in the hosting environment that can be used to recreate the disk images. BuddyFS can be used to reduce the overhead of managing virtual devices in now rapidly expanding virtualization environments such as cloud computing.
[component sharing, file-system, disk images, Virtualization]
Intrinsic Plagiarism Detection with kohonen Self Organizing Maps
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Summary form only given. In this invited talk, the millimetre-wave (mmW) antenna arrays which are fully integrated into low-temperature co-fired ceramic (LTCC) with substrate integrated concept are reviewed. We start with addressing the important challenges in designing mmW antennas such as losses, fabrication, and measurement. After that, three typical designs are introduced as examples. A 60-GHz antenna array with greatly reduced loss caused by surface waves is first introduced. With the proposed cavity technique, the gain of the array increases by up to 2 dB. Second, a broadband high-gain 60-GHz LTCC array is shown. The multiple layered LTCC substrate provides more freedom to integrate the array and feeding network in substrate with much low insertion loss and consistent radiation patterns using parallel feeding structures. Finally, the design and measurement of a 140GHz LTCC antenna array is reported. The challenges related to fabrication and measurement is highlighted.
[Authorship Verification, Intrinsic Plagiarism Detection, Plagiarism, Style Markers, Self Organizing Maps]
Database based and RESTful email system with offline web based email client
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Summary form only given. Power management techniques that leverage voltage as a handle are being extensively used in power sensitive designs. These techniques include power gating, power gating with retention, multiple supply voltages, dynamic voltage scaling, adaptive voltage scaling, multi-threshold CMOS, and active body bias. The use of the power management techniques also imply new challenges in validation and testing of designs as new power states are created. We look into verification issues along with the solutions to these issues using a verification strategy that involves power-aware simulation, rule-based structural checking, formal tools, and methodology recommendations. We detail our varied experiences with various design teams in addressing these low power verification issues for applications such as the wireless handset, low power microprocessors, and GPS.
[IMAP, RESTfull, HTML5]
Workshops &amp; tutorials
2011 International Conference on Advances in ICT for Emerging Regions
None
2011
Provides an abstract for each of the workshop presentations and a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.
[]
Message from the conference chair
International Conference on Advances in ICT for Emerging Regions
None
2012
The International Conference on Advances in ICT for Emerging Regions (ICTer) is the successor to the International IT Conference IITC, the major IT Conference in Sri Lanka since 1998. It is a forum for the sharing of knowledge through the presentation of research carried out on various aspects of ICT in the region. This year particular effort was made to establish the conference web site and to include all its past conference papers as well as to index them in Google Scholar. Publicity for the conference was made through many conference promotion sites which led to more site access from over 100 countries. Conference also attracted around 15 international submissions in addition around 60 local papers.
[Indexes]
Forward by the co-chairs
International Conference on Advances in ICT for Emerging Regions
None
2012
We are pleased to welcome you to the 3rd International Conference on Advances in ICT for Emerging Regions (ICTer 2012). ICTer is the successor to the International Information Technology Conference (IITC) held in Sri Lanka since 1998.
[]
Organizing committee
International Conference on Advances in ICT for Emerging Regions
None
2012
Provides a listing of current committee members.
[]
Program committee
International Conference on Advances in ICT for Emerging Regions
None
2012
Provides a listing of current committee members.
[]
Logistics committee
International Conference on Advances in ICT for Emerging Regions
None
2012
Provides a listing of current committee members.
[]
Guest speakers
International Conference on Advances in ICT for Emerging Regions
None
2012
Provides an abstract for each of the presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.
[]
Keynote speakers [3 abstracts]
International Conference on Advances in ICT for Emerging Regions
None
2012
These keynote discusses the following: multicore and extreme scale computing: programming and software challenges; strategies for neutralizing sexually explicit language in cyberspace; and decision analysis in societal planning.
[multiprocessing systems, decision theory, multicore computing, cyberspace, decision analysis, programming languages, societal planning, sexually explicit language neutralization]
Speaker independent Sinhala speech recognition for voice dialling
International Conference on Advances in ICT for Emerging Regions
None
2012
Speech is the most natural and the most powerful way of communication between humans. Speech recognition for voice dialling applications has already been developed for languages such as English, French and Japanese, etc. However, there is no evidence of existence of such applications for voice dialling in Sinhala language with speaker independent environment. The work described in this paper is based on an attempt to implement a speaker independent Sinhala speech recognizer and a voice dialling application which has been used to communicate with a VoIP application. The underlying concept of building the speech recognizer is Hidden Markov Model (HMM) and the system is developed using the Hidden Markov Model Toolkit (HTK). The first stages of building the speech recognizer involve the preparation of speech samples for training and the creation of the pronunciation dictionary which lists all the speech samples along with their phonetic representations. A noise reduction method has been applied at the front end of the voice dialling application to clean up the speech signal from the beginning. The middle stages comprise of employing a good feature extraction technique to enhance the speech recognition, and building and training the acoustic model to match a spoken digit to the observed input while the latter stages involve the creation of the language model to determine which digit has spoken. The results show that 87.37% of the digits are correctly recognized by the speech recognizer under quiet environment while 82.19% of the digits are correctly recognized in noisy environment.
[hidden Markov model toolkit, noise reduction method, voice dialling application, Laboratories, Noise reduction, pronunciation dictionary, Acoustics, signal denoising, speech signal, hidden Markov models, feature extraction technique, Databases, speech recognition, French, Language model, speaker independent Sinhala speech recognition, Acoustic model, VoIP application, Speech understanding, speech recognizer, phonetic representations, natural language processing, HMM, speech sample preparation, Vectors, Grammar, Japanese, English, Pronunciation dictionary, Speech recognition, acoustic model, Hidden Markov model, Feature extraction, Internet telephony, HTK, dictionaries]
Data-driven spell checking: The synergy of two algorithms for spelling error detection and correction
International Conference on Advances in ICT for Emerging Regions
None
2012
Sinhala, the majority language of Sri Lanka, is still in its infancy with respect to natural language processing research and applications. Spell checking is an important application which has received inadequate attention. One of the major issues with implementing a Sinhala spell checker is the deficiency of resources such as morphological analyzers, tagged corpora and comprehensive lexica. Due to the richness of Sinhala morphology, using an entirely rule based approach is deficient. An interesting alternative is to use data-driven approaches. This research attempts to improve the quality of Subasa, an existing n-gram based data driven spell checker using minimum edit distance techniques and to make the system freely available online. Our empirical results show that the proposed design improvements succeeded in improving the spell checking coverage. In addition, we also compare the performance of this system with others in the literature.
[Sinhala spell checker, Dictionaries, natural language processing, Sri Lanka, corpora lexica, morphological analyzers, natural language processing research, Subasa, spelling error correction, edit distance techniques, comprehensive lexica, natural language processing applications, Sinhala spell-checking, spelling error detection, data handling, two algorithm synergy, Data-driven, edit-distance, data driven spell checking]
A Translator from Sinhala to English and English to Sinhala (SEES)
International Conference on Advances in ICT for Emerging Regions
None
2012
This paper presents a rule based machine translation system which is capable of translating sentences from Sinhala to English and vice versa. This is the first Sinhala to English and English to Sinhala machine translation system which comes with features such as a Sinhalese font translator, which is capable of interpreting Sinhalese words written in English characters (Singlish) to Sinhala characters, and an English grammar and spell checker. An entered sentence to the system will be tokenized and translated according to a rule. When translating Sinhala sentences to English the user input should be in Singlish and when translating English sentences to Sinhala input should be in English. The main objective of this translator is to enable a smooth flow translation of words, sentences and paragraphs to locals as well as foreigners and thereby eliminate the language barrier. A considerable amount of rules, patterns and words of both languages were used to develop this system. With 87% accuracy this pilot machine translation system translated 500 grammatically well-structured Sinhala sentences to English and 150 grammatically well-structured English sentences to Sinhala. The system is capable of translating approximately 70 sentences in one minute.
[Google, Singlish, Sinhala to English Translator, natural language processing, SEES, rule based machine translation system, Rule base machine translation, Sinhala-to-English machine translation system, language barrier elimination, spell checker, English, Accuracy, grammars, English to Sinhala Translator, knowledge based systems, Sinhala, English-to-Sinhala machine translation system, English characters, English grammar, English sentence translation, Sinhalese words interpretation, Sinhala characters, language translation, Sinhala sentence translation]
Feeling the motion of object in a dynamic image sequence through haptic interface
International Conference on Advances in ICT for Emerging Regions
None
2012
In this paper we discussed how to incorporate haptic signals with a dynamic image sequence or other words a video to feel the motion of objects in it. Haptic technologies are being used in a wide range of application areas. However, the incorporation of haptic interface technology into a video media is still in its infancy. With the invention of digital multimedia and immersive displays, significance of exploring new ways of interacting with video media has grown up. Rather than just seeing and hearing a video, viewers' experience can be further enhanced by letting them feel the movement of the objects in the video through haptic interface, as it is an additional sensation to seeing and hearing. The objective of this research is to use haptic interface technology to interact with a video and enable the viewers to feel the motion of objects in the video beyond passive watching and listening. In this paper, we discuss how to feel the motion, which is computed from frame to frame calculation of velocity using optical flow. For haptic motion rendering, we have proposed a method by experimentally evaluating two methods using a gain controller and using a non-linear function. To interact with the video we used the string based haptic device, SPIDAR, which provides a high definition force feedback sensation to users.
[force feedback, SPIDAR, frame to frame calculation, Haptic Interface, video media, haptic interfaces, string based haptic device, Image sequences, haptic signals, viewers experience, haptic interface technology, rendering (computer graphics), video signal processing, image sequences, SPIDAR (Space Interface Device for Artificial Reality), gain controller, dynamic image sequence, optical flow, digital multimedia, passive listening, nonlinear function, Optical Flow, passive watching, immersive displays, high definition force feedback sensation, Haptic Motion, haptic motion rendering]
Multi agent based approach to assist the design process of 3D game environments
International Conference on Advances in ICT for Emerging Regions
None
2012
Designing complex and reasonable 3D environments for modern 3D games is one of the time consuming challenges faced by present video game industry. We have critically reviewed the existing approaches to automate the design of 3D environments. It was identified that current 3D environment generation techniques being specific to one or few types of environments and the lack of customizable frameworks which are common to many types of environments as the main issues to be addressed. According to literature, surprisingly complex and interesting global behaviours can arise in multi agent systems as a result of simple rules that are followed by number of simple agents operate in an environment. We hypothesize that this emergent behaviour of multi agent systems can be used to design 3D game environments with emergence properties that were not visible in initial constituents. The proposed solution provides a multi agent based approach to develop a framework which is common to design many types of 3D game environments. Each 3D model in a 3D game environment is associated with an agent with simple rules and this system allows users to introduce new 3D models and associate them with agent types. The main input for the proposed system is a parameterized description of an imaginary 3D environment. Output of the system is a 3D game environment with self organized 3D models positioned and oriented in most suitable places. The proposed approach has been evaluated by implementing a prototype and comparing the proposed approach with traditional 3D game environment design approaches.
[3D Game Development, multi-agent systems, video game industry, Artificial Intelligence, imaginary 3D environment, Ontologies, parameterized description, 3D game environments, computer games, Games, Ear, multiagent based approach, design process, Emergent Intelligence, Multi Agent Systems, Game Design]
Single camera based Free Viewpoint Video recording mechanism for premeditated scenarios
International Conference on Advances in ICT for Emerging Regions
None
2012
Free Viewpoint Video (FVV) technology is one of the emerging home entertainment mediums. FVVs give viewers the freedom to choose the viewpoint, which they want to watch the video. FVV making technologies mainly follow two approaches, virtual view synthesize and 3D model based video making. Most of the researches are using multiple video streams for 3D reconstruction and texture application on constructed 3D models. This research presents a system that makes a FVV with prebuilt 3D models and one video camera. The proposed system is less process intensive and produces a structurally accurate FVV.
[3D Graphics, Solid modeling, 3D model based video making, Video Creation, Home Entertainment, Engines, premeditated scenarios, 3D reconstruction, Reality to Virtual World, 3D Game engine for video making, video streaming, texture application, video signal processing, single camera based free viewpoint video recording mechanism, video recording, home entertainment mediums, Free Viewpoint Video, video cameras, Educational institutions, virtual view synthesis, image reconstruction, image texture, 3D Models, FVV technology, multimedia, motion tracking, multiple video streams, Animating 3D Models]
Simulating narrow channel effect on surge motion of a ship in a virtual environment
International Conference on Advances in ICT for Emerging Regions
None
2012
Ship navigation behaviors are quite different in narrow and shallow water channels than in an open sea. Pivot point and the resistance to surge motion of a moving ship are changed according to the characteristics of the channel. When enhancing real-time computer based ship simulation in narrow channels which can be used for ship navigational trainings, the resistance force should be considered. This resistance force effect in narrow channels is calculated considering different channel widths and channel depths in a mathematical ship model. This prediction algorithm for narrow channel resistance on surge motion effect is compatible with algorithms and physical models used in a real-time ship simulator which simulates six degrees of freedom ship motions. This paper presents an analysis of observations and findings on the narrow channel resistance on surge motion of a ship that occurs as a result of blockage factor in such a real time ship simulator.
[Algorithm design and analysis, narrow channel, Electronic publishing, virtual reality, digital simulation, real-time computer based ship simulation, ship simulation, pivot point, Real-time systems, channel widths, ship navigation behaviors, channel depths, Marine vehicles, resistance force, Navigation, surge motion, blockage factor, mathematical analysis, open sea, narrow channels, ships, virtual environment ship, shallow water channels, Information services, mathematical ship model, Internet, simulating narrow channel effect]
Virtual Eye: A sensor based mobile viewer to aid collaborative decision making in virtual environments
International Conference on Advances in ICT for Emerging Regions
None
2012
Current virtual simulation techniques often include multi-user interactivity in virtual environments that can be controlled in real time. Such simulation techniques are mostly employed in virtual military training sessions and in real time gaming experiences, where users have to make more strategic decisions by analyzing the information they receive, in response to the actions of the other users in the same virtual environment. Generally, in the real world, collaborative decision making takes place when a team of people work together to control the behaviour of a single object which cannot be handled alone by an individual. A ship with its crew can be held as an example. When applying this scenario into virtually simulated environments, multiple users have to involve in representing a single object in the virtual world. These users need to obtain sufficient information about the activities in the environment that will contribute to the collaborative decision making process. Out of many sources, visual information is the most reliable source the users tend to depend on. The use of traditional static displays to obtain visual information limits the capability of providing a rich set of information about the 3D environment. Head Mounted Displays address these limitations while introducing several new problems. On the otherhand, our work is focused on exploring how smart devices can be employed by a collaboratively working team of users to obtain visual information to the level beyond which a static display provides, thus aiding the process of decision making. To serve the above purpose, we propose a solution, &#x201C;Virtual Eye&#x201D;, which uses a smart mobile device with the ability to view the visual output of the virtual world and the ability to control that view according to user's orientation changes and movements with the use of its inbuilt sensors.
[Visualization, virtual reality, static display, collaborative decision making, Mobile communication, digital simulation, virtual world, Servers, virtual eye, mobile computing, streaming, computer games, Virtual reality, virtual environments, Optical reflection, visual information, virtual military training sessions, collaborative decision making process, virtual simulation techniques, mobile, Educational institutions, multiuser interactivity, aid collaborative decision making, sensor based mobile viewer, sensors, Communication channels, decision making, head mounted displays, Optical sensors]
Sensor information fusion architecture for virtual maritime environment
International Conference on Advances in ICT for Emerging Regions
None
2012
This paper presents a ongoing research on generic sensor fusion architecture and its application to a maritime surveillance system. The importance of information fusion for various sensor types and specialized sensor fusion systems in various domains are discussed. In sensor fusion, centralized versus decentralized refers to where the fusion of the data occurs. In centralized fusion, the clients simply forward all of the data to a central location, and some entity at the central location is responsible for correlating and fusing the data. In this research we intend to correlate multiple maritime sensors such as RADAR, AIS, and other electronic object detection systems. Sri Lanka Navy has myriad of surveillance information sources such as AIS (Automatic Identification System), RADAR (Radio Aid Detection and Ranging), SONAR (Sound Navigation and Ranging), MSTT, HFSWR, AVL (Automatic Vessel Locating), HF Communication, Intelligence Data ect. So it is obvious that an information fusion methodology is needed to harness the effectiveness of multiple sensor information. An object identification pipeline is conceptualized such that an unknown object in the maritime domain is detected reducing the uncertainty of obtained information. The radical new virtual reality application has been developed to visualize the information fused from sensors and discussed in depth in addition to the introduction of the fusion process. The technologies used in developing the virtual world and incorporating the real time information in to the virtual world is presented in simplified modal for the purpose of clarity. Also design aspects and some experimental analysis developed in an applied project at the Sri Lanka Navy intended to demonstrate fusion technologies in this environment through an operative prototype are presented.
[Solid modeling, oceanographic techniques, central location, virtual reality application, virtual reality, Computational modeling, virtual maritime surveillance system, fused information visualization, Information fusion, Radar tracking, Mobile communication, sensor fusion, object detection, Tactical display, object identification pipeline, virtual world, sensor information fusion architecture, centralized data fusion, maritime sensor, data visualisation, Networked information processing, video surveillance, operative prototype]
A comparative performance evaluation of different application domains on server processor architectures
International Conference on Advances in ICT for Emerging Regions
None
2012
In this paper we analyze and describe the impact of processor performance parameters such as: `Resource Stalls, Branch Mis-predictions, Translation Lookaside Buffer (TLB) Misses and Cache Misses' on the performance of different application domains and we analyze how this behavior varies among server processor architectures. We analyze the variant behavior of those processor performance parameters, among different application domains. We carry out this research based on two server microprocessors namely `single processor quad core Intel Xeon E5506' and `dual processor dual core AMD Opteron 2220 SE'. Our findings show that the above parameters makes a major impact in the performance of applications and we find that this behavior varies from application domain to domain and microprocessor to microprocessor. We have evaluated the performance of the two micro-architectures by analyzing the performance statistics obtained from the respective microprocessor hardware performance monitoring counters. In this paper we summarize our results with respect to above discussion made.
[TLB Misses, Microprocessor Hardware Performance Counters, comparative performance evaluation, Resource Stalls, TLB, resource stalls, Cache Misses, computer architecture, Computer architecture, branch mis predictions, multiprocessing systems, performance statistics, performance evaluation, microprocessor chips, Decoding, microarchitectures, Branch Mis-predictions, dual processor dual core AMD Opteron 2220 SE, single processor quad core Intel Xeon E5506, Xeon\\ Opteron, Performance Evaluation, server processor architectures, processor performance parameters, translation lookaside buffer, Microprocessor, statistical analysis, different application domains, Clocks]
TikiriPower - Using TikiriDBabstraction on Smart Home systems
International Conference on Advances in ICT for Emerging Regions
None
2012
In the domain of Wireless Sensor Networks, Smart Home applications are becoming the newest trend. Such deployments face challenges of underlying complexity in programming of traditional wireless sensor networks as well as lack of collaboration within hardware components. To address these issues, a platform that considers sensors and actuators in a wireless sensor network as a database framework is presented. Monitoring electrical and environmental parameters and controlling electrical appliances in a Smart Home via SQL queries is suggested. A prototype system consists of monitoring and controlling capabilities was implemented to evaluate the framework. Usage of our platform would makeSmart Home applications more efficient, reliable and maintainable. In return, reduction of domestic energy consumption and cost in monetary terms would be beneficial.
[wireless sensor networks, Power Management, domestic appliances, Wireless communication, SQL queries, monitoring capabilities, actuators, TikiriPower, Prototypes, environmental parameters, Multiple User Accessibility, Monitoring, programming, TikiriDBabstraction, Indexes, Wireless Sensor Networks, power engineering computing, SQL, Wireless sensor networks, hardware components, Database Abstraction, prototype system, domestic energy consumption, Smart Home, Layout, controlling capabilities, electrical parameters, Reliability, database framework, monetary terms, smart home systems, electrical appliances]
Applicability of three complexity metrics
International Conference on Advances in ICT for Emerging Regions
None
2012
Over the years a number of complexity metrics have been proposed. However, there have been only a few studies conducted to compare those proposed metrics in terms of their practical applicability. The few researches that have been conducted to assess the applicability of a complexity metric have also used the five properties proposed by Briand et al. However determining whether a complexity measure satisfies some theoretical complexity properties is not a reliable method of determining the practical applicability of it. Thus, the main intent of this study was to compare three proposed code complexity metrics: McCabe's cyclomatic complexity, Halstead's software science and Shao and Wangs' cognitive functional size and identify which metric is the most suitable metric that can be used in the current state of the art with the help of thirty programmers. To conduct this empirical study ten freely available java programs were used as the base. From this study it was identified that Shao and Wangs' cognitive functional size is the best complexity metric that can be used in the real world.
[Industries, Measurement, Java, McCabe cyclomatic complexity, McCabe's Cyclomatic Complexity, Reliability theory, complexity measure, Shao and Wangs' Cognitive Functional Size, Complexity theory, theoretical complexity properties, practical applicability, Software Complexity, cognitive functional size, Halstead's Metrics, code complexity metrics, Halstead software science, Java programs, computational complexity, software metrics]
Analogue driven handling of emergent complexity
International Conference on Advances in ICT for Emerging Regions
None
2012
Complexity Science has noted as the next evolution of the science in which the main idea is a global emergent behavior, which is resulting from the interaction between its local, dynamic, complex, interconnected, distributed, and uncertain entities. In Computer Science; modelling of complex systems are not naive and many technologies have been used for this specially due to the advancements in Artificial Intelligence. This paper presents a novel approach to model complex systems through relations on analogy making. Analogy making is considered as a mapping of knowledge between two domains. Multi Agent Technology has been used to facilitate the underneath support for this, while primarily using the power of relating in different domains as the working mechanism for agents. Agents are used to isolate an appropriate domain in which the same problem that happens to be analogically feasible; and for this domain selection, communication and negotiation features of agent technology have been used. The model has been partially scrutinized in the geometric analogy domain for empirical validations and the idea is still in a conceptual level.
[multi-agent systems, analogy making, Computational modeling, Analogy making, Complex systems, Frequency control, artificial intelligence, Cognitive Modelling, analogue driven handling, agent technology, computer science, multiagent technology, complexity science, Multiagent Systems, emergent complexity, geometric analogy, Emergent Intelligence, computational complexity]
An end-to-end caching protocol for web services
International Conference on Advances in ICT for Emerging Regions
None
2012
Web services have become an extremely popular technology for application integration due to its platform independent nature. However the use of web services has been limited in some areas mainly because of poor performance. Most web service usage scenarios fall into a client server architectural pattern, where a server component serves multiple clients. Caching is considered to be a well-known performance boosting approach in these types of applications. Even though web services have many similarities with the web, it is not easy to apply the same caching strategies used in the web in the context of web services. One key reason for this is that the request XML messages do not reveal enough information about the service semantics. The intention of this research is to implement an end-to-end caching protocol for web services, similar to HTTP caching. The proposed scheme consists of two caches - at the server and at each client. A set of SOAP headers similar to cache control HTTP headers will be used for managing this caching mechanism.
[client-server systems, performance boosting approach, caching strategy, cache control HTTP headers, World Wide Web, service semantics, cache storage, server component, Servers, end-to-end caching protocol, caching, SOAP headers, HTTP caching, Web services, application integration, client server architectural pattern, performance, transport protocols, XML, Data models, XML messages, web-services]
A framework for building web sites that are friendly to visually impaired
International Conference on Advances in ICT for Emerging Regions
None
2012
Proper access to World Wide Web has emerged as an essential need for all kinds of groups in society. There is no apparent alternative to it in most disciplines where it is highly involved. Therefore it is crucial to make the World Wide Web accessible for every person regardless of his or her capabilities, social status, purchasing power, etc. One potential group that can be discriminated with regards to web accessibility is visually impaired because of the strong tendency of web sites and applications towards visual consumption. In recent years various bodies have been emphasizing the need for making web friendlier to visually impaired people, which resulted in generating a significant pressure on web content providers. On one side, laws are being imposed that strengthen visually impaired people to prompt legal action against organizations that ignore them. On the other hand social value systems have changed so that the value of a business can depend on the degree of support offered towards differently abled people. The challenge in making web content more accessible for visually impaired have been attacked in different fronts. Major software platform providers have included lot of supportive features such as voice capabilities in their products. Web development agencies also have started paying attention on accessibility during the development process. This paper includes a study on different types of visual impairments and recommended means of addressing them. It also sheds light on guidelines for developing web sites and applications that are friendly to visually impaired. Output of the research also includes a framework and a convenience tool that can be immensely useful during implementation of accessible web sites and applications.
[handicapped aids, web accessibility, Web accessibility, World Wide Web, Printers, assistive tools, visual impairments, social value systems, Web development agency, visual consumption, software platform providers, visual impairment, software engineering, Internet, Web content providers, Web sites, visually impaired, voice capability]
SciPro idea bank: Matchmaking ideas, people and organizations to facilitate innovative theses
International Conference on Advances in ICT for Emerging Regions
None
2012
This article focus on thesis writing and how to match a large number of students with available supervisors based on creative ideas. Another challenge is to connect the students' thesis topics with current research activities at the university and businesses. In order to facilitate a good start, the Idea Bank has been developed. This pool of ideas is generated by business, research funding bodies, supervisors and students. This management problem is of general interest for all universities and of importance for quality thesis output as well as for skills and learning in demand by the public and private sector. The Idea Bank is the point of departure for the thesis process, supported by the IT-system, SciPro. Aim: To describe and analyse matching based on ideas, students and supervisors in order to facilitate quality thesis production. Methods: The research approach is based on action research and design research principles. Data collection methods: interviews, observations, focus group discussions and log data during a period of 1,5 year. Results and Discussion: Students appreciate as much information and inspiration as possible when creating their thesis topics. Our model consists of one semester of &#x201C;thinking&#x201D; and developing and during that period ideas are available from supervisors, business enterprises and public sector organisations. This paper presents three IT-models that have been developed to manage these thesis ideas and the matching with supervisors. Conclusions: The Idea Bank and matching system definitely add value, saves time and increase the quality of theses. Due to conflicting interests about the process between the stakeholders, the system has been rebuilt each year in order to create the best compromise. The process implemented rewards active supervisors and active students by providing freedom, control and selection of relevant topics to a high degree.
[facilitate innovative theses, educational computing, information technology, university, public sector, Registers, SciPro idea bank, creative ideas, matching, data collection methods, thesis writing, idea bank, Abstracts, supervision, Lead, management problem, Business, matchmaking ideas, business, Educational institutions, IT-system, ideas, IT, Theses, innovative, private sector, management, Data models, data handling, SciPro. Aim, organisational aspects]
Concealed data in two way text messaging: A framework for interactive mobile learning environment
International Conference on Advances in ICT for Emerging Regions
None
2012
A major limitation in two-way texting is sending back a part of received data with the reply message. This limitation results in users of a mobile learning environment being unable to reply back to the correct destination as the mobile communication gateway handles sending out information of several users through a single phone number. In this paper, we propose an open-source and secure messaging system that can be easily integrated to a learning management system (LMS) to provide an interactive learning experience to the user community. Initially, a database is integrated into the LMS that holds message information such as recipient's phone number, message body, user data header (UDH), etc. A specific port associated with short messaging service (SMS) is used to send data relevant to a particular course unit concealed in the SMS body itself. Subsequently, software installed in the user's mobile device captures this SMS and sends back the reply message to the appropriate course unit allowing both teachers and students to view messages sent and replied pertaining to a particular course unit. Results indicate the relevance and interoperability of the proposed technique.
[Multiplexing, interactive mobile learning environment, network servers, open systems, message body, single phone number, mobile communication gateway, internetworking, secure messaging system, user community, Telephony, UDH, Modems, Universal Serial Bus, short messaging service, two way text messaging, PDU, open-source system, user mobile device, interoperability, Object recognition, user data header, concealed data, mobile communication, LMS, Authentication, Logic gates, SMS, computer aided instruction, learning management system, course unit, SMS body]
A novel web-based tool to enhance learning of mathematical concepts
International Conference on Advances in ICT for Emerging Regions
None
2012
This paper presents two tools that employ novel human computer interaction methods, allowing users to create and edit mathematical content in electronic documents. We apply one of these in a study in a classroom environment which aims to investigate whether this system can assist students to learn mathematical concepts via creating mathematical e-content. We show that there is some evidence that, by using this tool, some students can improve their general understanding of mathematical concepts, comparing &#x201C;deep&#x201D; natural language descriptions with representations based on &#x201C;shallow&#x201D; application-specific interactions.
[document handling, Learning Mathematics, shallow application-specific interactions, Educational institutions, deep natural language descriptions, Spoken Mathematics, electronic documents, mathematical concepts, HCI, Web-based Mathematical Interfaces, classroom environment, mathematical e-content, Web-based tool, Assistive Technology, Educational Technology, human computer interaction methods, Mathematical Text Editing, natural languages, human computer interaction, computer aided instruction, Internet, learning enhancement]
OntoCD - Ontological solution for curriculum development
International Conference on Advances in ICT for Emerging Regions
None
2012
Design of a new curriculum and revision of an existing curriculum are considered as tedious tasks for academics. This process requires considerable amount of man hours from subject matter experts in several areas. In this paper, we present a human-assisted semi-automated solution for the design and revision of curricula for degree programmes. We postulate the curriculum design and revision as an ontology modelling process. The solution has been developed as a plug-in, named as OntoCD, for the popular ontological modelling environment, Prote&#x0301;ge&#x0301;. A curriculum developer can customize OntoCD by introducing benchmark domain ontology of a certain degree, and loading a skeleton curriculum for the intended degree programme. Alternatively, the domain ontology can be used to design a curriculum on the visual interface provided, and proceed to improve it. The developer can also use OntoCD to load a known curriculum and to do the modification to align with the benchmark domain ontology. The power of OntoCD exemplifies during the process of editing and improving a curriculum. In this process, OntoCD handles many tasks including the credit balancing with core and elective modules, guidance to choose elective modules to meet local needs and resolving name confusions of modules by ensuring an identity of a degree within the respective area. At this stage, OntoCD has been informally tested by designing a Computer Science degree curriculum according to benchmark domain ontology of ACM/IEEE guidelines for computing degrees. The results show that OntoCD guides the developer by reducing the burden due to clerical mistakes, oversights and negligence of some aspects in the development process.
[Decision support systems, Algorithm design and analysis, Irrigation, computing degrees, skeleton curriculum, Curriculum Design, Ontology, OntoCD, user interfaces, Computing, Engines, curriculum development, Protege, credit balancing, computer science degree curriculum, Benchmark testing, Lead, curriculum design, computer science education, Computational modeling, academics, degree programmes, benchmark domain ontology, human-assisted semi-automated solution, ACM-IEEE guidelines, curriculum revision, elective modules, visual interface, ontologies (artificial intelligence)]
Developing online tutors and mentors in Sri Lanka through a community building model: Predictors of satisfaction
International Conference on Advances in ICT for Emerging Regions
None
2012
This paper discusses the results of a tutor mentor development program that utilized a community building model to train online tutors and mentors in higher education institutions and professional organizations in Sri Lanka. Based on WisCom; an instructional design model for developing online wisdom communities, this tutor mentor development program which utilized a blended format of face-to-face and online activities in MOODLE, attempted to build a learning community between trainees, both academics and professionals who represented diverse disciplines and organizations. A regression model examined predictors of learner satisfaction, using four independent variables: Community Building, Interaction, Course Design, and Learner Support. Interaction emerged as a strong predictor of Learner Satisfaction explaining 50.2% of the variance in Learner Satisfaction. This finding shows the importance of designing interactive learning activities to support learning online, and contradicts the general belief that Sri Lankan participants would be less likely to interact online because they come from a traditional education system that encourages passivity and reception of ideas from a more learned teacher. Qualitative analysis showed evidence of several types of learning online as a result of collaborative group interaction, as well as issues that contributed to non-participation. Factors that motivated participants to stay engaged in learning could be classified into three categories: (1) general enjoyment, interest and motivation; (2) collaborative learning and community building; and (3) knowledge building. These results suggest that the online learning design based on WisCom led to learner satisfaction and supported interaction and collaborative learning in the Sri Lankan socio-cultural context.
[diverse disciplines, learner support, interactive learning activities, Communities, online learning design, regression analysis, professionals, community building model, online wisdom communities, online mentors, education system, regression model, course design, MOODLE, Education, diverse organizations, e-mentoring, professional organizations, instructional design model, face-to-face activities, Context, National Distance Education Systems, further education, Buildings, Sri Lanka, collaborative group interaction, academics, online activities, general enjoyment, Indexes, general interest, faculty development, Online learning communities, WisCom, higher education institutions, online tutors, learner satisfaction, knowledge building, collaborative learning, inquiry-based learning, general motivation, tutor mentor development program, computer aided instruction, educational institutions, Sri Lankan sociocultural context]
ICT based education for students with special educational needs in Sri Lanka
International Conference on Advances in ICT for Emerging Regions
None
2012
In this fast moving world, it is a failure to provide equal access to information and knowledge for everybody. One of the reasons behind this is that there is a specific group of people who have inability to engage in learning in a regular manner because of some physical, mental or psychological disabilities. That group of students with special educational needs requires individual attention and special assistance from parents and teachers in their learning process. They might be beneficial from some special learning techniques provided as learning aids rather than from conventional learning methods. Since Information and Communication Technology (ICT) based learning is a novel approach which integrates learning with computing aspects, this research is intended to explore the relevancy of ICT based education for enhancing the learning effectiveness of students with special needs. In order to achieve that objective some computer games and activities were developed considering both functional and non-functional requirements which are gathered through discussions had with doctors and teachers in the field of special education. These games are basically focusing on basic concepts of three subject areas as colour, number and language in mother tongue. For the performance evaluation, two tests were carried out as `pre test' and `post test' by giving developed games for a sample of students. Number of levels completed by a particular student, time taken and number of mistakes s/he has made during the game were measured throughout the user evaluation phase. According to the obtained results, the performance improvement rates of sample students for colour skills, number skills and language skills are approximately 48%, 63% and 60% respectively. Therefore, it has been proven that ICT can be used as a driving tool for special education to improve its effectiveness.
[handicapped aids, learning process, Game based learning, user interfaces, physical disabilities, Education, computer games, functional requirements, Learning disabilities, computer activities, Monitoring, special learning techniques, number skills, Blogs, Sri Lanka, psychological disabilities, information-and-communication technology based learning, medical disorders, ICT based education, nonfunctional requirements, performance improvement rates, learning effectiveness enhancement, language skills, human computer interaction, colour skills, computer aided instruction, mental disabilities, Special education, students-with-special educational needs]
Technology assisted tool for learning skills development in early childhood
International Conference on Advances in ICT for Emerging Regions
None
2012
Importance of proper early childhood education is a fact which is often overlooked and neglected. But it is a very important phase in a child's life and it cannot be under-estimated. Experiences during this phase extensively influence physical and neurological developments, which drive biological, psychological and social responses throughout the entire human lifespan. This research introduces a technology assisted tool for the learning skills development in early childhood. The final outcome is a Tablet PC based application to help the toddlers in their learning experience at early ages. This tool is able to improve the writing and speaking skills of the toddler in an entertainment based way. This features an easy way to teach the toddlers in a productive and efficient manner. The objective is to ensure the children are trained and practiced in early days of their lives using standards and cutting edge methodologies, so that they will be ready to face the challenges in their future.
[Guided handwriting training, Fourier transformation, entertainment, Psychology, social responses, Training, Word speech training, writing skills improvement, notebook computers, Mirrors, early childhood education, entertainment based way, speaking skills improvement, Control point evaluation, neurological developments, Fuzzy logic, Unguided handwriting training, Letter speech training, Writing, technology assisted tool, Feature extraction, Speech, human computer interaction, computer aided instruction, learning skills development, biological responses, tablet PC based application, Chain code analysis, physical developments, psychological responses]
Control pattern based analysis of HCM-L, a language for cognitive modeling
International Conference on Advances in ICT for Emerging Regions
None
2012
HCM-L, a conceptual language for modeling human behavior within the context of ambient assistance is introduced. By exhibiting the results of a pattern-based analysis it is shown that HCM-L features all concepts to express control flows as discussed in [1] and as is relevant for human behavioral modeling. The work is part of the Project HBMS (Human Behavior monitoring and support) which aims at supporting cognitive performance of individuals.
[HBMS, Behavior Modeling, Pattern, Research Challenges, Unified Modeling Language, cognition, Unified modeling language, Humans, Innovative Applications, control pattern based analysis, HCM-L, pattern based analysis, human behavior monitoring and support, Analytical models, UML, Lightning, Humidity, human behavior, Language Analysis, cognitive performance, Ambient Assistance, human behavioral modeling, cognitive modeling language, pattern recognition]
An ensemble of Artificial Neural Networks in Rainfall Forecasting
International Conference on Advances in ICT for Emerging Regions
None
2012
Accurate weather forecasts are essential for various human activities. Weather forecasting is a complex process that can exhaust the resources of many computational devices. Out of numerous weather forecasting techniques Artificial Neural Networks (ANN) methodology is one of the most widely used techniques. In this study the application of Neural Network Ensembles in Rainfall Forecasting is investigated by using an Ensemble Neural Network (ENN) to forecast the rainfall in Colombo, Sri Lanka. The ensemble consist of a combination of Multi Layer Feed Forward Network with Back Propagation Algorithm (BPN), Radial Basis Function Network (RBFN) and General Regression Neural Network (GRNN). The performance of ensemble is compared with the performance of BPN, RBFN and GRNN. The ANNs are trained, validated and tested using daily observed weather data for 41 years. The results of our experiment show that the performance of the ensemble model is better than the performance of the other models for this application.
[BPN, ENN, radial basis function network, regression analysis, GRNN, weather forecasting, Artificial Neural Networks (ANN), rainfall forecasting, Humidity, radial basis function networks, ANN testing, Colombo, multilayer feed forward network, RBFN, ANN training, multilayer perceptrons, General Regression Neural Network (GRNN), rain, ANN validation, human activities, backpropagation algorithm, Sri Lanka, Artificial neural networks, Back Propagation Algorithm (BPN), Radial Basis Function Network (RBFN), Ensemble Neural Network (ENN), Multi Layer Feed Forward Network (MLFFN), weather forecasting techniques, backpropagation, general regression neural network, artificial ensemble neural network, Rainfall forecasting]
Opinion mining and sentiment analysis on a Twitter data stream
International Conference on Advances in ICT for Emerging Regions
None
2012
Opinion mining and sentiment analysis is a fast growing topic with various world applications, from polls to advertisement placement. Traditionally individuals gather feedback from their friends or relatives before purchasing an item, but today the trend is to identify the opinions of a variety of individuals around the globe using microblogging data. This paper discusses an approach where a publicised stream of tweets from the Twitter microblogging site are preprocessed and classified based on their emotional content as positive, negative and irrelevant; and analyses the performance of various classifying algorithms based on their precision and recall in such cases. Further, the paper exemplifies the applications of this research and its limitations.
[opinion mining, text analysis, microblogging data, emotional content, Data preprocessing, data mining, advertisement placement, Twitter, Classification algorithms, Data mining, emotion recognition, Niobium, item purchasing, Accuracy, publicised tweet stream, learning (artificial intelligence), pattern classification, sentiment analysis, machine learning, Twitter microblogging site, stream classification, Support vector machines, classifying algorithm, stream preprocessing, Machine learning, Twitter data stream, social networking (online), feedback gathering]
Aligning ontologies using Multi Agent technology
International Conference on Advances in ICT for Emerging Regions
None
2012
Modern information systems extensively use ontologies to model domain knowledge. With the large amount of already available ontologies, there is a high demand for sharing and reusing the knowledge in existing ontologies. Since ontologies are complex structures, sharing of knowledge coming from various ontologies has become a tedious task. This has resulted in the birth of research area called ontology alignment. There are numerous techniques for the alignment of ontologies, and the field still faces many challenges. Due to the inherent nature of multiple relationships among the ontologies, it postulates that the Multi-Agent System technology is a better technology to automate the ontology alignment with little human intervention. This paper presents multi-agent based approach for ontology alignment, developed as a plugin for the popular ontological modelling environment known as Prote&#x0301;ge&#x0301;. It simulates how different processes interactively operate inside the human mind to perform certain activities intelligently. Indeed, the proposed solution uses agent communication, negotiation, and coordination as the primary method of exploring the semantic relationships between the ontologies. The system accepts ontologies maintained in any major form of ontology representation languages as its inputs, and generates ontology with new semantic relationships as its output. The generated ontology could be used as a shared understanding between information systems that are running on input ontologies. The success of the proposed approach was evaluated by using ontologies of conference organizing and agricultural domains. It was evident that the system could discover over 70% accurate relationships, and thus, the authors claim that the proposed approach could resolve the complexity in ontology alignment.
[Decision support systems, Algorithm design and analysis, Adaptation models, multi-agent systems, domain knowledge model, complex structures, Design methodology, knowledge sharing, Ontologies, Resource description framework, Protege, Autonomous Software Agents, Multi-Agent Systems, multiagent based approach, agent communication, information systems, knowledge reusing, ontology representation languages, Ontology Alignment, OWL, agricultural domains, ontology alignment, knowledge representation languages, ontological modelling environment, ontologies (artificial intelligence), multiagent system technology]
Faster human activity recognition with SVM
International Conference on Advances in ICT for Emerging Regions
None
2012
Human activity recognition finds many applications in areas such as surveillance, and sports. Such a system classifies a spatio-temporal feature descriptor of a human figure in a video, based on training examples. However many classifiers face the constraints of the long training time, and the large size of the feature vector. Our method, due to the use of an Support Vector Machine (SVM) classifier, on an existing spatio-temporal feature descriptor resolves these problems in human activity recognition. Comparison of our system with existing classifiers using two standard datasets shows that our system is much superior in terms of the computational time, and either it surpasses or is on par with the existing recognition rates. It performs on par or marginally inferior to existing systems, when the number of training examples are a few due to the imbalance, although consistently better in terms of computation time.
[Measurement, object recognition, optic flow, support vector machines, image classification, Humans, human activity recognition, support vector machine classifier, Optical imaging, Vectors, object detection, Silhouette, spatio-temporal feature descriptor, SVM, Support vector machines, Training, label activities, feature extraction, Feature extraction, human activity detection, SVM classifier, normalized bounding box, activity recognition]
Question answering through unsupervised knowledge acquisition
International Conference on Advances in ICT for Emerging Regions
None
2012
Current question answering systems are usually based on a knowledge base which is populated with domain specific knowledge and managed through Unstructured Information Management Architecture (UIMA). But drawback in this approach is that knowledgebase may be grown with knowledge which is not relevant to the users connected with the system. In order to address this drawback we propose unsupervised knowledge accumulation algorithm which can monitor user preferences and acquire knowledge without any supervision of the system management unit. Basically, this algorithm learns domain of interest of each and every user connected with the system and extract knowledge from the web or from a given corpus. We have also adopted several Natural Language Processing algorithms to design this high-level algorithm. Knowledge modelling is done through a conceptual graph based knowledge base. This novel paradigm is evaluated with the help of several connected users and with more than 280 questions. We have achieved excellent accuracy during the evaluation phase. It shows our novel approach is effective and can be used to address the drawback decently.
[Knowledge acquiring, question answering, Natural Language Processing, conceptual graphs, knowledge management, Monitoring]
A review of domain adaptation for opinion detection and sentiment classification
International Conference on Advances in ICT for Emerging Regions
None
2012
Social networks and micro-blogging sites have become a treasured source to reveal &#x201C;What other people think&#x201D;. However, the usage is quite limited without sophisticated framework for mining and analysing those opinions. Even though the supervised classification methods outperform human produced baselines, using it for such a framework is impractical, mainly due to the fact that those data spans so many different domains. Thus, domain adaptation is a key feature that requires for a useful framework. Hence, this paper discusses existing works on domain adaptation in the context of opinion detection and sentiment classification. It focuses the areas covered by reviewed frameworks and evaluates papers, based on important parameters. Set of experiments are also performed to compare the effect on classification accuracy due to domain adaptation.
[Context, opinion mining, supervised classification method, pattern classification, data analysis, Social network services, cognition, opinion detection, sentiment classification, data mining, microblogging sites, Data mining, Training, social network, Accuracy, Feature extraction, Motion pictures, social networking (online), domain adaptation, data span]
&#x201C;e-PaddySurv&#x201D; - a sustainable crop surveillance system for Sri Lankan paddy cultivation
International Conference on Advances in ICT for Emerging Regions
None
2012
This study seeks to evaluate the existing methods available for minimizing the spread of pests and diseases in order to improve the crop surveillance strategies of the Sri Lankan paddy cultivation. And hereby proposes a system which utilizes the power of ICT to carry out the crop surveillance much more efficiently and effectively lead by the intention of upgrading the economical status of the farmers through being preventive than curative in pest and disease catastrophes arriving in future.
[sustainable crop surveillance system, Manuals, integrated pest management, geographic information systems, crops, Sri Lankan paddy cultivation, Remote sensing, Global Positioning System, sustainable development, pest catastrophe, Surveillance, farmer, plant diseases, surveillance, pest control, lCT, disease catastrophe, crop surveillance, Geographic information systems]
Enabling rural BPOs move up the value chain: Secure distribution of office documents
International Conference on Advances in ICT for Emerging Regions
None
2012
In recent years there has been an increased focus and awareness in India on use of ICT based approaches to promote socioeconomic development of rural areas [1]. Among commercial ventures with this focus, rural Business Process Outsourcing (BPO) is an emerging and rapidly growing business sector. Rural BPO companies have Internet enabled delivery centres in villages or semi-urban areas, where trained employees handle document and information driven tasks such as data entry, localization, etc.
[BPO, information technology, commercial ventures, Manuals, value chain, Control systems, Silicon compounds, Document Distribution, rural business process outsourcing, Lead, Rural BPO, Document Security, socio-economic effects, rural areas, document handling, enabling rural BPO, India, socioeconomic development, distribution security, security of data, office documents, XML, Internet, ICT, Low bandwidth, business sector, business data processing]
A study of factors affecting the usage of the Government Information Centre in Sri Lanka
International Conference on Advances in ICT for Emerging Regions
None
2012
The Government Information Centre (GIC) was launched in Sri Lanka on August 2006, with a view to dissemination of government information to every citizen's fingertips through a common interface, in a convenient, comprehensive and friendly manner. The GIC call history analysis of 2009 indicated a fluctuation in the usage pattern, which motivated the researcher to conduct this study. Hence, the key objective of this research is to identify the factors which affect the usage of GIC, also to analyze their impacts and thereby suggest recommendations for improvement.
[usage pattern, information dissemination, GIC call history analysis, government information centre, government information dissemination, computer centres, government data processing]
GPU-based detection of stopping vehicles
International Conference on Advances in ICT for Emerging Regions
None
2012
In this work we focus on the problem of detecting vehicles that come to a stop, in a video of approximately 15 frames per second. The videos are retrieved by surveillance cameras fixed as shown in Fig. 1 which are located few meters from the ground.
[Integrated optics, surveillance cameras, vehicle detection, road vehicles, Graphics processing units, object detection, traffic engineering computing, stopping vehicles, graphics processing units, GPU-based detection]
SYMPHONY: Bloom's Taxonomy based attitude development tool
International Conference on Advances in ICT for Emerging Regions
None
2012
Humanity has grown in leaps and bounds from humble beginnings, to be the dominant race on planet earth. The exponential growth of humanity is due to rational thinking power and the ability to differentiate the good from the bad. The Symphony is tailored to fit the classroom environment in accordance with Bloom's Taxonomy and the Affective Domain, to help teachers measure the current attitude levels of children, develop behavioral attitudes in children, analyze different levels of behavioral attitudes and to monitor the behavioral attitude changes in children. The Symphony consists of three major components. They are: role playing game, attitude knowledge based application and grading components. They follow a systematic approach forwarded by Bloom with his Affective Domain. The Affective Domain contains five sub levels: Receive, Respond, Value, Organize and Internalize. All these five levels are perfectly mapped into the application and components of the role playing game.
[organize level, education, rational thinking, behavioural sciences, educational system, exponential growth, human traits, value level, symphony, receive level, affective domain, attitude knowledge based application, internalize level, behavioral attitudes, classroom environment, bloom taxonomy based attitude development tool, grading components, role playing game, humanity, adult behavior, respond level]
A sustainable mechanism for gathering road traffic data using smart-phones
International Conference on Advances in ICT for Emerging Regions
None
2012
In this paper, our goal is to propose a socially and economically viable mechanism based on the FCD principle, through which the state of traffic congestion can be detected using inbuilt capabilities of modern smart-phones.
[road traffic, road traffic data gathering, inbuilt capabilities, automobiles, smart phones, traffic congestion, floating car data, traffic engineering computing, FCD principle, smart-phones]
Data mining approach to minimize child malnutrition in developing countries
International Conference on Advances in ICT for Emerging Regions
None
2012
Child malnutrition condition can be considered as a major health issue for a country since they are the future workforce which directly affect to the economic growth of the country. This impact is significant mainly in developing countries. This research is carried out with the purpose of reducing the prevalence of child malnutrition based on the Sri Lankan context with the analysis of the children under five years of age.
[macroeconomics, public administration, health issue, developing countries, data mining, Sri Lankan context, data mining approach, country economic growth, health care, child malnutrition condition]
Workshops &amp; tutorials
International Conference on Advances in ICT for Emerging Regions
None
2012
Provides an abstract for each of the tutorial and workshop presentations and a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.
[Runtime, Processor scheduling, Conferences, Tutorials, Lead, Hardware, Computational efficiency]
Message from the conference chair
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Presents the introductory welcome message from the conference proceedings.
[]
Message from the conference chair
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Presents the introductory welcome message from the conference proceedings.
[]
Organizing committee
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Provides a listing of current committee members and society officers.
[]
Program committee
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Provides a listing of current committee members and society officers.
[]
Keynote speakers
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Provides an abstract for each of the keynote presentations and may include a brief professional biography of each
[]
Keynote speeches: Video Forgery and motion editing
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
These keynotes discusses the following: video forgery; motion editing; health communication using digital media; document image analysis; bioinformatics; systems biology; multimodality, multimedia, and sensors; design-based mobile learning; communication and sustainability; statistical relational learning; and digital knowledge ecosystems.
[Computers, systems biology, document image analysis, motion editing, Mobile communication, sensor fusion, knowledge management, mobile computing, Dynamics, Market research, communication, video signal processing, design-based mobile learning, Media, document image processing, statistical relational learning, Educational institutions, medical information systems, multimodality, sustainability, image motion analysis, sustainable development, digital media, multimedia, sensors, health communication, digital knowledge ecosystems, video forgery, bioinformatics, Speech, computer aided instruction]
Automatic panorama generation from a video with dynamic background
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Panorama photos are very useful when capturing large scenic backgrounds like famous constructions or eye catching landscapes. Users normally prefer capturing such backgrounds with them or friends as the foreground, but the moving people in such popular locations always obstruct the iconic structure in the background. In this paper a solution for automatic panorama generation is presented which is capable of removing moving objects in the background. First user captures a short video starting from the centre of the focus area and then following a clockwise circular path. The proposed application generates the panorama based on input video following the steps: segmentation of human object, removal of moving human objects, and generation of panorama. Experimental output panorama photos show that the proposed system is very usable and results are satisfactory.
[moving human object removal, image inpainting, Calibration, image reconstruction, dynamic background, Automatic Panorama Creation, Image segmentation, Image Inpainting, Image color analysis, human object segmentation, image segmentation, short video, clockwise circular path, Clustering algorithms, Bismuth, automatic panorama generation, Feature extraction, Cameras, panorama photos, video signal processing]
Active contour-based segmentation and removal of optic disk from retinal images
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
A retinal fundus photograph is widely used in the diagnosis and treatment of various eye diseases such as diabetic retinopathy and glaucoma. Computer-aided analysis of fundus images provides an immediate detection and characterization of retinal features prior to inspection by a specialist. Segmentation of structures in such a retinal image can be used to detect and calculate the geometric shape and size of the optic disc and anterior segment with abnormal growth of any region in the eye. In this paper, we propose an algorithm based on active contours, often referred to as snakes, to remove the optic disk from retinal images. The proposed method consists of two main steps. In the first step, the optic disk boundary is approximated by means of edge detection, morphological operations and circular Hough transformation. In the second step, the exact boundary of the optic disk boundary is detected using an active contour model. The proposed algorithm was tested using 130 colored fundus images. Among those images, 20 were normal and 110 contained signs of the diabetic retinopathy. Results indicate a 90% accuracy in detecting the optic disc by the proposed technique.
[Integrated optics, computer-aided analysis, eye disease treatment, optic disk boundary approximation, colored fundus images, Retina, snakes, optic disk removal, Active contours, image segmentation, retinal images, mathematical morphology, retinal fundus photograph, edge detection, image colour analysis, morphological operations, medical image processing, eye disease diagnosis, Optical filters, active contour model, Optical imaging, diseases, optic disc, active contour-based segmentation, diabetic retinopathy, circular Hough transformation, eye, Hough transforms, Adaptive optics, Optical sensors]
Computational cell classification methodology for hepatocellular carcinoma
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Liver cancer is one of the frequent causes of death in the world. Hepatocellular carcinoma (HCC) is the most common histological type of primary liver cancer. HCC can be graded according to the malignancy of the tumors. Generally, a HCC grade is determined based on the characteristics of liver cell nuclei. This paper illustrates a methodology for classifying liver cell nuclei and grading HCC histological images quantitatively. The liver cell nuclei are classified in three consecutive tasks: nuclear segmentation, fibrous region detection, and nuclear classification. Each task utilizes the pixel-based textural features that are obtained through multifractal computation on digital images. First, the system segments every possible type of nuclei and excludes the nuclei within fibrous regions. Then, it classifies the rest of the nuclei to discriminate liver cell nuclei. For tumor grading, this method utilizes the following four categories of nuclear features: inner texture, geometry, spatial distribution, and surrounding texture. The proposed method was employed to classify a set of HCC histological images into five.
[Feature selection, image classification, Segmentation, pixel-based textural features, Liver, Textural feature descriptor, Fractals, object detection, nuclear classification, spatial distribution, nuclear segmentation, Histograms, Cancer grading, feature extraction, image segmentation, surrounding texture, multifractal computation, computational cell classification methodology, tumor malignancy, Multifractal measures, medical image processing, hepatocellular carcinoma, Multifractal computation, fibrous region detection, image texture, HCC histological images, liver cell nuclei classification, Image segmentation, HCC grade, tumor grading, Feature extraction, cancer, liver cancer, geometry, fibrous regions, Tumors, Cancer, inner texture]
A novel approach to simulate wind-driven ocean waves in the deep ocean
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
In computer graphics, there are several mechanisms to display the ocean waves on screen. Albeit there are many models to simulate oceanic behavior, yet there is no rendering mechanism for wind-driven deep ocean waves, with a satisfactory outcome. Moreover, there is no way to plug those wave models onto existing maritime training simulators. Thus, the oceans computed and rendered by those models have no bearing on the computed sway, surge, heave, yaw, pitch, or roll of the vessels. This paper presents a novel approach to simulate wind-driven deep ocean waves which include marine dynamic models and their integration for the purpose of developing a simulator. It's subsequent to a survey on ocean wave models and rendering techniques which are frequently used in computer graphics to simulate deep ocean water surfaces. While exploring the prevalent methods, three main approaches have been identified to model the formation of an ocean water surface based on geometrical description models, spectral description models, and physically based models from Computational Fluid Dynamics (CFD). In the context of oceanography and computer graphics, there is a considerable body of literature on ocean water generating and rendering techniques. According to the literature, ocean water rendering techniques in computer graphics can be categorized into three major domains, viz. spatial domain, spectral domain and hybrid methods combining the two. This paper analyses the above wave models, rendering techniques and proposes a novel approach to develop a computer simulation program in which the physical models are implemented in order to achieve a realistic representation of a vessel in a virtual environment considering physical characteristics of the vessel. Further, introduces a spectral wave model and rendering by using a hybrid method with the focus of user perception. Hence, it consists of model parameters which describe the user perception.
[CFD, Sea surface, Solid modeling, flow simulation, rendering mechanism, virtual reality, oceanic behavior simulation, vessel roll, digital simulation, vessel yaw, spatial domain, computer simulation program, training simulators, waves simulation, ocean water generating techniques, ocean water rendering techniques, vessel pitch, Ocean waves, Computer graphics, ocean wave simulation, hybrid methods, Mathematical model, ocean waves, rendering (computer graphics), vessel heave, oceanography context, ocean waves display, marine dynamic models, Computational modeling, vessel sway, computational fluid dynamics, geophysics computing, wind-driven ocean waves, geometrical description models, deep ocean, user perception, computer graphics, vessel surge, Surface waves, maritime training simulators, virtual environment, spectral domain]
DILVI &#x2014; A platform to build language training simulations
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
This paper introduces DILVI: an abstract OSGI based framework which enables the developers and researchers to focus more on advanced pluggable modules such as Speech Recognition, Automatic Language Assistance and Student Evaluations rather than concentrating on the underlying framework while developing language training simulations. The evaluation of DILVI has proven to be a successful as it has shown 70% reduction of development efforts significantly.
[Training, Computational modeling, Conferences, Simulation, Abstracts, Speech recognition, Educational institutions, Language Training, Framework]
Facial expression recognition using active shape models and support vector machines
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Facial Expression Recognition is the subsequent step after Face Detection and Real time recognition of facial expressions is a challenging task. Various technologies of Facial Expression Recognition has been experimented by researchers over the past few years. In this paper, it has been observed the accuracy and effectiveness of employing Active Shape Models and Support Vector Machines to achieve higher recognition rates. Active Shape Model is used to locate the facial feature deformations of a face detected by using Haar classifiers. These facial coordinates are fed into a Support Vector Machine and the trained system classifies the expressions into seven categories, namely happy, sad, anger, disgust, fear, surprise and neutral. The system was tested on JAFFE Database and Cross Validation had been used as a mechanism for analysing the results of the experiment.
[image classification, facial feature deformation location, face detection, happy, Feature Extraction, emotion recognition, active shape models, anger, Machine Learning, Support Vector Machines, Training, Active Shape Models, JAFFE Database, feature extraction, sad, face recognition, shape recognition, facial coordinates, Face, facial expression recognition, Testing, fear, surprise, support vector machines, Face recognition, neutral, Face detection, recognition rates, Support vector machines, Haar classifiers, Haar transforms, Feature extraction, disgust]
Video steganography
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
With the development of the technology, people have tend to figure out methods which are not only capable in hiding a message, but also capable of hiding the existence of a message. Steganography was introduced as a result of such research work. The current study is conducted in order to hide a video in a visual file. We suggest changing the LSB (Least significant Bit) of each byte of the carrier file. As this method does not add any new data but only change the LSB, this method does not increase the size of the carrier file unusually. Thus, the existence of the message cannot be detected. To improve the better performance, cryptographic techniques are also used and implemented in this research. The system was evaluated by checking the ability of hiding the existence of a message and the ability of retrieving the message correctly. Results show that the system has addressed its research objectives. The limitation for this research is that the library avifi1l32.dll can only be used for uncompressed AVI files.
[Visualization, message retrieval, Production facilities, Encryption, cryptographic techniques, Equations, carrier file, Steganography, least significant bit, steganography, Logic gates, LSB, video steganography, Mathematical model, Cryptography, video signal processing]
Impact of refactoring on external code quality improvement: An empirical evaluation
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Refactoring is the process of improving the design of the existing code by changing its internal structure without affecting its external behaviour, with the main aims of improving the quality of software product. Therefore, there is belief that refactoring improves quality factors such as understandability, flexibility, and reusability. Moreover, there are also claims that refactoring yields higher development productivity. However, there is limited empirical evidence to support such assumptions. The objective of this study is to validate/invalidate the claims that refactoring improves software quality. Experimental research approach was used to achieve the objective and ten selected refactoring techniques were used for the analysis. The impact of each refactoring technique was assessed based on external measures namely; analysability, changeability, time behaviour and resource utilization. After analysing the experimental results, among the tested ten refactoring techniques, &#x201C;Replace Conditional with Polymorphism&#x201D; ranked in the highest as having high percentage of improvement in code quality. &#x201C;Introduce Null Object&#x201D; was ranked as worst which is having highest percentage of deteriorate of code quality.
[Q-factor, Software maintenance, understandability factor, software quality, Data mining, resource utilization measure, refactoring process, code quality improvement, analysability measure, experimental research approach, time behaviour measure, Software measurement, Refactoring, Time behaviour, flexibility factor, development productivity, replace conditional with polymorphism, Changeability, Time measurement, Resource Utilization, software maintenance, quality factors, ISO 9126, introduce null object, Analysability, Software quality, changeability measure, software product quality, reusability factor]
Location based advertising framework for mobile and web application developers in Sri Lanka
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
The development of multimedia and technology has introduced various methodologies for business advertising where the target audience for an advertisement can be converted into potential customers for the business. With the rapid growth of smartphone users and internet users in Sri Lanka, an opportunity is there to create a link between them and businesses making advertising more effective. This research is carried out to develop a framework where mobile and web application developers can develop their applications on top of the framework enabling location based advertisement streaming in their applications. Businesses can publish advertisements tagged to specific geo locations and the smartphone and internet users in the nearby area of the tagged locations can view the advertisements in their smartphone applications or in the websites they visit. The primary goal of this project is to encourage the mobile and web application developers in Sri Lanka by providing a framework to monetize their applications. The secondary goal of the project is helping smartphone users and internet users to find business promotions in nearby area and guide them to reach the business locations associated with the advertisements, by providing directions.
[Location Based Advertising, business promotions, tagged locations, Internet users, Advertising Framework, geo locations, Mobile Advertising, Mobile communication, multimedia development, Web Advertising, mobile computing, Software Development, LBS, Advertising, technology development, advertising data processing, business advertising, business locations, Sri Lanka, mobile application developers, smart phones, smart phone users, Web services, Location Based Services, Web application developers, User interfaces, Application Monetization, Internet, Smart phones, location based advertising framework]
Web browsers on smart mobile devices: A gap analysis on the state of the art
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
In recent years, we have seen an accelerated development of mobile devices in terms of hardware capabilities, navigation techniques and physical design. Today users are gradually shifting towards choosing a smart mobile device as their preferred device. The technologically advanced capabilities that current smart mobile devices possess have spawned a plethora of engaging applications that are attractive and effective in their usefulness and usability. In contrast, the web browser, which can be considered one's personal gateway to the World Wide Web, has not transformed to keep pace with the technology advancements of smart mobile devices in order to create a better experience to the user. All of these browsers are built on top of the same visualization techniques and layouts used by the desktop oriented web browsers. This is not the ideal form of presentation for a smart mobile device. The underlying issue is that the majority of generic websites have not been designed to cater to the relatively smaller mobile device screens. Web browsers for mobile devices have not been able to effectively address this issue. This has created a significant user experience gap between web browsing applications and the smart mobile device capabilities. In this paper, we have presented a gap analysis framework for smart mobile device web browsers in which we have analysed the aforementioned issue from different perspectives. With this framework, we intend to pin down a set of guidelines for a mobile browser that would lead to a better presentation of generic web sites.
[gap analysis, Content Adaptation, Mobile communication, Mobile handsets, Resource description framework, smart phones, Browsers, Smart Mobile Devices, Mobile Cloud, browsing applications, mobile device Web browsers, user experience gap, Semantic Web, mobile computing, Semantics, Web pages, online front-ends, generic Websites, Rendering (computer graphics), human computer interaction, mobile device screens, Web sites, Web Visualization, smart mobile device]
Extensive compression of text messages in interactive mobile communication
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
An extensive text message increases the message payload size causing a standard text message to be stripped into several concatenated message. Sending such concatenated messages to transmit a single message is a major drawback considering the cost associated in sending out multiple messages. In this paper, we propose an extensive text message compression technique having message confidentiality, authenticity and integrity with cryptographic protection to enhance security. Initially, the extensive text message is compressed using the MD5 algorithm into a cipher text that consists of 32 characters. The encryption is performed by using an initialization vector and a secret key while extensive message compression is achieved simultaneously. Finally, this cipher-text is transmitted through the SMS gateway to the recipients who will decompress the cipher-texts into its original form. Results indicate that message delivery time is not affected by the proposed mechanism.
[text analysis, message compression, electronic messaging, internetworking, multimedia message service, cryptographic protection, Mobile communication, Encryption, secret key, interactive mobile communication, message integrity, initialization vector, SMS gateway, mobile computing, Databases, message payload size, encryption, message authenticity, interactive systems, short messaging service, MD5 algorithm, multimedia communication, extensive text message compression technique, Ciphers, data compression, message confidentiality, cryptography, Vectors, data integrity, Standards, computer network security, cipher text, vectors, MMS, SMS, security enhancement, concatenated message, message delivery time]
Impact of the information systems service quality on performance of IT sector organizations in sri lanka
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
The Information Systems (IS) function now includes a significant service component and it is not just a computer - based solution. However, commonly used measures of service effectiveness have focused on the manufacturing industry and IT industry has not been much focused so far. In local context, neither IS service quality nor functionality is highly focused and critically evaluated. Many instruments have developed such as SERVQUAL which had been used to measure the IS service quality in the marketing field can offer as possible measures of IS service quality. Purpose of this research is to identify the relationship between IS service quality and perceived performance of Sri Lankan IT organizations. The factors affecting IS service quality and perceived performance were identified from literature and the hypothetical model was developed. Research was conducted quantitatively in selected 5 IT companies. The data was analysed using Partial Least Square technique. A strong relationship was revealed between IS service quality and perceived performance of the organizations and safe use, interaction, accuracy and functional coverage were the most impactful factors for IS service quality which drives the organizations' performance with financial viability, motivation and capacity.
[IS service quality, least mean squares methods, information systems service quality, IT industry, Instruments, Organization's performance, Sri Lanka, DP industry, Companies, partial least square technique, management information systems, quality of service, IT companies, Information systems, Standards organizations, IT sector organizations performance, Information Systems service Quality, organizations perceived performance, Reliability, Investment]
Techno-economical optimization of a solid waste management system using evolutionary algorithms
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Renewable energy technologies are becomming popular due to higher depletion rate of fossil fuel resources. In such circumstances conversion of municipal solid waste into energy is helpful in many ways. However, it is difficult to come up with an optimum conversion technique which depends on number of techno-economical factors. There are number of difficulties in using classical optimization to optimize solid waste management systems. This research paper introduces a novel optimization algorithm based on evolutionary algorithms to conduct the optimization. The novel optimization algorithm is having the capability to conduct Pareto multi objective optimization considering constraints in both objective and decision spaces. Life cycle cost, net energy produced and landfilling capacity were taken as objective functions in the multi objective optimization. Finally, a brief discussion is presented based on the results obtained.
[fossil fuel resource, life cycle cost, net energy production, Cogeneration, Evolutionary computation, evolutionary algorithms, municipal solid waste, Resource description framework, optimization algorithm, Multi Objective Optimization and Evolutionary Algorithm, Optimization, techno-economical optimization, renewable energy technologies, decision space, waste management, Pareto optimisation, Waste Management, renewable energy sources, landfilling capacity, Waste to Energy Network, objective functions, resource depletion rate, Waste management, objective space, evolutionary computation, Pareto multiobjective optimization, Solids, solid waste management system, energy conversion]
A recommender systems approach to optimising career pathways development planning for youth in emerging knowledge economies
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
A key resource in emerging regions is the intrinsic knowledge potential of its youth. For the potential of this resource to be fully realised, we believe that there should be a systemically designed national career pathways development system (NCPDS). An NCPDS can help channel each young person into a career best suited to that individual, whilst giving consideration to career choice and national needs. This paper discusses an NCPDS founded on knowledge-based decision support systems and evolving recommender system frameworks, able to handle large volumes of data and provide analytics. We discuss an initial prototype designed and implemented in New Zealand.
[Knowledge-based Decision Support Systems, human resource management, Engines, ICT4D in emerging regions, Databases, knowledge economies, Prototypes, Recommender systems, NCPDS, Recommender Systems, Engineering profession, data analysis, Career Pathways Development, Knowledge based systems, national needs, knowledge-based decision support systems, Educational institutions, recommender systems approach, decision support systems, New Zealand, recommender systems, career choice, intrinsic knowledge potential, data handling, national career pathways development planning]
Going global &#x2014; Lessons learned from developing an online master's in ICT4D
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Information and Communication Technology for Development (ICT4D) is a rapidly expanding field where successful outcomes require interdisciplinary collaborations. Stakeholders involved in ICT4D projects have a wide variety of educational backgrounds and ICT4D training. Literature and education on ICT4D has been compared to a lost sheep but currently there exists seven master programmes in ICT4D at university level (University of Colorado, Boulder, Berkeley University of California, University of Cape Town, Royal Holloway University of London, University of East London, University of Manchester and Kobe Institute of Computing). However, none of these existing programmes are entirely available online and possible to complete by distance studies only. The aim of the present study is to analyse and discuss the needs and requirements for a master's programme in ICT4D given entirely online as distance education. Applicants to a new online master's programme developed at the Department of Computer and Systems Sciences at Stockholm University have responded to an online questionnaire on what they find important in an ICT4D programme. Findings show that even though online education has been around for quite a while, there are still a lot of issues to address and globally oriented distance education does have particular pedagogical, cultural, administrative and technical challenges. The lack of interdisciplinary programmes in ICT4D is evident and we definitely think that there is a need for a new master's programme that is given in distance mode only. Furthermore, our vision is to open up the programme in the line of open access principles in a near future when course content and pedagogical ideas have been evaluated more in detail.
[Computers, ICT4D projects, Royal Holloway University of London, distance education, information and communication technology for development, ICT4D literature, Training, e-learning, ICT4D training, educational backgrounds, Communications technology, ICT4D education, computer science education, Distance education, further education, Buildings, online questionnaire, Technology enhanced learning, online masters degree program, Educational institutions, Berkeley University of California, University of Cape Town, Online learning, ICT4D, distance learning, University of East London, Stockholm University, Kobe Institute of Computing, University of Manchester, Collaboration, educational institutions, Department of Computer and Systems Sciences, University of Colorado]
Ontology based annotation mechanism for financial documents
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
The Vast number of publicly available electronic financial documents and document repositories and their rapid growth pose a great challenge in understanding, managing and structuring the information. Due to several reasons content of these documents is open to variety of differing interpretations and resulting ambiguity. Annotating these data with semantics to constrain the inconsistent interpretation of data facilitates better reuse and interoperability. We propose a semi-supervised approach for creating annotations for the extracted text of financial documents. A Supervised approach would include human experts in the annotation process. Unsupervised or machine based annotation is done by recommending Financial Industry Business Ontology (FIBO) terms for document sections based on the Okapi Similarity measure. Annotation data can be used to infer knowledge from important sentences or document sections to gain better understanding or decision making. Our annotation results indicate that similar pairs of sections have more common FIBO terms and different pairs of sections have a lesser number of similar FIBO terms.
[text analysis, text extraction, Ontology, Knowledge based systems, Ontologies, electronic financial documents, FIBO terms, Information retrieval, Financial Data, Frequency measurement, ontology based annotation mechanism, Financial Industry Business Ontology terms, document repositories, semisupervised approach, Annotation, Semantic Web, Semantics, Okapi similarity measure, ontologies (artificial intelligence), financial data processing, unsupervised based annotation, machine based annotation, Contracts]
Prediction of horizontal gene transfer in escherichia coil using machine learning
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Horizontal Gene Transfer (HGT), also known as Lateral Gene Transfer is a process where an organism acquires genetic material from another organism without being a descendant of that organism. Horizontal gene transfer is said to be the predominant method of evolution in prokaryotic organisms. This study is focused on constructing a method that employs genome comparison and semi supervised learning to identify genes that are horizontally transferred to Escherichia coli 0157:H7 and attempting to find a link between these genes and other organisms that display pathogenic behaviour. E.coli 0157:H7 is compared to E.coli K-12 which is a harmless strain of the same organism. This comparison yields the set of genes that has not originated from the same ancestor (non-homologous) and is the possible cause of its pathogenic properties. A supervised self-organizing map was constructed to classify the non-homologous genes as either horizontally or vertically transferred. Most of the obtained horizontally transferred genes have shown a striking similarity to other pathological bacteria and Achaea. The results have indicated that, while it is possible to discern the mode of transfer of a gene based on compositional feature to a certain degree, it is better to combine several other features to further refine the findings.
[E coli K-12, semisupervised learning, Self-organizing map, Genomics, Escherichia coli, Amino acids, pathogenic behaviour, pathological bacteria, GC content, Microorganisms, genetics, Lateral Gene Transfer, biology computing, self-organising feature maps, Achaea, supervised self-organizing map, learning (artificial intelligence), Bioinformatics, Horizontal gene transfer, Codon adaptation index, pattern classification, horizontal gene transfer prediction, genome comparison, machine learning, E coli O157:H7, pathogenic properties, lateral gene transfer, Unsupervised learning, Strain, microorganisms, prokaryotic organisms, Vegetation, Supervised Self-organizing map, nonhomologous genes classification]
Semi-supervised algorithm for concept ontology based word set expansion
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Word lists that contain closely related sets of words is a critical requirement in machine understanding and processing of natural languages. Creating and maintaining such closely related word lists is a critical and complex process that requires human input and carried out manually in the absence of tools. We describe a supervised learning mechanism which employs a word ontology to expand word lists containing closely related sets of words. The approach described in this paper uses two novel supervised learning techniques that complement each other for the purpose of expanding existing lists of related words. Expanding concept variable lists of RelEx2Frame component of OpenCog Artificial General Intelligence Framework using WordNet is used as a proof of concept. Intervention of this project would enable OpenCog applications to attempt to understand words that they were not able to understand before, due to the limited size of existing lists of related words.
[OpenCog artificial general intelligence framework, natural language processing, Pipelines, supervised learning, word set expansion, Ontologies, RelEx2Frame component, concept ontology, Equations, WordNet, Connectors, semisupervised algorithm, supervised learning mechanism, word ontology, Databases, Semantics, ontologies (artificial intelligence), learning (artificial intelligence), word lists, ontology, closely related word sets]
Short-term forecasting of electricity consumption in maputo
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
We present a short-term load forecasting model for Maputo. The model is based on the concept of multiple models. A clustering method is combined with expert's knowledge to identify sub-models. The resulting model, which is the combination of several sub-models, is evaluated and compared to the model currently used by the Electricidade de Mo&#x00E7;ambique E.P (EDM). The results show that the developed model performs better accuracy than the one currently used by EDM. The results obtained by the application of the model when translated into financial figures demonstrate significant economic advantages. The social and environmental implications of the model are also analysed.
[environmental implications, Maputo, clustering method, Electricidade de Mocambique, Predictive models, social implications, electricity consumption, Load forecasting, Mozambique, Electricity, short-term load forecasting model, Mathematical model, socio-economic effects, Short-term load forecasting, Load modeling, economic advantages, expert knowledge, Forecasting, power system economics, Day-Ahead-Market, pattern clustering, load forecasting, robust regression, Data models, clustering, multiple models]
Learning a stochastic part of speech tagger for sinhala
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
This paper presents the results of developing a part of speech (POS) tagger for Sinhala. The tagger is able to handle lexical items with multiple POS tags while also predicting POS tags of previously unseen words. A stochastic approach, Hidden Markov Model (HMM) with tri-gram probabilities was used as the training and tagging model. Linear Interpolation is used to smoothen the tri-gram probabilities while the Viterbi algorithm is used to decode the results of the HMM to decide on the best POS tags for each word. The tagger learns the lexical items (words and their possible POS tags) and the tri-gram probabilities using a POS tag annotated corpus. The tagger achieved an overall accuracy of 62%. Approximately 24% of the errors were for words whose POS tags have been unknown in the corpus. The lack of a Named Entity recognizer has also contributed to 10% of the overall error.
[Sinhala language, hidden Markov model, Stochastic processes, learning, linear interpolation, Training, hidden Markov models, Accuracy, speech recognition, Viterbi algorithm, Part of speech tagging, Hidden Markov Model, learning (artificial intelligence), stochastic approach, Linear Interpolation, natural language processing, training model, Probability, HMM, part-of-speech tagger, interpolation, POS tagger, tri-gram probabilities, Hidden Markov models, lexical items, Tagging, Speech, named entity recognizer, tagging model]
A comparative analysis of opinion mining and sentiment classification in non-english languages
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
In the past decade many opinion mining and sentiment classification studies have been carried out for opinions in English. However, the amount of work done for non-English text opinions is very limited. In this review, we investigate opinion mining and sentiment classification studies in three non-English languages to find the classification methods and the efficiency of each algorithm used in these methods. It is found that most of the research conducted for non-English has followed the methods used in the English language with only limited usage of language specific properties, such as morphological variations. The application domains seem to be restricted to particular fields and significantly less research has been conducted in cross domains.
[Algorithm design and analysis, opinion mining, Text mining, pattern classification, text analysis, Machine learning algorithms, Blogs, sentiment classification, data mining, Classification algorithms, Data mining, language specific properties, Machine Learning, Support vector machines, Accuracy, nonEnglish text opinions, morphological variations, nonEnglish languages, Natural Language processing, behavioural sciences computing]
Efficient use of training data for sinhala speech recognition using active learning
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Automatic Speech Recognition is an area which requires a large amount of training data. Collecting such quantities of data involves significant time and cost owing to the tedious nature of collecting speech recordings and manual nature of transcribing it. For a low resourced language such as Sinhala, collecting a sufficient data set is a major problem. To address this issue we used the Active Learning technique from the Machine Learning paradigm which is applied to many tasks such as information retrieval. Our experiment using a simple Sinhala speech corpus shows that through the use of Active Learning, the amount of utterances that need to be transcribed can be reduced by some 42% to achieve the same accuracy as using the whole data set without such a strategy. This suggests that Active Learning techniques can be successfully applied to make optimal use of scarce resources for speech recognition for new languages.
[Vocabulary, Word posterior probabilities, Acoustics, Information extraction, automatic speech recognition, Training, Accuracy, speech recognition, NLP, training data, Low Resourced Languages, learning (artificial intelligence), Sinhala speech recognition, ASR, Automatic Speech Recognition, Computational modeling, information retrieval, Natural Language Processing, machine learning, Active Learning, Confidence scoring, Sinhala speech corpus, Sinhala, Speech recognition, Speech, active learning technique]
Document analysis based automatic concept map generation for enterprises
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Ever growing knowledge bases of enterprises present the demanding challenge of proper organization of information that would enable fast retrieval of related and intended information. Document repositories of enterprises consist of large collections of documents of varying size, format and writing styles. This diversified and unstructured nature of documents restrict the possibilities of developing uniform techniques for extracting important concepts and relationships for summarization, structured representation and fast retrieval. The documented textual content is used as the input for the construction of a concept map. Here a rule based approach is used to extract concepts and relationships among them. Sentence level breakdown enables these rules to identify those concepts and relationships. These rules are based on elements in a phase structure tree of a sentence. For improving accuracy and the relevance of the extracted concepts and relationships, the special features such as titles, bold and upper case texts are used. This paper discusses how to overcome the above mentioned challenges by utilizing high level natural language processing techniques, document pre-processing techniques and developing easily understandable and extractable compact representation of concept maps. Each document in the repository is converted to a concept map representation to capture concepts and relationships among concepts described in the said document. This organization would represent a summary of the document. These individual concept maps are utilized to generate concept maps that represent sections of the repository or the entire document repository. This paper discusses how statistical techniques are used to calculate certain metrics which are used to facilitate certain requirements of the solution. Principle component analysis is used in ranking the documents by importance. The concept map is visualized using force directed type graphs which represent concepts by nodes and relationships by edges.
[summarization, graph theory, Data mining, fast information retrieval, enterprises, document repositories, Optimization, concept extraction, phase structure tree, graph node, document pre-processing techniques, principle component analysis, natural language processing techniques, Natural language processing, document handling, Java, natural language processing, structured representation, information retrieval, Natural Language Processing, sentence level breakdown, Sun, Concepts/Relationships Extraction, concept map construction, Concept Map, information organization, graph edge, documented textual content, Feature extraction, document analysis, automatic concept map generation, force directed type graphs, principal component analysis, document summary, rule based approach]
ISP friendly peer selection in bittorrent
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Peer-to-peer (P2P) applications provides services such as content sharing, video-on-demand, voice-over-IP which are very popular among Internet users and it accounts for a significant amount of global internet traffic. Use of overlay networks pose significant new challenges to Internet Service Providers (ISP). In order to reduce operational costs ISP are throttling or blocking P2P traffic which is unfavourable for a majority of internet users. In this paper, we design and evaluate an approach of reducing these costs when using BitTorrent P2P applications. Our approach involves of using knowledge of network paths that can be gathered in trackers and using it to bias the peer selection without any modification to any client software. Using the results of an evaluation of nearly 300 users in PlanetLab testbed the proposed approach will reduce cross-ISP traffic by 44% while improving in download speed (40%) and upload speed (39%).
[peer selection, Protocols, voice-over-IP, PlanetLab testbed, Internet users, cross-ISP traffic reduction, content sharing, traffic locality, network path, BitTorrent P2P applications, peer-to-peer applications, Bandwidth, Peer-to-peer, video-on-demand, BitTorrent, IP networks, cost reduction, neighbour selection, peer-to-peer computing, upload speed, ISP friendly peer selection, Routing, P2P applications, Internet service providers, P2P traffic, performance, download speed, Software, Peer-to-peer computing, Internet, operational cost reduction]
KAnt: Leveraging ant colony optimization for automatic knowledge acquisition from web documents
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
This paper suggests a novel algorithm (KAnt) inspired by ant colony optimization strategies for knowledge acquisition. KAnt algorithm attempts to devise a unique solution for eminent knowledge acquisition problem of losing interest in content rich documents due to low familiarity. We utilize our solution to work with web based documents, considering documents as nodes in a graph problem. Locating content rich documents is achieved through intelligent ants that are equipped with numerical statistic for document identification. Documents are found via pheromones deposited by such ant colony. Experimental results acquired through domain expert evaluation show that our proposed approach has contributed for knowledge acquisition remarkably.
[Ant Colony Optimization, Ant colony optimization, Knowledge acquisition, Conferences, Roads, Abstracts, Swarm intelligence, Web based documents, Informatics, Particle swarm optimization]
Churn prediction methodologies in the telecommunications sector: A survey
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Predicting customer churn is a critical requirement of many if not all companies dependent on customer subscription services. The telecommunication sector is especially impacted due to the rival competition being very high and since tariff rates are maintained at a lower level. This paper describes the efforts made by researchers to build successful churn prediction models highlighting their special characteristics.
[telecommunication industry, telecommunications sector, Companies, Artificial neural networks, churn prediction, Predictive models, consumer behaviour, Telecommunication, customer subscription services, Telecommunications, customer retention, customer churn preduction, Accuracy, churn prediction methodologies, Decision trees, Expert systems]
Energy-efficient communication with wake-up receiver technologies and an optimised protocol stack
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
In the domain of distributed embedded systems, available resources regarding computing power, energy, and memory are strongly limited. With focus on the energy resources, communication hardware and communication tasks represent critical consumers for most of the common application scenarios. Accordingly, optimised approaches for the communication have to be found, including routing, topology control, and scheduling. Wake-Up-Receivers (WuRx) represent a promising approach for minimising the energy consumption in wireless communication environments. To use the conceptual benefits of such technology, an adapted communication behaviour is required. Communication paradigm, communication protocols as well as the runtime behaviour must fit together. In this paper, we introduce a WuRx-optimised routing and topology optimisation approach - WRTA. We discuss the hardware integration as well as the adaptation of the communication task scheduling on application layer. The design matching process of all these aspects allows significant improvements of the energy-efficiency in typical sensor network scenarios. For achieving these goals, WRTA represents a lightweight protocol for data-centric WSN environments. The approach combines complex route path calculations and topology optimisation mechanisms, considering a given asynchronous communi cation environment. For proof of concept, we implement several heterogeneous test benches in both soft- and hardware. Hence, the presented simulation results as well as the respective real world measurements provide interesting results regarding the scalability and the efficiency. The analysis of the data shows minimum protocol overhead and outstanding characteristics regarding scalability and robustness. We clarify that application-specific adaptations &amp; configurations within the overall system architecture are essential to ensure an reliable communication behaviour in energy self-sufficient WuRx environments.
[distributed embedded systems, Protocols, Protocol Stack, Topology Optimisation, minimum protocol overhead, wake-up receiver technologies, energy-efficient communication, WuRx, Optimization, Wake-Up Receiver, Network topology, receivers, data-centric WSN environments, Hardware, Embedded Systems, protocols, communication, wireless communication environments, low-power, Receivers, telecommunication network topology, Routing, Topology, topology optimisation approach, optimised protocol stack, telecommunication network routing, WuRx-optimised routing, wireless, Energy efficiency]
My sensors: A system for secure sensor data sharing over internet
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Privacy of sensor data should be considered since it is evidence for the behaviour and life style of the sensor owners. Some people attempt to store their data in the third party servers like the Cloud Computers. This is unsafe for the reason that user does not know whether third parties access their valuable data. Storing sensor data will be an essential for researches and several other aspects. In this research work, a mechanism is introduced for saving the information outside the Cloud severs while using the infrastructure of those servers. My Sensors system includes its own request handling mechanisms to access those data saved.
[Cloud computing, Google, sensor fusion, Sensor systems, Servers, Intelligent sensors, sensor data sharing, data storage, Cloud Computing, Data Store, sensor data privacy, My Sensors system, request handling mechanisms, Local Agent, third party servers, data access, cloud computers, data privacy, Internet, cloud computing, Sensor Data]
Reconfigurable universal sensor interface for distributed wireless sensor nodes
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Wireless sensor networks of today play a large role in industrial grade field data acquisition systems. The need for vast sensor compatibility will be an evident requirement as wireless sensor networks go mobile and become autonomous. Current technologies make use of multiple signal conditioning circuits which result in bulky power hungry wireless sensor nodes. This paper presents an implementation of a reconfigurable universal transducer interface based on a CMOS multiplexer network supporting a vast diversity of industrial sensors while being compact and energy efficient, which is conducive to wireless sensor networking. The concept, design scheme, prototype implementation with industrial components and the results of integrating this interface into a prototype wireless sensor node are discussed in this paper to illustrate potential applications in mass scale data acquisition based on wireless sensor networks.
[Multiplexing, vast sensor compatibility, multiple signal conditioning circuits, wireless sensor networks, mass scale data acquisition, Multiplexers, CMOS multiplexer network, signal conditioning circuits, transducers, Reconfigurable Hardware, Wireless communication, Temperature measurement, Wireless sensor networks, reconfigurable universal transducer interface, Accuracy, WSN, Thermistors, Hardware, CMOS integrated circuits, reconfigurable universal sensor interface, distributed wireless sensor nodes, multiplexing equipment, Universal Interface]
An investigation into dynamic TLPs for smartphone communication: To facilitate timed response in way finding for vision impaired people
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
A reliable, high speed and efficient data transfer method is a very important factor in real time Way-finding systems since it requires information with very low latency to discover paths, avoid dangerous situations, identified changes in existing maps and alternative routes. This research will develop models and methods to facilitate bounded timing with minimal latency for way-finding application for vision impaired people. As a result of analyzing the requirements for Way-finding applications, it was noted that some typical behaviours involve relatively small amount of data transfer through networks. Existing Transport Layer Protocols (TLP) are not ideal for providing such requirements. This research investigates existing TLPs and proposes modifications / extensions to facilitate demands in Way-finding applications and will implement the Dynamic TLP to incorporate both reliable data transfers with high efficiency as well as frequent data transfers which do not require reliability.
[handicapped aids, Protocols, Indoor navigation, transport layer protocols, Process control, Educational institutions, smart phones, dynamic TLP, Servers, transport protocols, Way-finding, data transfer method, Data transfer, vision impaired people, real time way-finding systems, Reliability, smartphone communication, Dynamic Transport Layer Protocol, Payloads]
Hybrid framework for privacy preserving data sharing
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Privacy preserving data mining has become increasingly popular and continuously evolving field of study. It allows sharing of privacy sensitive data for analysis purposes. The recent advancement in data mining technology to analyze vast amount of data has played an important role in several areas of Business processing. Data mining also opens new threats to privacy and information security if not done or used properly. Therefore this research elaborates and introduces new Hybrid Algorithm for Privacy Preserving Data Sharing. It opens the gates to touch finer points of Hybrid methodologies in privacy preserving data mining. Experiments based on the discussions of literature, mainly about data sanitization done to prove the set of hypothesis mentioned on this paper.
[Measurement, Data privacy, data analysis, privacy sensitive data sharing, data mining, information security, Data mining Algorithms, business processing, Privacy preserving, Association rules, Data mining, Data sanitization, Privacy, Databases, hybrid methodologies, Data models, data privacy, data mining technology, hybrid framework, privacy preserving data sharing, privacy preserving data mining]
Big data solution for Sri Lankan development: A case study from travel and tourism
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
In this paper, the key aim is to provide conceptual, technical solution design to implement a supportive dashboard which integrates with Big Data indicators and online transaction processing (OLTP) systems. The proposed solution is mainly focusing on a case study of Travel and Tourism industry in Sri Lanka. We carried out in-depth analysis to identify the necessity of a dashboard and examine significant challenges need to consider when designing the solution. Moreover, we evaluate suitable big data technologies for implementation and Hadoop, Hbase, MapReduce has been proposed. Centralized repository for user Meta data, Contextual Search, Early Warning Alerts, Index Indicators, Analytic tool and Reports, Marketing campaign optimization, Link with social media features, Sales and marketing forecasting are main dashboard features that has been designed based on the requirements. Our results attest importance of Index indicators, one of the major functionality which is built-in to dashboard. In this work, we present a detailed analysis of a total efficiency index using four indexing strategies of varying complexity including Visit Index, Wealth Index, Health Index, and Lifestyle Index. We conclude by designing an open architecture, that can track and leverage data on the behavior of tourist via a dashboard which consider trends, to make better decisions, reduce risks and drive personal tourist experiences.
[Industries, tourism industry, personal tourist experiences, Data handling, big data solution, Apache Sqoop, data mining, Dashboard, Information management, marketing campaign optimization, MapReduce, online transaction processing systems, OLTP systems, contextual search, Index Indicators, social media features, meta data, Hadoop, Big Data, Sri Lankan development, Indexes, early warning alerts, Data storage systems, Apache Mahout, visit index, health index, travel industry, wealth index, indexing strategies, Hbase, lifestyle index]
Comparing support vector regression and random forests for predicting malaria incidence in Mozambique
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Accurate prediction of malaria incidence is essential for the management of several activities in the ministry of health in Mozambique. This study investigates the comparison of support vector machines (SVMs) and random forests (RFs) for this purpose. A dataset with records of malaria cases covering the period 1999-2008 was used to evaluate predictive models on the last year when developed from one up to nine years of historical data. Mean squared error (MSE) was used as the performance metric. The scheme for estimating variable importance commonly employed for RFs was also adopted for SVMs. SVMs developed from two years of historical data obtained the best prediction accuracy. Hence, if we are interested in predicting the actual number of malaria cases the support vector machines model should be chosen. In the analysis of variable importance, Indoor Residual Spray (IRS), the districts of Manhi&#x00E7;a and Matola and month of January turned out to be the most important predictors in both the SVM and RF models.
[indoor residual spray, health ministry, variable importance analysis, regression analysis, Predictive models, random forests, malaria incidence cases, IRS, SVM, Matola district, Training, Analytical models, Accuracy, mean squared error, Mozambique, malaria incidence prediction, learning (artificial intelligence), Kernel, mean square error methods, MSE, Manhi&#x00E7;a district, support vector machines, diseases, Diseases, Support vector machines, support vector regression, RF, predictions support vector machines, medical computing]
Spatial data mining technique to evaluate forest extent changes using GIS and remote sensing
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Development of new computational, visual analytical and statistical methods to process, analyse, and understand complex and massive geospatial and temporal data is of vital importance at present in the world. Therefore, Spatial Data Mining (SPD) technique is very useful tool to access environmental phenomena. Spatial data mining is the process of discovering interesting and previously unknown, but potentially useful patterns from large spatial datasets. The main purpose of the present study was to identify forest extent changes during two decades using SPD techniques. For this study, multi-temporal satellite images (Land sat 5 TM 1992 and ASTER 2006) were used. Nuwaraeliya was selected as the study area for this research. Two thematic maps were derived from following tow approaches. The first and second approaches were consisted of unsupervised and supervised classification, respectively; derived thematic maps (unsupervised and supervised) were combined with Geographical Information System (GIS) overlay technique to generate a new map. These three maps were reclassified and converted to American Standard Code for Information Interchange (ASCII) format which is suitable formatting interface for SDM modelling. In order to carry out spatial data mining, Back-propagation algorithm was used. Overall accuracy of ASTER was 96.2 whereas that of land sat TM was 94. Results revealed that the extent of forest cover was lost by 5.28% in the present study area within in the period from 1992 to 2006. The results of this study are expected to be useful for researchers, managers and policy makers for updating existing forest maps, detecting forest changes and planning.
[GIS, Spatial data mining, forest, Conferences, Spatial databases, Agriculture, Data mining, Information technology, Remote sensing, Geographic information systems]
Dynamic partitional clustering using multi-agent technology
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Most of the well established clustering algorithms assume that the underlying clustering structure of dataset does not change over the time. Hence, those algorithms fail to identify underlying cluster structures in currently available large scale dynamic data sources in an efficient manner. This paper presents a Multi Agent based approach to identify partitional clusters in a dynamic data source. Set of partitional clusters in a dynamic data source is identified by interactions and negotiations among the agents who represent data records in the data source. After identification of potential clusters for data records that are assigned to what are called cluster agents. By interactions and negotiations between cluster agents and data record agents, the identified cluster configuration is continuously improved according to the internal cluster evaluation measures. The proposed method is evaluated by synthetic data sets with different number of clusters in 2D and 3D spaces. Results indicate that the proposed method successfully identifies the clusters in those datasets with minimal human intervention.
[dataset clustering structure, internal cluster evaluation measures, Uncertainty, multi-agent systems, Heuristic algorithms, unsupervised machine learning technique, Partitioning algorithms, large scale dynamic data sources, Data mining, cluster configuration identification, Multi-agent Technology, unsupervised learning, Databases, pattern clustering, Clustering algorithms, Data visualization, multiagent technology, data record agents, data structures, dynamic partitional clustering algorithms, cluster agents, Partitional Clustering, Dynamic Clustering]
A federated approach on heterogeneous NoSQL data stores
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
NoSQL has now become a topic of major interest. It addresses the problems of scalability and performance of the traditional RDBMS (Relational Database Management System) with high volumes of data. Today there are over hundred NoSQL implementations mainly focused around four data models with a lot of heterogeneity between them. Therefore integrating several NoSQL data stores to work together in situations such as changing the underlying data store becomes a hectic task and migrating the data from one system to another is also not feasible due to the high volumes of data involved. The objective of this research is to address the heterogeneity of NoSQL data stores through database federation which has been around since the early 80's which has proven to be successful in integrating heterogeneous data storages. In this research we have successfully implemented a NoSQL federation with Cassandra, MongoDB and CouchDB proving that NoSQL federation is feasible with a certain degree of overhead.
[data volume, overhead degree, Database Federation, heterogeneous NoSQL data stores, CouchDB, Cassandra, data migration, relational databases, Database languages, Standards, database federation, SQL, relational database management system, data models, storage management, Runtime, Structured Query Languages, RDBMS, data heterogeneity, Libraries, Data models, Database systems, MongoDB, NoSQL Data store]
Non invasive human stress detection using key stroke dynamics and pattern variations
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Stress is considered as a very harmful health problem in the modern world. A large proportion of sick leave in the industrial world is believed to be related to stress. While some level of stress can act as a positive factor, extensive exposure to high levels of stress can have detrimental effects on one's health. Depression, panic attacks, high blood pressure, diabetes, heart problems are few of such diseases that can be initiated or worsened by stress. With the increasing people centricity in contemporary developments of computer science, Affective Computing has become a popular research area. According to the existing research, affective computing has shown positive results in detecting human stress. Stress detection has been tackled in various approaches including heart rate variability (HRV), skin conductance (SC), pupil diameter (PD) based detection, Finger Temperature (FT) and etc. Our focus in this study is to utilize a readily available yet underutilized resource in Affective Computing, key stroke dynamics (KSD). Recent developments in KSD based affective computing and Biometrics research proves that key stroke variations is a very powerful source of input that provides a valuable insight about an individual's psychological and emotional states. Our methodology suggests a personalised approach in detecting stress levels through key stroke variations. An application specific Individual key stroke pattern profile is created for an individual based on his normal typing patterns. This profile consists of trained average values for a set of typing features. Real time stress specific deviations of these features are analysed in order to arrive at the individual stress level. The remainder of the paper is structured as follows. First we introduce the research problem that this study is attempting to address. Then the significance of our approach is brought to the attention. The related work section tries to analyse and evaluate the existing related literature revolving around this research area. After that we present the details of our approach through the methodology section. The experiment section describes about the experiment conducted to gather the keystroke data that are to be analysed as stress and non-stress data samples. A brief overview of the results of the experiment is provided towards the end of the paper.
[pattern variations, stress data samples, noninvasive human stress detection, keystroke patterns, non-invasive, normal typing patterns, nonstress data samples, Real-time systems, trained average values, Monitoring, health care, Stress measurement, medical diagnostic computing, pattern classification, real time stress specific deviations, key stroke dynamics, KSD based affective computing, application specific individual key stroke pattern profile, Stress, Stress detection, occupational stress, Skin, Heart rate variability, Biomedical monitoring, key stroke variations]
V-Touch: Markerless laser-based interactive surface
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Human Computer Interaction (HCI) is one of the major disciplines in the field of computing which defines the way people interact with machines. HCI is a combination of computer vi science, behavioral science, design and several other areas which determines the best and optimized ways to interact with computers. The way people interact with machines changed dramatically after the 21st century due to the advancements of the computing devices. Computers became more portable and embedded to the environment with the improvement of processing power and miniaturization of devices. New concepts such as ubiquitous computing are also emerged with these advancements of technology. Traditional HCI concepts were failed to meet the requirements of the emerging technologies since most of these new concepts requires natural interactions rather using tangible devices. This paper present a computer vision based interactive surface application for human computer interaction which enable users to perform QWERTY keyboard and mouse interactions on a flat surface. Primarily, this research addresses the existing issues related to gesture based interactive interfaces by presenting a novel approach to perform interactions without stereoscopic vision and wearable markers. The proposing approach present a system (V-Touch) based on Haar-like features with single camera and a laser projection module that allows users to perform traditional keyboard and mouse interactions naturally using low cost hardware setup.
[Markerless laser-based interactive surface, V-Touch system, behavioral science, QWERTY keyboard, Interactive surface, Augmented Reality, gesture based interactive interfaces, cameras, gesture recognition, computer vision based interactive surface application, feature extraction, computer vision science, Surface emitting lasers, Virtual Keyboard and Mouse, interactive devices, Haar-like features, Laser beams, HCI, laser projection module, Human computer interaction, mouse interactions, Layout, Keyboards, tangible devices, computer vision, Feature extraction, computing devices, Mice, human computer interaction, single camera]
Analysis of the awareness of collaborative e-learning (CeL) in Sri Lankan university education
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
E-learning introduced new ways of learning using computer and internet, and is rapidly evolving with the development of technology. Learners can actively participate and collaborate in a learning process using either synchronous or asynchronous e-learning. Collaborative e-Learning (CeL) is an effective way of learning which also improves the processing skills of the students. In this study, the awareness of the effectiveness of CeL instructional models used in the Sri Lankan university education was analyzed. The population for this research study is the students and lecturers of 15 Sri Lankan National universities where the CeL model is used in the academic curricula. The study was conducted by interviews, phone calls and email among the participants. The interview results were analyzed and the definition of CeL in Sri Lankan context is defined. Further, the factors affecting CeL, the tools used in CeL, the advantages of practicing CeL, and the challenges that arise when implementing CeL are identified. The factors are then categorized into different types and the critical factors identified. The key challenges faced by the lecturers and students were also identified. Finally, this paper presents recommendations to improve the quality of education in Sri Lankan universities and specifies future research opportunities in this field.
[Availability, Sri Lankan National universities, collaborative e-learning in Sri Lankan university education, Educational institutions, Collaborative e-Learning, awareness about collaborative e-learning, collaborative e-learning instructional models, Electronic learning, asynchronous e-learning, Sri Lankan university education, Collaboration, groupware, Collaborative work, Internet, computer aided instruction, educational institutions, academic curricula, synchronous e-learning, collaborative e-learning awareness analysis, CeL instructional models]
A framework for adaptive learning management systems using learning styles
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Learning management systems (LMSs) are becoming increasingly popular in many educational establishments such as universities. However, they provide the same content for all learners in a given course. Educational theory suggests that learners possess different styles of learning. In this study, we propose a framework for adaptive LMSs that can tailor course content to the learning style of the individual learners. The Felder-Silverman learning styles model was used as the basis for our system implementation. Further, we present initial findings of application of the framework to a course conducted in Moodle LMS.
[Adaptation models, Adaptive systems, Least squares approximations, further education, course content, adaptive learning management systems, e-learning learning management systems, Moodle, Materials, educational establishments, Felder-Silverman learning styles model, educational theory, Educational institutions, Electronic learning, learning management systems, learning styles, universities, educational courses, educational institutions, Moodle LMS]
Affective e-learning model for recognising learner emotions in online learning environment
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Today online learning provides wider coverage many different approaches such as distance learning, classroom-based electronic learning and self-access learning. Online learning has been recognized as a support tool for educators and researchers simply it gives is luxury of using at anytime, anywhere. Like any learning process, online learning depends on effective communication of human knowledge, whether this occurs in a face-to-face classroom or across the Internet. Emotions can have enormous affects on learning and play a vital role in decision making, managing learning activities, timing, and reflecting on the studies. Emotions are also important in teaching and learning and often find expression in particular ways, such as interactions with others and motivation in learning. The aim of the research is to develop a computational model for recognizing leaner emotions in online learning environment. The research study was focused on developing a tool to recognise the online learner's emotions. Therefore, the study has developed Online Achievement Emotion Questionnaire (AEQ) based on the AEQ which is suited for the online learning environment. Also the study has identified a methodology for recognising learner performances during learning. That has being measured through six parameters which represent the learner's level of learning during the learning experience. These parameters are analysed using multiple regression analysis and a model equation was developed to compute the online learner's level of learning. Finally the study has analysed and evaluated the correlation between the learner emotions and the observed behaviour. This research study therefore developed a novel model of affective online learning which can be use as a tool to recognise online learner's emotions with regard to the performance in learning.
[affective computing, regression analysis, self-access learning, teaching, learning, learning activities management, emotion recognition, Analytical models, online learning environment, classroom-based electronic learning, learner emotion recognition, human knowledge communication, multiple regression analysis, Mathematical model, Emotion recognition, face-to-face classroom, emotions, Computational modeling, e, AEQ, distance learning, affective e-learning model, model equation, Electronic learning, decision making, computational model, computer aided instruction, Internet, Reliability, online achievement emotion questionnaire, online learning]
Multimodal &#x002B; multimedia &#x002B; sensors &#x003D; pleasant interfaces
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
If the computer is a machine to help humans, its functions should be completely useful, otherwise it is ineffectual, despite containing several powerful functions. Thus, interface development is an essential issue. We discuss the idea of a pleasant interface in this paper. The pleasant interface does not require much effort while using the computer and operates in the background. In addition, this interface helps humans do a thing which is worth doing. In this study, trials conducted in a laboratory are explained as a step toward realizing pleasant interfaces, which include multidip aquatic interface, spatial auditory, and gait interface systems.
[Computers, gait interface systems, pleasant interface, Educational institutions, Sensor systems, multimodal, aquatic interface, spatial auditory system, user interfaces, Multimedia communication, multimedia, sensors, Pleasant interface, User interfaces, sensor, gait interface, multidip aquatic interface, Floors, spatial auditory]
How to put an elephant in a refrigerator: Architectural concerns of an ESB for lightweight environments
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Summary form only given. With the introduction of IPV6, the address space has increased. Thus in the future, every electronic device can have a unique address. These devices would generate data every day. We can use this data to generate information and create intelligent systems. The concept related to this scenario is known as the Internet of Things (IoT). Interconnecting a multitude of these devices and sharing data and services will eventually become a significant challenge. Enterprise Service Buses (ESB) which are used to integrate enterprise applications can be used to address this challenge by interconnecting every device in a more scalable manner. Even though existing ESBs are suitable for enterprise application integration, they may not be suitable for lightweight hardware environments.
[Performance evaluation, Enterprise Service Bus, lightweight environment, Refrigerators, IPV6, Programming, Educational institutions, intelligent systems, Internet of Things, IoT, Computer languages, address space, enterprise application integration, enterprise service bus, data generation, Internet protocol version 6, ESB, Internet, business data processing, Event driven model]
Twitter news classification: Theoretical and practical comparison of SVM against Naive Bayes algorithms
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
With the development of web technology, researchers had started using blog data in many research aspects and twitter messages is one of them. However, these data are un-organized and thus, it should be organized before gather the information. Classification is one way of organizing the twitter messages. SVM and Naive Bayes classifiers are the most popular classification methods which are often use for text classification. Theoretically, it proves that Naive Bayes performs more faster than any other classifiers with less error. However, this depends on how the situation achieves the Naive Bayes assumptions as naive Bayes assumes that the features are independent. This paper presents a practical experiment to choose a high perform classification method and the theoretical reasons for the high performed classification.
[pattern classification, support vector machines, classification methods, Noise, Blogs, Web technology, Educational institutions, Classification algorithms, SVM, text classification, Support vector machines, blog data, data organization, Naive Bayes Classification, Text categorization, high perform classification method, Twitter news classification, Feature extraction, social networking (online), naive Bayes algorithms, information gathering, Text classification]
A model based approach to simulate excess water of reservoirs in Sri Lanka
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
The research is focused on the risk of floods due to spilling of reservoirs in Sri Lanka. Through this research we expect to illustrate how ICT can effectively address the above scenario and to create a number of significant avenues to continue researches to build a perfect system.
[floods, Sri Lanka, emergency management, Predictive models, reservoirs, Reservoir, neural network, Optimization, Physics, Neural Network, Flood, model based approach, Physics based Model, Neural networks, reservoir excess water simulation, Reservoirs, ICT, Mathematical model, emergency services, neural nets]
Intelligent Web companion (IWC): Personalized web surfing tool
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
World Wide Web is an essential component for day to day computer users. One of the common problems that most web surfers face is searching or the same piece of information multiple times in the web. Web browsers support bookmarking important web sites for future use. This might depend on the machine and the user may need to find the same kind of information in another machine. Redundant search on the same piece of information wastes the computer surfer's time and resources. To address the above mentioned issues the authors have developed an Intelligent Web companion (IWC), a web surfing tool to allow users to have more personalized web browsing experience independent from the location, computer and the web browser. IWC is a web based application which allows each user to create own profile and surf the web. IWC is capable of tracking the user's browsing pattern and based on tracked information IWC provides important sets of services to the web surfer.
[Computers, intelligent Web companion, World Wide Web, personalized Web surfing tool, text classification, Information technology, Customized web Browsing, Web pages, personalized Web browsing experience, Computer architecture, online front-ends, users browsing pattern tracking, Web based application, human computer interaction, Service-oriented architecture, Internet, Web browsers]
Paving the path to a geoscience gateway
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Geoscience is one of the most prominent research areas today, involved in modelling and analysing the evolvement of Earth systems for the betterment of mankind. Geoscientists engaged in geoscience research and experiments often use sophisticated software tools such as Geographic Information Systems (GIS). Nevertheless, as computational geoscience is an emerging field, effective management and utilization of available geoscience data remains a major challenge. Open Geospatial Consortium (OGC) Web Processing Service (WPS) standard provides extensive support and contribution towards the field of computational geoscience. WPS standard offers an interface for distributed geoprocessing and as a result it enables integration of various geoprocessing libraries and processes into WPS implementations. Furthermore, it facilitates sharing common geoprocessing services among different communities and eliminates the need of redeveloping. OGC WPS is a widely adopted standard among geoscientists.
[Web processing service, geoprocessing libraries, Communities, Geoscience, geographic information systems, Earth systems, OGC WPS, geoscience research, software tools, Geographic information systems, OGC WPS standard, geophysics computing, Educational institutions, geoscience experiments, Standards, Computer science, GIS, Geoscience Gateway, Web services, computational geoscience, Apache Airavata, Logic gates, geoprocessing services, distributed geoprocessing, geoscience gateway, software standards, Open Geospatial Consortium]
Integrating e-learning with English language learning
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
The emergence of English as a global language has created great impact especially with the youth on the lookout for suitable professions to match educational qualifications. At a time when e - Learning has become popular and effective, young learners fascinated by new technology, do not appear stimulated enough to make use of it in improving language skills. With computer literacy among Sri Lankans in the ascension, this study reveals how new technology can be used constructively to upgrade English Language proficiency, basically among young adults.
[Computers, English language learning, natural language processing, language acquisition, Cultural differences, Information technology, Stress, Electronic learning, Sri Lankan, e-learning, virtual classroom, Writing, language skills, computer aided instruction, e-learning integration, computer literacy, English language proficiency]
A theoretical framework to conduct informal mobile-learning research in agriculture
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Mobile devices have been successfully used in facilitating learning in informal education. In the study reported on here, we propose designing mobile based informal learning in the domain of agriculture to aware farmers on better farming practice. Thus, learning is referred to as in-situ practice of agriculture compared to traditional classroom learning. The facilitation of communication and interaction among farmers and other stakeholders is important to foster informal learning. Accordingly interactive mobile-learning environments can encourage participatory attitudes, excite interest and commitment among learners and thus become important in adult learning.
[Context, Technological innovation, Farmers, Communities, Activity theory, Mobile communication, Educational institutions, adult learning, Mobile handsets, mobile-learning research, farming practice, mobile based informal learning, agriculture, mobile computing, interactive mobile-learning environments, Agriculture, Mobile learning, computer aided instruction, Informal learning]
An analysis of rapid application development of AJAX based Rich Internet Applications
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
With popular applications such as Google and Facebook enabling a very feature rich experience, users expect to feel the same richness in other web applications they consume as well. As an open source technology, AJAX plays a major role in Rich Internet Application Engineering. But its adoption within Rich Internet Application engineering is complex and difficult due to various reasons. Rapid Application Development is a methodology which can be used to produce such applications rapidly with the use of Computer Aided Software Engineering tools. In this paper, we try to interpret the current status related to difficulties and complexities of Rapid Application Development of AJAX based Rich Internet Applications and suggest possible solutions to be investigated in subsequent work.
[Java, Computer aided software engineering, Buildings, Rich Internet Applications, Educational institutions, AJAX rapid application development analysis, Complexity theory, Rich Internet Application Engineering, computer aided software engineering tools, Software Engineering, XML, open source technology, Rapid Application Development, Designing, Feature extraction, computer aided software engineering, Internet, asynchronous JavaScript and XML, AJAX]
Dynamic resource scheduling in forest fire situations in Sri Lanka
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
According to the gathered data from Disaster Management Centre, Regional forest officers and Fire Brigade of Colombo Municipal Council current procedure of controlling and extinguishing forest fires has number of weak points which have to be addressed immediately in order to minimize the damage caused by the forest fires. Allocation of the available resources in a competent and proficient manner at a time of disaster (real time) has gained huge attention among those weak points. Therefore this study focuses on exploring an approach to dynamically utilize the available resources during a forest fire situation in Sri Lanka.
[Forest Fire Management, dynamic resource scheduling, Sri Lanka, Disaster Management, Estimation, Dynamic Resource Scheduling, emergency management, Dynamic scheduling, forest fire situations, Processor scheduling, fires, Fires, Disaster management, scheduling, Resource management, Meteorology]
Riyadisi &#x2014; Intelligent driver monitoring system
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Road accidents have become a major problem that causes nearly 1.3 million people die and 25-50 million people injured or disabled in each year all around the world. It has been calculated that 10% to 20% of traffic accidents with dead drivers are caused by driver inattention. Drowsiness and distraction of drivers have become the main causes for driver inattention. Drowsiness is something unavoidable and out of control of the driver. Sleepiness increases reaction time and generates the decreased vigilance level, alertness and concentration. Hence the quality of decision making may be affected. Reduced attention and raised reaction time increase the probability of road accidents. Distractions such as looking away, using mobile phone or navigation systems are also obviously cause to make driver loses his/ her focus.
[Visualization, road accident probability, human factors, driver inattention, Machine Learning, driver concentration, Vehicles, alertness, automated driver attention assistance system, Driver drowsiness and distraction detection, driver information systems, IR camera, Real-time systems, video streaming, video stream, video signal processing, Monitoring, vigilance level, intelligent driver monitoring system, video cameras, traffic accidents, drowsiness, sleepiness, Road accidents, Sleep, infrared imaging, distraction, Riyadisi, decision making, computerised monitoring, reaction time, Computer Vision, Biomedical monitoring]
A novel approach to optimize crime investigation process using palmprint recognition
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
A crime investigation is generally carried out to aid the crime solving process by identifying criminals and in some cases victims. Print evidence plays a crucial part in identifying criminals or suspects. According to Sri Lankan Criminal Records, 30%-35% of the print evidences are in the form of partial palmprints. Partial-to-full palmprint matching has attracted the experts in print identification area and researchers in palmprint matching. An efficient partial palmprint identification approach can increase the efficiency of the criminal investigation process in Sri Lanka as well as in other countries.
[print evidence, Forensics, Manuals, Palmprint segmentation, Palmprint classification, Educational institutions, criminal identification, suspects, suspect identification, image matching, System analysis and design, crime solving process, Minutiae matching, palmprint recognition, police data processing, partial-to-full palmprint matching, Databases, crime investigation, Authentication, Software, Partial palmprint recognition, Sri Lankan Criminal Records, partial palmprint identification approach]
Towards Sinhala Tamil machine translation
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
Statistical Machine Translation is a well established data-driven approach to translate source language text to target language text using statistical methods using bilingually aligned corpora. However there has been little research in this area for less well-resourced languages such as Sinhala and Tamil. The focus of this research is to investigate how translation performance varies with the amount of parallel training data in order to find out the minimum needed to develop a baseline machine translation system for the Sinhala-Tamil language pair.
[Measurement, Sinhala-Tamil language pair, statistical machine translation, Buildings, Laboratories, Statistical Machine Translation, Educational institutions, Language Modeling, Tuning, Sinhala Language Processing, Training, machine translation system, data-driven approach, bilingually aligned corpora, Tamil Language Processing, statistical analysis, source language text, target language text, parallel training data, statistical methods, language translation, translation performance]
Medical informatics
2013 International Conference on Advances in ICT for Emerging Regions
None
2013
During last few decades, medical experts have collaborate with the engineers to develop advanced techniques and tools for improving the significances of medical diagnosing techniques. Especially, with the development of high-resolution imaging devices and high-spec computers modeling the medical specialists' knowledge into mathematical methods has become a practical problem. This workshop aims to introduce and give hands experience in on cutting-edge medical informatics technologies. Intended audience is Medical doctors, bioinformaticians, post-graduate medical informaticians, etc.
[Cloud computing, Conferences, Green products, Tutorials, Games, Medical diagnostic imaging]
Message from the conference chair
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.
[Industries, Data analysis, Education, Tutorials, Mobile communication, Software, Natural language processing]
Foreword by the co-chairs
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.
[Schedules, Conferences, Sections, Tutorials, Information technology, Research and development, Organizing]
Organizing committee
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Provides a listing of current committee members and society officers.
[Industries, Australia, Organizing]
Technical program committee
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Provides a listing of current committee members and society officers.
[Cities and towns, Australia, Information technology]
Keynote speakers
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Provides an abstract for each of the keynote presentations and may include a brief professional biography of each
[Context, Data analysis, Education, Australia, Machine intelligence, Information exchange, Testing]
Invited talks
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Provides an abstract for each of the presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.
[Information security, Mobile communication, Data processing]
Keynote speakers: Designing safe and secure cyber physical systems: Challenges in defense and testing
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Summary form only given. An increasing frequency of unauthorized attempts to intrude into public infrastructure with (possibly) malicious intent has led to heightened research activity aimed at the design of safe and secure Cyber Physical Systems (CPS). In this talk, we focus on work related to the design and testing of systems such as water purification and smart grid using testbeds under construction at SUTD. We examine attacker models and potential attacks, and dwell on how one could test CPS to ensure their safety and security. We will also examine novel ideas of CPS defense and testing based on physical and logical invariants, hardware and software mutations that we call attacklets, and device-specific intelligent checkers. Our proposed methodology for CPS testing is aimed at generating suitable metrics for assessing the level of security and safety of a CPS and to assist designers in creating layered cyber defense infrastructure.
[program testing, security of data, cyber physical system, cyber defense infrastructure, system design, system testing, CPS security, software metrics]
Cyber-physical systems: Challenges from data analysis perspective
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Summary form only given. We are blessed with the sophisticated technological artifacts that are enriching our daily lives and the society. It is believed that the future Internet is going to provide us the framework to integrate, control or operate virtually any device, appliance, monitoring systems, infrastructures etc. In this talk, we first present the concept of cyber-physical systems and various research challenges from several application perspectives. Finally, we present several adaptive representations for understanding all types of complex data from text to graphs networks.
[cyber-physical systems, text networks, text analysis, data analysis, graph theory, complex data, graphs networks]
Understanding people, culture and context as the basis for ICT development
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Summary form only given. In this talk I will discuss ICT interventions that work and fail and the reasons that people accept or reject new technologies. I will draw upon case studies from both marginalized and mainstream communities in developed and developing countries. I will also discuss how we use people centered approaches to define and develop our significant research projects in the area of emerging technologies, many of which are funded by the Australian Research Council Discovery program: (a) Designing the Internet of Things to engage the ageing population (b) Crowd sourcing recreational birdwatchers to analyze big environmental data.
[people centered approach, data analysis, crowd sourcing, information and communication technology, technology rejection, Big Data, ICT intervention, technology acceptance, Australian Research Council Discovery program, Internet of Things, ICT development, big environmental data analysis]
Technology-Enhanced Assessment (TEA) in online education: Challenges and opportunities
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Summary form only given. Technology is used in all educational contexts (online and blended education) and especially in learning activities, both for teaching (the point of view of the teacher) and for learning (the point of view of the learner). Thus, assessment is becoming ever increasingly important and interactive tools are needed to facilitate it. Learning technologies open new opportunities for more personalized, authentic, and engaging assessment experiences. However, the use of digital technologies for assessment, referred to as Technology-Enhanced Assessment (TEA), has yet to transform most of the current practices which often replicate traditional assessment methods. In particular, to generalize new experiences and ways to conduct assessment, deliver feedback and enhance the learning experience is a main challenge. The potential of TEA brings to technologists, educators and designers very valued challenges and opportunities to explore.
[TEA, learning activity, assessment experience, online education, technology-enhanced assessment, educational context, teaching, blended education, learning technology, computer aided instruction, teaching activity, digital technology]
Health information exchange in the wake of &#x2018;big data&#x2019; paradigm &#x2014; The theme is from &#x2018;quality of information to quality of life&#x2019;
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Summary form only given. Health Information Exchange (HIE) is an interesting phenomenon. It is a patient centric health and/or medical information management scenario enhanced by integration of Information and Communication Technologies (ICT). While health information systems are repositioning complex system directives, in the wake of the `big data' paradigm, extracting quality information is challenging.
[patient centric health, health information systems, information management, HIE, Big Data, health information exchange, information and communication technologies, medical information systems, big data paradigm, ICT, health care, medical information management]
Mitigating information security risk in financial sector
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Summary form only given. Number of incidents of information security violations are increasing year by year. Organizations are now suffering more from data theft than from physical theft. Financial sector became an obvious target as &#x201C;that's where the money is&#x201D;. At the same time, companies are spending huge amounts of money trying to secure systems that are unlikely ever to be attacked. Hence the investigative journey into what is information security and how it encapsulate Information system security and broader sphere of other non-electronic formats of information. Then to share some real life examples of information security violations. Finally to discuss information security risk mitigation framework for financial sector.
[information security risk management, risk management, security of data, information security risk mitigation framework, information system security, financial sector, financial data processing, information format, information security violation]
Large scale data processing in real world: From analytics to predictions
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Summary form only given. Large scale data processing analyses and makes sense of large amounts of data. Although the field itself is not new, it is finding many usecases under the theme "Bigdata" where Google itself, IBM Watson, and Google's Driverless car are some of success stories. Spanning many fields, Large scale data processing brings together technologies like Distributed Systems, Machine Learning, Statistics, and Internet of Things together. It is a multi-billion-dollar industry including use cases like targeted advertising, fraud detection, product recommendations, and market surveys. With new technologies like Internet of Things (IoT), these use cases are expanding to scenarios like Smart Cities, Smart health, and Smart Agriculture. Some usecases like Urban Planning can be slow, which is done in batch mode, while others like stock markets need results within Milliseconds, which are done in streaming fashion. There are different technologies for each case: MapReduce for batch processing and Complex Event Processing and Stream Processing for real-time usecases. Furthermore, the type of analysis range from basic statistics like mean to complicated prediction models based on machine Learning. In this talk, we will discuss data processing landscape: concepts, usecases, technologies and open questions while drawing examples from real world scenarios.
[large scale data processing, Big Data, batch processing, targeted advertising, machine learning, Internet of Things, market surveys, smart health, urban planning, usecases, parallel processing, IBM Watson, IoT, MapReduce, stream processing, product recommendations, fraud detection, smart cities, distributed systems, complex event processing, Google Driverless car, smart agriculture, stock markets, statistics]
Reference architecture for a complex system of connected smart things in the enterprise
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Summary form only given. There are different smart things available in today's enterprises, designed with diverse processing capabilities (starting from 8 bit uC to multi-core uPs), ranging from handling specific simple tasks (sensing and actuation) to sophisticated duties. With today's diversified wired and wireless communication modes, these smart things can be easily connected to the enterprise IP network either directly or through network gateways. Once these millions of heterogeneous smart things are connected together, an enterprise wide complex system emerges. However in reality, it brings forth many technical challenges to be addressed, in order to attain expected business objectives.
[reference architecture, fortune 500 global enterprises, IP networks, enterprise wide complex system, business data processing, connected smart things, large-scale systems, enterprise IP network]
Dynamic 3D modelling of the human left ventricle
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Visualization and quantification of cardiac function is important in diagnosing and management of heart diseases. As quantitative analysis performed on the images is crucial to understand the heart mechanics, an accurate diagnosis of heart conditions can be done if clear visualization of ventricular volume, mass and function are obtained from echo-cardiograph images. This paper presents a technique to develop a dynamic three dimensional model of the left ventricle of the human heart to illustrate both the shape and motion of the ventricle along a cardiac cycle. The proposed methodology includes a multistage approach that involves a pipeline of image processing routines such as filtering, contrast stretching and binary morphology to isolate heart tissues. Subsequently, cubic spline curves are used to generate a smooth surface of the heart muscle using a set of control points extracted from the locations of boundaries of the heart muscle. A complete pulse included 40 images and it takes an average of 16.0665 seconds for the model to deform over a pulse.
[image processing routines, splines (mathematics), left ventricle, echocardiography, contrast stretching, image filtering, binary morphology, data visualisation, quantitative analysis, filtering, medical image processing, echo-cardiograph images, ventricular volume visualization, dynamic three dimensional model, dynamic 3D modelling, heart muscle, cardiac function quantification, heart disease diagnosis, heart disease management, dynamic modelling, diseases, heart tissue isolation, heart mechanics, human left ventricle, human heart, cardiac function visualization, cubic spline curves, cardiac cycle, multistage approach, solid modelling]
Locally adaptive isotropic detection of corners in object boundaries
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Detection of corners is an important task in computer vision to capture discontinuous boundaries of objects of interest. Present operators designed to detect boundaries having sharp corners often produce unsatisfactory results because the points detected can also be an isolated point, ending of a thin line or a maximum curvature region of a planar curve. A novel corner detection operator, capable of detecting corner points that exist only on the boundary of an object, is presented in this paper. Initially, candidate corner points are detected by exploiting local neighbourhood intensity information and associated connectivity pattern around the center point within a local window. Further verification is done to confirm whether the detected corner point is on the boundary of the targeted object. As the proposed operator is isotropic, it covers all the orientations and corner angles by performing a single computation step within the local window. The performance of the operator is tested with both synthetic and real images and the results are compared with other major corner detectors.
[corner detection operator, connectivity pattern, locally adaptive isotropic detection, computer vision, local neighbourhood intensity information, Object detection, object boundary, object detection, corner detection, boundary detection, Corner detection, Feature point detection]
Location estimation in a maritime environment using a monocular camera
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Maritime surveillance is a very important task in coastal areas, especially in harbour environments. The most popular such systems include components like Automatic Identification System (AIS) and Radar. Camera based visual surveillance can be used as an alternative to these systems in order to overcome the lacking features of them. Sea surface object detection and identification is a major need for such visual surveillance systems. Most of the current visual surveillance systems don't have the ability of identifying vessels in real time. A vessel can be identified using information from other systems, if the location of the vessel is identified. Location estimation of sea surface objects is mainly explored in this research. Video stream from a single geo stationary camera is used as the input; however camera properties are not used for any calculation. Mainly two distance measurements are considered and different approaches for estimating the distances are explored. Neural network approach gave considerably accurate results in vertical distance estimation and it was found that the shortest distance from camera to the object can be measured best using B-spline 3D curve fitting. Data taken from AIS is used for fitting curves and training neural network. After calculating distances, latitudes and longitudes are calculated. An evaluation has been done comparing the calculated values and the values obtained from AIS data using various statistical tests. There, the different approaches are compared and accuracy levels are described. Vessel identification is done comparing the estimated location and the available location information from AIS data.
[splines (mathematics), Distance Estimation, Maritime, geostationary camera, object detection, neural network approach, distance measurement, monocular camera, video stream, video surveillance, vertical distance estimation, location estimation, maritime surveillance, sea surface object detection, maritime environment, Monocular Vision, Location Estimation, Global Positioning System, ships, B-spline 3D curve fitting, statistical test, camera based visual surveillance, sea surface object identification, marine navigation, curve fitting, vessel identification, neural nets]
Frame feature tracking for speed estimation
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Frame feature tracking, relative pixel distance, relative pixel direction measurement and conversion of pixel distance to real world distance are the techniques used to estimate the speed of the vehicle. The balance between the performance and accuracy are the critical tasks in many existing speed detection techniques. In this paper, a novel speed estimation technique using feature tracking is presented. The main goal of this research is to increase the accuracy of the speed estimation while having an acceptable performance level. The proposed technique use feature tracking of subsequent image frames and estimate the speed using relative distance of the features. Experimental results with several traffic situations revealed that new technique has the desired accuracy with a satisfactory level of performance.
[image processing, pixel distance conversion, Feature Tracking, Region of Interest, Iron, traffic engineering computing, relative pixel distance measurement, Good Features, tracking, speed detection techniques, vehicle speed estimation, distance measurement, relative pixel direction measurement, traffic situations, velocity measurement, frame feature tracking]
Use of audio in software visualization
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
The concepts and processes of computer programs and algorithms are often found difficult to learn and teach. However, software visualization is an alternative tool to facilitate learning and teaching of those abstract and dynamic entities. In this study, experiments and interviews were carried out to explore the perceived utility of combining animations and text with audio in software visualization. The study thus examines whether learning and teaching can be improved regarding the understanding of basic concepts of object-oriented programming for beginner students by adding recorded verbal explanations. Two kinds of software visualization &#x2014; program visualization and algorithm visualization &#x2014; were investigated.
[Computers, student learning, student perspective, Visualization, Heuristic algorithms, Software algorithms, Education, Abstracts, Software, Software visualization]
E-assessment in high-level cognitive courses: Improving student engagement and results
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Introducing e-assessment in high-level cognitive courses is still a difficult issue, especially when adapting theoretical models and systems to real courses. One of the challenges is that most of the e-assessment tools offer simple types of questions such as Multiple Choice Questions (MCQ), which does not allow proper assessment for skills. Another challenge is to find an appropriate way to offer formative assessment in this type of courses through both practice and assessment facilities with personalized feedback. In this paper, a general e-assessment system and a formative e-assessment model for high-level cognitive courses are presented. They allow going beyond MCQ type of questions, and an easy adaptation to different learning scenarios. The model and the system are applied into an actual high-level cognitive course, a Logic course of a Computer Science degree program in a fully online learning environment. As a result, it showed that students' participation in the continuous assessment has increased. Overall when comparing students' results before and after the introduction of the e-assessment system, it shows that with the introduction of the system, students' performance, in terms of students' marks had improved.
[computer science education, e-assessment tools, high-level cognitive courses, student engagement, computer science degree program, learning scenarios, formative e-assessment, multiple choice questions, educational administrative data processing, general e-assessment system, logic course, formative e-assessment model, formative assessment, online learning environment, e-learning, educational courses, MCQ, computer aided instruction, high-level cognitive course, personalized feedback, virtual learning environments]
Creating m-learning opportunities to facilitate collaborative learning: A mobile SMS based Twitter implementation
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Mobile learning opens up for collaboration and sharing of contents. This study discusses the outcome of a mobile SMS based Twitter implementation to facilitate collaborative learning among a group of young farmers. The mobile learning approach (mLA) was developed in collaboration with the study community using a design based research process for a period of two years. The objectives of the study were to analyse the learning process based on constructivism learning theories, study the learner interactions in the mLA, the impact of mLA, and the potential uses of the mLA in collaborative learning. Data were collected using questionnaires, follow up discussions and through logged data in the devices. The data were analysed using descriptive methods, qualitative data analysis methods, and network analysis methods respectively. The mLA assisted learners to construct knowledge, and obtain useful feedback to reinforce learning through the interaction within mobile learning environment. The participants were satisfied with the mobile learning experience however there were some drawbacks needed to be addressed in the future. Since participants didn't have adequate previous experience, they faced some technical difficulties in receiving tweets in the mobile phones. Difficulty in moving for higher order learning skills and limited opportunities for collaborations due to SMS based platform and interface were the other drawbacks. Learners needed more technical support and assistance together with better interface to promote collaborative learning opportunities in the future.
[electronic messaging, mobile SMS, mobile phones, content sharing, Twitter, learner interactions, descriptive methods, groupware, network analysis methods, design based research process, data analysis, further education, mLA, constructivism learning theories, qualitative data analysis methods, Collaborative learning, mobile learning, content collaboration, m-learning opportunities, mobile learning approach, higher order learning skills, collaborative learning, SMS, social networking (online), Mobile learning, High definition video]
Establishing traceability links among software artefacts
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Artefact management in a software development process is a difficult problem in software engineering. Usually there is a wide variety of artefacts, which are maintained separately within a software development process such as requirement specifications, architectural concerns, design specifications, source codes and test cases to name a few. Artefact inconsistency is a major problem since these artefacts evolve at different rates. Maintaining traceability links among these artefacts and updating those artefacts accordingly can be a solution to address artefact inconsistency. There is a need for establishing these artefact traceability links in semi-automatic way. Proper management and visualization tool is required for effective software artefact management in an incremental software development. We provide a prototype tool to establish artefact traceability links and visualization. This paper describes the research methodology and relevant research carried out for semi-automatic traceability link establishment and visualization of software artefacts.
[software development process, incremental software development, Traceability Links, Traceability Management, software maintenance, software artefacts traceability links, semiautomatic traceability link establishment, Software Artefacts, software artefact visualization, Visualisation, software engineering, program visualisation, software artefact management]
Best practices for rapid application development of AJAX based Rich Internet Applications
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
AJAX is a powerful script based approach for Rich Internet Application development, yet AJAX is suffering from various complexities which make the AJAX based Rich Internet Application engineering is difficult and Rapid Application Development is supported inadequately. If we can simplify the AJAX based Rich Internet Application engineering process by providing standards, the Rapid Application Development methodology can be used effectively to raise the productivity and the quality. In this paper, we propose a set of best practices to facilitate the project management of AJAX based Rich Internet Applications - hence utilize Rapid Application Development methodology - in the initial development and post-deployment maintenance, modification and expansion phases. These best practices are meant to increase the realization of the Rich Internet Application and the AJAX adoption - therefore reduce the complexities - by providing a standard structural arrangement for the development project. We plan to design a general architecture for AJAX based Rich Internet Applications and combine with the best practices discussed in this paper to formulate a new platform to support the Rapid Application Development methodology adequate, by increasing the realization, which causes to minimize the complexities.
[project management, software development management, rich Internet applications, Rich Internet Applications, software maintenance, rich Internet application engineering, rapid application development, structural arrangement, Rapid Application Development, rich Internet application development, Best Practices, post-deployment maintenance, script based approach, Internet, AJAX]
Crowdsourcing towards User Experience evaluation: An intelligent user experience questionnaire (IUEQ)
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Smartphones have become one of the leading devices with advanced computing capability. User Experience (UX) design involves in improving customer satisfaction in any product including smart phones. This research aims to promote collaboration among Android smartphone users, who held the highest percentage of market share among the existing popular mobile operating system by the year 2013[1] allowing them to cooperate within the complex, resource expensive and iterative UX design process using a crowdsourcing approach. The paper discusses the encountered challenges with the existing collaborative platforms of achieving collaboration and the techniques which have been taken to overcome those challenges. Further this research discusses on how crowdsourcing can be used in User Interface (UI) design evaluation based on the UX User Centered Design (UCD) matrices; an intelligent system of generating UX questionnaire is presented.
[collaborative platforms, user experience evaluation, UX UCD matrices, User Experience, UX design, Android smartphone users, user interface design evaluation, intelligent user experience questionnaire, Android (operating system), mobile computing, customer satisfaction, groupware, smartphones, computing capability, User Centered Design, user centred design, UI design evaluation, Human Computer Interaction, Crowdsourcing, crowdsourcing, smart phones, UX questionnaire generation, mobile operating system, UX user centered design matrices, User Experience Questionnaire, user experience design, outsourcing, IUEQ, intelligent system]
An efficient discrete model for implementing temporal coding spiking neural network
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Spiking neurons, which makes up SNNs are more biologically realistic artificial neurons which convey information by the timing of spikes. SNNs have been applied for various learning tasks and they are capable to perform with improved accuracy in less number of training cycles. Due to the temporal nature a spiking neuron cannot be implemented as a standard neuron. Generally spiking neurons are implemented as a discrete model and the output is computed through an iterative process. Here, each iteration is assumed to take one unit time. Even though the learning models of SNNs can learn in less number of cycles, they consume more computational resources due to the large number of iterations they require. This paper proposes a numerical approach using Newton-Raphson method to estimate the firing time of a spiking neuron in lesser number of iterations. Proposed model was implemented and analysed to test its accuracy, convergence and capability for learning. Tests were performed using the Iris plants dataset and Breast cancer dataset from UCI Machine learning repository. The proposed model was able to find the actual neuron firing time within only a few iterations. Tests have shown that for the proposed approach the required iterations needed to estimate the firing times to an accuracy of two decimal places would be at least 400 fold lesser compared to the standard approach. Number of required iterations found to be independent of the firing time in contrast to the standard approach. The model also found to be smoothly converges in finding the actual firing time. Further the model was tested to cluster Iris and Cancer data sets and the accuracy was found to be 92.7% and 97.4 % respectively. The results demonstrate that the limitation of estimating the actual firing time with less computational resources can be resolved using the proposed discrete approach. This would pave way to devise better learning algorithms for SNNs with even higher accuracy and low training cycles.
[iris plants dataset, Newton-Raphson method, learning task, Spiking Neural Networks, Temporal coding, breast cancer dataset, iterative process, learning convergence, learning accuracy, Numerical approximation, SNN, Hafnium, UCI machine learning repository, data handling, biologically realistic artificial neuron, learning (artificial intelligence), temporal coding spiking neural network, discrete model, SNN learning model, learning capability, neural nets]
A novel approach to automate surrounding ships in a virtual maritime environment
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Full mission marine training scenarios are essential in training marine trainees with ship handling simulators. In a good training simulation not only the static environment but also the dynamic surrounding ships plays a major role in terms of behaviour realism. The surrounding ships also need to navigate according to COLREG (Convention on International Regulation for Preventing Collisions at Sea) navigational rules. This research presents a novel approach to automate the surrounding vessels in a marine simulation environment with a central controller to control the behaviours of each surrounding vessel in the marine environment. The controller uses positioning data of real ships which are derived from a set of historical Automatic Identification System (AIS) data and map the positioning data with the surrounding ships in virtual environment to obtain the navigation. An Ant Colony Optimization (ACO) algorithm is used to avoid the collisions by generating a new path when both trainee's ship and surrounding ships are in the vicinity of each other. The collision handling mechanism uses COLREG rules. The ACO algorithm generates successful collision avoided paths in all head-on, crossing and over-taking encountering situations. The number of turning points is used to measure the smoothness of the path and number of obstacles in the environment and number of nodes in the graph affects the smoothness of the path. With these results it is revealed that AIS data can be used as an assistant to automate surrounding vessels in a virtual maritime environment together with a proper collision avoidance mechanism.
[collision avoidance, virtual reality, autonomous navigation, target ships, surrounding ships, ACO algorithm, over-taking encountering situations, head-on situations, surrounding vessels, Automatic Identification System, Convention on International Regulation for Preventing Collisions at Sea, Radio frequency, ship handling simulators, ant colony optimization, collision handling mechanism, ant colony optimisation, central controller, Ant Colony Optimization (ACO), crossing situations, AIS, marine simulation environment, historical AIS data, ships, virtual maritime environment, COLREG navigational rules, marine navigation, surrounding ships automation]
Modelling altruistic and selfish behavioural properties of Ant Colony Optimisation
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Cooperativeness/competitiveness and altruism/selfishness are two key pairs of factors that could be adopted by natural algorithms in order to experience significant variations as well as to improve the quality of the existing solutions. Identifying the individual and social components separately and fine tuning the use of said behaviours of natural ants is worth investigating with regards to the behaviours of artificial ants in Ant Colony Optimisation. According to the experimental results of this study, it can be shown that the solutions are affected by these two key pairs of factors of ants and the colonies while their corresponding influences can make differences in the solution quality of the algorithm. This research has attempted to adapt the said behaviours of ants to solve two general issues of Evolutionary Algorithms, decreasing the delay in convergence and premature convergence. Travelling Salesman Problem is used as the reference problem.
[Adaptation models, evolutionary algorithms, Ant Colony Optimisation, travelling salesman problem, Statistics, Game theory, Optimization, Convergence, Travelling Salesman Problem, evolutionary computation, altruistic behavioural properties, premature convergence, Social component, Sociology, Games, Individual component, selfish behavioural properties, ant colony optimisation]
Genetic programming tuned fuzzy controlled traffic light system
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
A blend of fuzzy logic and genetic programming is used in this research to achieve a single fine-tuned fuzzy rule, upon giving hundreds of fuzzy rules as the input. The system has Poisson arrival rate of vehicles, and decisions are taken to alter the sequence of lights based on the queue lengths of the lanes. The traffic simulator handles routing of vehicles in a single four-leg intersection with left and right turns. The fuzzy logic traffic controller system is used to generate the simulation data to feed the genetic programming system. The genetic programming system then creates an optimum fuzzy rule. This fine-tuned fuzzy rule is proven to be qualitatively better with respect to the mean square queue length and its error of the total system at any given point of time.
[Out of order, genetic programming, traffic controller system, fuzzy logic traffic controller system, road traffic control, fuzzy logic, traffic simulator, fine-tuned fuzzy rule, genetic algorithms, Integrated circuits, fuzzy control, vehicle routing, Poisson arrival rate, optimum fuzzy rule, tuned fuzzy controlled traffic light system]
Next generation smart transaction touch points
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
In a rapidly evolving world financial transactions opportunities have become inseparably linked with advanced Information Technology. This paper presents the integration of a NFC (Near Field Communication) enabled mobile wallet with a NFC enabled payment card as a next generation smart transaction. The objective of the research is to provide customers of a financial institute/bank with a mobile application to perform banking transactions while enabling merchant payments through a NFC enabled SMART card. This solution introduces a new local initiative for enabling NFC based mobile payments which will promote the acceptance and adoption of NFC technology in Sri Lanka. This in turn will provide flexibility, mobility and control to consumers who use cashless payment mechanisms. Our solution will also address the problem of merchants and banks needing to generate and process paperwork, as receipts and promotions are delivered to the customer digitally. The uniqueness of this research is the integration of NFC enabled card and the mobile wallet, which has not been offered by any existing mobile wallet vendors in the market and eliminating transaction fees currently paid to international merchants. This solution will enable local economic growth and at the same time promote greener initiatives while encouraging the general public to utilize and obtain the advantages of the latest technology advancements. This paper elaborates the research carried out with respect to NFC and mobile wallets, and present the design and the features of our Next Generation Touch Points Solution.
[Smart cards, next generation smart transaction touch points, information technology, local economic growth, smart cards, Mobile communication, Mobile handsets, NFC, Security, Next generation networking, financial institute, mobile computing, NFC enabled smart card, NFC enabled payment card, Green Banking, Mobile Wallet, mobile wallet, Sri Lanka, Banking, mobile application, banking transactions, cashless payment mechanisms, financial transactions, merchant payments, near-field communication, Green products, near field communication, bank data processing]
Business intelligence in relation to other information systems
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Business intelligence (BI) systems are one of the major computing trends during the last ten years, in developed as well as developing countries. However, as often witnessed, the implementations are to a large extent not very successful. Our concern in this paper is the decision support role of BI systems, the perceived business value of implemented systems, and their contribution to facilitate the fulfilment of organisational goals. The study builds upon deep interviews with managers in combination with a previous quantitative survey. The survey and the interviews used three categories of questions: 1) how visions, objectives, strategies are supported by BI systems; 2) how business values are derived from such systems; and 3) how design and implementation issues affect the solutions. The overall conclusion of the study is that there are major problems in all three areas although not equally dire. What clearly emerges is that much of the problems encountered come from failing to appreciate the different nature of BI systems compared to support systems for daily operational processes. Thus, a fundamental reason for BI projects not succeeding entirely is that they are being wrongfully treated as just another kind of traditional information systems.
[decision support role, BI system, information systems, decision support, competitive intelligence, business value, Business intelligence, business intelligence, decision support systems]
Web based project collaboration, monitoring and management system
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
The software project is a highly people intensive effort that spans over period of time, with the fundamental implications on work and performance of many different teams. The success of a project is heavily relying on timely transfer of information among the parties involved such as project managers, team leaders, developers, designers and clients. In present scenario most of the software companies works on multiple projects simultaneously, therefore there need to be an efficient project management procedure in term of resource allocation and project planning. Web Based Project Collaboration, Monitoring and Management System provides a solution by automating project management functionalities which covers all the aspects of project management process including document management, resource management and team collaboration. The system addresses the functionalities such as assessment of actual progress, team collaboration, update feedback with email and short messages, server login manager, customer portfolio manager, invoices with online payment option and the important aspect is that it provides management reports, which will lead to effective decision making.
[resource management, customer portfolio manager, document management, team working, resource allocation, invoices, project management functionalities automation, email, WebPCMM system, project management, software companies, DP industry, software development management, server login manager, management reports, software project, Web Based Project Collaboration Monitoring and Management System, Project Management Project Monitoring Project Collaboration, update feedback, short messages, actual progress assessment, online payment option, computerised monitoring, Internet, project planning, team collaboration]
Ads-In Site: Location based advertising framework with social network analyzer
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Social networks contain a vast amount of data that holds very valuable information and is nowadays identified as a very effective source in marketing. The content of social networks can be used to identify the business needs and preferences of people. This research is carried out with the aim of providing suitable advertisements for people based on their preferences by analysing their social network content. Users' demographic details are also considered in providing suitable advertisements of the shops that are most conveniently located for a particular user. The primary goal of this research is to build an advertisement framework that supports targeted advertising by analysing social network content. The information extracted by analysing the content of social networks is used to predict the advertisement categories that interest a particular user. The framework applies location based services to filter advertisements based on the location of the shop.
[social network content analysis, advertisement category prediction, advertising data processing, ads-in site, business needs, location based services, Location based Services, Support Vector Machines, Target Advertising, marketing, mobile computing, advertisement filtering, Social Networks, social networking (online), user demographic details, location based advertising framework]
Framing services based on value activities in healthcare
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Present-day successful ICT deployments in any sector heavily depends on accurate and complete service designing and then deployment in domains with relevant technical environments. In healthcare service sector, ever increasing specialties, large number of providers offering wide spectrum of services and associated highly complex service coordination in networked environments intensified the pressure on stakeholders of service-solution development workflow. The research work presented in this paper is partial contribution in getting established framework for systematic facilitation and guidance for healthcare service designers to achieve the success. Such a framework should assist different modeling layers in service-solution development ranging from higher motivation levels to lower technical realizations. In order to achieve this business/IT alignment, notion of "Value" has been introduced covering broader aspects gluing aforementioned layer focuses while ensuring bi-directional traceability between such modeling layers. Introduced value actor, value activity, value object and associated classification schemas are the central contribution of this research. Further, we have briefly demonstrated the applicability of this approach in simple case study. Our initial intuition through the completed case study is this approach assists service designers in early identification of correct and complete services, then to design and deploy with guaranteed successful service solutions.
[pattern classification, healthcare value activities, value object, service-solution development, business-IT alignment, Value Activity, value activity, Value Object, healthcare service designers, classification schemas, e-Services, value engineering, value actor, High definition video, Goals, medical computing, health care]
A simulation approach for reduced outpatient waiting time
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Extended waiting time for treatment in National hospitals is very common in Sri Lanka. This situation has created several problems to patients, doctors and even to other health workers. The quality of service leaves a lot to be desired and is costly to the economy. This study analyses different queues which create bottlenecks in the Out Patient Department at national eye hospital in Sri Lanka and critically evaluate several appointment scheduling rules with the help of a simulation model to come up with a solution which minimises the total patient waiting time. Our results shows that total patient waiting time can be reduced more than 60% using proper appointment scheduling system with process improvement.
[hospitals, extended waiting time, out patient department, OPD, waiting time, Sri Lanka, simulation, national hospitals, Iron, process improvement, national eye hospital, appointment scheduling rules, reduced outpatient waiting time, scheduling, total patient waiting time, medical administrative data processing, simulation approach]
Versatile inter system information exchange facilitator [VISIEF]
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
No longer application systems operate as standalone applications. They are interconnected with various other businesses applications. This helps data interoperability among systems. Connectivity and data transmission may function in real time or batch/offline basis. Offline data transmission is very common in today's business applications. In addition to day-to-day business operations, this is widely used in data migrations, data warehouse data populations and many more. Offline data transmission is performed using flat files (.csv, .txt etc.) and these are in different formats for different business functions. Hence, transformation process (processing the data files) can be very different from one business function to another. This influences the organizations to write hundreds of transformation scripts/program codes for hundreds of file formats. Further, this brings enormous difficulties when modifying the file format with respect to the time and the development effort. Versatile Inter System Information Exchange Facilitator(VISIEF) is a novel software tool which assists business organizations by eliminating or minimizing the script writing in data exchange using flat files. Further, this provides a range of value adding features which improves the staff efficiency.
[Data interoperability, Data migration, open systems, data exchange, script writing minimization, data interoperability, Versatile Inter System Information Exchange Facilitator, VISIEF, Offline data exchange, business organizations, electronic data interchange, software tool, software tools, business data processing]
Natural language dependencies for ontological relation extraction
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Natural Language Processing techniques play an essential role in extraction of necessary information for ontology construction from unstructured text. Identifying syntactic constituents and their dependencies in a sentence, boost the information extraction from natural language text. Main ingredients required for ontology construction are required to be extracted from text in the form of entities and relations between them. Language dependency constructs that express the binary dependencies of the lexical terms in a sentence can be considered as good indicators in identifying binary relationships existing between entities. In this paper we describe that how the typed dependencies produced by a natural language parser are used by a multi agent system to generate rules for relation extraction between two identified entities. The typed dependencies produced by parsing are processed to eliminate unnecessary dependencies and make them more appropriate to be used in rule learning for relation extraction. All the relations derived are expressed as predicate expressions of two entities. We evaluate our agent system by applying it on number of wikipedia web pages from the domain of birds.
[ontological relation extraction, text analysis, multi-agent systems, unstructured text, rule generation, Ontology, lexical terms, typed dependencies, multiagent system, Wikipedia Web pages, natural language dependencies, syntactic constituent identification, learning (artificial intelligence), Agent, rule learning, natural language processing, knowledge acquisition, binary relationship identification, natural language parser, Relations, natural language text, binary dependencies, language dependency constructs, Annotation, Parser, Entities, information extraction, grammars, Tagging, ontologies (artificial intelligence), ontology construction, Typed Dependencies]
User centered ontology for Sri Lankan agriculture domain
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
People working in the agriculture domain in Sri Lanka are affected by not being able to get vital information required to support their domain related activities in a timely manner. Some of the required information can be found in government websites, agriculture department leaflets, newspapers, etc. The required information is hard to find from these knowledge sources due to its unstructured, incomplete, varied formats, and lack of targeted delivery methods. Thus finding the right information within the context in which information is required in a timely manner is a challenge. The required information and relevant knowledge needs to be provided not only in a structured and complete way, but also in a context-specific manner. To investigate some of the underlying research challenges an International Collaborative Research Project to develop mobile based information systems for people in developing countries was launched. User centered Ontology was developed as a part of this project. We developed a new approach to model the domain knowledge to meet particular access requirements of the users in agriculture domain in Sri Lanka. Through this approach, we have investigated how to create a knowledge repository of agricultural information to respond to user queries taking into account the context in which information is needed by them at various stages of the farming life cycle. The Delphi Method, Modified Delphi Method and the OOPS! (web-based tool) were used to validate the quality of the ontology. Initial system was trialed with a group of farmers in Sri Lanka. The online knowledge base with a SPARQL endpoint was created to share and reuse the domain knowledge that can be queried based on user context. A semi-automatic end-to-end ontology management system was developed to manage the developed ontology as well as the knowledge base. It provides the facilities to reuse, share, modify, extend, and prune the ontology components as required.
[OOPS!, Sri Lankan agriculture domain, agricultural information, user centered ontology, Knowledge Modeling, Ontology, query languages, Agricultural Information, Delphi method, agriculture, query processing, user query response, SPARQL endpoint, forecasting theory, knowledge based systems, knowledge repository, Ontology Management, knowledge source, ontologies (artificial intelligence), online knowledge base, Contextual Information, user centred design]
Baseline analysis of 3 innovation ecosystems in East Africa
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
The potential impact of technology innovation supporting social and economic development in developing countries is very dependent on the level of maturity of National Innovation Ecosystems (including policy environment, infrastructure and socio-economic diversification). Kenya, Tanzania and Uganda have recently experienced considerable technological entrepreneurial growth, facilitated by Innovation friendly regulatory environments, evolution of National Research Education Networks (NReNs) and rollout of Obre optic backbones. However, while it is clear that ICT, Job Creation and developing a Knowledge Economy are common policy priorities, the Innovation Ecosystems in Nairobi, Dar es Salaam and Kampala are still fragmented. Innovation Spaces are insufficiently differentiated and have sustainability challenges with their business models and there is a limited funding and entrepreneurship support as well as insufficient collaboration and coordination between Stakeholders. This paper analyses these Innovation Ecosystems and provides some recommendations about how these challenges can be addressed.
[Technological innovation, technological entrepreneurial growth, Ecosystems, innovation space, Africa, Tanzania, economic development, Mobile communication, National Innovation Ecosystem, NReN, technology innovation, Kenya, Collaborative Open Innovation, ICT4D, Training, Innovation management, Uganda, innovation management, social development, National Research Education Networks, business data processing, East Africa]
Commercializing university research outcomes: A Sri Lankan experience
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Sri Lankan government has taken a policy decision to develop the country as a knowledge hub in Asia. Universities have a pivotal role in realizing this goal and they have the responsibility to contribute new knowledge, through innovation and research, towards the economic development. Research culture in the Sri Lankan universities is gradually developing and there have been several research projects that resulted in commercializable innovative outcomes. However, commercialization is a challenging task due to several reasons and only a few significant outcomes of the university research have been successfully commercialized. Commercialization challenges are an integral part of the universities and research institutes and they are looking for pragmatic solutions. In developed and industrialized countries, it is now widely accepted that the research outcomes of universities plays an important role in the economic development and it is quite common for the industry to work in collaboration with the universities to innovate and find solutions to their problems. However, this is not the case in Sri Lanka and due to this there is a large gap between the university research outcomes and industry expectations. In this paper, as a case study, we present our experience in taking the outcome of a university research project and adapting it to solve a problem faced by two entities responsible for handling maritime traffic in Sri Lanka. We have productized the research outcome to a large extent and deployed it to handle a real world problem. While we cannot claim that it is fully commercialized yet, we have bridged the gap between the expectations of the real world users and the researchers at the university. Also, in this paper we explore how other countries have handled the problem of commercializing research projects as well as the Sri Lankan effort in this regard.
[maritime traffic handling, Sri Lankan universities, research institutes, economic development, knowledge management, Sri Lankan government, research and development management, Asia, Strategies, research commercialization, university research outcomes, Developing Countries, educational institutions, Research Innovations, knowledge hub, Commercialization, university research project]
SME EIS adoption: Towards development of EIS for SMEs in Sri Lanka
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Small and Medium Enterprises (SMEs) compose a large portion of Sri Lankan economy due to their significant contribution in terms of employment, domestic resource usage, innovation, exports, regional development, and stimulating other economic activities. This sector is believed to be the `backbone' of both developed and developing economies. Therefore healthy performance of SME sector is paramount important in economy of any country. The businesses, irrespective of their scale of operation, are digitizing rapidly, to enhance their presence and delivery. The information systems have become a smart approach of exploiting in this digitization. However, necessitate of these `chief players' in the economy have been ignored by majority of Enterprise Information System (EIS) applications. The paper first identifies and prioritises factors that determine SMEs willingness and attractiveness towards EISs, using TOE (Technology-Organisation-Environment) Framework following recommendations EIS vendors, SME and IT policy makers can adapt to address the gap in current level and the potential for SME EIS adoption in Sri Lanka. The research findings will assist SMEs to create business opportunities with information management and reconcile pressures from competition. Further specific SME ICT needs to be addressed strategically, in order to ensure their competitive position in the economy, will be discussed.
[SME ICT, information management, Sri Lanka, small-to-medium enterprises, SME, TOE Framework, economy, TOE, Enterprise Information Systems/EIS, SME EIS adoption, SMEs, enterprise information system applications, small and medium enterprises, information systems, technology-organisation-environment framework, IT policy, business data processing, organisational aspects]
Adoption of SaaS enterprise systems &#x2014; A comparison of Indian and Australian SMEs
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
SaaS enterprise systems (ES) are the best opportunity for Small and medium-sized enterprises to take advantage of their generic benefits without the investment costs associated with on-premise models. Using a multiple-case study approach, this study analyses and compares the challenges in the adoption of SaaS ES in Australia and India. Vendor's reputation, software fit to business and accounting shift of costs are common triggers for adoption in both countries. Over reliance on the advice from external stakeholders, higher concern for security of the data, customizability of the software and relative importance to relationship management are the key differences.
[Indian SME, small and medium-sized enterprises, vendor reputation, data security, SaaS, small-to-medium enterprises, Enterprise systems, case studies, SaaS enterprise systems adoption, Australian SME, software customizability, security of data, adoption, relationship management, cloud computing, business data processing]
Sentence similarity measuring by vector space model
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
In Natural Language Processing and Text mining related works, one of the important aspects is measuring the sentence similarity. When measuring the similarity between sentences there are three major branches which can be followed. One procedure is measuring the similarity based on the semantic structure of sentences while the other procedures are based on syntactic similarity measure and hybrid measures. Syntactic similarity based methods take into account the co-occurring words in strings. Semantic similarity measures consider the semantic similarity between words based on a Semantic Net. In most of the time, easiest way to calculate the sentence similarity is using the syntactic measures, which do not consider grammatical structure of sentences. There are sentences which have the same meaning with different words. By considering both semantic and syntactic similarity we can improve the quality of the similarity measure rather than depending only on semantic or syntactic similarity. This paper follows the sentence similarity measure algorithm which is developed based on both syntactic and semantic similarity measures. This algorithm is based on measuring the sentence similarity by adhering to a vector space model generated for the word nodes in the sentences. In this implementation we consider two types of relationships. One of them is relationship between verbs in the sentence pairs while the other one is the relationship between nouns in the sentence pairs. One of the major advantages of this method is, it can be used for variable length sentences. In the experiment and results section we have been included our gain with this algorithm for a selected set of sentence pairs and have been compared with the actual human ratings for the similarity of the sentence pairs.
[text analysis, natural language processing, Semantic Similarity, data mining, vector space model, semantic structure, StanfordCoreNLP, WordNet, Word Similarity, vectors, Syntactic Similarity, hybrid measures, syntactic similarity measure, semantic net, text mining related works, Sentence Similarity, Manganese, sentence similarity measurement]
Morphological analyzer and generator for Tamil Language
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Morphological analysis is an essential component in Natural Language Processing (NLP) applications ranging from spell checker to machine translation. When performing a morphological analysis it leads to segmentation of a word into morphemes, combined with an analysis of the attachments of these morphemes. In English language the complexity of the formation of words is not much higher compared with Indic languages. Hence, Tamil language too does have its complexities when building up a NLP application. The morphemes in the language, the rules how these morphemes are connected and the changes occur when they attach together are the important factors that need to be considered when building up a Morphological Analyzer for any language. Our &#x201C;Morphological Analyzer and Generator for Tamil Language&#x201D; will be generating the word forms of a stem/ root, given a particular context and at the same time, a surface form in Tamil language should get analyzed into its proper context. This model tries to cover only the nouns and verbs in the Tamil language. This paper illustrates how the lexicon and the orthographic rules of Tamil language have been written as regular expressions using only finite state operations and how this approach has been implemented to develop a morphological analyzer/generator. This model is built using the Xerox toolkit, which uses &#x201C;Two-level Morphology&#x201D;, and almost 2000 noun stems and 96 verb stems have been incorporated into the network. A noun stem now produces about 40 different forms and a verb stem produces up to 240 forms. We have also defined our own transliteration scheme for this purpose.
[morphological analyzer, Finite State Transducer, Tamil Morphological Analyzer and Generator, natural language processing, finite state machines, Tamil language, morphemes, morphological generator, spell checker, finite state operations, word segmentation, NLP, orthographic rules, two-level morphology, Morphology, machine translation, regular expressions, Xerox toolkit, Regular Expressions, transliteration scheme, lexicon, language translation]
A shallow parser for Tamil
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
This research is an attempt to build a shallow parser designed to assign a partial structure to natural language sentences in order to recover useful syntactic information from Sri Lankan Tamil sentences. It uses a combination of a maximum entropy based part-of-speech (POS) tagger which automatically labels each word in a sentence with the appropriate POS tag, and a rule-based chunker which segments the sentences into syntactically correlated word groups, without the need for a large annotated corpus. To do this, we developed a POS tagset consisting of 20 POS tags using expert input, manually annotated a corpus of approximately 12500 words, and identified 390 chunk patterns to extract the chunks. Our POS tagger and chunker demonstrated promising f-measures of 81.72% and 78.3% respectively. Our combined shallow parser gives an f-measure of 66.6% owing to error propagation.
[POS tagset, natural language sentences, natural language processing, corpus annotation, shallow parser, partial structure, Chunking, Maximum Entropy Model, Sri Lankan Tamil sentences, f-measure, Three-dimensional displays, POS tagger, grammars, useful syntactic information recovery, Shallow Parsing, rule-based chunker, maximum entropy methods, maximum entropy based part-of-speech tagger, Tamil Language Processing, Partial Parsing, Part-of-speech Tagging, Manganese]
An efficient transport layer protocol with reduced packet losses and minimized retransmission time in wireless networks
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
This research will design and develop a protocol that supports less packet drops and consumes a low retransmission time which is able to transmit data in a speedy and efficient manner within a wireless environment. This is vital in real time systems; specifically in way finding applications in order to gather critical information of patients, evade hazardous situations for disable persons, and receive alternative paths in navigation systems in instances of impediments. This research examines the existing Transport Layer Protocols (TLP's); mainly TCP since it has a high rate of data packet loss and high retransmission time when operating in wireless networks. This paper proposes two modified algorithms that solves high packet loss rate by avoiding buffer overflows and high retransmission time by applying a spaced hop methodology. The simulations are performed through the Network Simulator 2 software operating on the Linux platform (Ubuntu) and will graphically and statistically display the improvement achieved by the modifications.
[Computers, Protocols, buffer overflows, spaced hop, Wireless networks, Packet loss, retransmission time, Buffer overflows, Way finding applications, packet loss, Transmission Control Protocol, Information technology]
Enhanced bag-of-words model for phrase-level sentiment analysis
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
We propose a novel rule-based model to incorporate contextual information and effect of negation that enhances the performance of sentiment classification performed using bag-of-words models. We employed morphological analysis in feature extraction to ensure feature vector contains only opinionated words in a textual review. Also it reduces the dimensionality of feature vector and, eventually improves the efficiency of the classification algorithm. Further, we consider grammatical relationships to incorporate the context of adjectives and scope of negations within a phrase, to the feature vector. This enables our model to capture contextual polarity of adjectives and impact of negation words. For the morphological analysis we mainly employ Part Of Speech taggers (POS taggers) and grammatical relationships which are obtained using typed dependency parsers. By using dependency-based rules, we relax the conditional independent assumption of bag-of-words models by way of combining adjectives and negations to identified target words and, hence obtain a sentiment classification accuracy that significantly better than baseline performance.
[Sentiment analysis, bag-of-words model, rule-based model, classification algorithm, part of speech taggers, grammatical relationships, negation words, typed dependency parsers, adjectives, Analytical models, Accuracy, dimensionality reduction, feature extraction, Context, pattern classification, phrase-level sentiment analysis, POS taggers, natural language processing, performance enhancement, sentiment classification accuracy, sentiment analysis, conditional independent assumption, dependency-based rules, contextual information, contextual polarity, textual review, feature vector, vectors, grammars, Support vector machine classification, Feature extraction, bag-of-words, Context modeling, morphological analysis]
Named entity recognition for Sinhala language
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Named Entity Recognition (NER) is one of the major subtasks that have to be solved in most Natural Language Processing related tasks. However it is very much challenging to build a proper Named Entity Recognition system especially for Indic languages such as Sinhala because of the language features it inherits such as the absence of capitalization. Since there has not been much previous work based on NER for Sinhala, the concept and the needed resources have to be built from scratch. This paper tries to find out the effectiveness of using data-driven techniques to detect Named Entities in Sinhala text. Conditional Random Fields (CRF) and Maximum Entropy (ME) model were applied to this task. It is found that the former outperformed the latter in all experiments. A CRF model is able to detect Sinhala Named Entities with a very high precision (91.64%) and reasonable recall (69.34%) rates.
[text analysis, Sinhala language, Named Entity Recognition, natural language processing, probability, Conditional Random Fields, Named Entity, Natural Language Processing, named entity recognition, maximum entropy model, Maximum Entropy model, data-driven technique, conditional random field, CRF, ME model, DH-HEMTs, Hafnium, Sinhala Language, maximum entropy methods, NER, IP networks, Electronics packaging]
Retrieving abstract information from multi-party conversations
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
This paper presents the use of dialog acts and addressee information in extracting domain-specific abstract information from multi-party conversations. Identification of dialog acts and addressee information is done in a domain-independent manner. This information is then used with a domain-specific rule set for identifying abstract information in chat conversations. To retrieve abstract information from a conversation in a new domain, the only requirement is to define a new rule set. This eliminates the need of domain-specific corpora. This paper also presents an improved version of a commonly used addressee recognition algorithm.
[abstracting, natural language processing, domain-specific rule set, information retrieval, Data structures, abstract information retrieval, addressee information, Noise measurement, machine learning, dialog act recognition, rule-based algorithms, dialog acts, Boolean functions, multiparty conversations, addressee recognition algorithm, interactive systems, addressee recognition, domain-specific abstract information, learning (artificial intelligence), chat conversations]
Smart web content bookmarking with ANN based key phrase extraction algorithm
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
This paper introduces a smart web content bookmarking tool which gives the ability of bookmarking only a selected text other than bookmarking whole pages and keeping a set of links relevant to those pages for later reference. This novel concept helps to collect most important text and paragraphs into one place for the ease of use. The major component of this research is the use of an artificial neural network (ANN) with author identified parameters especially applicable in the domain of small textual contents to extract the key idea of the selected text and to organize bookmarked contents under this system suggested meaningful names. Key phrases are an important mean of document summarization and the manual assignment of key phrases to documents is very laborious. The purpose of this neural network approach is to automate this extraction process and bookmark a selected paragraph with extracted key idea using the developed key phrase extraction method with artificial intelligence. The front end of Smart Web Content Bookmark is developed as a browser extension so that the web users can extend their browsers with it to experience the efficient and meaningful bookmarking method in web.
[artificial neural network, key phrase assignment, Bookmarks, document summarization, information retrieval, feature extraction process, Key Phrase Extraction, artificial intelligence, ANN based key phrase extraction algorithm, Artificial Neural Network, key phrase extraction method, Internet, neural nets, author identified parameters, smart Web content bookmarking]
Empirical network jitter measurements for the simulation of a networked control system
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Delay variation or jitter is an inherent feature of packet switched communication networks due to bottlenecks. In communication systems buffering is commonly used to mitigate in real time multimedia applications at the expense of an additional delay. This method is therefore not suitable for control systems implemented over packet switched communication networks due to the additional delay which can make the system unstable. Hence, jitter modelling and management is necessary. This paper focuses on the development and experimental verification of a suitable jitter model for wireless and wired network bottlenecks. The effects of jitter are then investigated by quantifying the performance of a simulated Networked Control System (NCS). According to the results, the reduction in attenuation due to jitter compared to a jitter free benchmark ranges from approximately 0.01-0.04dB depending on the encoding type.
[radio networks, Networked control systems, multimedia applications, packet switching, delay variation, networked control system simulation, Jitter, buffering, wired network bottleneck, Wireless communication, empirical network jitter measurements, jitter management, Attenuation, Communication networks, self similarity, attenuation reduction, communication networks, Encoding, packet switched communication networks, cyber-physical systems, jitter, wireless network bottleneck, encoding type, networked control systems, jitter modelling, Delays, NCS]
An adaptive routing protocol with congestion avoidance for opportunistic networks
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Routing and forwarding of messages towards destinations in opportunistic networks is a challenging task due to the topological uncertainty caused by node mobility and frequent disconnections between node pairs. One of the recently proposed adaptive routing protocol [1] for opportunistic networks makes informed forwarding decisions based on the expected level of connectedness and the predictability of nodes as determined heuristically on the past history of contacts [1], [2]. Though this kind of forwarding in adaptive routing increases the final delivery probability, some nodes in the network will have to devote more of their resources than others as popular nodes often get congested with too many messages to store and carry, and be forced to drop incoming messages. In opportunistic networks, when congestion occurs at intermediate nodes messages get dropped and will not be forwarded towards their destination. In this paper we propose, implement and evaluate the performance of an enhanced congestion aware adaptive routing protocol for opportunistic networks and show that the proposed routing protocol outperforms many of the well-known routing protocols in the field.
[topological uncertainty, congestion avoidance, routing protocols, opportunistic networks, opportunistic routing protocols, message routing, message forwarding, forwarding decisions, adaptive routing protocol]
Guaranteeing quality of service and low power consumption in mobile ad-hoc networks
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Mobile Ad-Hoc Networks are used widely in these days. It is suitable for emergency situations or disaster areas when existing communication infrastructure is damaged and rapid deployments of a communication networks are needed. In a MANET, power awareness is an important challenge to improve the communication energy efficiency at individual nodes. In this paper authors have proposed and implemented efficient low power consuming routing protocol on top of AODV. The main goal of the proposed routing protocol is increasing the network lifetime of the MANET. Additionally paper evaluates the implemented protocol using the NS2 simulator in different network scales taking the power consumption into consideration. The proposed algorithm reduces for more than 9.8% of the total energy consumption and decreases the mean delay and achieves a good packet delivery ratio.
[communication energy efficiency, telecommunication power management, low power consumption, quality of service, MANET, mobile ad-hoc networks, power awareness, QoS, mobile ad hoc networks, routing protocols, low power consuming routing protocol, Power Consumption, network lifetime, AODV]
RideBuddies &#x2014; Multi agent system for ride sharing/carpooling
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Carpooling or ride-sharing is the sharing of car journeys so that more than one person travels in a car. Carpooling reduces each person's travel costs such as fuel costs, tolls, and the stress of driving. This research focuses on implementing a ride-sharing solution in Sri Lanka using a multiagent system through the communication, negotiation and coordination of agents.
[multi-agent systems, Sri Lanka, multi-agent system, RideBuddies, route matching, journey intersection, transportation, multiagent system, agent coordination, Carpool, agent negotiation, agent communication, ride sharing, carpooling]
A cloudlet-based approach to tackle network challenges in mobile cloud applications
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Advancement in mobile broadband communication enables to effectively communicate anywhere at any time. More specifically, for people who live in rural areas of developing countries it is the best means to communicate with the rest of the world. This has prodigious potential of enabling new opportunities in their live. The appearance of cloud computing, the recent improvements in communication networks, and the mobile phone market penetration allow a large number of users to access remote computing systems using their mobile devices.
[Distributed System, Edge Computing, mobile phone market, Mobile Cloud Applications, remote computing systems, mobile cloud applications, mobile computing, developing countries, cloudlet, mobile broadband communication, network challenges, Cloudlets, cloud computing, rural areas]
Sociocultural dimensions of e-learning in emerging nations
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
The economic and sociocultural dimensions of e-learning are sometimes ignored in system and policy implementation in emerging nations. Many learning objects, systems, and courses (i.e. MOOCs) originate in Western developed nations and are presented in English, thus contain explicit and implicit cultural bias. Based on the author's experience in using cross-cultural e-learning systems in the emerging nation of Qatar and a relevant literature review, this contribution outlines sociocultural aspects of national and multinational online learning (with a focus on the Arabic-speaking nations) that must be considered for successful implementation.
[multinational online learning, social aspects of automation, linguistics and e-learning, gender, individualism, cultural aspects, privacy, economic dimension, sociocultural dimension, Arabic-speaking nations, national online learning, cross-cultural e-learning system, ambiguity, cultural bias, Qatar, E-learning: social dimensions, computer aided instruction, electronic learning]
ReputationBox: A system to analyse importance of emails and reputation of email senders
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
E-mail is one of the primary mediums of electronic communication used today. The number of email accounts are expected to go over 4.3 billion accounts by the year 2016 according to the latest email statistic reports. Users receive a bulk of emails on a daily basis and consequently they tend to overlook their inboxes and miss important emails from important people. This email management issue imposes an adverse effect on the productivity of email communication. Although many email clients today are equipped with tools to filter emails based on keywords, email addresses; most of these filters are static and are not updated automatically. The productivity of email communication will drastically improve if emails can be automatically evaluated for their goodness, so that users can promptly identify important and interesting emails before reading them and proceed with suitable actions on a timely manner.
[Productivity, Algorithm design and analysis, email analysis, ReputationBox, email filtering, email reputation, electronic mail, reputation, electronic communication, Electronic mail, Servers, machine learning, Analytical models, email addresses, Filtering algorithms, email management, Data models]
Improving eLearning to meet challenges in 21st century
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Elearning has been practicing for more than a decade, it is evolving and changing rapidly to meet the needs of users. Many countries are moving from an industrial-based to information-based economy and the education systems must respond to this change. The skills needed in a modern world are critical thinking, creativity, collaboration, metacognition, and motivation. Last couple of decade eLearning focused more towards the individual development and literally assessing the student's lower order thinking. The pedagogy supports to achieve learning outcomes based on individual performances leaving the learner in an isolated learning environment. The latest disruption in online learning is the Massive Open Online Courses (MOOC). Many researchers assert that it provides sound pedagogical change leading to many advantages. Our research aims to address the gap between current and past outcomes produced by eLearning with that of next few decades to come. We used qualitative method Grounded theory to identify the factors affecting to an effective eLearning and ranked them according to the priority by using quantitative method Principle Component Analysis (PCA) in SPSS (Version 10.0 for Windows).
[massive open online courses, qualitative method, Interaction, isolated learning environment, grounded theory, quantitative method, CPS, student lower order thinking assessment, 21st century skills, PCA, MOOC, Pedagogy, educational courses, principle component analysis, elearning, pedagogy supports, Collaborative Problem Solving, computer aided instruction, SPSS, principal component analysis, online learning]
Framework for integrated environment to facilitate scientific research method
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Scientific research methodology is now very popular in the Asian region and it is a fine-tuned version of deductive research approach. As it demonstrates the majority beauties of science such as rigor objectivity parsimony and etc it provides a good metaphor to strongly establish the conclusions of research studies. When considering about the scientific research methodology it is observable seven clear steps such as, Observation, Preliminary Study, Problem Definition, Hypothesis Development, Experimental Design, Data Collection, and Data Analysis &amp; Conclusion.
[data analysis, scientific research methodology, Research Methods, deductive research approach, natural sciences computing, integrated environment, Scientific Research, Integrated Environments]
Leaf recognition and classification algorithm to be used by indigenous medicine
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
In Sri Lanka there is a lot of emphasis on herbal and indigenous medicine. Majority prefer Ayurvedic medicine to Western medicine due to various factors such as less or rather no side effects. The fact that Ayurvedic medical system stood the test of time sums up to its worth as an alternative course of treatment for various ailments. However, a major drawback in the practice of indigenous medicine is the difficulty in finding ingredients. We developed a system that recognises the leaves of the herbs used for Ayurvedic treatment. The system takes the leaves of the trees as inputs and outputs the name of the tree or plant. We used a combination of image processing techniques and neural networking to train a model and perform pattern matching to recognise the leaf with a pre-set level of confidence for its accuracy. As a supplementary feature, the system is also capable of providing a description of the identified herb's medicinal usage in reference to illnesses by going through feed data.
[image processing, pattern matching, image classification, Sri Lanka, Ayurvedic treatment, image processing techniques, Ayurvedic medical system, medicine, pharmaceuticals, image matching, indigenous medicine, leaf recognition algorithm, neural networking, leaf classification algorithm, Western medicine, Ayurvedic medicine, herbs medicinal usage, neural nets]
A novel approach to estimate nitrogen content of paddy
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Nitrogen (N) is an essential element in photosynthesis which makes it critically important that cultivations are provided with sufficient amounts of N to gain a fertile yield. Majority of this requirement is fulfilled through N based fertilizer. Paddy farmers in Sri Lanka rely on information given by Agricultural Instructors to decide fertilizer requirement for their paddy fields. However, due to insufficient number of officials, currently they are in a dire situation of not being able to get timely information. As a result farmers have opted to use their previous experience in applying fertilizer. This has resulted in either over application or under application of N fertilizer, which causes significant impacts both to the farmer as well as the environment. While over application of N fertilizer lead to critical issues for bio-diversity, contamination of water, contamination of soil and health issues under application of fertilizer will result in a reduced harvest to the farmer. Therefore, the objective of this work in progress research is to suggest a novel approach to estimate N content of paddy in Sri Lanka.
[biodiversity, water contamination, Sri Lanka, nitrogen, design science research, mobile application, paddy cultivation, water pollution, fertilisers, agricultural pollution, nitrogen content estimation, paddy field, fertilizer, N, contamination, health issues, photosynthesis, Nitrogen estimation, soil pollution, agricultural engineering, soil contamination, health hazards]
An experimentation framework towards longitudinal analysis of EEG/ERP data to assess brain plasticity
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Whilst there are many studies at present conducting research on brain related activities, many of its functions still remain a mystery. Neuroplasticity is one such area specifically in relation to its effects and changes in brain disorders. Devising an experimentation framework towards longitudinal assessment of brain plasticity related to learning and rehabilitation via electrophysiological markers based &#x201C;EEG profiles&#x201D; is the main research aim of this study.
[Neuroplasticity, electroencephalography, EEG (Electroencephalography), bioelectric potentials, longitudinal analysis, learning, ERP (Event related Potentials), EEG profile, patient rehabilitation, medical disorders, brain related activities, rehabilitation, brain disorders, neurophysiology, EEG-ERP data, electrophysiological markers, brain plasticity, neuroplasticity]
Anthropometric classification of nasal indexes for a Sri Lankan undergraduate student population
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Whilst the human nose is a predominant facial feature of ones face where it is used in assessing ones beauty, in the field of anthropometric studies, its index is used in a number of clinical and forensic practices. This index is the most commonly used method in classifying the human nose into different categories. The calculation of which is done by dividing the nasal breadth by the nasal height and multiplying the result by 100, where; Nasal breath: Maximum breadth of the nasal cavity (at right angles to the nasal height), from alare to alare (al) Nasal height: height from nasion (n) to nasospinale (ns).
[FaceSDK, image classification, Sri Lanka, nasal cavity, object detection, nasal index classification, Sri Lankan undergraduate student population, nasal breadth, Anthropometric comparison, anthropometric classification, feature extraction, face recognition, nasal height, Nasal Index, facial feature, human nose classification]
A wave model for simulating vessel effecting shallow-water waves in real-time
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
We propose a novel solution to simulate vessel effecting shallow water waves in real-time for usage in maritime training simulators. The solution is based on the Navier-Stokes (NS-E) equations that describe the motion of fluids. The NS-E is derived from the continuity equation describing the conservation of mass and the conservation of momentum theory on 3 directions. Thus, the usage of NS-E produces the most accurate numerical results over other equations (Boussinesq Equn, Green-Naghdi Equn). By depth integrating the NS-E the resulting depth averaged equations are used to solve for wave heights in shallow water surfaces. We use the open source CFD software package OpenFOAM in our solution. The depth averaged NS-E , which is solved via the PIMPLE algorithm gives the output of the height fields of the waves over the simulation area considered.
[flow simulation, wave model, public domain software, digital simulation, mass conservation, Computational Fluid Dynamics (CFD), computer based training, NS-E equations, software packages, Navier-Stokes, depth averaged equations, Shallow Water Waves, OpenFOAM, computational fluid dynamics, momentum conservation, continuity equation, PIMPLE algorithm, marine engineering, Real-Time, shallow-water waves, vessel simulation, Simulation, maritime training simulators, shallow water equations, open source CFD software package, Navier-Stokes equations]
Onto-CDS: Medical decision support with timely updated knowledge
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
In medical domain DSSs are known as Clinical Decision Support System (CDSS) [1]. It is defined as software that helps in clinical decision-making. It matches the computerized clinical knowledge base with the individual patient's symptoms or the medical test results. After that the specific assessment or recommendations are then presented to the medical doctor for the decision. However, construction, maintenance and timely updating of such CDS have become challenges due to many reasons. Among others reasons, since body of knowledge in medicine is constantly updated, computer programmers are unable to timely update a CDS. Thus it is undisputed that automated solution for maintenance and updating of CDS solutions is of paramount importance. In this context, the concept of Ontology has gone beyond traditional data modelling approaches such as Entity-Relationship (ER) and the Object Oriented Modelling. More importantly, Ontology can automatically extract the up to date knowledge from the Internet and update the knowledge base of CDS.
[knowledge base, clinical decision support system, Ontology, medical information systems, decision support systems, Onto-CDS, ontology-based CDS, ontologies (artificial intelligence), Internet, medical decision support, clinical decision support systems, timely updated knowledge, CDSS, biomedical ontology]
Recognizing the level of alcohol intoxication in Sri Lankans through changes in suprasegmental effects and reaction time
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Alcohol is generally considered to be a central nervous system depressant. That is why alcohol has become one of the leading causes of road traffic accidents in Sri Lanka as well as all around the world. In Sri Lanka, diagnosis of alcohol intoxication detection is done by either breathalyser balloon test or clinical examinations conducted by a Judicial Medical Officer (JMO). However these, the current methods used in Sri Lanka are plagued with deficiencies and shortcomings. Blood alcohol testing, the most accurate form of alcohol detection is not routinely available due to its cost and the breathalyser does not have any reproducibility or reviewability of test samples. Hence, there is a necessity in the country for an accurate, objective and inexpensive alcohol test which can measure the level of alcohol intoxication.
[Sri Lanka, road traffic accidents, clinical examination, judicial medical officer, Reaction Time, JMO, alcohol intoxication detection, Alcohol Intoxication, medical signal processing, Suprasegmental Features, breathalyser balloon test, speech recognition, alcohol intoxication recognition, suprasegmental effect, blood alcohol testing, reaction time, central nervous system depressant]
Criminal shortlisting and crime forecasting based on modus operandi
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Crime detection and prevention is a very crucial wok which is in the hands of police, law enforcement agencies and local government. Experts in crime analyzing use crime scene evidences to capture unique ways a criminal has acted during a crime, which is also called as Modus Operandi(MO). Using MO as the main focus, the efforts taken in this research is to shortlist and predict criminals and criminal activities with the support of machine learning based algorithms.
[Machine learning algorithms, crime forecasting, local government, Machine Learning, Accuracy, police data processing, Clustering algorithms, machine learning based algorithms, crime detection, Prediction algorithms, learning (artificial intelligence), modus operandi, MO, crime prevention, law enforcement agencies, crime scene evidences, criminal shortlisting, Forecasting, police, forecasting theory, Feature extraction, criminal law, Criminal Profiling, Joining processes, Modus Operandi]
Social life network for disease and pest control
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
As a developing country agriculture has traditionally dominated the Sri Lankan economy and there are various issues such as overproduction, under supply, pest and disease outbreaks which has affected the farming community. Controlling diseases and pests related to cultivation is one of the major issues that farmers face during their farming activities. The current process of detecting and controlling pests and diseases is very time consuming in terms of collecting, analysing, processing pest and disease related data and notifying outbreaks to the relevant parties. This limits the timely and proactive actions that could have been taken to control those pests and diseases. To address the drawbacks and limitations in the current process, our proposed solution has built a Social Life Network to help control the spread of diseases and pests. Building a Social Life Network provides a good mechanism to link all the stakeholders of the agriculture sector. It also facilitates the integration of information, knowledge and resources which are scattered in different places and provide instant access to real time, dynamic information through the Social Life Network. Thereby improving the information visibility to its stakeholders and providing the ability to make accurate and timely decisions. With this system, details of crop pests or diseases (images with GIS data, spatial data) are obtained from farmers together with the spatiotemporal data with minimum delay would be available for analysis by the relevant officers to detect possible disease or pest. The spread of verified diseases or pests is alerted via a map showing the locations as hotspots. After collection of such data a model would be formulated to predict the spread of diseases or pests.
[spatial data, Sri Lankan economy, Web based mobile application, diseases, spatiotemporal data, agriculture, social life network, mobile computing, farming community, GIS data, Disease and Pest Control, disease control, Social Life Network, social networking (online), crop diseases, agriculture sector, Internet, pest control, crop pests]
Identification of the pedagogical design improvements of the TL process in the ICT/CS education in the university system of Sri Lanka
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
There is an ambiguity in identifying the quality status of the Information and Communication Technology/ Computer Science (ICT/CS) education in the university system of Sri Lanka as it is not specified in any of the previous studies. In order to identify whether there is a deficiency in the quality, international standards of the education are compared. As the quality of the TL process which is one dimension of the quality education consists of different sub processes: curriculum design, pedagogical design, implementation quality, outcomes assessment and resource provision, quality pedagogical design is one of the most significant component of the quality education and it is chosen as a way to enhance the quality of ICT/CS in this study.
[computer science education, pedagogical design, Practical oriented large classroom, further education, pedagogical design improvement, Sri Lanka, university system, Pedagogical techniques, Quality education, information and communication technology, implementation quality, resource provision, ICT-CS education, outcome assessment, ICT/CS education, curriculum design]
Analyzing transport layer protocols to create an API to satisfy timed response in dynamic requirements of wireless networks
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
In modern systems it is very vital to have an efficient data transmission mechanism. This becomes more critical factor when it is involved with a system like a way finding application for vision impaired people or a medical system that notifies the doctor's smartphone when the patient's heart rate goes down. The size of the data that is used frequently by the mentioned systems is relatively small. Additionally it might take more time for connection establishment despite of the requirement of urgency. Thus this kind of data transmission is not ideal for such systems. Therefore this diversity of data transmission makes a special category of systems that needs a reliable, efficient data transfer mechanism since requirements of those systems such as low latency, reliability are not being fully satisfied by the current Transport Layer Protocol (TLP) selection mechanism.
[radio networks, smartphone, transport layer protocols, data transfer mechanism, wireless networks, biomedical communication, smart phones, transport layer protocol, transport protocols, medical system, patient heart rate, TLP selection mechanism, data communication, Transport Layer Protocols, API, data transmission mechanism]
Speeding up data access in SOA
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Owing to the edge that IT provides to one's business over potential competition, it is important that IT infrastructure effectively leverage the business processes of an enterprise. SOA is a paradigm that can be used to build such enterprise architectures enabling those with needs (consumers) and those with capabilities (providers) to interact via services across disparate platforms, technologies, and ownership. Services are the cornerstone in service-based architectures where they act between the consumers and the providers. ESB is a deployable system that makes enterprise application integration a reality through SOA. It plays the role of an intermediary that orchestrates the service requests for various applications for optimal service delivery. The intention of utilizing an ESB is to enable smooth operation among the diverse Enterprise Applications' but there is a common complaint of degraded performance when fulfilling the requests' unlike in the standalone silos-like applications.
[enterprise application integration, optimal service delivery, SOA, ESB, IT infrastructure, business processes, service-based architectures, SOAP, Performance Benchmarking, business data processing, service-oriented architecture, enterprise architectures]
Unknown words analysis in POS tagging of Sinhala language
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Appearance of unknown words is one of the frequently occurring problems facing in part of speech (POS) tagging process, i.e., the words that appear in sentences, but are not contained within the training corpus. New words are continually coined to the language, and people will often use words that are parsing, the system may not expect. This problem get worse when NLP systems are used for more and more on-line computer applications. New words are continually entering the language, Acronyms and proper names are created very often and new nouns and verbs are adding to the language in a surprising rate. So it is impossible to train the tagger for every possible word in the language. So unknown words are non-negligible in POS tagging. Therefore, in order to build a complete tagger, tagger must be incurred with some knowledge of suggesting the tag for an unknown word.
[Sinhala language, natural language processing, POS tagging, Morphology, part-of-speech tagging, Sinhala Language, speech processing, Part of Speech tagging, NLP system, Unknown words]
Railway train dynamics analysis system
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Train Traffic Optimization System is a research targeting to seek a solution to minimize train delays and maximize train productivity in Srilanka Railways. Main purpose of the research is to find out feasible heuristic algorithm for train traffic optimization. Time table generation and application of evolutionary computing to solve above problem is another consideration of the research. This research encompasses with five major modules.
[Evolutionary Computing, evolutionary computing, vehicle dynamics, railway train dynamics analysis system, time table generation, Mobile handsets, Train Optimisation, Srilanka Railways, train traffic optimization, Transportation Media, Optimization, Global Positioning System, railway engineering, heuristic algorithm, evolutionary computation, Accuracy, mechanical engineering computing, Rail transportation, Real-time systems, Delays, data handling, train traffic optimization system]
Comparison of major clustering algorithms using Weka tool
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Clustering algorithms are used in wide varieties of fields in many contexts. In these cases the behavior of the datasets are different to each other. Their sizes, density or the distribution may vary from one another. In data mining, clustering algorithms are implemented to build clusters with respect to a given dataset. But it is not an easy task to find the most suitable clustering algorithm for the given dataset. Therefore this study is done on several datasets using four clustering algorithms to identify the most suitable algorithm. This study is based on comparison of clustering data mining algorithms by using WEKA machine learning software.
[pattern clustering, clustering algorithms, data mining, WEKA machine learning software, learning (artificial intelligence)]
Using multi user virtual environments to improve the quality of secondary education in developing countries
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
Secondary education systems of developing countries include a considerable amount of experiments that needs to be physically conducted in a laboratory. But due to lack of resources the student is expected to understand complex, less intuitive and cognitive demanding theories and concepts on their own with minimum opportunities to practical exploration. In this study we have explored the possible use of Multi User Virtual Environments (MUVEs) to overcome this barrier for student learning.
[secondary education quality iprovement, student learning, virtual reality, MUVE, developing countries, Secondary Education, multiuser virtual environments, computer aided instruction, Multi User Virtual Environments]
Tutorials
2014 14th International Conference on Advances in ICT for Emerging Regions
None
2014
These tutorials discuss the following: Living Labs and socio-cultural and technical considerations of ICT4D; Enterprises virtualization; Build first plan later: The voice of DIY Approaches in today's design; Orchestrating enterprise smart objects; Educational and technological frameworks for e-learning: Teaching and learning computer science online; e-Health and the modern society; and Human_centred design in ICT for emerging regions.
[computer science education, social aspects of automation, enterprises virtualization, teaching, virtualisation, ICT4D technical considerations, e-Health, e-learning, computer based training, ICT4D socio-cultural considerations, computer science online learning, computer science online teaching, Internet, enterprise smart objects, medical computing, business data processing, health care, human_centred design, user centred design, Living Labs, DIY approaches, do-it-yourself technologies]
Disclaimer
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Presents conference disclaimer messaging.
[]
Message from the conference chair
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
It is my great pleasure to welcome all of you to 15th International Conference on Advances in ICT for Emerging Regions (ICTer) [ICTer2015] held on 24th and 25th August 2015 at BMICH, Colombo, Sri Lanka. This annual International conference is organized by University of Colombo School of Computing in collaboration with IEEE Sri Lanka section and IEEE Computer Society, Sri Lanka chapter. Hence, ICTer2015 conference proceedings will be published in IEEE explorer after the conference, to disseminate it among a larger international audience.
[Industries, Silver, Plagiarism, Software, Standards]
Foreword by the co-chairs
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
ICTER is now recognized as a significant annual event in the academic and research calendar of ICT researchers in Sri Lanka and in the region having being conducted for the 15th successive year. This is amply illustrated by the fact that ICTER has been able to attract a large number of paper submissions this year numbering 130 from all over the world, out of which 44 full papers and 32 poster presentations have been accepted after a double blind peer review process. Moreover, this year, we are proud to collaborate with the organizers of the 8th International conference on Ubi-Media Computing in co-locating two conferences offering the maximum benefit to the research community. The two day conference with five parallel tracks consisting of key note speeches, paper and poster presentation and mini symposia will enable the widest exposure to the attendee this year. We would like to express our gratitude to the dedicated work of the program committee in reviewing the papers; the steering committee for their excellent planning in attracting the Ubi-media partners to this year's event and the planning that was required for the combined event. We would also like to extend our thanks to all the financial sponsors, who have been with us over the years, and all those who have tirelessly worked to bring the event into fruition. We wish all participants an extremely fruitful two days of deliberations and leading to many more collaborations between the research and the industry communities in extending the horizons of the ICT landscape in Sri Lanka.
[Conferences, Speech, Planning]
Keynote speakers
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Presents a listing of keynote speakers from this conference.
[]
Keynote speakers big data deployment in assessing the creditworthiness of low-income families and micro-enterprises in emerging economies: Platforms, methodologies and business models
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
General consumer and business finance companies and microcredit organizations have had limited success in serving the needs of economically active low-income families and micro-enterprises cost-effectively and sustainably. Recent advances in computing and telecommunications technology are dramatically transforming this landscape by changing the way the financial industry operates. A key mechanism underlying this transformation concerns the use of big data (BD) in assessing, evaluating and refining the creditworthiness of potential borrowers. The objective of this paper is to examine this issue from the perspective of emerging economies. It investigates how various inherent characteristics of big data - volume, velocity, variety, variability and complexity - are related to the assessment of the creditworthiness of low-income families and micro-enterprises. The paper also examines the platforms, methodologies and processes used by lenders in assessing the creditworthiness and lending decisions. Case studies of developing world-based BD companies involved in this business such as China's Alibaba, Tencents and Xiaomi, Africa's Agrilife, Farmforce and Kilimo Salama, Brazil's Cignifi and Mexico's Kueski will be discussed. It looks at various categories of personal financial and non-financial information that are being used as proxy measures for a potential borrower's identity, ability to repay and willingness to repay. The sources of data (internal vs. external to the BD organization) and providers of credits (BD organization vs. external partners or clients of the BD organization) considerations suggest the four basic categories of business models represented by the 2&#x00D7;2 matrix. The paper evaluates the business models represented by each cell from the perspective of potential borrowers. Also addressed are privacy and cybersecurity issues associated with this phenomenon.
[business models, creditworthiness, microcredit organizations, computing technology, big data deployment, general consumer, nonfinancial information, financial data processing, lenders, proxy measures, financial industry, Biological system modeling, Computational modeling, micro-enterprises, Big Data, world-based BD companies, business finance companies, cybersecurity, low-income families, BD organization, security of data, personal financial, potential borrower identity, financial management, lending decisions, emerging economies, telecommunications technology]
eLearning for the benefit of the learning mind
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
As has been pointed out by the Bloom's Taxonomy matrix, learning is initiated from the stage of memorizing and recalling, and then, to the stage of understanding, followed by the stages of applying, analyzing, evaluating, and creating. On the axis for the learning opportunity or what is learned, facts/events, concepts, procedures, and metacognitive reflections are arranged. In such matrices, the traditional eLearning for corporate training and education occupies only the grids for the stage of memorizing and recalling, and the stage of understanding, associated with the learning opportunities of facts/events, concepts, and procedures, where most routine work or study resides. On the other hand, the corporate training and education in a new paradigm takes the whole matrices as its realm of training and learning. In such a paradigm, active learning is the key, in which the learner finds the value through the learning process. It follows that the learning must be customized for individual learners needs, rather than the instructor's or teacher's arbitrary needs. In such a paradigm, the teacher or the instructor cannot impose the prefabricated knowledge or values on the learner. The learner himself or herself will find the value in the process of learning. In such learning, the instructor or teacher's role is to guide or point the learner to the direction of the learning goal/value designed in the curriculum map. It is the learner's mission to find the values through the process of learning. In other words, eLearning is meant for the benefit of the learning mind.
[Bloom taxonomy matrix, active learning, education, corporate training, learning goal, curriculum map, learning mind, computer aided instruction, eLearning, distance learning]
Internet of things (IoT): Technologies and applications
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
All of the analysis report pointed out the total connected things will reach 50 billion in 2020. So the internet of things (IoT) is major and big market for semiconductor and IC design. IoT is a big trend and there are many opportunities to create a new product, project and research. I talk about the emerging technology in IoT and wearable device market. One important of challenge is low power. Therefore, the power efficiency is the new battleground in IoT. And then, one of another important is security function. So choose an embedded microprocessor is very important for IoT or wearable device. I give a brief description of Andes CPU and it is suitable in IoT solution. Finally, Andes CPU has successful in IoT and wearable device market, a lot of products were made by IoT companies from Andes CPU licensed and these products will be displayed, especially in mobile and communication applications.
[Internet of things, security of data, Andes CPU, security function, microprocessor chips, wearable device market, embedded microprocessor, Internet of Things, IoT, power efficiency]
An online lighting model estimation using neural networks for augmented reality in handheld devices
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
The level of realism in augmented reality applications is heavily dependent on the consistency of illumination between real objects and virtual objects. This paper presents a comprehensive methodology to model the real world lighting and synthesize it with virtual objects which are rendered. While there is a substantial body of knowledge on this aspect, the novel methodology suggested in this paper has its own advantages of not having to have any prior knowledge on the environment or any special hardware, which increases the usability of the system while making it possible to be utilized in online systems.
[Handheld computers, online lighting model estimation, handheld device, Manuals, Artificial neural networks, augmented reality, rendering, Include most appropriate keywords or phrases more than one and less than four, rendering (computer graphics), neural network, neural nets]
A segmentation method for extraction of main arteries from Coronary Cine-Angiograms
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Coronary Cine-Angiogram (CCA) based subjective assessment of vascular malfunction is a preliminary diagnostic method in Cardiac clinical procedures. Even though there are many other medical image modalities available, improving the CCA method to objectively detect and assess the stenosis is a cost effective approach in Cardiac clinical procedures. Segmentation of Coronary Arteries (CA) is a basic and challenging area in such an endeavour. Hence, in this study we proposed a segmentation method to extract the major areas of CA based on Frangi's vessel enhancement filter and region growing segmentation method called flood fill. Experimental results of our proposed segmentation method have clearly proven its ability to extract the main CA almost completely. Moreover this proposed segmentation method possesses 93.73% average segmentation accuracy. Further, it detects the vessel path lines of the segmented frames using a thinning algorithm. The results obtained from this proposed segmentation method can be further enhanced to determine the functional severity of the CA and this study lays a foundation to improve the Coronary Angiogram image modality to do objective diagnosis of stenosis in future.
[stenosis assessment, vascular malfunction, coronary angiogram image modality, Frangi's vessel enhancement filter, image filtering, flood fill, Arteries, preliminary diagnostic method, cardiac clinical procedures, stenosis diagnosis, image enhancement, coronary artery segmentation, image segmentation, Frangi's filter, medical image processing, Biomedical imaging, CCA, thinning algorithm, vessel segmentation, medical image modalities, coronary cine-angiograms, angiocardiography, Image segmentation, Sensitivity, subjective assessment, region growing segmentation method, stenosis detection, main artery extraction]
Front-view car detection using vocabulary voting and mean-shift search
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Vehicle detection has received much attention over the recent years. In this paper we mainly address on the detection of cars in front-view static images and focus on local features that describe structural characteristics in particular. Our method is based on constructing visual vocabularies for the car and non-car objects (i.e., background). Extended speeded up robust features are used in constructing the vocabularies using K-means algorithm. For a test car image, e-SURF keypoints are extracted and possible background keypoints are rejected in order to retain keypoints that of car by using a vocabulary voting strategy. The retained keypoints are then scanned using mean-shift algorithm to find a candidate bounding box of the car. The extraction of keypoints with vocabulary voting and the mean-shift searching technique are repeated to every scale of the down sampled test image. The set of bounding boxes found at every scale are then mapped in to the original test image and a non-maximum suppression technique is used to predict the final bounding box of the car. The system is evaluated on 25 distinctive vehicle classes with 20 images per class. Testing results show that the method has a high detection rate of 96.8% on front-view cars. The method is flexible and can be easily extended to other views such as side or rear view by modifying the visual vocabularies.
[local features, Vocabulary, front-view static images, nonmaximum suppression technique, automobiles, mean-shift searching technique, front-view car detection, mean-shift, object detection, traffic engineering computing, Bounding box, vehicle detection, Image segmentation, K-means algorithm, car detection, bounding box prediction, vocabulary voting strategy, feature extraction, mean-shift search, visual vocabularies, e-SURF keypoint extraction, visual vocabulary, Feature extraction, search problems]
Video event classification and anomaly identification using spectral clustering
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
This paper proposes a spectral clustering based methodology to classify video events and to detect anomalies. Feature trajectories from objects in a video are modelled, compared and clustered in order to classify the detected object events. Principles of normalized spectral clustering are used with modifications to affinity structure. A novel method for determining spectral clustering parameters based on Eigen structure of the affinity matrix is introduced. Employment of unsupervised learning for event classification is made possible by the proposed successive cluster identity labelling algorithm. A mechanism to identify abnormal events under the context is also introduced. The effectiveness and the robustness of the proposed methodology are demonstrated through experiments conducted on video streams focusing on human motion patterns.
[anomaly identification, image classification, affinity structure, affinity matrix, spectral analysis, Videos, eigenvalues and eigenfunctions, Event classification, event classification, Employment, eigen structure, human motion patterns, Video Analysing, Matrices, Trajectory, Spectral Clustering, video signal processing, normalized spectral clustering, object feature trajectories, Anomaly detection, matrix algebra, unsupervised learning, video event classification, pattern clustering, Hidden Markov models, cluster identity labelling algorithm, video streams]
A study of cloud variation on the commencement of South-West monsoon around the Sri Lankan region
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Due to the high uncertainty involved in weather forecasting, more accurate methods need to be explored. In this paper a novel approach based on the cloud shape stability to predict the arrival of South-West monsoon is proposed. The cloud shape stability which is determined by the pixel orientation based on the neighbourhood of cloud images begins to drop in April-May and remains in that low level in subsequent months of peak monsoon period (May-September) in all three years 2012, 2013 &amp; 2014 considered in this research. The cloud cover which is determined by the brightness of the pixel starts to go up in the same period and remains in that high level in the same monsoon peak period. When the seven day moving average cloud shape life time is plotted for the months April, May &amp; June for all three years, a bell shaped gradual increase and decrease phenomenon can be observed for late May. Moreover, after decrease of the life time, no momentous life time increase or fluctuation is observed until the end of June. The above decrease happens due to the fact that, the monsoon onset week is determined right after the highest point of that bell shape. Therefore, probable days or a week of the SW monsoon onset can accurately be confirmed as May 18 - May 21, May 25 - May 28 &amp; May 17 - May 20 in the years 2012, 2013 &amp; 2014 respectively according to the above phenomenon. The proposed method can be adopted to predict the arrival of S-W monsoon more accurately in the future.
[Computers, time 7 day, Image resolution, South-west monsoon onset, Pixel orientation, cloud variation, cloud shape stability, Linear symmetry, Monsoons, south-west monsoon, cloud images, clouds, AD 2014 05 17 to 05 20, cloud shape life time, weather forecasting, Sri Lankan region, AD 2012 05 18 to 05 21, cloud cover, AD 2013 05 25 to 05 28, monsoons]
Identifying Adverse Drug Reactions by analyzing Twitter messages
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Adverse drug reactions (ADRs) have become the most common cause of deaths in the world despite post marketing drug surveillance. Expensive clinical trials do not uncover all the ADRs and also cumbersome for consumers and healthcare professionals. Majority of existing methods rely on patients' spontaneous self-reports. The recent explosion of micro blogging platforms such as Twitter presents a new information source to discover ADRs. In this study, the authors developed a system to automatically extract ADRs from Twitter messages utilizing Natural Language Processing (NLP) techniques. First, the authors proposed a novel method to filter out all the drug related messages from the Twitter data stream. Dictionary based approaches were used to identify medical terminology, emoticons and slang words. The interpretation of &#x201C;internet language&#x201D; was also addressed in this research. The best classifier for the classification of ADR reached an accuracy of 68% with F-measure of 69%. The results suggest that there is potential for extracting ADR related information from Twitter messages to support pharmacovigilance.
[Medical services, Twitter, Niobium, ADR, micro blogging platforms, NLP, patient treatment, Text Classification, Information filters, clinical trials, Twitter messages, natural language processing, Blogs, drugs, Natural Language Processing, patients spontaneous self-reports, medical terminology, Pharmacovigilance, Internet language, adverse drug reactions, post marketing drug surveillance, social networking (online), Internet, medical computing, Twitter Mining]
A dynamic semantic space modelling approach for short essay grading
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
The assessment of knowledge is considered as one of the most important aspect of the learning process. Despite its development over decades the underlying problem of `How best to assess learning?' still remains. In the field of education, essay questions are considered as the most appropriate question types for assessment compared to closed questions to evaluate the knowledge of the students. However, evaluation of answers of essay type questions consumes a long time, effort and includes unavoidable human errors. Therefore, the development of an automated essay assessment system is beneficial due to those reasons. The focus of this research is to present a novel approach for automated essay scoring (AES) using Vector Space Models (VSMs) and Natural Language Processing techniques. It employs model answer based evaluation for the scoring process. In order to handle variations in the students' essay answers, NLP techniques (lemmatization, tokenization, handling of spelling mistakes, relation of objects, upper and lower case of words, short term resolution) were used. Proposed approach does not need any pre-training prior to each essay questions compared to most of the existing systems. Importance of this approach is that it does not need any domain specific corpus; instead, a sematic space is built using same students' answers. The scores were derived by comparing the semantic similarity or deviation between the model answer and the student answers and finally provide an accurate and consistent score. Results suggested that there is a strong correlation between the system score and the average human score.
[short essay grading, education, essay questions, learning process, tokenization, Analytical models, word upper case, Semantics, Automated Essay Scoring, automated essay assessment system, automated essay scoring, natural language processing techniques, Natural language processing, word lower case, Numerical models, Mathematical model, spelling mistake handling, short term resolution, knowledge assessment, natural language processing, object relation, Natural Language Processing, learning assessment, student knowledge evaluation, Auditory system, Latent Semantic Analysis, vector space models, computer aided instruction, lemmatization, dynamic semantic space modelling approach, Vector Space Models, sematic space]
RESTFul POS tagging WEB service for Sinhala language
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
In the present context of human computer interaction, world has achieved tremendous progress in the field of Natural Language Processing (NLP) applications. The availability of lexical resources is vital to many natural language processing in the field of computation linguistics. But only few languages in the world have the advantage of having enough lexical resources. Though Sinhala language has a long history, Natural Language Processing and computational linguistic aided development of the language is far behind compared with other languages. Researches on NLP for Sinhala language can be pushed by creation of required lexical resources and tools. In this paper we present our research work that was carried out for contributing to NLP based development of the language by developing a part of speech tagger for Sinhala language. The tagger we developed shows over 91% of an accuracy, and the tagger is available as RESTFul web service on the Internet that is freely accessible to the public.
[Maximum likelihood estimation, Sinhala language, natural language processing, POS tagging, Natural Language Processing, RESTFul Web service, Data structures, part of speech tagging, Unknown words, Training, Boolean functions, Web services, NLP, Sinhala Language, human computer interaction, Part of Speech tagging]
Real-time natural language processing for crowdsourced road traffic alerts
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Out of many issues we face in transportation today, road traffic has become the most crucial issue that directly affects our lives and economy. Despite of many implemented and progressing solutions, this issue seems to be remaining in a significant level in many countries and regions. Instead of fully relying on solutions provided by the authorities, public has come up with different approaches to deal with this problem. In this study we are focusing on one such solution which effectively uses a popular social networking service, Twitter. But still this crowdsourced traffic alert service has a limitation due to its nature; the natural language representation. We are trying to cope with this limitation by introducing a real time natural language processing solution to generate machine readable road traffic alerts. We observe many potentials of transforming this raw data into a machine readable format. An architecture that can effectively capture, transform and present this data has been proposed in this study and it has been implemented in a prototype level to demonstrate the uses of such a model. We expect to see extended models that can handle similar issues in future by combining multiple fields of information technology.
[road traffic, real-time natural language processing, crowdsourced road traffic alerts, Roads, natural language processing, natural language representation, information technology, Twitter, traffic engineering computing, crowdsourced traffic alert service, machine readable format, transportation, Traffic monitoring, real-time systems, social networking service, social networking (online), complex event processing, Natural language processing, Real-time systems, Internet, Feeds, Monitoring]
Multi-feature based hand-gesture recognition
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
The work presents a comprehensive methodology for recognition of temporally progressing hand gestures. Motion measurements associated with the hand position, orientation and finger bending are considered as time-series data sets and utilized for the recognition process. In addressing the hand gesture recognition problem in its multi-feature nature, a novel methodology for discovering relevant features for each gesture class is proposed. The two staged comparison approach with the proposed stratification of gesture classes based on their relevant features enabled the methodology to handle the available large number of gesture classes. Gesture comparison is based on a subspace produced by Fisher Linear Discriminant Analysis (FLDA) of temporal features in a manner that rhythmic differences between gesture trials are minimized. Results of the overall methodology have been elaborated for available AUSLAN hand-gesture datasets.
[time-series data sets, AUSLAN hand-gesture datasets, FLDA, time series, hand-gesture recognition, Fisher LDA, image motion analysis, multifeature based hand-gesture recognition, gesture recognition, motion measurements, temporally progressing hand gesture recognition, Fisher linear discriminant analysis, temporal features, multiple features, spectral clustering]
Machine Learning based criminal short listing using Modus Operandi features
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
One of the most challenging problems faced by crime analysts is identifying sets of crimes committed by the same individual or group. Amount of criminal records piling up daily has made it cumbersome to manually process connections between crimes. These Crime series' possess certain attributes that are characteristic of the criminal(s) involved in them, which are useful in defining their modus operandi (MO). After a careful study in the grave crime category of House breaking and Theft in Sri Lanka, we have identified certain MO attributes which we have used to collect from past crime scene data from police records. Then we have explored whether it is possible to group suspects who have similar MO patterns through a machine learning approach and give a short list for a new crime from the existing data. The evaluation of the research presented an accuracy above 75% which proved that Machine Learning is capable of short listing criminals based on their Modus Operandi features.
[modus operandi feature, Sri Lanka, criminal record amount, Feature Extraction, grave crime category, Encoding, machine learning, Machine Learning, Unsupervised learning, police data processing, Weapons, crime analysis, Feature extraction, Hierarchical Clustering, criminal law, learning (artificial intelligence), Criminal Profiling, Modus Operandi]
SAFS3 algorithm: Frequency statistic and semantic similarity based semantic classification use case
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Sentiment analysis on movie reviews is a topic of interest for artists and businessmen alike for the purpose of gauging the reception of an artwork or to understand the trends in the market for the benefit of future productions. In this study we introduce an algorithm (SAFS3) to classify documents into multiple classes. This paper then evaluates the SAFS3 algorithm through the use case of analysing a set of reviews from Rotten Tomatoes. Thenovel algorithm results in an accuracy of 53.6%. SAFS3 algorithm outperforms the benchmark for this context as well as the set of generic machine learning algorithms commonly used for tasks of this nature.
[document handling, frequency statistic similarity, entertainment, sentiment analysis, Media, Licenses, SAFS3 algorithm, semantic similarity, Sentiment Analysis, classification, machine learning, movie review, classify document, TF-IDF, Classification, Lead, Motion pictures, Rotten Tomatoes, generic machine learning algorithm, learning (artificial intelligence), semantic similarity based semantic classification use case, Marine vehicles]
Optimizing neural network architectures for image recognition using genetic algorithms
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
This paper aims to present a method of implementing a better visual object recognition system with the inspiration gained from the processes of biological systems. Neural networks are closely related to biological systems in how they resemble the vertebra nervous system to perform classification tasks. However, in the success of neural networks, determining the configuration and the architecture of neural network plays a major role. Biological systems have evolved to their current state of cognition through natural evolution. Therefore, to attain an optimized neural network architecture for object recognition, the proposed system uses a genetic algorithm that simulates generations of neural network populations. A distributed parallel processing method is implemented on the system to undertake the enormous processing overhead required.
[object recognition, Visualization, Image recognition, biology, visual object recognition system, classification tasks, Biology, genetic algorithms, biological systems, distributed parallel processing, parallel processing, neural network architectures, Genetic algorithms, Neural networks, Robustness, neural net architecture, Yttrium, image recognition]
A study pertaining to the barriers in assessing the outsourcing risk factors in Sri Lankan software industry
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Among many papers which have been published for many years more research has been done on software outsourcing risk management and mitigation; but barriers which affects risk assessment has been left aside creating a void. With reference to existing literature six factors were identified and this paper will validate its applicability and operational ability in the domestic software industry. Complexity of the undertaken project, Contractual complications between the vendor and the service provider, project execution mechanisms, financial models adopted, legal framework of the country and the organizational cultures were these main six components which wre subjected to the study. Study is based on all the SLASSCOM registered companies in Sri Lanka which are involved in the software operational outsourcing business.
[Industries, risk assessment, service provider, software outsourcing risk mitigation, legal framework, Outsourcing risk, outsourcing risk factors, SLASSCOM registered companies, software outsourcing risk management, financial models, vendor, Operational outsourcing, Lead, software houses, project execution mechanisms, organizational cultures, risk management, project management, software operational outsourcing business, DP industry, software development management, domestic software industry, outsourcing, Sri Lankan software industry, Risk management, organisational aspects, operational ability, Software industry]
Mobile based collaborative learning tool to facilitate instructor-mediated informal learning in agriculture
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
This paper presents the development and testing of an android application (Agri-Lessons) to facilitate instructor-mediated informal learning in an agricultural community. In a previous experiment, this evaluation was carried out using a mobile SMS based Twitter application and basic phones to find out the effectiveness of mobile learning in agriculture. In this experiment, we are presenting a mobile application that is developed for Android based smartphones, to promote instructor-mediated informal learning. The paper also presents the evaluation of the app to justify effectiveness. The evaluation was carried out considering a pre-test and post-test to find out knowledge gain. A questionnaire was used to collect the user feedback in an anonymous way. The statistics of evaluation shows that the Agri-Lessons app as highly effective as a learning tool. The App can be further improved to modify the user interface, include a few more functionalities and Sinhalese language. In the future research this app can be improved to include multiple user groups among the farming community.
[mobile application, android, smart phones, mobile based collaborative learning tool, agriculture, Agri-Lessons app, mobile computing, instructor-mediated informal learning, Education, groupware, Agriculture, Mobile learning, smartphones, computer aided instruction, Android based smartphones]
Mapping land-use pattern using image processing techniques for Medium resolution satellite data: Case study in Matara District, Sri Lanka
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Last few decades the land-use pattern has changed in Matara District in Sri Lanka due to the influence of both natural and anthropogenic hazard impacts. These hazards have caused the interruption for social, economic and the environmental sectors in this area. Since the comprehensive field surveys are highly expensive, time consuming and requiring more human power the remote sensing satellite images can be used to map the changing pattern of land-use types over a large period of time. This study focuses on how far remote sensing data give the information on land-use pattern change as an effective information and communication technology in collaboration with GIS. The Medium resolution Lansdsat satellite images were used in this study because they are freely and readily available therein cost effective and highly efficient. The ground features have been extracted from the images in 1990, 1993, 2001, 2003, 2005, 2009 and 2014 respectively. Water body has been extracted using NIR band by using single band classification method while the vegetation cover was extracted by using Normalized Difference Vegetation Index (NDVI). Multiband image classification was also implemented for each year using Maximum Likelihood Classification. According to the results, the land-use pattern has changed over the last 24 years in a significant level. The accuracy of the Maximum Likelihood Classification is 84.43%.
[image classification, information technology, image processing techniques, geographic information systems, land-use pattern change, single band classification method, NDVI, Remote sensing, Earth, Vegetation mapping, multiband image classification, maximum likelihood classification, Land-use pattern, NIR band, environmental sectors, water body, Oceans, Sri Lanka, remote sensing satellite images, Landsat, anthropogenic hazard impacts, vegetation cover, medium resolution satellite data, GIS, normalized difference vegetation index, Satellites, Matara district, vegetation mapping, medium resolution Lansdsat satellite images, Spatial resolution, communication technology, Image classification]
International Interoperability through unified universal HL7 v3 Green Messaging
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Health Level Seven (HL7) is the most popular, global healthcare standard in use today. Introduced in 1987 by the HL7 International Inc., the current version 3 has been promoting Semantic Interoperability (SI) which is two or more computer systems exchanging valued healthcare information with homogenous understanding. Thus, efficient implementation for optimal, high-end SI entails the abridgement of verbose v3 Message paradigm representations, whilst strictly maintaining their semantic nuance and flavour. The resulting economised structures termed Green Messages, have to be truly universally overarching, affording and facilitating International Interoperability. Aligned with this core Greening requirement is the demand for secured, efficacious exchange of data and information &#x201C;in the wire&#x201D;, promoting overall efficiency. This paper outlines conclusive research on all greening fronts, and underscores sound methodologies to realize true International Interoperability and superlative efficiency, as appraised by the ten, archaic System Performance Indicators (SPIs) used.
[semantic interoperability, open systems, Health Level Seven, verbose v3 message paradigm representations, Semantic Map, International Interoperability, unified universal HL7 v3 green messaging, information exchange security, Semantics, global heaIthcare standard, medical administrative data processing, health care, data exchange security, Receivers, Color, HL7 International Inc, Semantic Blending, Standards, SPl, standards, electronic data interchange, security of data, Green products, XML, Syntactics, system performance indicators, green computing, international interoperability]
Creating a Domain Specific Modelling Method for Ambient Assistance
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Domain specific modelling languages (DSMLs) have gained increasing popularity: they are convenient, support the productivity of modelling, and help to increase model quality and comprehensibility. Some work has been published about how to use or evaluate a DSML. In contrast to that, there is hardly any guideline for the DSML creation process and almost none for creating a Domain Specific Modelling Method (DSMM). This paper aims at contributing to fill that gap: it introduces a process for creating a DSMM. For illustration it uses a modelling language that has been created for the domain of Ambient Assistance domain.
[Context, ambient intelligence, Adaptation models, Unified modeling language, Method Engineering, DSML creation process, ambient assistance, assisted living, domain specific modelling languages, Context aware systems, domain specific modelling method, Domain Specific Modelling Language, Behaviour Modelling, specification languages, behavioural sciences computing, Ambient Assistance, E-Science in social sciences, behaviour modelling]
Language localisation of Tamil using Statistical Machine Translation
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Language localisation, where the strings in interface and documentation are translated to a new language, is a rigorous and time consuming task. On the other hand machine translation systems, specifically Statistical Machine Translation (SMT) systems, are successfully used among many language pairs. A few SMT systems have been developed for generic domain; however, there are no systems available to aid localisation yet. This research proposes a new methodology in which language localisation can be done using SMT. This research also identifies suitable parameters on which a SMT aided localisation system could be built. A pilot system is developed and the system is also outlined in this paper. A RESTful API has also been developed to facilitate localisation in remote tools. Several open source software have been translated already to Tamil. Those translated English - Tamil pairs were collected from various language resource files and then cleaned, tokenised and were used to train the system. Another similar system is prepared with data from generic domain apart from the collected technical data. Systems were trained with 2-gram, 3-gram and 4-gram language models that are created using two different language modelling tools namely KenLM and IRSTLM. Then the results were evaluated using BLEU algorithm. Appropriate parameters for setting up SMT system for localisation were identified from the evaluation. The results show that it would be enough to train a system with 3-gram, and the modified BLEU algorithm will give better understanding of the results compare to the original implementation of it. Further KenLM was found to perform better than IRSTM in terms of accuracy of results and the speed of execution.
[RESTful API, Google, application program interfaces, statistical machine translation, natural language processing, open source software, BLEU, IRSTLM modelling tool, BLEU algorithm, KenLM modelling tool, Tamil, Tamil language localisation, SMT aided localisation system, Localisation, application program interface, SMT, Language Modelling, language translation]
Developing a commercial grade Tamil OCR for recognizing font and size independent text
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Optical Character Recognition (OCR) of Indic scripts such as Tamil and Sinhala has lagged behind those for languages based on the Latin script. Several attempts to build commercial grade OCR for these languages have failed in the past owing to them not generalizing well. This paper describes a set of training regimes for Tamil using the Tesseract engine that have enabled us to develop a robust Tamil OCR system. We describe in detail our training regime, which results in a performance improvement of 12.5% over the default Tamil module shipped with Tesseract on a set of ancient Tamil documents, which were part of an authentic project to digitize important Tamil manuscripts of Sri Lanka.
[Integrated optics, Optical Character Recognition, Tesseract OCR, text analysis, commercial grade Tamil OCR, Image recognition, Tesseract engine, Sri Lanka, font recognition, Optical imaging, ancient Tamil documents, Tamil manuscripts, Optical character recognition software, Character recognition, Radio frequency, optical character recognition, Indic scripts, Sinhala, Latin, size independent text recognition, Yttrium, Tamil OCR]
A robust algorithm for determining the newsworthiness of microblogs
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Microblogging platforms such as Twitter have become a primary medium for people to share their experiences and opinions on a broad range of topics. Because posts on Twitter are publicly viewable by default, Twitter can be used to get up-to-date information on events like natural disasters, disease outbreaks or sports events. Building a cohesive summary out of tweets on long running events is an interesting problem which research community is interested in. But the abundance of tweets containing user opinions and their sentiments towards a topic necessitates the need of extracting newsworthy tweets from a large stream of tweets on a single topic. But most of such methods require large hand-labeled corpora to be used for training the model. But this is not practical for a rapidly updating medium like Twitter. In this paper we address this problem with the introduction of a novel heuristic based annotation scheme to generate training dataset for the system. A hand-labeled corpus of tweets is only used for benchmarking the objectivity classifier. Our classifier could achieve an F1-score of 80% on a manually annotated gold standard dataset.
[Decision support systems, Irrigation, text analysis, sport events, objectivity classifier, Twitter, natural disasters, disease outbreaks, microblogging platforms, training dataset, Training, newsworthy tweet extraction, heuristic based annotation scheme, Tweets, user opinions, Summarization, research community, Gold, pattern classification, user sentiments, manually annotated gold standard dataset, sentiment analysis, hand-labeled corpus, Natural Language Processing, Fl-score, Standards, newsworthiness, Support vector machines, social networking (online), Web and Social Media Mining, Logistics]
Real-time translation of discrete Sinhala speech to Unicode text
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
This paper presents a methodology to translate discrete Sinhala speech to Sinhala Unicode text in real time. Initially, the Hidden Markov Model and the associated Hidden Markov Toolkit (HTK) is used as the speech recognizer. While real time decoding is obtained by the Julius decoder a three-states Bakis HMM topology is used to build the acoustic model. The normalized Mel frequency cepstral coefficients with zeroth coefficient as the feature vector is used to recognize speech. Although a single person is used during the training session, an average accuracy of 85% is obtained for both speaker dependent and speaker independent speech recognition. Performance evaluation shows the capabilities of the proposed system to convert discrete Sinhala speech to Sinhala Unicode in both quiet and noisy environments.
[text analysis, normalized mel frequency cepstral coefficient, hidden Markov model, Manuals, Acoustics, Julius decoder, real-time translation, discrete Sinhala speech, hidden Markov models, cepstral analysis, Sinhala speech, speech recognizer, speaker dependent, Computational modeling, natural language processing, Sinhala Unicode, Europe, performance evaluation, Decoding, Automatic Speech recognition, real time decoding, zeroth coefficient, feature vector, speaker independent speech recognition, Hidden Markov models, Sinhala unicode text, hidden Markov toolkit, Hidden Markov Models, Acceleration, HTK, speaker recognition, three-states Bakis HMM topology]
Citation network based framework for ranking academic Publications and venues
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Impact of Publication venues are the key consideration for researchers who aim for maximum possible visibility for their work. The number of publication venues has been increasing yearly, making it difficult for researchers to get an idea about publication venues. Most of the existing methods use citation count as the metric to measure the reputation of publication venues which does not take into account the quality of citations. If publication venue ranking scores are measured successfully, then the researchers can take their own decision about a particular publication venue much quicker and easier based on this mechanism. We propose a novel approach for ranking publication venues by considering publication history. Our approach is completely based on the citation network represented by the publications. In our publication ranking method, there are many aspects that contribute to the importance of a publication, including the citations it has received, the quality of the citing publications, the time metric and its authors. The experimental results show that our publication ranking method reduces the bias against more recent publications, which only have a few or zero citations.
[Algorithm design and analysis, citation network based framework, Computational modeling, time metric, Publications, citing publication quality, Citation Network, academic publication venue reputation, academic publication venue ranking scores, Databases, Ranking, Publication Venues, citation analysis, educational institutions, publishing, academic publication ranking method]
Evaluation of scalability of Hybrid Wireless Mesh Protocol in IEEE 802.11
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Mobile ad-hoc networks (MANETs) enable ubiquitous computing with wide availability of smart mobile devices and applications. However, robust and lightweight protocols are yet to be implemented for multihop communication. The latest IEEE 802.11 standard released in 2012 captures the concept of multihop MANETs under Wireless Mesh Networks and proposes Hybrid Wireless Mesh Protocol (HWMP) as the default multihop path selection protocol. Previous studies on the performance of HWMP have not addressed operating scenarios of mass mobility (to model human user mobility), non-availability of root nodes (to model absence of infrastructure support) and a wide span of node densities (to model different application scenarios). This paper analyses the scalability of HWMP in a MANET of IEEE 802.11 standard wireless mesh stations that move at human walking speeds. The end-to-end delay, data packet delivery ratio and path selection control overhead are evaluated in the presence of random waypoint and mass mobility models for increasing node densities. The simulation results show that there are no significant variations in any of the above important performance metrics among static, random waypoint mobility and mass mobility models. Furthermore, HWMP shows almost a linear path selection control overhead profile for increasing node densities while the packet delivery ratio and the end-to-end delay reaches a steady level as node density increases up to about 250 nodes.
[IEEE 802.11, linear path selection control overhead profile, IEEE 802.11 standard, muItihop MANET root node nonavailability, mobility management (mobile radio), multihop communication, default muItihop path selection protocol, ubiquitous computing, wireless mesh networks, HWMP, mobile computing, end-to-end delay, Bit rate, mobile ad hoc networks, protocols, wireless mesh network, mobile ad hoc network, random waypoint mobility model, data packet delivery ratio, Ad hoc networks, smart phones, Wireless Mesh Networks, hybrid wireless mesh protocol scalability evaluation, mass mobility model, Yttrium, wireless LAN, mass mobility operating scenarios, Mobile computing, smart mobile device]
A modified firefly algorithm to solve univariate nonlinear equations with complex roots
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Recently developed meta-heuristic algorithms such as firefly algorithm, bat algorithm, particle swarm optimization and harmony search are now becoming popular for providing nearly accurate solutions for tough optimization problems. This paper addresses the problem of finding all roots of a given univariate nonlinear equation with real and complex roots using a modified firefly algorithm (MOD FA). The appropriate modifications are applied to the existing firefly algorithm (FA) by introducing an archive. Better fireflies are noted and stored in the archive during the iteration process and then their positions are replaced by new random ones. A comparison was carried out with the original firefly algorithm and also with the genetic algorithm (GA) which has a similar behaviour to the firefly algorithm. Computer simulations show that the proposed firefly algorithm performs well in solving nonlinear equations with real and complex roots within a specified region. The suggested method can be further extended to solve a given system of nonlinear equations.
[Firefly Algorithm, iterative methods, Archive, MOD FA, Real Roots, Complex Roots, harmony search, genetic algorithms, complex roots, particle swarm optimization, Optimization, univariate nonlinear equations, genetic algorithm, nonlinear equations, iteration process, system of nonlinear equations, bat algorithm, real roots, Nonlinear Equations, modified firefly algorithm, metaheuristic algorithms]
An approach for transforming keyword-based queries to SPARQL on RDF data source federations
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
General public highly use keyword queries to fulfil their information needs on the Web. Semantic Web aims at transforming the Web to a format which is machine readable. RDF is the common format used in the Semantic Web to store data. Several existing approaches have proposed methods for keyword query processing on RDF data. SPARQL queries are capable of retrieving more relevant results than general keyword routing on RDF data. RDF federations are capable of connecting multiple heterogeneous data sources. Federations allow us to retrieve more complete results than querying a single source. Therefore we have introduced an approach which can transform keyword queries to SPARQL on a federation of heterogeneous sources. We utilized an ontology alignment approach for resolving vocabulary level heterogeneity. A keyword index was used to match keywords to data elements on the federation while a Path Index based approach utilized to identify suitable sub-graphs which can connect keyword elements. We were able to obtain promising results about the effectiveness of the generated queries from our proposed approach and performance of the approach.
[keyword matching, heterogeneous source federation, path index, RDF data source federations, RDF data retrieval, semantic Web, subgraphs, query languages, Include Semantic Web, Resource description framework, Indexes, data elements, keyword elements, machine readable format, SPARQL query generation, query processing, data storage, multiple heterogeneous data sources, keyword index, Keyword query processing, SPARQL queries, ontology alignment approach, keyword-based queries, vocabulary level heterogeneity]
A hybrid decision tree for printed Tamil character recognition using SVMs
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Optical character recognition (OCR) is one of the important research areas in image processing and pattern recognition. OCR for printed Tamil text is considered as a challenging problem due to the large number of (i.e., 247) characters with complicated structures and, similarity between characters as well as different font styles. This paper proposes a novel approach for multiclass classification to recognise Tamil characters using binary support vector machines (SVMs) organised in a hybrid decision tree. The proposed decision tree is a binary rooted directed acyclic graph (DAG) which is succeeded by unbalanced decision trees (UDT). DAG implements OVO-based SVMs whereas UDT implements OVA-based SVMs. Each node of the hybrid decision tree exploits optimal feature subset in classifying the Tamil characters. The features used by the decision tree are basic, density, histogram of oriented gradients (HOG) and transition. Experiments have been carried out with a dataset of 12400 samples and the recognition rate observed is 98.80%with the hybrid approach of DAG and UDT SVMs using RBF kernel.
[Frequency selective surfaces, text analysis, Image recognition, unbalanced decision trees, hybrid decision tree, printed Tamil text, optical character recognition, UDT-SVM, binary rooted directed acyclic graph, font styles, binary support vector machines, radial basis function networks, RBF kernel, gradient methods, Testing, pattern recognition, image processing, HOG, histogram of oriented gradients, support vector machines, UDT, Pattern recognition, DAG, Optical character recognition software, OVO-based SVM, muIticlass classification, Image segmentation, directed graphs, decision trees, DAG-SVM, Tamil OCR, optimal feature subset, Principal component analysis, OCR]
Student-Centred Learning in a blended environment - case study based on a final year undergraduate course
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Providing a quality education is a challenging task to both teachers and administrators in the university environment. In higher educational system, the students are supposed to gain an in-depth knowledge of subject matter in a course. Online and face-to-face education have different techniques that could be combined together in a blended environment for educating the undergraduates. The intention of this study is to identify effective ways to develop the Student-Centred Learning for students who are following courses in a blended environment. A final year course of undergraduate students was selected as a case study to carry out the investigation. The selected course was designed considering both continuous learning activities for formative assessment and individual and group work for summative assessment. According to the analysis of different data gathered together with students' feedback, we evaluate the applicability of student-centred learning in a blended environment. This paper also justifies the importance of ICT enabled environment in teaching and learning to implement the student-centred learning.
[Visualization, face-to-face education, student centred learning, final year undergraduate course, continuous learning activities, undergraduate students, educational administrative data processing, Online Learning, educational technology, Student-Centred Learning, quality education, higher educational system, blended environment, formative assessment, educational courses, university environment, Learner Interaction, Blended Learning Environment]
Case study on exploitation, detection and prevention of user account DoS through Advanced Persistent Threats
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Security analysts implement various security mechanisms to protect systems from attackers. Even though these mechanisms try to secure systems, a talented attacker may use these same techniques to launch a sophisticated attack. This paper discuss about such an attack called as user account Denial of Service (DoS) where an attacker uses user account lockout features of the application to lockout all user accounts causing an enterprise wide DoS. The attack has being simulated usingastealthy attack mechanism called as Advanced Persistent Threats (APT) using a XMPP based botnet. Through the simulation, researchers discuss about the patterns associated with the attack which can be used to detect the attack in real time and how the attack can be prevented from the perspective of developers, system engineers and security analysts.
[Irrigation, invasive software, Protocols, APT, user account lockout features, Electronic mail, Servers, security analysts, computer network security, sophisticated attack, user account DoS, usingastealthy attack mechanism, Databases, ISO Standards, advanced persistent threats, XMPP based botnet, denial of service, system engineers, Monitoring, User Account DoS, XMPP bots]
Location aware security for smart mobile devices
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Smartphones and related mobile computing device usage is increasing exponentially. People see their Smartphones as being more personal than any other device, hence they tend to store sensitive information such as credit card details, user credentials on these devices. One of the main shortcomings of technology for these devices is security, due to the inherent mobile nature of these devices, the security controls that apply to PC's aren't suitable for these types of devices. Malware targeting mobile devices are very complex, they tend to exploit a number of shortcomings of these devices. We analyze the current security trends for smartphones and propose a location context aware security mechanism, which takes into account the connectivity issues and the limited processing capabilities of mobile devices. A prototype implementation is provided for Android and the results of this implementation is presented.
[invasive software, smart mobile devices, malware, mobile computing device, smart phones, location aware security, Global Positioning System, Android, Android (operating system), mobile computing, Sockets, Computer architecture, security of mobile devices, Malware, smartphones, location awareness, Monitoring, Clocks]
A multilayered analysis of polarization and leaderships in the Catalan Parliamentarians' Twitter Network
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
This article examines three layers of interaction (Twitter's following-followers relationships, retweets and mentions) within a tight-crowd and affiliation network: the Catalan Parliamentarians' Twitter Network. The objective is to test if Twitter is opening communication between parties and enabling new leaderships or if it is reducing them to representatives of the same party or ideology and empowering party leaders. The study is based on a dataset spanning from 1 January 2013 to 31 March 2014 which covers following-followers relationships (4,516), retweets (6,045) and mentions (19,507) of Catalan parliamentarians. We use social network analysis and Gephi visualizations, jointly with multiple regression in order to explain which individual and network characteristics trigger a centrality position in the network. The data sustain that the political polarization is deeper in the relationship and retweet networks than it is in the mention and that even if party leaders are still at the center of communication flows, other parliamentarians are taking the floor and becoming network leaders.
[politics, Gephi visualizations, network leaders, Polarization, Manuals, regression analysis, ideology, Twitter, twitter following-followers relationships, affiliation network, Parliamentarians, political polarization, Education, multiple regression analysis, retweet networks, Facebook, Assembly, Network Leaderships, Catalonia, Blogs, Catalan parliamentarian twitter network, party leaders, tight-crowd network, communication flows, multilayered polarization analysis, leaderships, social network analysis, social networking (online), government data processing, mention networks]
The Impact of Social Media Networking (SMN) towards business environment in Sri Lanka
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
&#x201C;Social Media Networking (SMN)&#x201D; is one of most popular web concepts mainly used for interaction and entertainment purposes. Today world leading business organizations apply SMN for business activities as a value added service. Purpose of the research project is to identify SMN trends which are popular among Sri Lankan business environment and to identify benefits those organizations gain from it. Also to evaluate the value of using SMN Trends in Sri Lankan business environment and to encourage conservative Sri Lankan businesses to use SMN trends as value added services. This is an exploratory study which leads to pattern identification, a model development and hypothesizes formulation. Thus, data gathered from three samples; Purely, Partially and None SMN Based Organizations using stratified random sampling technique. For data analysis cross tabulation, chi square test, frequency and descriptive statistical techniques were used. Results conclude organizations' SMN Usage Pattern is directly effecting to its Business success. Higher percentage of successful businesses is Partially SMN Based Organizations which use SMN as a supporting service. Research results illustrates there is 10% of SMN Impact to the total Revenue Impact factors and 25% of SMN Impact to SMN Using Activities in Partially SMN Based Organizations.
[business success, Portable computers, Web concept, chi square test, value added service, stratified random sampling technique, SMN usage pattern, social media networking, Sri Lankan business environment, business organization, Social Media Networking, descriptive statistical technique, SMN Trends, Market research, statistical testing, business activity, data analysis cross tabulation, Business, sampling methods, frequency statistical technique, Ducts, random processes, Value Added Services, pattern identification, Organizations, social networking (online), Environment, Internet, entertainment purpose, business data processing, Digital TV]
Impact of social network usage on the job performance of IT professionals in Sri Lanka
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
An analysis was done on the work performance of IT professionals in Sri Lanka and its relationship to their usage of social networking sites using formal methods of statistical analysis based on the responses to a questionnaire.
[Correlation coefficient, average resolution time, engagement, Sri Lanka, dependability, performance evaluation, DP management, job performance, human resource management, IT professionals, YouTube, work performance, LinkedIn, performance objectives, social network usage, formal methods, decision making, social networking (online), statistical analysis, Facebook]
Traffic light optimization solutions using multimodal, distributed and adaptive approaches
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Finding the optimal staging of traffic lights and determining the optimal traffic light cycles is one of the crucial tasks involved in modelling modern traffic scenarios. In this paper, we propose two distinct approaches to find optimal traffic light cycles using Multi-agent Systems (MAS) and Swarm Intelligence (SI) concepts and compare the efficiency of these solutions against a default strategy under heterogeneous traffic regions using same input parameters. The solutions obtained are simulated using SUMO (Simulation of Urban MObility), a well-known microscopic traffic simulator. We have investigated both approaches with two large and heterogeneous metropolitan areas with hundreds of traffic lights located in the cities of Colombo in Sri Lanka and Chennai in India, and our research solutions are shown to obtain optimal traffic light cycles in both scenarios. In comparison with predefined static cycle programs (using SUMO's default traffic light cycle generation algorithm), our solutions achieved quantitative improvements for the two main objectives: reducing the waiting time and the journey time of vehicles significantly and qualitatively improving smooth traffic flow over the regions.
[Measurement, Adaptation models, multi-agent systems, traffic light cycles, simulation of urban mobility, digital simulation, Vehicles, optimal traffic lights staging, Chennai, Multi-Agent Systems (MAS), Sociology, traffic control, SI, Cities and towns, Colombo, swarm intelligence concepts, multiagent systems, journey time, waiting time, SUMO, Computational modeling, metropolitan areas, Sri Lanka, Traffic Simulation, Swarm Intelligence (SI), multimodal approaches, traffic engineering computing, adaptive approaches, Statistics, predefined static cycle programs, India, microscopic traffic simulator, traffic light optimization solutions, swarm intelligence, MAS, distributed approaches]
Towards optimising Wi-Fi energy consumption in mobile phones: A data driven approach
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Contemporary mobile devices are equipped with multiple network interfaces with diverse characteristics. Although the Wi-Fi interface bestows commendable throughput and data transfer efficiency, it is least power efficient in the idle state and causes highest energy overhead when scanning for networks. In this paper we present a data driven approach to alleviate this issue, focusing on Wi-Fi usage by the user's perspective. We model the Wi-Fi usage of mobile users based on their past usage to predict usage requirements. This allows intelligently switching on the Wi-Fi interface only if the user context demands. Thus, it reduces long periods of time being in the idle state and significantly lessens the number of futile network scans. Based on the trace data collected from Rice-Livelab study, we extract temporal, application usage, operational state and location context data to build our prediction model. This study includes a systematic feature engineering process followed by the deployment of machine learning algorithms on the target dataset. We used Sampling, Ensemble and Hybrid techniques to mitigate the class imbalance problem of our prediction model. Evaluated metrics indicate that decision tree based classification algorithms perform well with the dataset and suit for working with mobile usage data, which are mostly conflated with noise, data imbalance.
[hybrid techniques, ensemble techniques, mobile phones, Wi-Fi energy consumption optimisation, location context data, energy overhead, data transfer efficiency, mobile computing, power aware computing, multiple network interfaces, sampling techniques, operational state, data imbalance, mobile users, learning (artificial intelligence), machine learning algorithms, Wi-Fi energy dissemination, Context, decision tree based classification algorithms, pattern classification, data driven approach, sampling methods, Wi-Fi interface, contemporary mobile devices, user context, Context-awareness, Rice-Livelab study, Mobile usage prediction, systematic feature engineering process, usage requirements, decision trees, Mobile usage data pre-processing, wireless LAN, IEEE 802.11 Standard, Wi-Fi usage, mobile handsets]
A resource and policy aware VM scheduler for medium-scale clouds
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Medium-scale private clouds are being widely used in enterprises and universities. While, these clouds have a relatively small pool of resources, diversity of those resources, users, and their needs are still comparable with public clouds. We present a resource and policy aware Virtual Machine (VM) scheduling solution for such medium-scale clouds. The proposed scheduler enables the deployment of VMs based on a predefined set of policies and user priorities, while being aware of the resource utilization of the cloud. This is achieved by periodically polling resource statistics from the cloud nodes, enforcing a set of predefined policies, taking into account the priority levels of users and VM requests, and then scaling, migrating, and preempting VMs based on available resources and policies. Such resource and policy aware scheduling improves resource request acceptance rate and increases the utilization of cloud resources. A proof of concept solution is implemented using Apache CloudStack and validated against a carefully crafted set of resource requests.
[resource aware VM scheduler, Apache CloudStack, resource requests, cloud resources, Private Cloud, cloud nodes, enterprises, resource statistics, resource request acceptance rate, policy aware VM scheduler, resource allocation, virtual machine, Cloud Computing, universities, virtual machines, Medium Scale Clouds, data privacy, VM Scheduling, cloud computing, resource utilization, medium-scale private clouds]
Cloud-based driver monitoring and vehicle diagnostic with OBD2 telematics
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
We present a cloud-based vehicular data acquisition and analytics system for real-time driver behavior monitoring, trip analysis, and vehicle diagnostics. Our system consists of an On Board Diagnostics (OBD) port to Bluetooth dongle, a mobile app running on a smart phone, and a cloud-based backend. We use a Complex Event Processor (CEP) at both the smart phone and the backend to detect and notify unsafe and anomalous events in real time. For example, CEP engine at the smart phone can alert the driver about rising coolant temperature and rapid fuel drops. It also provides a trip log and filter out what messages to be send to the backend, saving both the bandwidth and power. CEP on the cloud detects reckless driving in real time based on the sensor data provided through the OBD port. Historical data is also used by the backend CEP engine to detect driving anomalies and to predict impeding sensor failures. The mobile app visualizes both real-time data from sensors and alerts. A web-based interface is provided to access the backend information. We tested the system on actual vehicles and demonstrated that the computing, bandwidth, and power consumption of the smart phone is reasonable. App is currently available in Google Play.
[cloud-based backend, OBD2 telematics, Irrigation, Visualization, Bluetooth, sensor data, Vehicle Diagnostics, backend CEP engine, real-time driver behavior monitoring, power consumption, trip analysis, mobile computing, Databases, driver information systems, Google Play, data visualisation, coolant temperature, complex event processor, data acquisition, cloud computing, Monitoring, mobile app, data analysis, vehicle diagnostic, cloud-based vehicular data acquisition-analytics system, OBD2, Web-based interface, Driver Monitoring, smart phone, OBD port, on-board diagnostic port, real-time data visualization, Internet of Things, sensor failures, rapid fuel drops, historical data, computerised monitoring, Telematics, Internet, Acceleration, Bluetooth dongle, cloud-based driver monitoring, trip log]
ANDROPHSY - forensic framework for Android
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
There have been many studies addressed towards various sections in the arena of Android platform. However conducting a digital forensics investigation using Open Source tools in Android platform is still a challenging task. As of the date of this study, there is no standard Open Source or noncommercial tool available to support the entire life cycle of the digital forensics investigation methodology. In order to bridge this gap in open source forensics tool for Android platform, the work implemented a user friendly, feature rich, open source, mobile forensic framework for Android platform that supports all phases of a full digital forensic investigation process.
[digital forensics, open source forensics tool, Forensics, public domain software, Android forensics, forensic framework, Android (operating system), Databases, evidence analysis, mobile forensic framework, Android platform, user friendly, data acquisition, feature rich, ANDROPHSY, Smart phones, digital forensic investigation process]
Wireless sensor node for simultaneous monitoring of health parameters
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Many diseases, such as cardiovascular and dengue fever, require constant monitoring of certain health parameters of patients which sometimes, is disturbing to patients who requires plenty of rest. In this paper, we present a non-invasive technique based on wireless sensor networks to monitor the temperature, blood pressure and the pulse rate automatically without having to disturb a resting patient. The wireless sensor node captures these vital health parameters and then sends them to a smart phone via Bluetooth. The smart phone handles all the processing tasks and produces systolic, diastolic and heart rates and gives alerts whenever an abnormal condition occurs. The prototype device managed to perform at 99.76 %, 88.40% and 92.70% accuracy levels on monitoring the temperature, blood pressure and pulse rate, respectively. The system, designed using low-cost peripherals with minimal electronic devices, can be used to monitor patients even from a remote location via wireless technology.
[e-health, Bluetooth, wireless sensor networks, health monitoring, wireless sensor network, Valves, Wireless sensors, patient monitoring, abnormal condition, Mercury (metals), Wireless communication, health parameter monitoring, body temperature monitoring, biomedical electronics, wireless sensor node, Probes, blood pressure monitoring, cardiovascular disease, heart rate, Microcontrollers, minimal electronic device, diseases, smart phone, Time measurement, smart phones, biomedical telemetry, Wireless sensor networks, dengue fever, prototype device, pulse rate monitoring, wireless technology]
Design of auxiliary simulator for analysing the deadlock occurrence using Banker's algorithm
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Once the necessary inputs are given, the tool will display the matrix including the total allocation, initial available resource amounts and the safe sequence. Therefore, this visualization tool can be used to demonstrate the behavior of Banker's algorithm for deadlock avoidance in operating system. The users will be able to practice this as a learning tool for both classroom and individual usage.
[safe state, Visualization, visualization tool, Banker's algorithm, operating system, digital simulation, deadlock, system recovery, deadlock occurrence, deadlock avoidance, auxiliary simulator design, data visualisation, safe sequence, System recovery, operating systems (computers), computer aided instruction, learning tool, algorithm]
Identification of characteristics of government web sites for effective service
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Government web site service is a subject which requires a great amount of local knowledge in order to implement successfully. A government web site model which has been successfully implemented in another country may not be directly applicable to a Sri Lankan environment without making the required adjustments. In the Sri Lankan context, locally generated knowledge on the field of government web services is lacking. This has resulted in slower progress in local government web site development. In order to address the above void, this research has built a model with the help of previous researches which consists of six variables. During the research the importance of each of those variables towards the sustainable development of Sri Lankan government web sites will be checked.
[executability, Sri Lanka, characteristics identification, quality of service, Sustainable development, Standards, democracy, user interface, sustainable development, Reactive power, identification, public administration, government Web site service, transparency, Web sites, government data processing, accountability]
Audio transporters for unrevealed communication
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Through the speedy expansion of information and communication technologies are constantly increasing demands to accomplish extreme safety and reliability in these areas. This is a current and highly debated issue and there is evidence the fact that such a situation will persist. Steganography has been introduced as a result of that research. Steganography is the art or fashion of concealing a message, image, or file within another source. Very effective tool to ensure the information concealment is also cryptography which compared Steganography uses a different mathematical principle of security classified information. Currently, the coupling of the two techniques is making very high degree of security and a number of programs available software tools specially for images, implementing just such combined information security. This research uses audio file format as carrier. Audio files are very sensitive and very big challenge to change inside without affecting its original quality. Research objectives are confidentiality, authentication, increase hidden data size, integrity, destroy the hidden message, assure unapparent perceptual transparency of audio file (Cover object) and the object containing secret messages and send/receive audio files. This system is called AudiSteg v1.0 and suitable for safe and careful preservation of sensitive records.
[perceptual transparency, audio file format, Embed, unrevealed communication, information security, cryptography, Encryption, Steganography, audio signal processing, information and communication technology, AudiSteg v1.0, steganography, audio transporter, information concealment, Cryptography, secret message, Digital audio players, authentication]
Exploring the user experiences of collaborative online learning
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Collaborative online is advantageous in developing team building skills through computer mediated leaning. The study has focussed on the user experiences of using collaborative online learning. According to the findings there are both positive and negative user experiences. Since the collaborative online learning supports in developing communication, team building, decision making and negotiation skills it is important to improve the collaborative online learning. This study can be further improved through developing suitable guidelines to create collaborative online learning.
[Computers, Buildings, user experience, distance learning, computer mediated leaning, groupware, decision making, team building skill, Collaborative work, negotiation skills, computer aided instruction, Internet, collaborative online learning]
Reconfigurable ALU optimization
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
The RALU optimisation research targeted to develop a soft processor, which is capable of a dynamic optimization of resource utilisation and increased processor throughput by changing its structure according to the running instruction. The RALU shows higher instruction gain and clock cycle gain compared to 8 bit microprocessor in similar scale. So the RALU approach provides solution to higher resource critical FPGA based design by improving the resource utilisation and providing higher processor throughput.
[Microcontrollers, field programmable gate arrays, FPGA, Reconfigurable computing, dynamic optimization, ALU, clock cycle gain, optimisation, Algorithms, reconfigurable architectures, reconfigurable ALU optimization, RALU optimisation research, soft processor, Field programmable gate arrays]
Designing a quality Health Information System: Case study analysis in Papua New Guinea
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
eHEALTH is an innovative IT tool that is an enabler in the delivery of quality healthcare services especially for developing countries. There are different forms of eHealth ranging from ePrescribing, telemedicine, consumer health informatics, health knowledge management, virtual healthcare teams, mHealth, medical research using grids and healthcare information systems. Healthcare Information Systems or software solutions, particularly for patient data management, work schedule management and other administrative tasks surrounding health, is vital for the delivery of quality and effective delivery of health services. This extended abstract provides an overview of a current research study concerning the adoption of eHealth, as an innovative tool to improve the health information systems in Papua New Guinea (PNG) to meet WHO standards. The research is a policy, process and application driven approach.
[Papua New Guinea, innovative IT tool, Medical services, mHealth, PNG, quality healthcare service, medical research, Health Information Systems, healthcare information system, eHealth, Information systems, developing country, WHO standard, eHEALTH, virtual healthcare team, quality health information system, consumer health informatics, Monitoring, health care, health knowledge management, telemedicine, health service, medical information systems, work schedule management, software solution, ePrescribing, Internet, patient data management, Australia, Biomedical monitoring, administrative task]
Conditionally evolving memory for computers
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Most of the contemporary computers are evolved from the Von-Neumann architecture which was built based on the Charles Babbage's mill and the store concept. Thereby this architecture consists of a processor and a memory where the memory improves the processing power. Later different kinds of smaller memories such as registers &amp; caches were introduced to enhance the processing power of the computer. It is an existing great research challenge to improve the performance of the computer and in doing so, there is a trend to design computing models by imitating human mind.
[Computers, Conditional Process, memory architecture, conditionally evolving memory, Von-Neumann architecture, contemporary computers, Charles Babbage mill, Computing Model, 24-Causal Relations, Turing Machine]
Analysis of the necessity of developing regulatory guidelines for eMoney Operations in Sri Lanka
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
"Virtual Money" has been an interest domain for many scholars and financial institutions especially during the last three decades. Different denominations printed on same sized papers of the same material can also be argued as virtual as the raw paper of the same size does not carry any face value. However, "Electronic Money" which is also known as eMoney or Digital Money is clearly segregated by the definition from other substitute products with electronic usage of money. Stored value or pre-paid products in which the monetary value is stored on an electronic device in the consumer's possession are considered as electronic money products. Hence, typical debit cards, credits cards, mobile banking and Internet banking are omitted from this category.
[e-money operations, eMoney, Regulations, virtual money, Sri Lanka, Legislation, Electronic Money, digital money, monetary value, electronic money]
Interaction design for tablet based edutainment systems for mathematical education of primary students
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Mathematics has been perceived as the core area of learning in most educational systems around the world including Sri Lanka. Unfortunately, it is clearly visible that a majority of Sri Lankan students are failing in their basic mathematics when the recent grade five scholarship examination and ordinary level exam marks are analysed. According to Department of Examinations Sri Lanka, on average, over 88 percent of the students are failing in the grade 5 scholarship examinations where mathematics plays a huge role while about 50 percent of the students fail in there ordinary level mathematics examination. Poor or lack of basic mathematics skills has been identified as the root cause.
[educational systems, graphical user interfaces, Department of Examinations Sri Lanka, mathematics skills, mathematics computing, ordinary level exam marks, Edutainment, Interaction Design, mobile learning, Sri Lankan students, ordinary level mathematics examination, primary students, tablet based edutainment systems, interactive systems, scholarship examination, human computer interaction, computer aided instruction, notebook computers, interaction design, Australia, mathematical education, Mobile game based learning, Human Computer Interaction]
Effective clinical decision-making from Practice-Based Evidence
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
This is an ongoing research investigating the use of health information technologies (HIT) to improve clinical decisionmaking processes. Effective and timely clinical decision-making can lead to positive improvements in patient's health outcome. The primary hypothesis of this research is that a Practice-Based Evidence (PBE) approach by utilisation of Electronic Health Records (EHR), improves clinical decision-making capabilities of healthcare professionals. This study therefore looks to answer the following research questions. (I) What is the current practice by healthcare professionals when making clinical decisions? (2) What limits the ability to make well-informed clinical decisions? and (3) How EHR and PBE assisting improvements to the clinical decision-making capabilities?
[practice-based evidence approach, patient health, electronic health records, patient care, EHR, Practice-Based Evidence, Electronic Health Record, decision making, clinical decision-making capabilities, Reliability, health information technologies, healthcare professionals, health care]
Use of Consumer Health Informatics as an employer strategy to improve productivity
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Employee population health performance management has become a critical factor for organisational productivity. The WHO report titled &#x201C;Healthy Workplace Framework and Model&#x201D; indicates that the most successful and competitive organisations are those that have the most physically and mentally healthy employees. This concept has prompted organisations throughout the world to search for strategies that will reduce productivity loss related to employee health impairments and improve the impact of their employee health promotion programs. This extended abstract explains an ongoing research study, investigating the ability to use Consumer Health Informatics (CHI) applications for organisational population health performance management, directed toward organisational productivity and considering the key stakeholders (employers and employees).
[CHI applications, medical information systems, Consumer Health Informatics, health performance management, manufacturing data processing, organisational productivity, Employee Sponsored Personal Health Records, productivity, Healthy Workplace Framework and Model, Lead, employer strategy, employee health promotion programs, employee welfare, consumer health informatics, Health Key Performance Indicators]
Context-aware sentiment classification
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Sentiment Analysis is a growing research area of Natural Language Processing which aims at identifying positive and negative opinions and emotions from a textual data. Presently. Sentiment Analysis research works range from document level classification to sentence-level. phrase-level or aspect/feature level analysis. Context-awareness is of key important for sentiment classification since particular evaluation phrase in one context may express a positive sentiment while in another context it may express a negative sentiment. For example, the adjective "unpredictable" may have a negative orientation in an automotive review, in a phrase such as "unpredictable steering\
[pattern classification, text analysis, natural language processing, sentiment analysis, sentiment classification, sentence-level analysis, sentiment analysis research, aspect-feature level analysis, typed dependency, context-aware, context-aware sentiment classification, phrase-level analysis, negative sentiment, textual data, document level classification, positive sentiment, negation scope]
Web-based intelligent tour planner and advisor
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Results obtained through the first prototype testing was where the ontology created using Protege was successfully added into the system, and travellers features were successfully mapped with the destination features (using scores), in order to display the most preferred attractions to the user. The intention of this system is to generate a grounded theory about the extent to which semantic technologies can assist in the creation and integration of a consistent and user-oriented web-based tourist information system.
[semantic Web, Ontologies, E-tourism, Web-based intelligent tour planner, Semantic Web, Protege, semantic technologies, Web-based intelligent tour advisor, travel industry, traveller features, user-oriented Web-based tourist information system, Semantics, ontologies (artificial intelligence), Personalized Trip Plans, ontology]
Facial index based automated composite tool
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
A facial composite is a graphical representation of a human face according to eyewitnesses' description. The failure rate of suspect identification through facial composite sketch has been declared as 92.86% in the year 2014 in Sri Lanka. In order to overcome this situation an automated image processing based software solution will be introduced which includes 2D facial feature templates created for the first time targeting the local population. The aforementioned templates will be based on facial indexes, both used in previous similar research studies and newly defined indexes suited for the current study.
[2D facial feature templates, automated facial composite tool, Filtering, Sri Lanka, Manuals, automated image processing based software, suspect identification, Anthropometric Measurements, facial index, police data processing, facial composite sketch, feature extraction, Facial Composite, face recognition, Facial Indexes]
Information Accountability of Healthcare Big Data
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
This ongoing research would lead from this investigation of proper data extraction points from healthcare big data and application of information accountability measures to enhance the practicability of real time quality decision making in healthcare service deliveries.
[Information Accountability, information accountability, data extraction points, quality decision making, Electronic Health Records (EHR), Big Data, Healthcare, medical information systems, health care, healthcare big data, healthcare service delivery]
Database modelling for vision impaired indoor navigation systems: Extended abstract
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Cooperative research has been conducted to improve navigation services for vision impaired when they are moving through an indoor environment. Hence, to facilitate vision impaired individual in indoor environment requires a formal modelling approach for map generation and decision making about navigation pathways avoiding obstacles. The proposed data model consists "AccessBIM" database (DB) and API functions. The "AccessBIM" features such as, database connection initiation, function call, function return and database connection termination are organized as a series of function objects that meet the various needs of the database to maintain the relational schema. The proposed API primarily consists of two components, namely; DB connector and the API functions. Proposed "AccessBIM" DB will be implemented using real-time database such as "PostgreSQL". The weighted focus will be given to the areas such as Queries, Indexes and Transactions in relation to tuning the DB and the queries. The performance of the proposed API will be evaluated based on the time required to parse and Data insert rate and retrieval rates.
[indoor navigation, handicapped aids, AccessBIM, Database Optimization, application program interfaces, PostgreSQL, database management systems, indoor environment, function call, data retrieval rates, database connection initiation, database connection termination, vision impaired indoor navigation systems, Navigation, DB connector, real-time database, information retrieval, vision defects, data insert rate, SQL, relational schema, database modelling, Data Model, function return, API functions, AccessBIM features, AccessBIM database]
Quality of information for quality of life: Healthcare big data analytics
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Business intelligence and analytics, and big data analytics have become increasingly important in describing the data sets and analytical techniques in software applications that are so large and complex. These two techniques have been used as analytics by several e-commerce communities. For example, vendors such as Amazon and eBay have adapted these techniques to significantly advance in innovative and highly recommended scalable e-commerce platforms and product systems to target potential customers thus increasing business revenues. In a similar context, the health community have experienced not only more complex and large data content, but also information systems that contain a large number of data sources with interrelated data. Furthermore, due to the increasing diversity and differentiation of expansions by service providers in the form of primary or nursing care, a variety of service organisations in the public and private hospital networks including new medical specialist facilities have resulted in challenging, and highly dynamic environments resulting in the creation of big data with its enumerate complexities, for instance sharing information with expected security requirements of stakeholders. Therefore, the health community will have to adapt the concept of big data analytics in order to solve major issues that have occurred due to complex shared information.
[hospitals, information quality, information sharing, Healthcare Big Data Analytics, healthcare big data analytics, analytical techniques, e-commerce platforms, Quality of Information, competitive intelligence, business intelligence, public hospital networks, Value Co-creation, e-commerce communities, information systems, health community, nursing care, health care, data analysis, Big Data, business revenues, medical information systems, business analytics, private hospital networks, software applications, service organisations, Electronic Health Record (EHR), quality of life]
Activity theory based analysis of mobile Language Learning among School Leavers of Sri Lanka
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
This study of the interaction analysis carried out using the activity theory reveals efficacious results in initiating m-learning research among the school leavers of Sri Lanka. In future we expect to design a mobile application and experiment it with the use of AT.
[English Language Learning, linguistics, activity theory based analysis, languages, Sri Lanka, school leavers, Mobile Assisted Language Learning, interaction analysis, Activity Theory, mobile learning, mobile language learning, m-learning research, AT, M-Learning, computer aided instruction, educational institutions]
A neural network based approach for mobile communication demand prediction
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
In a competitive mobile communication market, forecasting the future demand is of the highest importance to allow a better service for the subscribers and a balanced workload for the operators.
[demand forecasting, mobile communication, telecommunication network management, competitive mobile communication market, Artificial neural networks, Predictive models, Mobile communication, neural network based approach, Demand prediction, telecommunication computing, neural nets, mobile communication demand prediction]
Tutorials
2015 Fifteenth International Conference on Advances in ICT for Emerging Regions
None
2015
Presents a listing of tutorials included in this conference.
[]
Message from the conference chair
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
It gives me pleasure to welcome you all to the 16th International Conference on Advances in ICT for Emerging Regions (ICTer2016) to be held on 1st and 2nd September 2016 at JetWing Blue, Negombo, Sri Lanka.
[]
Foreword by the co-chairs
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
It is a great pleasure for us to welcome you to the 16th International Conference on Advances in ICT for Emerging Regions (ICTer 2016), which will be held on 1st &amp; 2nd of September 2016 at the hotel Jetwing Blue, Negombo, Sri Lanka.
[]
Organizing committee
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Provides a listing of current committee members and society officers.
[]
Technical program committee
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Provides a listing of current committee members and society officers.
[]
Keynote speakers
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Provides an abstract for each of the keynote presentations and may include a brief professional biography of each
[]
Adaptive event tree-based hybrid CEP computational model for Fog computing architecture
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
With the bloom of data generation devices at the network-edge, obtaining data intelligence in real-time posed problems due to network incompetence. In this paper we present a novel computation model based on Fog computing that take advantage of its low latency computing capabilities. A proof of concept is designed on top of the computation model as a layered system architecture that consists of sensors as data sources and complex event processing as the computation model in a Fog node. An event tree based scheduling system is proposed to mitigate the event dependencies. We also introduce a Fog to Cloud gateway that schedule data to the Fog or to the Cloud using a rule engine and system resource prediction. We evaluate the system against a traditional Cloud based computation model to validate its effectiveness and real-time computation capabilities.
[Cloud computing, data sources, fog computing architecture, Computational modeling, system resource prediction, adaptive event tree-based hybrid CEP computational model, event tree-based scheduling system, data generation devices, cloud gateway, Edge computing, resource allocation, data intelligence, Data integration, layered system architecture, Computer architecture, Fog Computing, Fog to Cloud Gateway, Data models, Sensors, Sensor Data Fusion, cloud computing, Complex Event Processing]
Generalized and hybrid fast-ICA implementation using GPU
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Independent Component Analysis is proposed as a solution to the Blind Source Separation problem. Among many of its realizations such as Infomax-ICA, Fast-ICA, and EASI- ICA, the Fast-ICA algorithm is the most famous and considered to be computationally the most efficient. Although the most capable, Fast-ICA still consumes a considerable amount of time on CPUs in real world implementations. Therefore, researchers in the past have considered accelerating Fast-ICA with the assistance of emerging GPGPU technologies. Such accelerations are effective because Fast-ICA makes use of a vast number of matrix operations which GPGPU are good at. However, all such previous works have focused on a particular application and therefore cannot be considered as generalized approaches for different data sizes. Therefore, in this paper, we concentrate on proposing a generalized and hybrid Fast-ICA implementation that makes use of the CPU and the GPGPU at their best possible capacities. We recommend an approach, where, depends on the data size, the different components of the Fast-ICA algorithm is suggested to be run on either CPU or GPGPU for the best performance. We achieve this via performing a deep analysis and profiling of the Fast-ICA algorithm on both the CPU and GPGPU and identifying the limitations and boundaries of the algorithm.
[Algorithm design and analysis, Symmetric matrices, Graphics processing units, Accelerated Fast-ICA, ICA, GPGPU technologies, BCI, matrix operations, graphics processing units, GPU, CUDA, independent component analysis, blind source separation problem, Fast-ICA, Parallel processing, Libraries, hybrid fast-ICA implementation, Central Processing Unit, Acceleration, blind source separation]
Enhancing X10 performance by auto-tuning the managed java back-end
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
X10 is a programming language specifically de- signed with productivity and scalability in mind. In the era of distributed multi-core systems, X10 provides programmers a high-level abstraction which is an absolute necessity. In this paper we present an auto-tuning solution to enhance the performance of X10 programs that uses the Java back-end. Our auto-tuner is based on OpenTuner, an extensible framework for building auto-tuning applications. We present improved running times for X10 benchmark programs that are shipped with X10 and the well known LULESH benchmark. The auto-tuning experiments recorded a maximum performance improvement of 50% for LULESH while the average improvement for the set of benchmarks is 25%. We analyze the internal changes a Java Virtual Machine (JVM) undergoes as a result of our auto-tuning. Finally, the study of the behavior of tuned programs for their input sensitivity shows that our tuned JVM configurations would continue with enhanced performance over varying input sizes of a program.
[Productivity, JVM, Java, multiprocessing systems, distributed multicore systems, LULESH benchmark, Time measurement, programming languages, Tuning, Optimization, OpenTuner, performance, Java back-end auto-tuning, JATT, X10, virtual machines, X10 programming language, Benchmark testing, Java virtual machine, auto-tuning]
A method to extract essential keywords from a tweet using NLP tools
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
A tweet is an authentic use of Natural Language where the user has to deliver the message in 140 characters or less. According to previous researchers, this restriction increases the possible ambiguity of a tweet making it difficult for traditional Natural Language Processing (NLP) tools to analyze it. This research enhances the machine learning based Stanford CoreNLP Part-of-Speech (POS) tagger with the Twitter model to extract essential keywords from a tweet. The system was enhanced using two rule-based parsers and a corpus. The research was conducted using tweets of customer service requests sent to a telecommunication company. A domain specific corpus was compiled after analyzing the tweets. The POS tagger extracted the keywords while the parsers removed any possible noise and extracted any other keywords missed by the POS tagger. The evaluation of the system was done using the Turing Test. The proposed system was tested and compared against the Stanford CoreNLP. The testing was conducted using 6 test cases, each consisting of a human keyword generator and a supervisor. In order to ensure the impartiality and intellectual diversity, the response generators and supervisors were representatives of 6 different fields. As a result of the enhancements, the Turing Test score of the system increased from 50.00% to 83.33%. The accuracy of the system could be further improved by using a complete domain specific corpus. Since the approach used theoretical linguistic features of a sentence, the same method could be employed for other NLP tools.
[machine learning based Stanford CoreNLP part-of-speech tagger, domain specific corpus, Twitter, Twitter model, rule-based parsers, Customer services, knowledge based systems, Natural language processing, NLP tools, learning (artificial intelligence), customer service requests, essential keyword extraction, natural language processing tools, Turing test score, natural language processing, telecommunication industry, information retrieval, Natural Language Processing, Turing Test, Pragmatics, customer services, Keyword Extraction, POS tagger, tweets analysis, grammars, telecommunication company, Tweet Analysis, Tagging, Syntactics, Feature extraction, social networking (online)]
Making sense of large volumes of unstructured email responses
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Unstructured textual data has increased to unprecedented levels with the rapid spread of user generated content via social media. Handling large volumes of unstructured text data is a challenging task that is increasingly becoming needed in a variety of situations. Reading and extracting important information from large collections of text manually is impractical and often impossible. This research concerns making sense of 500,000 email submissions received in response to a debate on Net Neutrality in India. The large volume of HTML format data was preprocessed using natural language processing (NLP) before analyzing it. Topic modeling and sentiment analysis were used to explore the nature and scope of the submissions so received, and provided a framework for dealing with this increasingly recurring problem. Interesting topics were identified from the submissions by using the Latent Dirichlet Allocation (LDA) topic model, which included themes such as the speed of internet, security, privacy and internet traffic among others. Word clouds were then generated to visualize key concepts within these email responses. A lexicon-based approach was used to classify the sentiment polarity of responses as positive, negative and neutral. Two methods were used to classify polarity of responses. In the first method, negative and positive word lists were used to classify polarity. There was considerable accuracy in the classification results. In the second method, the SentiWordNet lexical resource was used for classification and resulted in improved performance.
[Sentiment analysis, user generated content, LDA topic model, Big Data Analytics, data mining, electronic mail, topic modeling, HTML, Electronic mail, Sentiment Analysis, Data mining, unstructured email responses, Analytical models, NLP, feature extraction, HTML format data preprocessing, Big data, data structures, net neutrality, text mining, social media, pattern classification, unstructured textual data, natural language processing, sentiment analysis, sentiment polarity classification, India, latent dirichlet allocation, Topic Modeling, information extraction, SentiWordNet lexical resource, Data models]
Hybrid Part of Speech tagger for Sinhala Language
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
This research presents a hybrid Part of Speech tagging approach which utilizes both rule based and stochastic tagging approaches for Sinhala Language. In the first phase, Hidden Markov Model based stochastic tagger is constructed which is based on bi-gram probabilities. A stemmer is used in the tagging process to enhance the accuracy of the tagger. An experiment on three POS tag set versions is carried out to come up with the best tag set which leads towards a meaningful and precise tagging process for Sinhala Language. Since Sinhala is a morphologically rich language, rules based on morphological features are used to predict the relevant tag for words which do not present in the training set. Further, an experiment is carried out to find out whether the implemented hybrid tagger can be used to enhance the size of the data set. The implemented hybrid tagger is successful in achieving an overall accuracy of 72% when the average unknown word percentage is 20%.
[text analysis, Sinhala language, Stochastic processes, stochastic tagging, Rule based Tagging, Stochastic Tagging, Training, hidden Markov models, Viterbi algorithm, rule based tagging, Part of Speech Tagging, feature extraction, knowledge based systems, POS tag set versions, Sinhala Language, morphological features, bi-gram probabilities, natural language processing, hybrid part of speech tagger, probability, Hybrid POS Tagger, Probability, Hidden Markov models, hidden Markov model based stochastic tagger, Tagging, Speech, hybrid part of speech tagging]
A psychological based analysis of marketing email subject lines
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Email has been an effective and popular communication medium since its birth in 1971 to now. The number of email users have increased from a handful to 2672 million as of 2016 and it is predicted to increase further. This enormous growth has established an effective marketing medium called email marketing. The present email advertisement revenue has reached $19,353 million, it has not reached to a significant proportion. A marketing email becomes a success only if the email is opened and read by the receiver. The subject line of an email and the email address of the sender are the main deciding factors for one to open an email or leave it. Sentiment analysis is a popular research area which uses natural language processing, text analysis and computational linguistics to identify and extract subjective information in source materials. This research work analyses the email subject lines in a psychological point of view, for their effect in a person when he/she read it and the decision he/she makes to open that email or neglect it. The objective of this research is to develop methods that can quantify the psychological effects induced by an email subject line; where this quantification is correlated with the action performed by the email receiver. This research work was carried out through sentiment analysis and data mining on three large data sets, namely Enron e-mail, Spamdex Digital Spam Archive and Google Open Adwords. Based on studies in the area of sentiment analysis seven types of analysis techniques were identified and utilised in this study. These seven type of analysis are categorised into three, namely Semantic analysis, Descriptive Analysis and Observational Analysis. Semantic analysis considered the meaning of words in the email subject lines and their psychological effects in three different aspects, namely, Emotional Analysis, Subjectivity Analysis and Sentiment Analysis. Particularly for the Emotional analysis, this paper proposes nine emotions based on the Indian aesthetics over the classical opinion analysis approach. Descriptive analysis and the Observational analysis considered the subject line structure and the effect of certain word/phrases as well as the number of words and characters respectively. Email subject line analysis is a new area of research and so far did not produced any scholarly articles. This study has identified the ways in which the email subject line analysis could be taken forward and has proposed forty rules which can be used to create successful email subject lines. It was observed that the results of this study matched with a neurological study on a similar topic which mapped brain hotspot changes for emotion reflections.
[communication medium, Sentiment analysis, text analysis, Enron e-mail, Dictionaries, computational linguistics, e-mail subject line analysis, Psychology, data mining, electronic mail, email subject line analysis, neurological study, Electronic mail, marketing medium, emotion reflections, email receiver, psychological based analysis, subjectivity analysis, subject line structure, Spamdex Digital Spam Archive, Semantics, Indian aesthetics, data sets, brain hotspot changes, Advertising, email marketing, advertising data processing, natural language processing, sentiment analysis, classical opinion analysis, Receivers, observational analysis, email advertisement revenue, source materials, descriptive analysis, semantic analysis, Google Open Adwords, scholarly articles, emotional analysis]
Automated assessment of multi-step answers for mathematical word problems
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
We present a system to automatically grade the mathematical word questions. The questions that we currently consider are at the level of GCE (General Certificate of Education) Ordinary Level (O/L) Mathematics paper standard in Sri Lanka. The solutions to these questions are open-ended multi step answers. The system uses a regular expression based information retrieval approach to validate the expressions in the answers. The implemented system properly evaluates student answers using a marking rubric and awards full/partial marks. We have tested the performance of the system using 500 answer scripts for five different questions from 50 students. The grades given by the system are compared against the manual grading marks and only one answer was graded wrongly. Therefore, the accuracy of the system is 99.8%.
[Computers, open-ended multistep answers, general certificate of education, automated assessment, mathematics computing, ordinary level mathematics paper standard, Sri Lanka, Manuals, information retrieval, GCE, mathematical word problems, Multi-Step Answers, Standards, XML, Training data, Computer Aided Assessment, computer aided instruction, Mathematical model, multistep answers, Automatic Grading, Mathematical word problem, student answer evaluation]
An innovative mobile learning framework for the field of Agriculture extension Sri Lanka
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Sri Lanka is a country which has got an opulent history in agriculture and it still performs large portion in the national economy. But dissemination of agricultural knowledge among the agricultural stakeholder is still a problem. Currently mobile learning is opening new dimension of learning and it enriches with any time anywhere facility. Therefore it is worthy to apply mobile learning to the Agriculture, but agricultural stakeholders are having their own inherited characteristics, it is required to conduct detail study. This study is based on experimental research methodology. Initial phase of this research found usability, teachers course management skills, learners learning style, course personalization, content personalization, activity based assessment, geo localized knowledge, interactive content, teacher student communication, collaboration of peers and expert support as key factors for the success mobile learning in Agriculture. Then Android and Restful web services based innovative mobile learning prototype was developed and perception based assessments were conducted to test them. Finally user feed backs confirm that factors which found in initial phase of this research are essentials for success of mobile learning in agriculture extension.
[peer collaboration, course personalization, agriculture extension, geolocalized knowledge, Mobile communication, Mobile handsets, learners learning style, Content personalization, agriculture, Analytical models, Android (operating system), Android Web services, innovative mobile learning prototype, Course personalization, Agriculture, activity based assessment, agricultural information dissemination, service-oriented architecture, service based learning management system, Restful Web services, information dissemination, Sri Lanka, teachers course management skills, agricultural knowledge dissemination, Global learning content, Object recognition, Interactive content, mobile learning, Activity based assessment, learning management systems, Web services, teacher student communication, content personalization, Geo localized knowledge, Geo localized facilitator, interactive content, Mobile learning, agricultural stakeholder, Stakeholders, Service based learning management system, Usability]
Adoption of Information Communication Technology in cashew sector: A case in Puttalam District of Sri Lanka
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Information and Communication Technologies (ICT) have a remarkable potential to improve the agricultural practices and innovation systems and to achieve significant benefits. To achieve the complete benefits of ICT, it is better to understand the constraints in ICT adoption for agricultural development, identify feasible options for reducing the constraints and contribute to develop effective policies at increasing the use of ICT. This study investigated the adoption of Information Communication Technology (ICT) in cashew sector which represents estates owned and managed both by small holders and plantation companies. A questionnaire based survey was conducted to collect data from 50 Small Holder cashew estates and 26 Plantation Company owned cashew estates in Puttalam District of Sri Lanka. To quantify the adoption of ICT, three indices were developed viz. &#x201C;Primary ICT Adoption Index&#x201D;, &#x201C;Secondary ICT Adoption Index&#x201D; and &#x201C;Tertiary ICT Adoption Index&#x201D;. Further, t test was carried out to find out the relationship between the ICT adoption index of Small Holder cashew estates and Plantation Company owned cashew estates. Eight statements were used to calculate the attitudinal percentage of ICT of managers and owners. The results show that these estates were not innovative ICT by adopting Tertiary or Secondary type of technologies; however they were mostly confined to the basic facilities. The results from the three indices highlighted that the plantation company owned estates have higher ICT adoption than small holders. According to the analysis, no significant relationship was observed between ICT adoption and working experience and age of the managers, number of employees in the estate and cashew production. However, a positive relationship was observed between education level and the ICT adoption in the cashew sector in Puttalam district.
[Puttalam district, Cashew, Sri Lanka, Companies, agricultural products, Electronic mail, Indexes, Information and Communication Technologies, t test, agricultural development, Agriculture, cashew sector, Information and communication technology, Internet, information communication technology, secondary ICT adoption index, cashew estates, primary ICT adoption index, tertiary ICT adoption index, Adoption]
A technique for Quantitative Coronary Analysis of Cine-Angiograms using segmentation and vessel path tracking
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Coronary Cine-angiogram (CCA) is one of the widely used preliminary invasive medical image modalities in Interventional Cardiology for the detection of luminal obstructions in Coronary Artery (CA) vasculature. It is apparent that the clinical judgments based on angiography are subjective and lead to overestimation and underestimation of the detected stenosis. Hence, such imprecise diagnosis can have an adverse impact on the patients' quality of life imperfectly. This study elaborates a novel method for Quantitative Coronary Analysis (QCA) for objectively assessing the severity of the detected stenosis in main CAs recorded in direct CCAs. The proposed QCA method is based on the segmented vessels' geometry and vessel path tracking and consists of five major implementation phases namely; preprocessing, segmentation, vessel isolation, vessel path tracking and diameter calculation. The result of the proposed method has successfully proven its ability to detect relevant features, clinical supportability for stenosis detection and capability to objectively assess the clinically approved stenosis regions. Moreover, this proposed method can be further extended to assess the stenosis severity based on the functional significance of the CAs.
[Visualization, Angiography, segmented vessel geometry, vessel path tracking, vessel isolation, interventional cardiology, Arteries, feature extraction, image segmentation, quantitative coronary analysis, segmentation, Skeleton, preliminary invasive medical image modalities, medical image processing, CCA, Image edge detection, coronary Cine-angiogram, blood vessels, angiocardiography, luminal obstruction detection, coronary artery vasculature, QCA method, feature detection, Image segmentation, stenosis detection]
Visually impaired support-system for identification of notes (VISION)
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Visually impaired community rely on many artificial aids which allow them to lead an average life in the complex modern society. Identification of currency notes is of utmost importance in this regard and many electronic currency note recognizers have been developed. Nevertheless, a compact, accurate and a cost effective recognizer optimized for local currency notes is highly preferred. In this paper we present the design of a less complex recognizer based on colour detection, thus avoids the expensive and bulky hardware. The test results demonstrate the designed note identifier to be performing in par with the existing similar products while it is capable of being used as a very handy handheld device.
[Visualization, handicapped aids, Visually impaired, electronic currency note recognizers, Object recognition, colour sensors, currency notes, designed note identifier, Training, visually impaired support-system, artificial aids, electronic classification, optimisation, Image color analysis, Prototypes, computer vision, note identification, Sensors, image colour analysis, colour detection]
Computer representation of Venn and Euler diagrams
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Venn &amp; Euler diagrams are well-defined mathematical diagram types, which are the major representation methods of Set Theory. Although understanding of different diagram types such as charts and coordinate graphs has been addressed, no research has been done for Venn and Euler diagram interpretation from an image. Venn and Euler Diagrams exist in various media types such as printed format in books, raster images and vector images in electronic media. In this research, a methodology for set details extraction from a vector image is presented and Venn data representation is introduced, which can store Venn details extracted from a Venn or Euler diagram.
[Computers, Venn Diagram, Shape, mathematics computing, mathematical diagram, Boundary conditions, diagrams, Venn diagram interpretation, computer representation, set theory, Data mining, Euler Diagram, Venn data representation, Euler diagrams, Euler diagram interpretation, XML, set detail extraction, Computer architecture, Venn diagrams, Diagram Understanding, vector image, Set Theory, Vector Images]
Low-cost bitwise 2D ising model representation using Monte Carlo and metropolis algorithm
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
The 2D Ising model obviously deals with mass data to study the behavior of magnetization and energy related with temperature. This simulation should be worked out efficiently in terms of cost, time and memory consumption. In this paper, we introduce an innovative technique that executes bits instead of integers in order to reduce memory usage (1/32) and turnaround time (0.53). This approach has been implemented in two ways using C++: 1) Boolean 1D-array lattice representation, 2) Individual bits of unsigned integers. Improvement on the spatiotemporal performance of this approach over the method of traditional integer representation is proved both analytically and experimentally.
[turnaround time reduction, Monte Carlo algorithm, memory consumption, Lattices, innovative technique, magnetisation, storage management, spatiotemporal performance Improvement, unsigned integers, memory usage reduction, Mathematical model, Boolean 1D-array lattice representation, 2D Ising model, spatiotemporal performance, electrical engineering computing, Metropolis algorithm, lattice bits, Magnetization, Computational modeling, magnetization, Two dimensional displays, Boolean algebra, C++ language, spatiotemporal phenomena, low-cost bitwise 2D Ising model representation, Memory management, C++ implementation, Boolean 1D-array, Arrays]
Train traffic optimization to minimize stochastic delays
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Optimization is a wide research area applicable to many areas of science and technology. Day by day, the increasing demand and complexities in the area of transportation, trigger many countries in the world to draw their attention on maximizing rapid adoption of railway transportation. The main consideration is how ever is to utilize the existing infrastructures in order to provide better and enhanced service. There is no difference in Sri Lanka, compared with other countries, facing same problems in transportation in order to provide efficient railway services with limited infrastructure and resources. Providing better railway service in Sri Lanka is big challenge than other countries due to managing stochastic delays. This is one of critical problems has to be addressed in Sri Lankan context. Annual train delays due to stochastic events are considerably high in rate than other countries. This directly effects on total productivity of the country itself intern. Main concern of this research is to reduce delay created by stochastic events, applying optimization technologies and low cost devices. This paper discuss the idea without delve into deep technical details.
[Ant Colony Optimization, stochastic events, rapid adoption, Meta heuristics, Sea measurements, railway services, traffic engineering computing, Pheromones, Servers, train traffic optimization, Optimization, railways, railway engineering, optimisation, Stochastic delays, Databases, Rectangle Bound Theory, science and technology, productivity, stochastic delays, Rail transportation, Real-time systems, Delays, railway transportation]
Decision support system for school cricket in Sri Lanka (CricDSS)
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
The management of Sri Lankan school and club level cricket board faces the challenge of dealing with match statistics in match analysis using manual methods. The analysis of previous cricket matches is time consuming and messing up due to lack of technology. The aim of this research is to upgrade the Sri Lankan school cricket with the blend of information technology to solve the existing problems. The proposed solution is focusing on implementing a web based system using open source technologies to solve the issues regarding with match analysis. Also a Genetic Algorithm based advanced team selection model is presented in line with the web solution. Mainly the inputs to the system are gathered through the online scorecard while the outputs of the system are in the form of graphical representation. The web based solution is suggested to use in school cricket of Sri Lanka in order to witness the cost effective technological advantages in their decision making activities.
[Decision support systems, school cricket, Web based system, public domain software, information technology, Decision making, Sri Lanka, Manuals, educational administrative data processing, genetic algorithms, Information technology, Biological cells, decision support systems, team selection, Genetic algorithms, match analysis, genetic algorithm, decision support system, open source technologies, Software, educational institutions, Internet, sport]
Vemaque: Approximately verifiable remote computation of k-clique and maximum clique problems
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
When a client needs to delegate the computation of a task to another party, there will often be a need to verify the result returned from that party, without re-executing whole of the computation. Recent work on verifiable remote computation has made a significant advancement on this problem by solving it to near practicality. However such works can only handle a restricted class of computation such as linear computations. Towards solving this gap, this paper presents Vemaque, a system to approximately verify two NP-complete computations (the k-clique problem and the maximum clique problem) that are not addressed in prior works. Experimental results show that Vemaque has achieved more than 98% accuracy of verification and reasonable performance using probabilistic proof systems.
[Performance evaluation, Cloud computing, Vemaque, Protocols, maximum clique problems, graph theory, k-clique problem, Memory, Probabilistic logic, Interactive Proofs, probabilistic proof systems, NP-complete computations, formal verification, Verifiable remote computation, linear computations, Probabilistically checkable proofs, Maximum Clique problem, Manufacturing, theorem proving, approximately verifiable remote computation, k-clique problems, Capacity planning, computational complexity]
Biofeedback based computational approach for Working Stress reduction through meditation technique
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Working stress is recognized as one of the major challenges faced by the working community around the world. Working Stress is the response of the people, when presented work demands are not matched to their knowledge and ability and which challenge their ability to cope. Increased stress at work cause depression and anxiety. Working stress cannot be avoided, so mechanism to cope with the stress positively should be identified and practiced. Mindful meditation together with biofeedback helps to reduce the working stress. Quantitative classification of mental stress is important to cope up with the stress effectively. This paper proposes a novel approach for detecting and classifying stress using galvanic skin response and image based biofeedback assisted mindfulness meditation to cope with the stress positively in real time. Stress was classified into two levels and meditation was identified as separate level using a statistical framework and during the evaluation of the framework proposed method obtained the accuracy of 82.418%, 73.945% and 64.96% for each respective level.
[Mindfulness Meditation, image based biofeedback, statistical framework, Public speaking, quantitative classification, Stress, Galvanic Skin Response, Mental Stress, occupational stress, galvanic skin response, Skin, Real-time systems, Biofeedback, Biological control systems, working stress reduction, Biomedical monitoring, working community, mindfulness meditation, mental stress, Stress measurement, health and safety]
Missing data imputation using Evolutionary k- Nearest neighbor algorithm for gene expression data
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Gene expression data are recognized as a common data source which contains missing expression values. In this paper, we present a genetic algorithm optimized k- Nearest neighbor algorithm (Evolutionary kNNImputation) for missing data imputation. Despite the common imputation methods this paper addresses the effectiveness of using supervised learning algorithms for missing data imputation. We have compared the k- Nearest Neighbor Imputation algorithm with the proposed Evolutionary k- Nearest Neighbor Imputation algorithm. The two algorithms were tested using gene expression datasets. Certain percentages of values are randomly deleted in the datasets and recovered the missing values using the two algorithms. Results show that Evolutionary kNNImputation outperforms kNNImputation.
[Algorithm design and analysis, gene expression data, Machine learning algorithms, supervised learning, Genetic algorithm optimization, genetic algorithms, Gene expression, Optimization, Genetic algorithms, missing data imputation, Training, genetic algorithm, Missing data imputation, evolutionary kNN imputation, EvlkNNImputation, genetics, evolutionary k-nearest neighbor algorithm, biology computing, kNNImputation, Prediction algorithms, data handling, learning (artificial intelligence)]
Identification &amp; verification of mutations in Human Genome
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
The completion of Human Genome Project (HGP) catalyzed the development of Next Generation Sequencing (NGS) technologies. An important use of NGS techniques is to detect the full range of genomic variation which lead to diseases. However, the velocity at which such findings are published sometimes causes latency to exist between the NGS data available to researchers and the latest research that is published. Due to the prevalence of gaps and inconsistencies in the variant analysis process, researchers are facing issues in discriminating disease-associated variations (mutations) from a large number of un-harmful genomic variants. This paper presents a framework to discriminate variants with deleterious effects and to verify such effects using an automated literature search. The proposed regression model to identify mutations quantitatively assesses the harmful nature of variants by taking into account the annotated information about variants from online databases. In addition, a TF-IDF based document relevancy ranking algorithm is used to improve the efficiency of document retrieval for verifying the harmfulness of the variants. The regression model was successfully able to narrow down variants to a very small number of candidate variants achieving a value of 89.5% for the average accuracy. Spearman's rho and Kendall's tau values were measured to assess the performance of the ranking algorithm, yielding values of 85.5% and 68.8% respectively, confirming the validity of the framework in verification of deleterious impacts of identified mutations.
[genomic variation, logisitc regression, disease-associated variations, Genomics, regression analysis, mutation verification, online databases, automated literature search, Sequential analysis, regression model, Databases, document retrieval efficiency improvement, mutations, genomics, human genome project, NGS data, Bioinformatics, document handling, TF-IDF based document relevancy ranking algorithm, mutation identification, NGS techniques, Information retrieval, Next Generation Sequencing technologies, variant analysis process, Diseases, prioritization, HGP, relevance feedback, tf-idf, bioinformatics, Logistics]
An automated method to extract information in the biomedical literature about interactions between drugs
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Text mining techniques are useful in extracting hidden information about the biomedical interactions such as Protein-Protein, Drug-Drug and Protein-Drug. Recently, there is an increased interest in automated methods due to the vast growth in the volume of published text regarding biomedical interactions. This work mainly focuses on extraction of Drug-Drug interactions (DDIs) in biomedical research articles from well-known databases such as DrugBank and MedLine. The proposed approach is developed based on feature engineering through natural language processing (NLP) techniques such as bag-of-words approach, tokenization, part-of-speech (POS) tagging, lemmatization and so on. This uncomplicated and easy to implement set of features are combined into a feature vector which is used to train a machine learning model. The effectiveness of the proposed approach was measured by conducting several experiments on the &#x201C;DDI Extraction 2013&#x201D; corpus. The system showed encouraging F-measure value of 76.9%.
[Drugs, drug interactions, protein-protein, data mining, biomedical interactions, Bag-of-words, machine learning model training, Proteins, Databases, DrugBank, feature extraction, DDIs, text mining techniques, NLP techniques, Natural language processing, learning (artificial intelligence), biomedical research articles, Drug-Drug Interaction (DDI), Text mining, automated method, natural language processing, drugs, protein-drug, feature vector, information extraction, drug-drug interaction extraction, feature engineering, Feature extraction, medical computing, MedLine]
A trust-aware recommender algorithm based on users overlapping community structure
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Retrieving items in online e-commerce systems with abundance of products is time consuming for users. To deal with this issue, recommender systems (RS) aims to help users by suggesting their interested items in the presence of thousands of products. Generally, RS algorithms are constructed based on similarity between users and/or items (e.g., a user is likely to purchase the same items as his/her most similar users). In this paper, we introduce a novel time-aware recommendation algorithm that is based on overlapping community structure between users. Users' interests might change over time, and thus accurate modelling of dynamic users' tastes is a challenging issue in designing efficient recommendation systems. The users-items interaction network is often highly sparse in real systems, for which many recommenders fail to provide accurate predictions. We apply the proposed algorithm on a benchmark dataset. Our proposed recommendation algorithm overcomes these challenges and show better precision as compared to the state-of-the-art recommenders.
[Algorithm design and analysis, trust, Heuristic algorithms, purchasing, reliability, trust-aware recommender algorithm, Recommender algorithms, overlapping community structure, Clustering algorithms, Prediction algorithms, dynamic user taste modelling, Recommender systems, time-aware recommendation, network science, electronic commerce, social networks, information retrieval, online e-commerce systems, user-item interaction network, recommender systems, Collaboration, social networking (online), item retrieval, Reliability, trusted computing, user overlapping community structure, user interests]
Enhancing Wikipedia search results using Text Mining
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Wikipedia is an online encyclopedia which contains millions of articles related to different subject domains. Wikipedia also has a search page itself to display the links corresponding to Wikipedia articles for a given user query input. This search result page displays the search results according to the relevance order, without any content based grouping. This paper presents an experimental deduction of a search result clustering methodology to group the links, returned by the search result page for a particular keyword, based on the contents of the HTML documents, represented by the links and label these resulted groups meaningfully. The proposed methodology is based on the concepts and theories of Text Mining. Grouping of search results makes easy and efficient for the user in finding the desired Wikipedia document. It is also possible to view the different applications and usages of a given keyword very quickly. This work identifies the best clustering algorithm for document clustering and investigates the ways to determine optimum number of clusters to have a better grouping and label the groups. We evaluate our proposed method by conducting several experiments and the results indicate that our method has a higher precision and recall.
[Algorithm design and analysis, Text mining, Electronic publishing, text analysis, online encyclopedia, Wikipedia document, data mining, Wikipedia search result page, user query input, document clustering, Encyclopedias, Wikipedia, Text Mining, query processing, pattern clustering, Clustering algorithms, text mining, Search Result Clustering, Internet, Web sites, HTML documents, hypermedia markup languages]
Hybrid approach for optimal management and querying of data and knowledge
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Nowadays, many applications require to represent both data and knowledge together. Regardless of the requirement, the normal practice is either using only database or only ontology. These approaches are proven to have drawbacks. There is still no proper methodology to obtain the benefits from both ontology and database management systems together. The issues raised by the rapprochements between such worlds are well known and addressed by consolidated mapping and transforming languages which may result in loss of data or hindering the reasoning power in knowledge. Nevertheless, to the best of our knowledge, a best practice for establishing such rapprochement is missing which we present through this research; a guideline based cooperation between database and ontology. We have introduced a hybrid approach of relational database and ontology for optimal management and querying of data and knowledge. Our method optimizes the storing mechanism by allowing of distributing data between ontology and database. Further, it optimizes the query execution by allowing some part of the data to be queried through database via SQL and some part of the data to be queried through ontology via SPARQL. We were able to obtain promising results about the performance in terms of storage and query execution and accuracy from the proposed approach.
[SPARQL, query execution, Ontology, Relational databases, Ontologies, Cognition, database management systems, Optimization, Guidelines, query processing, storage management, optimisation, Semantics, storing mechanism optimization, Database, optimal management, knowledge querying, data querying, relational database, Data &amp; Knowledge representation, SQL, ontologies (artificial intelligence), Data models, data handling, distributing data]
A framework for Mixed Reality application development: A case study on Yapahuwa archaeological site
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
A major challenge in developing Mixed Reality (MR) applications is the lack of a generic framework that can be used for easy development of MR applications employing multimodal user interaction techniques. The main objective of having such framework is that, whenever needed, it should be possible to simply design and develop a complete MR application to provide an immersive user experience based on the given framework. In this research we have designed and developed a mixed reality application using the proposed framework as part of the research; this MR application is customized to run on resource constrained portable devices such as smart phones. Moreover, it is capable of capturing required user inputs without their active intervention through the inbuilt sensors of the device, while using its screen for rendering visualization. Hence, the expensive and physically constrained explicit hardware devices are not required for a user to enjoy the MR experience. The framework presented in this research allows easy development of such MR applications relying on its architecture. By building a MR application in the domain of archaeological site reconstruction and exploration, the usefulness of the framework was emphasized. The proposed solution was tested to analyse the resource usage on the mobile device, accuracy of visualization and level of user experience, which are discussed in the paper.
[Visualization, virtual reality, immersive user experience, Mobile communication, User Immersion, Yapahuwa archaeological site reconstruction, Three-dimensional displays, MR application, user experience level, Multimodal Interaction, data visualisation, Virtual reality, archaeology, Sensors, rendering (computer graphics), user inputs, resource constrained portable devices, Yapahuwa archaeological site exploration, mixed reality application development, multimodal user interaction techniques, smart phones, Mixed Reality Applications, resource usage, mobile device, Data visualization, Games, User experience, visualization rendering, solid modelling]
Real-time realistic ocean wave rendering model for visualization of different sea states
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
At the present time virtual simulation has become a very popular subject in computer graphics. The main goal of the simulation in the context of computer graphics is reproducing the natural phenomena surrounding us in a more true-to-life possible way. When representing natural phenomena, more sensible factor is increasing the reality. Among many kinds of simulations realistic ocean simulation has become an important arena. Actually, it is a very interesting natural object to model because two third of the surface of the earth is covered by the ocean and water is an intrinsic part of day to day life. There are different models to represent ocean surface. However, due to highly dynamic behavior of the ocean, representing the visual complexity of these phenomena using basic simulation models is a challenge. Thus ocean water simulation is a computationally expensive process. The main aim of this research is proposing a substantive ocean wave visualization model taking into account different sea states proposed by Beaufort Sea scale. Since yet there is no such single approach with a satisfactory outcome. The state of the sea is changing time to time according to wind speed and other various phenomena. This dynamic feature is very important for serious computer games and simulators use for maritime trainings. The rendering mechanism suggests in this thesis is intended to provide an efficient and accurate method to represent the high quality of visual characteristics and runs in real time to produce highly realistic ocean scenes regardless of the complexity of the wave model. Building a mathematical model for representing the shape of the ocean surface is not an objective of this research. But suitable existing wave models are used for the study. Further this thesis is trying to identify the most suitable wave model among different kind of existing wave models for representing the each selected sea state.
[Sea surface, sea state visualization, wave model, ocean wave visualization model, visual characteristic quality, Sea state, digital simulation, data visualisation, Beaufort scale, serious computer games, Mathematical model, ocean waves, rendering (computer graphics), real-time realistic ocean wave rendering model, realistic ocean scenes, Computational modeling, visual complexity, wind speed, geophysics computing, Sea States, virtual simulation, Real-Time, realistic ocean simulation, computer graphics, Surface waves, Rendering, maritime trainings, mathematical model, Rendering (computer graphics)]
A decentralized vehicle re-routing approach using vehicular ad-hoc networks
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Sustainable economic growth and appreciable living standard in a country heavily depend on the reliability and efficiency of its transport infrastructure. One possible way of enhancing the travel experience of commuters is by using intelligent applications in vehicles that communicate through wireless networks. Envisioning these applications to new heights can be achieved with the recent advancements in wireless communication technologies. Vehicular ad-hoc networks (VANETs) are a special type of mobile ad-hoc networks (MANETs) which can be used to define intelligent interfaces for vehicle to vehicle (V2V) or vehicle to infrastructure (V2I) communication requirements. In this paper, we propose a vehicle rerouting approach for accident situations through VANET scenario simulations. For this research, we have used OMNeT++ network simulator to simulate the mobile network involved and SUMO microscopic traffic simulator to simulate vehicular movements in parallel and Veins framework as a bridging interface between OMNeT++ and SUMO. We have validated our solution with two heterogeneous metropolitan areas with significant structural dissimilarities located in the cities of Kandy and Colombo in Sri Lanka. Our solution achieved lesser values for waiting time and the trip duration of vehicles and qualitatively improving the traffic flow when comparing against the absence of rerouting component.
[sustainable economic growth, heterogeneous metropolitan areas, Kandy, vehicular ad-hoc networks, ITS, SUMO microscopic traffic simulator, OMNeT++ network simulator, Vehicles, mobile network simulation, decentralized vehicle rerouting approach, V2V communication requirement, mobile ad-hoc networks, Veins, vehicle-to-vehicle communication requirement, transport infrastructure efficiency, Colombo, transport infrastructure reliability, vehicular ad hoc networks, Object oriented modeling, Urban areas, V2I communication requirement, Sri Lanka, vehicle-to-infrastructure communication requirement, accident situations, VANET, intelligent transportation systems, wireless networks, structural dissimilarities, appreciable living standard, traffic engineering computing, intelligent interfaces, VANET scenario simulations, MANET, wireless communication technologies, network simulator, Vehicular ad hoc networks, vehicle routing, traffic flow improvement, microscopic, Accidents]
A data delivery protocol for extremely resource constrained Wireless Sensors
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Applications based on Wireless Sensor Networks (WSN) have a huge potential to enhance human life. A typical WSN application uses a large number of sensor nodes and they will cover a large geographical area. Such sensor nodes cost a lot and implements entire IPv6 stack for its communication. Since most of the current applications are focused on smaller environments, implementing entire IPv6 stack is a resource wastage. With the current development in the industry it is possible to develop extremely resource constrained sensor nodes which cannot run IPv6 stacks. In this study we present a data communication protocol which is capable of working on top of such extremely resource constrained devices. This protocol will use a cross layer approach where it will only use the MAC layer and Application layer instead of the full IPv6 networking stack.
[Cross layer design, wireless sensor networks, data communication protocol, access protocols, Wireless Sensor Networks, data delivery protocol, Wireless sensor networks, sensor nodes, extremely resource constrained wireless sensors, Resource Constrained Sensors, application layer, Media Access Protocol, data communication, Routing protocols, Sensors, Data communication, WSN application, MAC protocols, cross layer approach]
Integrating Context-Awareness with reminder tools
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
People use reminders to recall tasks to-do. But sophisticated enough tools are unavailable. Context-Awareness in mobile computing is more engaging area in gathering information about the user's current situation and would be ideal to integrate with the reminders to generate context-aware reminder where rich context is used to identify when a reminder should be presented to its recipient. Here we have proposed a model to integrate context-awareness with reminder's decision making process and develop a Context-Aware reminder. In this research more focus has put on capturing user context using technologies like IoT. Context is captured under five categories; Location, User Activity, User Preference, Identity of the User and Date and Time. Also developed a context representing model and processing context data to infer valuable information in a mobile environment. Then a conceptual framework for a context-aware reminder has presented and finally &#x201C;RemindMe&#x201D;, an android app has developed as the proof of concept.
[Schedules, context-aware reminder, human factors, Context-Awareness, Ontologies, Mobile communication, decision making process, Batteries, Fuels, context-awareness, user location, mobile computing, reminder tools, user preference, Context-Representation, Context, Context-aware services, Reminder, user context, user identity, context representing model, Context-Capturing, context data processing, user activity, decision making, data handling]
Radio tomographic imaging using extremely resource constrained devices
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
This paper presents a simple and cost effective method for radio tomographic imaging (RTI) using extremely resource constrained devices. The idea is to measure and analyse packet loss rates under various power levels and obtain images of objects in an interested area. We have implemented an experimental prototype for the RTI system using extremely resource constrained devices and results show that the packet loss ratio for RTI is a cost-effective method for image estimation and provides better results when the transmitted power is low.
[Radio transmitters, Buildings, Packet loss, Receivers, Line of Sight, Radio Tomographic Imaging, computerised tomography, Received Signal Strength, radio tomographic imaging, radiofrequency imaging, Tomography, image estimation, packet loss rates, RTI system, extremely resource constrained devices]
Reusing discarded-smartphone capabilities on quadcopters: The rationale, benefits and issues
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Smartphones have become a tremendous influence on human lives over the past decade. With attractive and advanced features integrated into smartphones, they are now considered more as a handheld computer than just a mobile phone. Driven by these improvements and desire for the latest devices, consumers replace their smartphones in a rapid rate, increasing the number of discarded devices. Fortunately, most capabilities of a discarded smartphone remain unharmed even after considerable damages, which make them ideal for reuse. In this study we demonstrate the reusability of these capabilities on micro aerial vehicles. Quadcopter is a micro aerial vehicle which has requirements such as sensor inputs, processing power, communication infrastructure and camera capabilities which the today's smartphone can accomplish independently. We focused on evaluating the possibility of reusing discarded smartphones to meet the requirements of quadcopters. Compared to traditional approaches of building quadcopters, reusing discarded devices has many advantages; low price, better performance, connectivity options and programming interfaces, etc. A statistical comparison was conducted to evaluate whether the remaining capabilities of a discarded smartphone are sufficient enough to meet the requirements of a quadcopter. The outcomes depicted that 87.5% of the features in smartphones correspond to those of quadcopters. To further illustrate the validity of our approach and to understand the practical issues, we then implemented several hardware and software applications as a proof-of-concept. Positive results achieved from the tests carried out to evaluate implementation components prove the suitability of our implementation methodologies to be utilized in real world applications.
[programming interfaces, Humanoid robots, Pulse width modulation, discarded smartphones reusability, recycling, Smartphone Sensors, smart phones, Discarded Smartphones, Quadcopters, microaerial vehicles, Android, autonomous aerial vehicles, handheld computer, software applications, connectivity options, discarded-smartphone capabilities, quadcopters, Cameras, Hardware, hardware applications, Androids, Smart phones]
A quality metric for object detection and focus for low-cost UAVs
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
With the flooding of low-cost UAVs to the consumer market, there is a rejuvenated interest to develop applications using consumer UAVs to enhance the quality of day to day lives of us humans. However, the limited capacity with respect to memory and processing power makes adopting a consumer UAV to advanced tasks such as object detection and tracking challenging. The modern day object tracking quadcopters available in the market place is not concerned about maintaining the quality focus on the detected object. This in turn affects aspects that are dependent on the quality of the focus of the object detected such as in video streaming and tracking applications. This would result in less than sufficient experience for users of this technology. As a first step in solving the aforementioned issue, in this paper we propose a quality metric to measure the focus of the detected object in order to evaluate the quality of detections. This paves the way for advanced object tracking in quadcopters that are capable of preserving the quality of the object focus while tracking it.
[quality metric, Quadcopter, processing power, tracking applications, Image edge detection, consumer market, Quality metric, consumer UAV, object detection, Classification algorithms, Object tracking, low-cost UAV, Image quality, autonomous aerial vehicles, helicopters, Object detection, object tracking quadcopters, market place, Histogram of Gradients, object tracking, video streaming, Drones]
Ensemble inference based framework for creating knowledge from big data in IoT
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Internet of Things (IoT) is an evolution of the current Internet into a ubiquitous network of interconnected objects which collects inputs through the sensing mechanisms and takes actions based on those inputs. Fuelled by the falling costs of the sensors, streams of raw data is transmitted to the IoT network continuously which is voluminous in the scale of Big Data. This puts an immense value on the frameworks, tools and techniques which can convert this raw data into usable knowledge.
[ensemble inference based framework, IoT network, Big Data, raw data streams, sensing mechanisms, Inference, ubiquitous network, Internet, inference mechanisms, Internet of Things]
Object identification in Vision Systems for expert learning platforms
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
This Vision System would be able to identify the objects in the digital imagery by reducing the current limitations by increasing accuracy. Further the extensively trained Vision System could be applied over the Learning Platforms where the outcome could be used to develop rich learning tools where the learners could learn through vision over text.
[Algorithm design and analysis, object recognition, Expert Learning Platforms, Digital images, Vision Systems, vision systems, learning tools, Artificial Intelligence, Artificial neural networks, Object recognition, Artificial Neural Networks, learning platforms, Image Processing, Machine learning, computer vision, Feature extraction, object identification, learning (artificial intelligence), expert learning platforms]
A machine learning approach to dynamically generate context sensitive applications on top of a monolithic enterprise system
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
This industrial research paper outlines an outcome of a machine leaning approach to dynamically generate context sensitive Application User Interfaces (Adaptive UI) on top of a monolithic enterprise software product.
[Context, Google, Roads, context sensitive application user interfaces, adaptive UI, user interfaces, machine learning, Machine Learning, Engines, monolithic enterprise software product, User interfaces, Software, software engineering, Monolithic Enterprise Applications, learning (artificial intelligence), Adaptive UI, Business]
UML generator - an automated system for model driven development
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
This research mainly focused on automation of Unified Modeling Language (UML) diagrams from the analyzed requirement text using Natural Language Processing (NLP). The proposed system is an efficient and accurate way to obtain elements of the use case and class diagrams from proposed methods. This research mainly focuses on the design phase of a software. Nowadays everybody needs a quick and reliable service. It was needed to have some sort of quick, accurate and intelligent software for generating UML based documentations to save time and budget of both the user and system analyst [1].
[Unified Modeling Language, Object oriented modeling, natural language processing, Unified modeling language, class diagrams, Artificial Intelligence, UML diagrams, Natural Language Processing, Generators, UML Diagrams, Class Diagram, Classification algorithms, use case diagrams, Machine Learning, software design phase, model driven development, Software Design Phase, XML, Natural language processing, Software, software engineering, UML generator, Use Case Diagram]
Site-ability: A website usability measurement tool
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Usability plays a major role towards user acceptance of website and it is increasingly becoming an important topic for organizations that develop and implement websites to market their products and services. Thus evaluating usability is critical for organizations in order to develop user friendly websites. One major challenge in usability evaluation is that most of the evaluation methods are subjective which depends on the evaluator's personal interpretations and judgment of the website. This is due to the lack of availability of automated tools in the respective field. Further, most of the usability evaluation methods are involved with manual approaches that consume time and money which is not affordable for organizations. Site-ability is an automation tool for website usability evaluation which is capable of mimicking human usability experts and it is based on usability guidelines provided by U.S. Department of Health and Human Services' (HHS) Research-Based Web Design and Usability Guidelines.
[social aspects of automation, Machine learning algorithms, Automation, personal interpretations, human factors, user friendly websites, Classification algorithms, site-ability, Expert System, Guidelines, personal judgment, US Department of Health and Human Services, Training data, human usability experts, automation tool, HHS Research-Based Web Design and Usability Guidelines, Website Usability, Data models, Web site usability measurement tool, Web sites, user acceptance, Usability]
Development of statistical approach for estimating key competitive performance measures of smartphone applications
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Along with the wide spread of mobile devices to access the Internet from anywhere at any time, the smartphone application market has been growing with amazing speed. The study of usages of smartphone applications by individual users, however, has been rather limited in the literature, relying upon real data collected from either a limited number of volunteers or the network level information at the sacrifice of details of individual users. This is so because it is virtually impossible to obtain such data needed for the study. Recently, however, this seemingly impossible task has been accomplished by a Japanese software development company named Fuller, Inc. by establishing a win-win relationship with Android smartphone users. Based on the massive data acquired from Fuller, Inc., this paper establishes a novel statistical approach for estimating the values of key competitive performance measures, which will provide useful business implications of interest to application developers.
[competitive performance measures, business implications, Humanoid robots, human factors, Companies, Mobile communication, Fuller, Android smartphone users, Android (operating system), Sociology, network level information, software performance evaluation, smartphone application market, DP industry, Japanese software development company, Smartphone applications, estimation of the future values, smart phones, Games, key competitive performance measures, mobile devices, Internet, Androids, statistical analysis, statistical approach, Inc]
Managing Service Level Agreements in Service Oriented Product Lines
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Service Oriented Architecture (SOA) and Software Product Line (SPL) have individually proven to be Software Engineering concepts, which are creating values for developing software systems. While SOA is being used for developing applications from an orchestration of web services, SPL has ability to prepare core sets of assets and manage with variable components. The combination of SOA and SPL has highlighted the term of Service Oriented Product Line (SOPL) which is setting up the application to manage common parts and reuse them without developing from scratch. It helps to manage service component bundles dynamically according to identified commonalities and variabilities. In this paper, we present our implementation approach of SOPL and manage Service Level Agreements (SLAs) in such environments by monitoring Quality of Service (QoS) attributes in bundles of web service components. The designing and developing service bundles for representing core sets of assets in SOPL are followed by the initial feature based analysis and identification of service components. Then, the managing SLAs is handled by detecting the deviation between actual and acceptable pre-defined QoS metrics values in previously analysed web service components via Web Service Level Agreement (WSLA) language specified templates.
[Quality of service, quality of service monitoring, Software product lines, contracts, WSLA language, SPL, Analytical models, feature model, business process models, service-oriented software product lines, Monitoring, service-oriented architecture, software engineering concepts, service level agreements, QoS monitoring, software reuse, SOA, service oriented product lines, service bundles, quality of service, Web service level agreement language, Web services, software reusability, Service-oriented architecture, software systems development, quality of services]
Evaluating the impact of DevOps practice in Sri Lankan software development organizations
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
The purpose of this study is to conduct an analysis on practicing DevOps in software development companies in Sri Lanka. DevOps is extended from agile with a mix of patterns intended to improve collaboration between development and operations. The main objective of this research is to identify whether there is a relationship between quality, responsiveness to business needs and agility with implementation of DevOps. Other objectives of this research are to identify barriers Sri Lankan software companies have faced and provide recommendations to overcome those issues. This study was carried out using a deductive approach. Data have been collected from IT professionals in Sri Lanka who had prior experience or knowledge about DevOps. Recommendations are given based on interview feedback, hypotheses output and descriptive statistical analysis. According to results software professionals in Sri Lanka are in a perception that implementation of DevOps has a positive impact on Quality, Responsiveness to Business Needs and Agility to New Technologies. Culture, Automation, Measurement and Sharing are important factors to be considered when implement DevOps in Sri Lanka. As a result of this study it is recommended to implement and practice DevOps in Sri Lankan Software companies.
[Industries, business need responsiveness, software prototyping, Companies, software quality, IT professionals, agile software, software houses, measurement factor, Software Lifecycle, software professionals, deductive approach, Product Quality, sharing factor, Sri Lankan software development organizations, DevOps Challenges, professional aspects, DevOps, culture factor, Collaboration, automation factor, Software, Cams, Software Development Industry, statistical analysis]
Scaling personality traits of interviewees in an online job interview by vocal spectrum and facial cue analysis
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
The landscape of personnel recruitment has been changed with the emerging trend of online approaches whereas the past custom was accompanied with face to face interview approach with time consuming process flows in recruitment decision making. Online interviews can be used as an initial study to the formation of first impressions for initial screening and shortlisting purposes. Therefore, in this research we provide an ICT based solution to identify the personality type characteristics of an interviewee and classification according to the levels exhibited in respective personality characteristic through facial expression recognition techniques along with vocal analysis to match with the personality characteristics of Passion, Cooperation, Confidence and Emotional Stability for IT job positions where high level of communication need to be done when performing the duties.
[Industries, IT job positions, Correlation, personality characteristic, human resource management, personality traits, recruitment decision making, emotion recognition, facial cue analysis, vocal spectrum, personnel recruitment, Personality traits, face recognition, Face, Interviews, online job interview, Business, facial expression recognition techniques, Stability analysis, Non-verbal behavioural analysis, emotional stability, ICT based solution, face-to-face interview, decision making, Cameras, Online-interviews, personality characteristics]
Personalized eye fatigue detection for mobile users
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
In the current digital environment, mobile devices make large amounts of information available at our fingertips. As a result of that, eye fatigue has become one of the major alarming factors faced by increasing amount of mobile device users. But the issue in this area is unavailability of feasible, practical and more importantly personalized solution to minimize this eye fatigue. Therefore, as a solution for that, this research explores whether a mobile based application could be used to detect personalized eye fatigue and alert the users before fatigue occurs.
[Tracking, human factors, android, Fatigue, Mobile communication, Mobile handsets, personalized eye fatigue detection, blink detection, personalized, eye, mobile device, mobile computing, gaze tracking, eye fatigue, feature extraction, Eyelids, blink rate, Data collection, Real-time systems, mobile users, open CV, real time]
Sentiment Analysis in Twitter messages using constrained and unconstrained data categories
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
This paper describes a system to answer a specific sentiment analysis problem described in 2015 iteration of SemEval (Semantic Evaluation series), Sentiment Analysis in Twitter as the base challenge to be improved. When it comes to sentiment analysis competitions and shared tasks, this is the most popular to date with more than 40 teams participating each year from its inception in 2013. Only subtask B (Message Polarity Classification) was considered under main task (task 10) in this model, as it was a return from previous years and remained highly challenging and competitive among teams from around the world. The proposed model performed exceedingly well, notably getting best results (1st) against 2015 test set, 2nd best results for evaluations against 2013 and 2014 test sets. We performed evaluation using both constrained and unconstrained data under two major classification techniques, single classifier based approach and ensemble approach. For single classifier based approach, classifiers such as Support Vector Machines, Logistic regression, BayesNet and Artificial Neural Networks and for ensemble approach algorithms such as Bagging, Ada Boosting, Random forest and Voting techniques were used. Several key contributions of this research including enhanced feature extraction algorithms, newly created sentiment lexicon, exhaustive analysis by means of various classification techniques using both constrained and unconstrained data clearly prove to be effective in addressing the given task..
[Sentiment analysis, Twitter, random forest, Data mining, Training, unconstrained data categories, semeval 2015, message polarity twitter classification, feature extraction, Twitter messages, logistic regression, BayesNet, sentiment lexicon, voting techniques, Testing, Semantic Evaluation series, support vector machines, ada boosting, sentiment analysis, feature extraction algorithms, exhaustive analysis, bagging, SemEval, single classifier, artificial neural networks, message polarity classification, Tagging, Feature extraction, social networking (online)]
Impact of day of the week effect on All Share Price Index (ASPI) and a comparison of forecastability of GARCH and NARX models
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Forecasting volatility in the stock market is an important research topic that has been immensely reviewed over the years. However, in Sri Lankan context this research topic is studied by only few researchers and they did not incorporate the day of the week effect in their studies. Therefore, this study examines the impact of the day of the week effect on All Share Price Index (ASPI) of Colombo Stock Exchange and compares forecastability of Generalized Autoregressive Conditional Heteroskedastic (GARCH) model and `Nonlinear Autoregressive model with exogenous inputs' (NARX), for the period of 1st of January 2007 to 28th of February 2015. This study uses four other exogenous factors namely gold price, world crude oil price, Sri Lanka Inter Bank Offer Rate (SLIBOR) and the exchange rate in modelling the conditional return and conditional volatility along with the day of the week effect. The results indicate that there exists a day of the week effect in Colombo Stock Exchange. It suggests that first two days of the week has a thin trading behaviour while the last three days of the week shows an active trading behaviour. Therefore, it is more recommended to buy shares on Tuesday and sell shares on Thursday and Friday. Moreover, this study finds that, the difference between the gold price at time t-1 and t-2 shows a negative impact on conditional stock returns at time t. The results also indicate that gold, Sri Lanka Inter Bank Offer Rate (SLIBOR) and exchange rate returns tend to have a positive effect on conditional stock market variance. However a better forecast can be obtained through the GARCH(1,1) model with day of the week effect, three past return terms of ASPI and one lag return of gold price in the mean equation while current gold return in conditional variance equation. Finally, a comparison between the built GARCH and NARX model has been carried out on the basis of the forecasted results. It has found GARCH model is comparatively powerful in predicting the direction whereas both NARX and GARCH models have their own pros and cons.
[day-of-the-week effect, trading behaviour, Correlation, world crude oil price, conditional return modelling, Volatility, Predictive models, Share prices, conditional stock market variance, generalized autoregressive conditional heteroskedastic model, GARCH(1, Sri Lanka Inter Bank Offer Rate, conditional stock returns, GARCH model forecastability, Day of the Week effect, exchange rates, exchange rate returns, GARCH, Stock markets, NARX, conditional variance equation, Colombo Stock Exchange, Gold, Oils, SLIBOR, gold price, autoregressive processes, stock market, 1) model, Indexes, exogenous factors, conditional volatility modelling, ASPI, economic forecasting, all-share price index, pricing, NARX model forecastability, nonlinear Autoregressive model-with-exogenous inputs, forecasting volatility]
The intelligent windshield wiper system
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Safety in a travel is a very important factor we consider in our day today life because we live in a very dynamic and a busy lifestyle. As a result the tendency of making failures in critical moments could create a fatal mistake and it could lead even to lose lives. To ensure maximum safety nowadays the researches and design engineers put their maximum efforts. The technology adopts to enhance daily routines has become a trend in the recent times and have produced many of such tools for travel and transportation. The impact on travel and transportation is significant because it affects everybody as a whole.
[digital image processing, high definition camera module, Raspberry Pi, Image processing, Digital Image Processing, intelligent transportation systems, Vehicles, transportation, high end single board computing, Rain, computer vision, Cameras, Sensors, optical windows, Computer Vision, Detection algorithms, Intelligent Windshield Wiper and Washer, Automotive components, automotive components, intelligent windshield wiper system]
Classification of stages of diabetic retinopathy in human retina
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Diabetic retinopathy is a major health problem which is prevalent in a vast variety of diabetic patients. It will lead to eventual blindness due to changes of blood vessels in the retina. Retinal anomaly identification is a complex, time consuming task for ophthalmologists as they have to investigate a large portion of the area at once with the involvement of expert ophthalmologists or expensive equipment such as Fundus camera.
[Retinopathy, image classification, Blood vessels, blood vessels, Retina, diseases, diabetic patients, Fundus camera, microaneurysms, patient care, diabetic retinopathy, retinal recognition, retinal anomaly identification, Multi Agent System, biology computing, human retina, expert ophthalmologists, Diabetes, exudates, Mathematical model, Lesions, Biomedical imaging, Diabetic Retinopathy]
A hybrid algorithm for multiple DNA sequence alignment
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Multiple sequence alignment (MSA) methods infer the homologous regions within DNA and protein sequences. Among the other algorithms for MSA, the center star method (CSM) is useful when processing a large number of sequences. In this method, the partially conserved regions among the non-center sequences tend to hide in the alignment. Therefore, existence of subsets of similar sequences in the input set leads to a significant accuracy loss. As a solution to the above problem, this research introduces an algorithm for MSA based on a solution proposed by D. Gusfield in 1991. In this research, the sequences are first grouped into subsets, aligned separately using CSM and finally these alignments are merged by applying progressive alignment procedure. The detailed solution for this problem is presented in the following section.
[Algorithm design and analysis, multiple DNA sequence alignment, progressive alignment procedure, sequence alignment, Phylogeny, Computer science, Proteins, center star algorithm, genetics, Clustering algorithms, DNA, proteins, bioinformatics, CSM, Bioinformatics, protein sequences, MSA methods, center star method]
Moving from detection to pre-detection of Alzheimer's Disease from MRI data
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Alzheimer's Disease (AD) is the most common form of dementia, affecting approximately 10% of individuals under 65 years of age, with the prevalence doubling every 5 years up to age 80, above which the prevalence exceeds 40%. Currently diagnosis of AD is largely based on the examination of clinical history and tests such as MMSE (Mini-mental state examination) and PAL (Paired Associates Learning). However many present studies have highlighted the inaccuracies and limitations of such tests. Thus medical officers are now moving to the more accurate neuroimaging data (Magnetic Resonance Imaging- MRI) based diagnosis for these types of diseases where brain atrophy transpires. However it is a considerable challenge to analyse large numbers of images manually to get the most accurate diagnosis at present.
[Neuroimaging, biomedical MRI, magnetic resonance imaging, MRI, Convolutional neural network, diseases, brain, MATLAB, Alzheimer's disease detection, Support vector machines, Atrophy, neuroimaging data, Magnetic resonance imaging, AD diagnosis, Image Processing, dementia, MRI data, Alzheimer's disease, medical image processing, Alzheimer's disease predetection]
An approach to predict the survival time of Childhood Acute Lymphoblastic Leukemia patients
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
Cancer is the second leading cause of death in children (after accidents). Childhood Acute Lymphoblastic Leukemia (ALL) is the most common and high risk cancer among the children. Medical practitioners make predictions about the survival time using their previous experiences and observations. They still cannot give an accurate survival prediction since the relationship between health status and survivability is still unknown. Survival time prediction (prognosis) is the task of predicting the length of time that a patient will survive. An accurate model that can predict survival time can help in the treatment and care of patients. The success of a survival prediction system will undoubtedly increase the quality of health care.
[Pediatrics, Predictive Models, childhood acute lymphoblastic leukemia patients, Predictive models, Regression, patient care, health care quality, machine learning, Statistics, patient survival time prediction, Machine Learning, Support vector machines, paediatrics, health status, patient treatment, Sociology, Acute Lymphoblastic Leukemia, cancer, childhood ALL, learning (artificial intelligence), medical computing, health care, Cancer]
Tutorials
2016 Sixteenth International Conference on Advances in ICT for Emerging Regions
None
2016
These tutorials discuss the following: Towards the Vehicular Cloud: From Connected Cars to Smart Cities; Overview of Big Data - Promises and Pitfalls, Tools Techniques; Innovative ways to represent and Process Language; and Cyber-Attacks: Detection and Recovery.
[Cloud computing, Smart cities, Conferences, natural language processing, vehicular cloud, Tutorials, Big Data, traffic engineering computing, Automobiles, cyber-attack recovery, security of data, smart cities, cyber-attack detection, Safety, cloud computing]
Keynote speakers
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Provides an abstract for each of the keynote presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.
[]
Tutorial
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Provides an abstract of the tutorial presentation and may include a brief professional biography of the presenter. The complete presentation was not made available for publication as part of the conference proceedings.
[Algorithm design and analysis, Conferences, Tutorials, Feature extraction, Software, Security, Problem-solving]
A framework for automated corpus compilation for KeyXtract: Twitter model
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
The corpus is a limiting factor for a keyword extraction process with a word matching stage. This paper proposes a framework to automate the corpus generation stage required for the Twitter Model of KeyXtract, an algorithm used for essential keyword extraction from tweets. The initial algorithm was designed with two manually compiled corpora that limited the adaptability of the system. The automated framework proposed in the present research is an extension to the keyword extraction process of KeyXtract and would address this limitation of the system. The design was carried out using open-class words of the source text and by matching them against the bag of words compiled by analyzing the tweets. The automated corpus had a total of 138 words, out of which 74 words were also found in the handpicked corpus (which had a total of 206 words). However, when the corpus was used with the keyword extraction system, the average F1 scores of the system showed a decrease of 0.07, proving that the automated corpus cannot perform parallel to the human-made corpus in complexity. This was because the human-made corpus was compiled using syntactic, semantic and pragmatic features while the automated framework focused only on the syntactic features. However, there were individual tweets in which the F1 score showed an increase. Thus, this was a promising first step in the corpus automation process. The automatic corpus generation framework could be made more accurate by including the semantic analysis of the lexical items. Thus, the present framework is able to substantially address the limitation of the corpus compilation which was present in the Twitter Model of KeyXtract.
[Algorithm design and analysis, text analysis, average F1 scores, limiting factor, word matching stage, corpus generation stage, Twitter, Twitter model, KeyXtract, tweets, Tweets, syntactic features, Customer services, Adaptive, natural language processing, automated corpus compilation, Natural Language Processing, Automated Corpus, automatic corpus generation framework, source text, Pragmatics, open-class words, Web pages, keyword extraction process, Syntactics, Feature extraction, social networking (online)]
Domain specific language for specifying operations of a central counterparty
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Domain Specific Language (DSL) approach empowers effectve financial contract management through fixed and precisely defined set of combinators and observables. Haskell Contract Combinator Library (HCCL) follows DSL approach and it offers a flexible mechanism in composing Financial Contracts(FCs). Financial institutes such as banks, use FCs. Central Counterparty(CCP) is one such financial institute and this institute is highly regulated one. Out of all operations, &#x201C;Margin Calculation&#x201D;(MC) operation in CCP, consider to be most significant operation. The process of MC involves series of rules to follow. For example, a rule could specify, transfer of money if certain condition met by a given date. All these rule specify a form of probable future cash flow. In the research literature, the DSL approach has not explored in the context of CCP rules. In our research, we analyzed a contract that goes through CCP operations and we modeled series of FCs using HCCL clearly showing the steps and cash flow semantics. In our research, we defined two new data types Instrument and Trade that embodies and preserve the properties of FCs. Through our research we proved the hypothesis that, HCCL could be use in defining CCP rules and as a result we could use HCCL in the process of MC. We introduced a &#x201D;seed&#x201D; contract to simulate the contract behaviour in our design methodology. We further explored the HCCL defined CCP rules in the context of financial contract management.
[Frequency modulation, public domain software, HCCL, contracts, formal specification, banking, MC operation, financial institute, observables, Contract management, Central Counterparty, Functional Programming, specification languages, FCs, Domain Specific Language, Haskell, Libraries, Financial Contracts, DSL, DSL approach, Margin Calculation operation, contract management, CCP rules, probability, combinators, probable future cash flow, CCP operations, Currencies, Domain specific languages, contract behaviour, CCP, financial management, real-time systems, Financial institutes, Domain Specific Language approach, seed contract, Haskell Contract Combinator Library, functional languages]
Hybrid framework for master data management
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Master data management and real-time data warehousing are gaining increased prominence within the worlds of business and technology. Past research efforts have shed light towards development of many master data management approaches. On the other hand, growth of technology has demanded real-time analytics and real-time processing of data. This trend has shed light in developing multiple real-time data warehousing approaches to perform real-time analytics based on an organization's requirements. With the evolution of real-time data warehousing, Master Data Management was an issue for large organizations' when both systems are working in the same business environment. Since both systems focus on real-time integration, similar, duplicated and parallel data extraction processes were executed by these applications. This was due to the fact that master Data Management was designed to focus on the operational aspect and real-time data warehouse was designed to focus on analysis aspect of the organization. Hence, each had its own ways of managing master data. These duplicated extractions caused data quality issues in these parallel applications. This research provides a framework that combines both master data management and real-time data warehousing and ultimately proposing to build a Hybrid Real-Time Data Warehousing Architecture in order to achieve enterprise wide master data management.
[enterprise wide master data management, data analysis, Hybrid Real-Time Data Warehousing Architecture, real-time analytics, Data warehouses, Data mining, data quality issues, Data Quality, Distributed databases, Real-Time Data Warehouse, Master Data Management, Real-time systems, parallel data extraction processes, real-time data warehousing approaches, data warehouses, business data processing, duplicated data extraction processes]
An ontology-based and domain specific clustering methodology for financial documents
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Financial documents play an important role in modern financial analysis and information retrieval tasks. In order to accomplish various investigational needs, financial organizations continuously search for accurate and meaningful unsupervised document classification techniques. Nevertheless, unsupervised document categorization or document clustering is a challenging problem studied by many scientists. Incorporating semantic knowledge from an ontology into document clustering has been extensively studied and it has provided enhanced clustering performances. The incorporated semantic knowledge is generally used for identifying the correct meanings of the ambiguous words in the documents. Most of the proposed methodologies were experimented on general document datasets and most of the few available domain specific clustering studies were constrained to specific domains where complete domain ontologies are available. Although financial domain has several domain ontologies, none of them are complete and suitable for semantic document clustering. In this context, our study proposes a document clustering methodology for financial documents which adapts WordNet ontology to the financial domain to serve as an external knowledge source. This study empirically shows that nouns are relatively prevalent and more important for document clustering rather than other terms in a document. Afterwards, a subset of nouns is identified as most important for the clustering, based on their frequency distribution within the main noun list. We developed a word sense disambiguation technique which uses ontological knowledge for noun disambiguation. Finally, nouns in each document are disambiguated with the proposed word sense disambiguation technique, associated with tf-idf weights and clustered. On the basis of the empirical results of this research, it can be concluded that the proposed methodology can significantly enhance the clustering performance compared to no disambiguation and pure WordNet based disambiguation approaches.
[financial analysis, unsupervised document categorization, Clustering methods, Ontologies, Length measurement, unsupervised document classification techniques, semantic document clustering, domain specific clustering methodology, word sense disambiguation technique, Semantics, financial organizations, financial documents, financial data processing, document handling, domain specific clustering, Word sense disambiguation, information retrieval, WordNet based clustering, Resnik similarity, semantic knowledge, complete domain ontologies, pattern clustering, Biomedical measurement, Feature extraction, ontologies (artificial intelligence), Financial document clustering]
Texture analysis of ultrasound images of chronic kidney disease
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Chronic Kidney Disease of unknown aetiology (CKDu) is a prevalent disease in the North Central Province of Sri Lanka. Towards the latter stages of the disease, kidney function fails by 80%. During the initial stages of CKDu, interstitial fibrosis is formed and grows as the disease progresses. The cause of the disease remains elusive and early detection is vital to arrest the progressive decline of kidney function. The objective of this study is to construct a computer program to perform texture analysis on ultrasound kidney images and extract various features that can be used to distinguish between normal and diseased kidney patients. The computer program was developed using MATLAB and a user interface was created to perform mathematical operations such as: Fourier analysis to extract Root Mean Square and First Moment values and Grey Level Co-occurrence Matrix (GLCM) to extract Homogeneity and Sum Average values. A sample of ultrasound images were taken from 32 patients. Region of interest (ROI) selection was performed on entire kidney, cortex region and white (renal medulla or renal sinus) region separately. Among these methods Root Mean Square values over the entire kidney (p=0.03) and cortex region (p=0.0049) gave significant results in distinguishing between normal and diseased kidneys.
[chronic kidney disease, kidney function, Sri Lanka, CKDu, biomedical ultrasonics, diseases, Fourier analysis, MATLAB, co-occurrence matrix, Kidney, image texture, unknown aetiology, Diseases, prevalent disease, kidney, Ultrasonic imaging, interstitial fibrosis, feature extraction, ultrasound kidney images, Market research, Feature extraction, DICOM, medical image processing, texture analysis]
Large scale visual classification with SVM, create the unique article through NLP
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Lack of Proper Information around Sri Lankan Historical Places cause to give false information. If ruins scattered around same place tourists are struggling to identify them. Sometimes there are small sign boards but they don't provide enough information. In this paper we address this challenge by using user captured image or search imaged. Our approach is produced a single document about identified places. System identify the places through training dataset using SVM. System will increase the accuracy of prediction by taking GPS data and user inputs necessarily. The evaluation shows that our approach is more accurate than the existing systems.
[Visualization, High Performance Computing, Image processing, image classification, SURF detector, Classification algorithms, training dataset, SVM, Sri Lankan Historical Places cause, Support Vector Machine, false information, Engines, NLP, data visualisation, Detectors, Natural language processing, unique article creation, single document, support vector machines, natural language processing, Natural Language Processing, Global Positioning System, Support vector machines, travel industry, large scale visual classification, user captured image, place identification, GPS data, tourists]
A comparison of accuracy of forecasting models: A study on selected foreign exchange rates
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Exchange rate, an economic indicator of the country is the relative price of one country's currency in terms of another country's currency. Stability in exchange rate is important for stable economic growth. Exchange rates, a financial time series highly fluctuate and are chaotic in nature. Forecasting exchange rate fluctuations is very important to countries' economy. Many researchers reported that the three classes of models, namely stochastic models, Artificial Neural Network (ANN)models and Support Vector Regression(SVR) models provided good forecasts. The aim of this research was to compare the forecasting accuracy of most widely used classes of models and to identify better model for forecasting daily exchange rates of Sri Lankan Rupees to Euro and Yen. Daily time series data collected from 2nd July, 2012 to 31st August, 2016 (1008 trading days) from the official website of Central Bank of Sri Lanka were analysed using Eviews, MATLAB and R packages. Stochastic models fitted were found to be inefficient in explaining the variations of daily exchange rates. A Nonlinear autoregressive neural network (NAR) model using Scaled Conjugate Gradient (SCG) learning algorithm and aSVR model with Gaussian radial basis kernel function were designed to the exchange rate returns. Mean Squares Errors and directional accuracy measures revealed that both the machine learning models, ANN and SVR models explained the variation in the series well. However, SVR models provided a better directional accuracy than ANN models. These findings could be useful for domestic as well as foreign investors. Further the forecasting ability can be improved by evolutionary neural networks.
[conjugate gradient methods, exchange rate fluctuations, ANN, Sri Lankan Rupees, Stochastic processes, regression analysis, ANN models, Predictive models, SVR, Analytical models, Nonlinear autoregressive neural network model, stochastic models, exchange rates, radial basis function networks, machine learning models, exchange rate returns, Support Vector Regression models, financial data processing, SVR models, Mathematical model, learning (artificial intelligence), mean square error methods, support vector machines, stable economic growth, Biological system modeling, autoregressive processes, time series, Artificial Neural Network models, Forecasting, financial time series, Exchange rates, Gaussian processes, forecasting models, selected foreign exchange rates, Stochastic models, economic forecasting]
Applying intelligent speed adaptation to a road safety mobile application &#x2014; DriverSafeMode
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Road safety is an utmost important concern regarding motorized transportation. The increasing motorized transportation has placed a significant burden on people's health in the form of uncontrollable growth rate of road traffic accidents and fatalities which has caused detrimental social and economic consequences in Sri Lanka. Despite number of interventions and action plans the government of Sri Lanka has enforced in order to ensure road safety, the statistics under road safety remain dangerously negative. In this paper, we present an intelligent mobile application solution &#x201C;DriverSafeMode&#x201D;, which applies Intelligent Speed Adaptation (ISA) to aid drivers to avoid excessive speed, which is the most common and dangerous road and traffic offence committed by the drivers in Sri Lanka. In addition, the proposed system provides an effective aid to avoid mobile phone distraction while driving. The test results and user evaluation has proved that the proposed solution provide a reachable and a contrasting approach, compared to the existing road safety systems.
[Intelligent Speed Adaptation (ISA), increasing motorized transportation, DriverSafeMode, Mobile handsets, road safety, Vehicles, road safety mobile application, intelligent speed adaptation, mobile computing, dangerous road, road accidents, driver information systems, ISA, Injuries, road traffic, Sri Lanka, road traffic accidents, Mobile applications, traffic offence, road safety systems, uncontrollable growth rate, excessive speed, intelligent mobile application solution, economic consequences, fatalities, detrimental social consequences, Road safety, mobile phone distraction, Accidents]
Detection of change frequency in web pages to optimize server-based scheduling
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
The Internet at present has become vast and dynamic with the ever increasing number of web pages. These web pages change when more content is added to them. With the availability of change detection and notification systems, keeping track of the changes occurring in web pages has become more simple and straightforward. However, most of these change detection and notification systems work based on predefined crawling schedules with static time intervals. This can become inefficient if there are no relevant changes being made to the web pages, resulting in the wastage of both temporal and computational resources. If the web pages are not crawled frequently, some of the important changes may be missed and there may be delays in notifying the subscribed users. This paper proposes a methodology to detect the frequency of change in web pages to optimize server-side scheduling of change detection and notification systems. The proposed method is based on a dynamic detection process, where the crawling schedule will be adjusted accordingly in order to result in a more efficient server-based scheduler to detect changes in web pages.
[Algorithm design and analysis, Schedules, web pages, Crawlers, change detection and notification systems, web page, server-based scheduling, Servers, static time intervals, notification systems, Web pages, scheduling, Internet, change frequency detection, crawling, change frequency, Monitoring, server-side scheduling]
Improving diagnostic viewing of Coronary Cine-angiogrphy through frequency filtering based frame enhancement method
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Coronary angiography is an invasive medical image modality which is widely used in Interventional Cardiology to detect luminal obstructions in Coronary Arteries (CA). It has been reported that these recorded Coronary Cine-angiograms (CCA) are suffered from various visual artifacts such as noise, non-uniform illumination, low contrast and epicardial motion. As a consequence of these problems, the diagnostic visualization of the CCA degrades. In this study, it has been proposed a frequency filtering based frame enhancement method for CCA to improve its diagnostic visualization. The proposed method is based on homomorphic butter worth high pass filter and empirically validated contrast stretching technique. In order to correct the epicardial deformations optical flow based frame stabilization method has been applied in later stage of the proposed method. Study results clearly emphasized the visual improvement obtained through this novel method. The resulting enhanced CCA frames produced in this study can be further used to improve the angiography image modality for quantitative stenosis assessment.
[Visualization, epicardial deformations optical flow based frame stabilization method, quantitative stenosis assessment, Angiography, diagnostic visualization, image filtering, visual improvement, Coronary Cine-angiogrphy, Coronary Arteries, image enhancement, invasive medical image modality, image segmentation, Lighting, luminal obstructions, medical image processing, Optical filters, cardiovascular system, Filtering, Discrete Fourier transforms, high-pass filters, epicardial motion, blood vessels, diseases, optical flow, angiocardiography, frequency filtering based frame enhancement method, angiography image modality, homomorphic butter worth high pass filter, frame enhancement method, contrast stretching technique, visual artifacts, angiogram enhancement, Homomorphic filtering]
Network based prediction of drug-drug interactions
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Drug-drug interactions (DDIs) are responsible for many serious adverse events; their detection is crucial for patient safety but also very challenging. In recent years, several drugs have been withdrawn from the market due to interaction related Adverse Events (AEs). Currently, the US Food and Drug Administration (FDA) and pharmaceutical companies are showing great interest in the development of improved tools for identifying DDIs. We describe a predictive model, applicable on a large scale to predict novel DDIs based on similarity of drug interaction candidates to drugs involved in established DDIs. The underlying assumption is that if drug A and drug B interact to produce a specific biological effect, then drugs similar to drug A (or drug B) are likely to interact with drug B (or drug A) to produce the same effect. We constructed a 352 drug DDI network from a 2011 snapshot of a widely-used drug safety database, which contains 3 700 established DDIs, and used it to develop the proposed model for predicting future DDIs. The target similarity for all selected pairs of drugs in DrugBank was computed to identify DDI candidates. The proposed model mainly follows two distinct approaches: the first one is `Which forces the preservation of existing (known) DDIs' and the other one is `without forced to preserve existing DDIs.' Predictions were made under each of these approaches using three different techniques: target similarity score, side effect similarity (P-score) and resulting score. The methodology was evaluated using Drugbank 2014 snapshot as a gold standard for the same set of drugs. The proposed model generates novel DDIs with an average accuracy of 95% for force to preserve existing (known) DDIs. Average accuracy for without forced to preserve existing DDIs is 92%. These two approaches also give average AUC (Area Under the Curve) of 0.9834 and 0.8651 respectively. The results presented in this study demonstrate the usefulness of the proposed network based drug-drug interaction methodology as a promising approach. The method described in this article is very simple, efficient, and biologically sound.
[Drugs, Target similarity score, Symmetric matrices, drug safety database, patient safety, Computational modeling, drugs, Drugbank 2014 snapshot, Predictive models, P-score, adverse events, Drug-drug Interactions, Proteins, drug DDI network, Databases, network based drug-drug interaction methodology, medical computing, area-under-the-curve, Adverse Events]
Effective use of test types for software development
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Software industry has shown an exponential growth during the last decade with regards to technology development. The prime aim of the software industry is to deliver high quality software to the end user satisfying the clients as per the agreed norms of the business. Hence, software testing has become an important phase in the software life cycle, ensuring the ultimate product quality. The purpose of this study is to examine whether there is a relationship between testing constraints and test types executed in software companies. The research expects to provide recommendations to use test types effectively. A conceptual model was developed and three hypotheses were derived based on the extensive literature review carried out. According to the results it can be claimed that there is a negative strong relationship between testing constraints and the level of test type execution. Also there is a positive strong relationship between application architecture type and level of test type execution. As the results of data analysis and interviews, it is recommended to minimize the influence of skill, time and poor requirement testing constraints. Automating test suites, risk based testing, proper effort estimation and resource planning can help organization to overcome time constraints. Skills can be improved with skill gap analysis and conduct knowledge transfer sessions. Following a process and walk through sessions to identify the correct project requirements are needed to increase the level of test type execution. According to analysis, small scale companies need to focus to minimize testing constraints. In conclusion, it is recommended software companies to overcome testing constraints with mitigation plans and consider application architecture type to increase the level of test type execution.
[Software testing, program testing, Companies, software quality, requirement testing constraints, test suites, software industry, product quality, Computer architecture, high quality software, software life cycle, test types, Testing Constraints, test type execution, Application Architecture Type, software development, software companies, software testing, DP industry, application architecture type, Software Testing, Test Types, ISO 9126 Quality Characteristics, ISO Standards, Software quality, testing constraints]
Highly efficient and robust audio identification and analytics system to secure royalty payments for song artists
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Radio is yet one of the most popular broadcast media in many emerging regions and operates as one of the principle sources of income for licensors and publishers, collectively termed as owners of copyrighted music. Royalty payments are legal obligations towards owners of copyrighted music under intellectual property rights legislations. Independent conjoint monitoring of copyrighted music being broadcast over every radio station on each day is an intricate requisite for upholding the said legislations of a country or region and therefore requires automated techniques that are efficient, scalable and robust to both radio and content noise. We consider the development of an automated radio broadcast audio monitoring system with identification and analytics capabilities to assist collection of royalty payments from radio music licensees for copyrighted music, specifically for songs. First, we pre-process a radio broadcast stream to identify song segments, aka objects via an efficient onset detection mechanism. Next, we perform efficient hashing of identified objects in the frequency domain and compare generated hashes with those in the entries of a pre-compiled copyrighted song database using an efficient hash matching technique. Subsequently, our system stores broadcast data of the identified music objects (e.g. timestamp, name of lyricist, etc.,) in the database for later use from an analytic application.
[radio broadcasting, Visualization, copyright, copyrighted music, hash matching technique, robust audio identification, song artists, Databases, music, audio analytics system, radio station, broadcast media, Visual analytics, feature extraction, data visualisation, Robustness, Monitoring, legislation, music objects, Content-based audio identification, Media, visual analytics, cryptography, onset detection mechanism, intellectual property rights legislations, Object recognition, content -based audio identification, content-based retrieval, automated radio broadcast audio monitoring system, royalty payment security, audio signal processing, Music, Royalty payments, radio music licensees]
Suppressing dengue via a drone system
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Dengue is one of the rapidly spreading and deadly diseases in Sri Lanka, transmitted by the bite of infected female Aedes mosquitoes. Public Health Inspectors (PHIs) in Sri Lanka are facing a problem of identifying certain dengue mosquito breeding sites which are capable of retaining water. The goal of such inspection of suspected sites is to reduce the number of dengue patients by eradicating dengue mosquito habitats. A drone which has been created with the rapid advancement of technology, is one of the most cost effective apparatus to capture the mosquito breeding sites. It can inspect both accessible and inaccessible places to a human. With respect to the aforesaid context, this paper presents a simple and a novel approach to identify dengue mosquito breeding sites via drone images. The proposed approach captures the images of the water retention areas via a drone and generates the map, marking those areas in the map. The field test found that the proposed method, produces a satisfactory level of accuracy in identifying possible water retention areas and the final results depend on the drone camera tilt angle and the effect of shadows.
[drone system, infected female Aedes mosquitoes, cost effective apparatus, Sri Lanka, Dengue, diseases, Mosquito Breeding Sites, Drone Systems, suspected sites, Videos, Diseases, Public Health Inspectors, Training, Support vector machines, Histograms, drone images, water retention areas, suppressing dengue, Feature extraction, mosquito breeding sites, medical image processing, drone camera, Drones, dengue mosquito habitats]
Framework for detection of anomalies in mass moving objects by non-technical users utilizing contextual &amp; spatio-temporal data
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Increasing utility of wireless sensors and their decreasing cost with technological innovation has increased their presence in many mobile &amp; wearable devices and many devices are able to sense and relate a variety of sensor data including GPS location to be used for decision making. However, much potential of this data remains unexploited due to inherent complexity of manipulating such information, which bars the majority of users benefiting from this. One potential application is the detection of anomalies by users from a non-technical background through definition of rules. As such, a methodology/framework, which could enable users to define rules/query information from sensors fused with other contextual data in a user-friendly manner would be highly useful in deriving value from this data. This research attempts to formulate a low-cost framework, which enables users without a strong technical background to make potential use of this. The research is performed using a case study; identification of anomalies in the behaviours and violations of rules by marine vessels in Sri Lankan waters. However, the framework is generalized to enable application to other contexts also. The framework also attempts to identify a possible method and a process to enable users enter geo spatial rules in an accurate as well as user friendly manner while allowing to enter rules of different levels of complexities accurately. The research attempts to solve this problem through the use of a map interface which enables users enter geo spatial data either plotting on a screen or as pairs of coordinates. Use of auto query forms with dynamically changing queries was proposed to enter conditions of rules and the interrelationships. The research was carried out using one prototype and two systems in three stages, using the input of one step to next. Both methods of spatial rule entry were deemed accepted by users considering the ease of use in direct plotting as well as accuracy in formal coordinate entry in the two methods. While auto query form was found as a suitable method with reasonable accuracy with accuracy increasing with the educational background of users and decreasing on several occasions with increased complexity (multiple conditions or ambiguity of underlying concept) of rules, the display of the rule query in user readable form at the bottom of the interface as well as enabling the user to dynamically view query results to refine the query showed increased accuracy.
[sensor data, spatio-temporal data, contextual data, user friendly manner, Sensor phenomena and characterization, sensor fusion, geospatial data, Mobile handsets, anomaly detection, nontechnical users, Temperature sensors, query processing, Databases, user readable form, inherent complexity, low-cost framework, auto query form, technological innovation, increased complexity, query form, wearable devices, GPS location, user-friendly manner, contextual anomaly identification, geo spatial data, rules/query information, geo spatial rules, Anomaly detection, wireless sensors, Global Positioning System, security of data, decision making, spatial rule entry, dynamic query, mobile devices, human computer interaction, Artificial intelligence, rule query, computational complexity]
Game based learning as a supplementary approach in teaching mathematics
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Selecting the best available teaching learning approaches is a critical factor that determines the success rate of an educational program. When it comes to a distance learning program that operates in e-Learning mode, the choice of such approaches are limited. This study explores the extent to which students in such a program would like a Game Based Learning (GBL) approach as a supplementary learning approach for learning Mathematics. The Foundation of Information Technology (FIT) program at the University of Colombo - School of Computing (UCSC), Sri Lanka, which is a distance-learning program that operates in e-Learning mode was selected to carry out the investigation. As a part of the research, a few games were designed based on the Mathematics syllabus of the FIT program and developed using Unity5. Feedback from 42 students who played games were collected and analyzed. Based on the results of the analysis the paper discusses the applicability of the GBL approach in the e-Learning environment to teach Mathematics.
[mathematics teaching, Art, mathematics computing, Mathematics, teaching, Information Technology program, Educational Games, e-Learning mode, DGBL, computer games, Safety, Game Based Learning, educational program, Sri Lanka, University of Colombo School of Computing, GBL approach, Information technology, distance learning, Games for Learning, Electronic learning, supplementary learning, educational courses, Games, distance learning program, Foundation of Information Technology program, Mathematics syllabus, computer aided instruction]
Visible light communication based authentication protocol designed for location based network connectivity
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Visible Light Communication (VLC) is a blooming research area which uses visible light spectrum as the communication channel. Exponential growth of Light Emitting Diodes (LEDs) deployment as a light source is encouraged to use for communication purposes as well. With the introduction of VLC, LED can be used for communication while providing the primary function of illumination. Since location-based network access protocols have not been implemented for Wi-Fi devices, this research has been conducted with the intention of using VLC to perform location-based authentication. In our location authentication protocol, VLC technology is used for authentication purpose and Wi-Fi is used for data transfer once the device has been authenticated. The proposed protocol provides location-based connectivity to Wi-Fi devices with minimum changes to Remote Authentication Dial-In User Service (RADIUS) and Wi-Fi Protected Access 2 (WPA2) protocol by using VLC.
[telecommunication security, Protocols, cryptographic protocols, location authentication protocol, Wi-Fi devices, communication channel, remote authentication dial-in user service, access protocols, Servers, VLC, visible light communication, location-based network access protocols, Wireless communication, visible light spectrum, Lighting, free-space optical communication, authentication protocol, VLC technology, light source, light emitting diodes deployment, Wi-Fi protected access 2 protocol, Wireless fidelity, Light emitting diodes, Wi-Fi Authentication Protocol, location based network connectivity, Authentication, wireless LAN, Location Based Connectivity]
Self-correcting portable projector
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Conventional projectors are designed to generate orthogonal projections on the screen. Manual adjustments to the location and the focal distance to receive an optimal projection are done in ad-hoc manner and they are tedious tasks. As such, there is a growing interest in developing projectors with casual placing, which enables to locate the projector in a desired location so that the display will be free from distortions. This research has been conducted to develop a smart projector with built in sensors and related units to generate an optimal display without human intervention. We developed techniques to enable real-time auto correction of projectors using low cost, commodity-off-the-shelf hardware. The proposed system acquire the exact display surface geometry and perspective-corrected imagery to a casually placed projector the without any space restriction. Our system does not require cameras and sensors placed away from the projector and it can be embedded in the projector without changing the physical dimensions of it.
[image processing, optimal display, real-time auto correction, Transmission line matrix methods, Shape, Optical distortion, perspective-corrected imagery, projector calibration, Distortion, display surface geometry, optical projectors, self-correcting portable projector, orthogonal projections, casually placed projector, optimal projection, display devices, Cameras, Real-time systems, Sensors, smart projector, hardware model, orientation sensors, keystone correction]
Hyperspectral imaging based land cover mapping using data obtained by the Hyperion sensor
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
This paper presents an analysis of hyperspectral image data corresponding to a strip along the North Eastern region of Sri Lanka, obtained by the Earth Observing (EO-1) satellite's Hyperion sensor. Using hyperspectral imagery in order to map land-cover maps is beneficial in many ways as it could be used as a basis to obtain useful information for natural resource and ecosystem service management, assessing the human induced and natural drivers of changes in land, foliage or water bodies and even in identification of fine details such as the distribution of minerals in an area. In the algorithm proposed in this paper, each pixel was represented as a point in a high dimensional space of which the dimensions represented each band of wavelength. Principal Component Analysis (PCA), Fisher Discriminant Analysis (FDA) and Spectral Clustering were used in a logical sequence, as discussed in this paper, in order to cluster the points in a reduced dimensional space. The pixels belonging to each cluster were labeled under `soil', `foliage' or `water bodies', with the aid of the k-means algorithm and the hyperspectral data of the training set obtained with the aid of Google Maps. Upon validation it was observed that the procedure employed is an effective and promising method of classifying a semi supervised hyperspectral dataset.
[Hyperion sensor, terrain mapping, high dimensional space, image classification, Hyperspectral Imaging, Classification algorithms, Covariance matrices, natural resource, hyperspectral data, ecology, reduced dimensional space, Earth Observing satellite, Spectral Clustering, learning (artificial intelligence), Principal Component Analysis, semi supervised hyperspectral dataset, Sri Lanka, North Eastern region, Fisher Discriminant Analysis, hyperspectral imagery, geophysical image processing, hyperspectral dataset, Reflectivity, map land-cover maps, Google Maps, hyperspectral image data, Hyperion, Soil, ecosystem service management, hyperspectral imaging based land cover mapping, hyperspectral imaging, principal component analysis, Hyperspectral imaging, Principal component analysis, water bodies]
Cloud motion tracking for short-term on-site cloud coverage prediction
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
A technique for cloud motion tracking and cloud motion prediction using ground-based sky images is presented. This cloud motion prediction technique primarily targets irradiance prediction as an application in Electrical Engineering. A sequence of whole sky images is processed to determine the time taken by clouds to reach the sun position on the image. Cross-correlation technique was used to track individual clouds from one image frame to next frame. Using Harris features detection algorithm cloud features were found and the deformation vectors were produced. To find the velocity vectors of each feature points Lukas-Kanade optical flow algorithm is proposed. Using the optical flow algorithm, 3 min ahead cloud position was estimated.
[ground-based sky images, irradiance prediction, Tracking, Clouds, Irradiance forecast, geophysical image processing, clouds, cloud features, Sun, Lukas-Kanade optical flow algorithm, image motion analysis, image frame, feature extraction, cloud motion tracking, Cloud tracking, cloud motion prediction technique, Harris features detection algorithm, Cameras, Prediction algorithms, cloud position, cross-correlation technique, on-site cloud coverage prediction, Power generation, image sequences]
Real-time non-intrusive appliance load monitoring under supply voltage fluctuations
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
This paper presents a complete real-time implementation of a Non-Intrusive Appliance Load Monitoring (NIALM) system that, is robust under residential voltage level fluctuations. Existing NIALM techniques rely on multiple measurements taken at high sampling rates, but, only have been proven in simulated environments without even considering the effect of residential voltage level fluctuations - which is a severe problem in power systems of most developing countries like Sri Lanka. In contrast, through the NIALM method proposed in this paper, accurate load monitoring results were obtained in realtime using only smart meter measurements taken at a low sampling rate from a real appliance setup under residential voltage level fluctuations. In the proposed NIALM method, initially in the learning phase, a properly constructed MATLABTM Graphical User Interface (GUI) was used to acquire signals of each appliance active power consumption and voltage levels. Then, obtained active power measurements were separated into subspace components (SCs) via the Karhunen Loeve' Expansion (KLE) while also taking the voltage variations into account. Using those SCs, a unique information rich appliance level signature database was constructed and it was then used to obtain the signatures for all possible device combinations. Next, a separate GUI was designed to identify the turned ON appliance combination in the current time window using the pre-constructed signature databases, after reading the total residential active power consumption and the supply voltage. To validate the proposed real-time NIALM implementation, data from a laboratory arrangement consisting of ten household appliances was used. From the results, it was found that the proposed method is capable of accurately identifying the turned on appliances even under severe residential supply voltage level fluctuations.
[Voltage fluctuations, graphical user interfaces, appliance active power consumption, real-time NIALM implementation, active power measurements, Non-Intrusive Appliance Load Monitoring (NIALM), domestic appliances, power consumption, Realtime NIALM, severe residential supply voltage level fluctuations, Home appliances, smart meters, household appliances, Power measurement, Voltage Fluctuations, Real-time systems, Real-time load monitoring, Demand Side Management(DSM), Monitoring, Smart Grid, Voltage measurement, Sri Lanka, graphical user interface, supply voltage fluctuations, real-time nonintrusive appliance load monitoring system, total residential active power consumption, power measurement, residential voltage level fluctuations, NIALM techniques, NIALM method, Subspace technique, unique information rich appliance level signature database, smart meter measurement, Feature extraction, Smart meters, accurate load monitoring results, Karhunen Loeve expansion, Matlab]
Solution for event-planning using multi-agent technology
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Commercial operations and functionalities have been enhanced with the development of web technologies. The process of event planning can be described as one business functionality that acts as a centralized terminal in connecting small to large scale business vendors in the fields of hotel, photography, floral decorations, music sounds, etc. According to the event planning process, customers planning required to spend more time on creating package with their own requirements. The customers planning process requires a considerable amount of time and money that could be saved if this process was automated. Moreover the customer requirements are dynamic, they change from person to person as well as from time to time. This research is based on providing a solution for the above problem, by integrating the multi-agent technologies with the web based solution to build up a platform between customer and service provider. The concept of using a group of agents to communicate in place of live objects as customers and vendors has been able to provide intelligent package generation. This requirement is achieved through integrating the MaSMT framework which enables agent development with the Java Server Pages. This solution is a real time saver and an optimized platform for the vendors to promote their services and get connected with the customers.
[multi-agent systems, service provider, Java server pages, event-planning, Servers, MasMT, Web technologies, multiagent technology, MaSMT framework, business functionality, Java, event planning, centralized terminal, multi-agent, JSP, intelligent package generation, time saver, Information technology, software agents, commercial operations, multiagent technologies, agent development, scale business vendors, Internet, floral decorations, music sounds, event planning process, customer requirements]
Design and analysis of an under water visible light MIMO communication system with a camera receiver
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
In this paper, design, implementation and analysis of a new underwater multiple input multiple output visible light communication (VLC) system is presented. The VLC system consists of a transmitter, water channel, and a receiver. The transmitter is made out of light emitting diodes (LEDs'), while a camera based architecture is adopted at the receiver. We present a possible system design and characterize the channel for symbol detection. At the training phase, the underwater channel is characterized using a channel matrix, which presents the relationship between the multiple input LED states and the pixel values of the frame in the video stream obtained from the camera receiver. Thereafter the inverse model of the system is obtained. Then symbol detection is carried out by analysing consecutive frames of the real-time video stream. Also we analyse the performance of this system in terms of the bit error rate (BER), bit rate, behaviour of the system at different transmission distances, and present results using the experimental setup. From our study, it was realised that, reasonable BER performance can be achieved using the proposed system designs at low and medium transmission distances compared to most of the existing underwater communication systems.
[telecommunication channels, camera receiver, camera based architecture, water channel, underwater communications, channel matrix, system designs, optical transmitters, multiple input multiple output, VLC system, underwater multiple input multiple output visible light communication system, light emitting diodes, optical receivers, Light emitting diode, Camera receiver, underwater communication systems, Visible light communications, symbol detection, underwater channel, free-space optical communication, water visible light MIMO communication system, MIMO communication, transmitter, error statistics]
Improve software quality through practicing DevOps
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
DevOps is extended from certain agile practices with a mix of patterns intended to improve collaboration between development and operation teams. The main purpose of this paper is to conduct a study on how DevOps practice has impacted to software quality. The secondary objective is to find how to improve quality efficiently. A literature survey has carried out to explore about current DevOps practices in industry. According to the literature survey, the conceptual research model was developed and five hypotheses were derived. Research objectives were accomplished by testing hypotheses using Pearson correlation. A linear model is derived based on the linear regression analysis. An online questionnaire was used to collect quantitative data whereas interviews with experts on DevOps and Quality assurance have been used to identify how to improve the quality of software by practicing DevOps. Recommendations are given based on interview feedback, hypotheses testing with regression analysis. According to the quantitative study, researchers have identified that quality of the software gets improved when practice DevOps by following CAMS (Culture, Automation, Measurement, Sharing) framework. Automation is the most critical factor to improve the software quality. As per the results of multiple regression analysis, it has proved culture, automation, measurement and sharing are important factors to consider to improve quality of the software. In conclusion it can be recommended to use DevOps to achieve high quality software.
[Automation, research objectives, software prototyping, software development management, Companies, regression analysis, software quality, operation teams, DevOps practice, ISO 9126, CAMS Framework, Quality assurance, DevOps, Quality, Software quality, high quality software, quantitative data collection, agile practices, linear regression analysis, Software measurement, practice DevOps, conceptual research model, Testing]
Continuous scrum: A framework to enhance scrum with DevOps
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
There has been a significant impact on software development lifecycle by the non-plan driven software processes such as Agile derived models i.e. Scrum, Extreme Programming (XP) and recently introduced DevOps practice. In this paper capabilities and limitation of these above mentioned Agile based practices has been examine. A Scrum based software development framework that supports continuous integration and rapid delivery had been developed. The developed software lifecycle management framework has overcame the common challenges that software practitioners may experience.
[Industries, Productivity, continuous integration, project management, continuous scrum, software prototyping, software development management, Programming, software quality, software practitioners, Scrum (Software development), DevOps practice, Software Development Life Cycle, Agile based practices, software development lifecycle, DevOps, developed software lifecycle management framework, Extreme Programming, nonplan driven software processes, Agile, Software, Scrum, Scrum based software development framework, Business]
People clues: Business intelligence tool for team dynamics
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Today in most sectors like ICT, Apparel and BPO, as the common practice employees are working as teams in projects. Selecting the right team for the right project in these industries is vital for the projects to make it a success since these industries have a high impact on the economy. In present this is mostly done with the experience of Higher Management. But with the churning of the employees' knowledge transferring process has been really complex since knowledge is not stored anywhere and also training a new candidate takes great amount of time and effort. People Clues is a business intelligence tool which selects the best team for a given project by analyzing their past experience, Educational Qualifications and Past Performances. People Clues has been built on the concept of Team Dynamics. User can provide Project details as the input and by analyzing human resource characteristics system will generate the best team for the relevant project. Mainly three algorithms have been used for the prediction while giving the chance of selecting the preferred algorithm to the user. In this paper we present a desktop and a web application that facilitates the task of automating dynamic team generation depending on the optimality or feasibility based on different knowledge areas such as team dynamics, predictive modeling, business intelligence, data mining and team characteristics.
[data mining, Team Dynamics, Predictive models, Data Mining, human resource management, team characteristics, Data mining, Business intelligence, competitive intelligence, knowledge management, automating dynamic team generation, candidate training, team working, Prediction algorithms, Business Intelligence, project management, Hadoop, Tools, Predictive Modelling, employees knowledge transferring process, business intelligence tool, predictive modeling, higher management experience, Data models, personnel, industrial project details, industrial training, ETL]
Enhanced in-store shopping experience through smart phone based mixed reality application
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
A prime concern in today's commerce offering is having satisfied customers through a range of business and technical solutions. Businesses invest and explore different approaches in their merchandising and product promotion to revolutionize in-store shopping experiences. With the advent of Mixed Reality (MR), Augmented Reality (AR) and Virtual Reality (VR) as consumer level technologies, it has now become possible to look at how shopping experience of customers can be enhanced from a fresh perspective. This paper presents Smart Phone based Mixed Reality Application (SPMRA), which makes it possible to gamify the whole in-store shopping experience with a low cost, easy to use, smart phone based mixed reality platform. This interactive, fun to use platform enables retail owners to create mixed reality based experiences with few clicks and customers to receive unique shopping experience during their stay in-store. Usage of the SPMRA in real world environments has been tested in Media-Markt outlets in Munich, Germany and Singer Mega show rooms in Moratuwa, Sri Lanka resulting in positive customer feedback and better overall shopping experience for customers. A significant 82.1% of SPMRA users in Germany and Sri Lanka agreed to the fact that the application assisted and influenced them in making their buying decisions.
[Augmented Reality, Shopping Experience, mixed reality based experiences, mixed reality platform, augmented reality, smart phones, Mobile applications, Gamification, Augmented reality, mobile commerce, Headphones, Smart Phone based Mixed Reality Application, Smart Phone, consumer level technologies, Multimodal Interaction, in-store shopping experience, retail owners, Mixed Reality, Smart phones, Robots, Virtual Reality, Business, retail data processing]
Automated audio monitoring approach for radio broadcasting channels in Sri Lanka
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Most of the people like to listen music. When music repository is growing, it is very hard to find a music song without knowing the exact Meta data of it like title, of the song singer, musician and so on. As a solution to this problem, many researchers have tried to provide a way to identify music songs by analyzing the content of it. This is known as content based audio identification. In this research we extend this idea to monitor and identify broadcasted radio streams since there are so many applications and business values of it. Before analyzing the content of radio stream, we converted the audio stream into machine friendly format. Then we tried to remove irrelevant audio objects like commercials and talks during the preprocessing stage. After that using a powerful content base audio identification algorithm, we recognized songs objects and identified them. We used a very large audio repository and store songs as fingerprints. At the end of this process we provide a detailed report of song broadcasting history of a given radio channel. Even though there were many useful applications of this research we focus only on the protecting the copy right ownership of artists.
[radio broadcasting, Audio fingerprint, radio stream, audio repository, Fingerprint recognition, audio streaming, audio coding, broadcasted radio streams, signal denoising, radio broadcasting channels, Databases, music, automated audio monitoring approach, Broadcasting, songs objects, audio stream, machine friendly format, Monitoring, meta data, broadcast monitoring, Sri Lanka, radio channel, powerful content base audio identification algorithm, Object recognition, irrelevant audio object removal, Silence detection, song broadcasting history, playlist generation, song singer, Meta data, audio signal processing, content based audio identification, Music, music repository, wavelets, Feature extraction, features extraction, music song, broadcast channels]
Mobile applications for real time information delivery on rapid bus transit systems in Tanzania
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Understanding the need for better service delivery with effective and efficient performance of a project, we conducted a study on the new Bus Rapid Transit (BRT) system in Dar es Salaam, Tanzania. The purpose was focusing on realizing the delivery of real time information to commuters and providing operators real time feedback from commuters and other stakeholders in the transportation industry, for better service. Our research uses mixed approaches on collecting data, both qualitative and quantitative techniques were used for a deeper understanding of the system and quality collection of necessary data. Statistical hypothesis testing was used in testing the collected data from the two surveys conducted before and after the use of the proposed solution. The conclusions show that giving commuters real time information on simple and mobile way has improved their commuting, also we could make many improvement to the system, due to the changes made by receiving real time feedbacks from commuters. Moreover, city awareness has improved among the commuters by using the proposed solution, they are able to locate various interesting and important places along the routes of bus rapid transit system.
[rapid bus transit systems, Urban areas, Transportation, Tanzania, Mobile communication, Mobile applications, traffic engineering computing, Dar es Salaam, statistical hypothesis testing, mobile computing, rapid transit systems, service delivery, Focusing, mobile applications, real time information delivery, Real-time systems, Bus Rapid Transit, statistical testing, Intelligent Transportation System]
ICT for universal access to agricultural information: The case of Malawian farmers
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
This paper assesses whether ICTs used in Malawi's agriculture sector can have an impact in improving the livelihood of farmers. Social factors together with level of technology adoption are important elements for success of ICT4D initiatives for farmers; hence, consideration of these factors when implementing ICT4D projects is very important. Illiteracy levels amongst rural farmers and the level of technology adoption will be our main focus. While most papers have discussed the impact of ICTs in Agriculture; socio-technical attributes that affect the outcome of the projects have not been fully explored. The main purpose of this paper is to assess how ICT4D initiatives can be contextualized so as to benefit the rural farmers who are both illiterate and do not use the most advanced mobile phones. The use of Interactive Voice Response System (IVR) to come up with a low cost phone service that use voice as a way of communication to farmers has been explored. The results suggest that ICT can play a significant role in improving farming productivity, although there are many challenges to be addressed. The study recommends that socio-technical factors should be considered in order for Malawi's ICT4D initiatives in agriculture to have a positive impact.
[ICT4D projects, information technology, illiteracy levels, mobile phones, Mobile communication, socio-technical factors, Malawi ICT4D initiatives, Mobile handsets, Information systems, universal access, Malawian farmers, agriculture, mobile computing, farming productivity, farming, Malawi agriculture sector, Sociotechnical, Agriculture, socio-economic effects, Interviews, mobile radio, project management, agricultural information, social factors, technology adoption, Africa, Interactive Voice Response, ICT4D, interactive voice response system, Information and communication technology, rural farmers]
Lane detection using hybrid colour segmentation and perpendicular traversal linear search algorithm
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Road lane recognition and departure tracking systems provide an additional level of assistance and security to have a safe drive. This Application identifies the roadway by recognizing the lanes on the road considering the current movements of the vehicle. This research contributes to resolving some of the outstanding challenges in real time lane detection systems. Research has proposed a perpendicular traversal linear search algorithm with hybrid colour segmentation to address appearance variations in lane marking occurs due to various weather conditions, shadows, and occlusions such as traffic on the road. Robustness of the application has been tested under various road conditions and experimental results have achieved an accuracy of 89% for the overall application performance.
[Algorithm design and analysis, perpendicular, Roads, hybrid colour segmentation, road safety, departure tracking systems, real time lane detection systems, lane marking, Image color analysis, road vehicles, perpendicular traversal linear search algorithm, driver information systems, feature extraction, image segmentation, segmentation, image colour analysis, vehicle camera, Colored noise, search problems, Meteorology, road traffic, linear, Image edge detection, driving safety, traffic engineering computing, road lane recognition, Image segmentation, hybrid, road conditions, image recognition]
An online traffic sign recognition system for intelligent driver assistance
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
This paper proposes a system that is capable of detecting, recognizing and indicating traffic signs to the driver to provide a safe and convenient driving experience. The system is composed of three phases; image pre-processing phase, detection phase and recognition phase. Image pre-processing phase deals with image segmentation that is employed to enhance the images to obtain clearer information under variable lighting conditions. During the detection phase, the objective is to find traffic signs in the input image frames and to return the regional coordinates of detected signs. In order to detect traffic signs, a cascade classifier was trained to analyse the frame and to detect signs in each frame. In the recognition phase, a multiclass support vector machine image category classifier was trained to recognize and alert the driver. The system comprised of these phases is capable of detecting, recognizing and alerting traffic signs with 98.6% accuracy while the vehicle is moving at a speed in the range of 40-45 km/h.
[online traffic sign recognition system, image classification, image pre-processing phase deals, safe driving experience, object detection, road safety, Machine Learning, multiclass support vector machine image category classifier, Vehicles, Training, Histograms, sign detection, Image color analysis, image enhancement, driver information systems, image segmentation, Image Processing, Detectors, detection phase, traffic signs, support vector machines, variable lighting conditions, input image frames, Active safety, traffic engineering computing, convenient driving experience, Support vector machines, intelligent driver assistance, Feature extraction, recognition phase, Computer Vision]
An approach for digitizing form based images
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Numerous associations still rely on paper-escalated work processes. Due to the fact that the printed and handwritten documents are all around acknowledged and perceived for any authoritative report. The major issues having handled the paper documents are the inability to monitor the lost data, storage and money and time wasted on re-keying data. It is possible to address these problems through a solution that can digitize the data in these paper documents. The most common approach is to identify handwritten of a single person through a template matching approach. In the proposed approach, the template of the document is identified and handwritten areas are extracted through an image processing component and the identification of the handwritten characters are addressed through training the system using a convolutional neural network. The accuracy level of 90% achieved with recognition of form template and 84.67% accuracy level achieved with handwritten character recognition.
[Image recognition, Shape, image processing component, Machine Learning, paper documents, Image Classification, feature extraction, handwritten documents, Handwritten Character Recognition, Kernel, handwritten character recognition, printed documents, convolutional neural network, document image processing, digitizing form based images, Character recognition, Optical character recognition software, Biological neural networks, Handwriting recognition, template matching approach, form template recognition, Pattern Recognition, printed handwritten documents, Template Based Forms, authoritative report, re-keying data, neural nets]
Hybrid model for data management and acquisition in sensor network
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Different ways are used for sensor data acquisition and management in wireless and sensor network (WSN). Two major approaches for data acquisition and management are data collection and logging network models. The data collection network provides a database abstraction from the base station. It considers the whole network as a database. Meantime, the data logging network is used to log the sensor readings and metadata inside the mote itself. Data logging network is provided a database for a sensor mote. The data collection network deals with real time sensed data and data logging network deals with stored sensor data bulk. Thus, there is a gap between them when communicating with each other. There isn't any existing approach to compare real time data and historical data. Hence, the proposed model bridges the gap between data logging network and data collection network. It addresses the real-world scenarios in a reliable manner, such as historical data and metadata management. A flexible sensor network which can act as both data collection and data logging networks based upon user requirements has been not introduced yet. Therefore, a novel hybrid model is a dire need of WSN. This research proved that the cost of communication energy of the network can be reduced by using the hybrid model. Hence, the total cost will also be reduced in WSN.
[Base stations, meta data, wireless sensor networks, data management, flexible sensor network, data logging network, sensor data acquisition, data collection network, wireless sensor network, Routing, time data, Wireless sensor networks, hybrid model, Databases, historical data, WSN, Data collection, Data models, Real-time systems, data acquisition, logging network models]
Mechanical design and flow simulation of a steam generator for parabolic trough solar thermal energy harnessing plant
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
A steam generator is designed for a parabolic trough solar thermal plant of aperture area 22.3 m2, which uses Mobil Therm-605 as the heat transfer fluid (HTF). The potential energy input rate from the plant to the steam generator is 4.56 kW, and the flow rate and temperature of the HTF of the plant are 11 min-1 and 268 &#x00B0;C respectively. The steam generator was designed as a shell and tube heat exchanger and the tubes are arranged in reflection symmetric configuration (n=6). Flow simulations was done by using SolidWorks CAD software, based on Finite Element Method were carried out for the steam generator design in order to find the optimum conditions by varying the parameters such as tube diameter, HTF flow velocity distribution and thickness of HTF thermal barrier, while minimizing the fluid pressure and maintaining even flow distribution through the tubes. The simulation scheme narrowed down to simulate for the commercially available sizes of food-grade stainless steel tube diameters of 1/8, 1/4, 3/8, 1/2 and 3/4 inch. Simulations reveal that the non-moving HTF layer (which acts as a thermal barrier) for the above tube diameters were 0.0 %, 0.0 %, 4.1 %, 10.7 % and 27.6% respectively. Adding cost factors to the simulation outputs, it was found that the minimum material cost of tube bundle can be achieved when the tubes of diameter 1/4 inch is used and the expected length of the tubes with that diameter is found to be 72 mm.
[Solid modeling, flow simulation, flow simulations, size 72.0 mm, stainless steel, Electron tubes, design engineering, potential energy input rate, food-grade stainless steel tube diameters, shell-tube heat exchanger, Fluids, parabolic trough, finite element method, heat exchangers, Mathematical model, pipes, thermal barrier, power 4.56 kW, solar power stations, heat transfer fluid, solar thermal energy, CAD, Mobil Therm-605, parabolic trough solar thermal energy harnessing plant, Generators, steam generator design, finite element analysis, Thermal energy, boilers, pipe flow, heat transfer coefficient, steam generator, heat transfer, Heat transfer, temperature 268.0 degC]
Differential diagnosis of eczema and psoriasis using categorical data in image processing
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
A number of attempts have been made at using image processing and machine learning to automate the diagnosis process of dermatological diseases. Psoriasis and eczema are two conditions that are usually misdiagnosed, and were selected after an investigation. The reason for this high rate of misdiagnosis is due to the margin of error present in the method doctors use to perform a diagnosis. This method consists of using the visual aspects of the disease along with non-visual patient history questions. This method is not as effective when certain diseases do not have definitive answers to these history questions and the doctors have to base the diagnosis almost entirely on the visual aspects displayed on this skin. The proposed solution addresses this problem by combining both the visual as well as nonvisual feature vectors into a single classifier, a support vector machine, which once trained, enables diagnosing to a reliable level of accuracy at 84%.
[Visualization, image classification, skin, diagnosis process automation, visual aspects, Image color analysis, eczema, statistical processing, categorical data, Lesions, learning (artificial intelligence), medical image processing, image processing, differential diagnosis, support vector machines, disease, nonvisual patient history questions, diseases, machine learning, Diseases, dermatological diseases, Image segmentation, machine leaning, support vector machine, psoriasis, computer vision, Skin]
The best preferred product location recommendation according to user context and the preferences
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Currently the Smartphones are more popular among the community with the available technologies such as sensor-based interactions and smart apps. The other kinds of trends in such apps lead on context awareness and the personalization for recommending the services for the users based on their context and the preferences. Further, the researches are going on tracking the location of a person and guiding them to the nearby places where the products and the services are available according to their preferences. To accomplish such tasks, tracking and analyzing of the user preferences on different categories of products is required. This paper describes a mobile-based solution; NavToPref where the user preferences and the contextual information are gathered from their mobile phones and recommend and guide them to the nearby locations where the most preferred products are available. Analyzing the metadata of the sites of the frequently and mostly searched products, their top preferred categories of products are identified. This is done by the analysis of the browsing history. Further from their mobile devices, their own contextual information such as whether, location, identified special events from the Google calendar are collected to achieve more personalization on product recommendation. By analyzing the identified preferred products and the user context at the moment, the best preferred product/service locations are notified in the Google map with the shortest path for each product location from the users current location and allows the user to navigate to such locations. If someone is looking for a best promotional deal for shopping, that information is notified along with the recommendation.
[mobile phones, user preferences, Metadata, Mobile communication, users current location, History, Servers, personalization, mobile computing, best preferred product location recommendation, context awareness, smartphones, retail data processing, shopping, Navigation, product recommendation, user context, smart phones, Context-awareness, contextual information, Google map, User Preferences, recommender systems, mobile-based solution, preferred product/service locations, Internet, Contextual Information, Context modeling]
Improving trusted routing by identifying malicious nodes in a MANET using reinforcement learning
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Mobile ad-hoc networks (MANETs) are decentralized and self-organizing communication systems. They have become pervasive in the current technological framework. MANETs have become a vital solution to the services that need flexible establishments, dynamic and wireless connections such as military operations, healthcare systems, vehicular networks, mobile conferences, etc. Hence it is more important to estimate the trustworthiness of moving devices. In this research, we have proposed a model to improve a trusted routing in mobile ad-hoc networks by identifying malicious nodes. The proposed system uses Reinforcement Learning (RL) agent that learns to detect malicious nodes. The work focuses on a MANET with Ad-hoc On-demand Distance Vector (AODV) Protocol. Most of the systems were developed with the assumption of a small network with limited number of neighbours. But with the introduction of reinforcement learning concepts this work tries to minimize those limitations. The main objective of the research is to introduce a new model which has the capability to detect malicious nodes that decrease the performance of a MANET significantly. The malicious behaviour is simulated with black holes that move randomly across the network. After identifying the technology stack and concepts of RL, system design was designed and the implementation was carried out. Then tests were performed and defects and further improvements were identified. The research deliverables concluded that the proposed model arranges for highly accurate and reliable trust improvement by detecting malicious nodes in a dynamic MANET environment.
[telecommunication security, Protocols, mobile conferences, malicious behaviour, ad-hoc on-demand distance vector protocol, Security, malicious nodes, Mobile ad hoc networks, healthcare systems, mobile ad-hoc networks, mobile ad hoc networks, reliable trust improvement, vehicular networks, learning (artificial intelligence), protocols, reinforcement learning agent, AODV, AODV protocol, military operations, Reinforcement learning, Routing, Trust, trusted routing, MANET, self-organizing communication systems, dynamic MANET environment, Learning (artificial intelligence), dynamic wireless connections, Peer-to-peer computing]
Semi-supervised instance population of an ontology using word vector embedding
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
In many modern-day systems such as information extraction and knowledge management agents, ontologies play a vital role in maintaining the concept hierarchies of the selected domain. However, ontology population has become a problematic process due to its nature of heavy coupling with manual human intervention. With the use of word embeddings in the field of natural language processing, it became a popular topic due to its ability to cope up with semantic sensitivity. Hence, in this study we propose a novel way of semi-supervised ontology population through word embeddings as the basis. We built several models including traditional benchmark models and new types of models which are based on word embeddings. Finally, we ensemble them together to come up with a synergistic model with better accuracy. We demonstrate that our ensemble model can outperform the individual models.
[pattern classification, Law, natural language processing, Ontology, modern-day systems, Ontologies, semisupervised instance population, word embeddings, Statistics, word2vec, word vector, Ontology Population, word processing, Word Embeddings, ontology population, Sociology, Semantics, manual human intervention, ontologies (artificial intelligence), Natural language processing, learning (artificial intelligence), traditional benchmark models]
Artificial neural networks for daily electricity demand prediction of Sri Lanka
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
As a developing country, energy is a factor that need to be utilized effectively and efficiently. Electricity is one of the main sources of energy in Sri Lanka. Thus accurate models to forecast future electricity demand is essential. This research focus on predicting the next day electricity demand for Sri Lanka. The study uses daily electrical consumption data for 11 years and use an Artificial Neural Network (ANN) model trained with back propagation algorithm and a Multiple Regression model to predict daily electrical consumption. The performance of the two models were compared using Root Mean Square Error (RMSE) Mean Absolute Percentage Error (MAPE) and Coefficient of Determination (R2), The ANN model shows better performance with lower RMSE and MAPE values than Multiple Regression Model.
[determination coefficient, Electricity consumption, regression analysis, multiple regression model, Predictive models, root mean square error mean absolute percentage error, power consumption, Load forecasting, developing country, Artificial Neural Networks, time 11.0 year, future electricity demand forecasting, artificial neural network model, mean square error methods, Load modeling, Biological system modeling, Sri Lanka, daily electrical consumption data, next day electricity demand prediction, Artificial neural networks, MAPE, RMSE, Forecasting, power engineering computing, back propagation algorithm, daily electrical consumption prediction, backpropagation, load forecasting, daily electricity demand prediction, Data models, ANN model, Short term load forecasting, neural nets]
Automatic detection of multi-line templates in software log files
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
This research proposes a method for automatically identifying and coding the structure in any text log file. Generated code is expressed in the declarative language LDEL, which was designed and implemented during earlier stages of this research. Once the code is available, the LDEL parser is able to scan a log file with the particular structure and extract log information into a tree-based data structure. Subsequently the extracted information can be processed according to prespecified logic, which is expressed in a procedural language which also was developed as a prior stage in this research. The language scheme used for expressing log file structure was carefully designed after examining log files from numerous domains as a result of the main author's previous research. This scheme is capable of capturing peculiar patterns occurring both within and across lines in log files. Since the development of this scheme and the procedural language, it was noticed that significant manual work was needed for a human expert to examine the log file and write the script that captures its structure. This approach was both time consuming and error prone. With this research we propose and evaluate a method to automatically detect a larger part of the log file structure so that the human specialist can use the generated script with minimal or no modifications.
[Knowledge Representation, prespecified logic, Automation, Particle separators, trees (mathematics), tree-based data structure, Tools, declarative language LDEL, log file structure, Log analysis, Data Extraction, software log files, Data mining, text log file, log information, formal logic, Pattern Detection, Software, data structures, Regular Expressions, Arrays, Suffix Tree, procedural language, Periodic structures]
Non-visual object generation model to ease music notation script access for visually impaired
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Music scores with notations and lyrics are considered as the main mediator in musical communication channel which lies between a composer and a performer. Music learners with visual impairment have less opportunity to access this main mediator since most of them are in visual format. With the assistance of a third-party, they convert visual music notations into Music Braille, again a complex format having spatio-tactile symbols. The research tries to redefine the best mediator in composer - performer musical communication channel when at least one of the participants is visually impaired. Music and Singing can be described more precisely using a format in temporal domain compared to a visual format such as a notation and lyric script in the spatial domain. The research proposes a non-visual object generation model specifically based on synthesized singing together with a controllable interface which can convey all type of information enclosed within a music notation script. Calculated scores on similarity and user scores on naturalness relevant to the synthesized auditory output reveal that this approach can be successfully utilized to fill the accessibility gap prevailed in assistive technologies for visually impaired.
[Visualization, Adaptation models, handicapped aids, visual music notations, Assistive technology, Synthesizers, Tools, Music Braille, assistive technologies, synthesized singing, music, auditory objects, Hidden Markov models, Music scores, visual impairment, nonvisual object generation model, music notation script access, musical communication channel]
State-of-art-in-indoor navigation and positioning of visually impaired and blind
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
This paper presents a survey of navigation and positioning aids for blind and visually impaired (BVI). Assistive technology based mobility and environmental accessibility methods are presented with their pros and cons and potential paths of explorations for future research improvements.
[indoor navigation, handicapped aids, Positioning, positioning aids, blind, Navigation, Visually impaired, Assistive technology, Buildings, vision defects, Sensor fusion, assistive technology, Acoustics, Sensor Fusion, BVI, Cameras, Collision avoidance, visually impaired]
Cluster based modular nonlinear autoregressive neural network to predict daily reservoir inflow
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Despite the ability of Artificial Neural Network (ANN) to handle nonlinear relationships in data, there are instances where ANNs have not been able to predict accurately in the presence of extremes values or other inherent groupings in the data. Although the ANN modeling expects the data to be evenly distributed over an entire data space, in practical situations data often consist of clusters or extreme values. Thus, instead of modeling the data as it is, appropriate mechanisms should be followed to handle those inconsistancies. This paper presents one such mechanism based on two clustering algorithms, k-means and fuzzy c-means. The base model is Nonlinear Autoregressive Artificial Neural Network (NAR-ANN). Altogether 14 model formulations of NAR-ANN were compared here with varying number of clusters and a trimming mechanism. Results suggest the superiority of cluster based NAR-ANN over the single NAR-ANN. Modular ANN approach with an optimum combination of the 14 models can be used for better results. The proposed cluster based NAR-ANN used in this paper is a novel generalization to NAR-ANN where the cluster effect is incorporated as a binary exogenous variable (NARX).
[cluster based NAR-ANN, binary exogenous variable, cluster, Artificial neural networks, reservoirs, autoregressive processes, ANN modeling, nonlinear, daily reservoir inflow, pattern clustering, Artificial Neural Network, clustering algorithms, Clustering algorithms, Reservoirs, NAR-ANN, inflow, Data models, Mathematical model, Cluster based modular nonlinear autoregressive neural network, neural nets]
Offline handwritten signature verification system using random forest classifier
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
This research was conducted to find a feasible solution to verify hand written signatures. The scope has been narrowed down to offline signatures which contains static inputs and outputs. Several classification methods such as Multinomial Naive Bayes Classifier (MNBC), Bernoulli Naive Bayes Classifier (BNBC), Logistic Regression Classifier (LRC), Stochastic Gradient Descent Classifier (SGDC) and Random Forest Classifier (RFC) were implemented to identify the most suitable classifier to verify hand written signatures. The classifiers were trained and tested using a signature database available for the public use. The best performance was obtained from RFC with and accuracy score 0.6. For an average, the system created has been successful in verifying signature images provided with a considerable accuracy level.
[algorithms, image classification, logistic regression classifier, Random forest classifier, regression analysis, stochastic gradient descent classifier, Classification algorithms, Bernoulli Naive Bayes classifier, artificial intelligence, Training, random forest classifier, Training data, gradient methods, Testing, handwritten character recognition, hand written signatures, multinomial Naive Bayes classifier, Offline handwritten signature, classification, signature database, Handwriting recognition, offline handwritten signature verification system, Feature extraction, Bayes methods, Logistics]
Message from the conference chair
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.
[]
Foreword by the co-chairs
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.
[]
A context aware &amp; personalized multiple location trip planner using Facebook check-ins of a user
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Travel planning in a new city or a country is tedious and time consuming as the traveller has zero or minimal knowledge on which locations to visit in the new region. To overcome this problem many commercial solutions such as TripAdvisor and Google Trips, as well as research level solutions have been introduced. Even though these solutions are capable of reducing the information overload to the user, they do not perform any personalization in making travel recommendations. Therefore, the need for a recommendation system that is capable of extracting the user's personal travel preferences more accurately is still significant.
[Collaborative Filtering, Travel Recommendations, Profile Similarity]
Industry expectations versus skills of ICT graduates of state universities in Sri Lanka: A case study of Uva Wellassa University ICT graduates
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Uva Wellassa University, which is one of the youngest universities in Sri Lanka, aims at producing graduates by focusing on employers' needs and entrepreneurship. The university offers two degree programs related to ICT, namely Bachelor of Industrial Information Technology and Bachelor of Science in Computer Science and Technology. These degree programs offer a wide variety of subjects, which are aimed at improving the technical skills as well as the soft skills of the undergraduates.
[graduates, Employability skills, ICT industry, qualitative data, descriptive method]
Security testing as a service with docker containerization
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Nowadays web applications are used widely in day to day life. These web applications need to be secured from security vulnerabilities. In order to test how much a web application is secured enough to stand against security attacks, security testers use various web vulnerability scanners. However, in order to run security scans as expected, these tools have to be properly configured and also require lots of computational resources. So anyone who is interested in doing a security scanning should have a thorough knowledge on configuration and usage of web vulnerability scanners to achieve required strength of security.
[Docker containerization, Web Vulnerability Scanner, Security Testing as a Service]
Android digital forensics &#x2014; Simplifying Android forensics using regular expressions
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
The advancement of technology has increased the computing power of mobile devices and at the same time keeping their size small enough to fit inside user's pocket. Therefore, digital evidence can be collected not only from computers but also from any other electronic devices which stores and process user related data. Since digital forensics community has done minimal research on mobile devices forensics, forensic investigators are struggling without a standard approach or procedure to follow during investigations. Therefore, validated frameworks that can be used to collect evidence from mobile devices are virtually not existent in current digital forensics environment. The aim of this research is to present an appropriate framework for mobile device forensics which can be used by forensic investigators during their investigation. Another important objective of the research is to identify how regular expressions can be used to simplify evidence examination and analysis in android forensics.
[Mobile Forensics, Tablets, Mobile Devices, Forensic investigational framework, Smart phones, Android]
Leech step path finding algorithm
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Leech Step Path Finding Algorithm (LSPFA) is a novel algorithm proposed by us which can be used for intelligent character recognition (ICR) for Sinhala characters. The study is based on an ongoing research which is focused to solve the problem of how to recognize a particular character among a set of Sinhala characters on a digital image via character feature extraction (mainly focused on printed characters, but the proposed algorithm can be enhanced to recognize handwritings too which is more useful in intelligent character recognition (ICR) engines) with 100% accuracy. LSPFA disclose an ability to extract all possible features on any symbol which can depict a character of any natural language. Since that, it will be able to use for character recognition in the adaptive classifier of any ICR, optical character recognition (OCR), optical music recognition (OMR) engine independent of the language used.
[Character Feature Extraction, Sinhala Characters, Intelligent Character Recognition]
Car park slot finding framework
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Increase in population has resulted in the increase of vehicles which make parking a vehicle during rush hours a horrendous task. This may result in congestion inside parking areas which causes unnecessary wastage of time and gasoline. Many attempts have been made to solve this problem, but most of them require various types of sensors to identify the presence of a vehicle. Although Image Processing based solutions also have been provided to solve this problem, it was noted that most of these Image Processing approaches tend to be un-customizable to fit any type of car park. This research presents an image processing based approach of designing and implementing a car park slot finding framework to address above mentioned problems. A customizable web based system in which the administrator can add, remove or reserve slots according to his needs is proposed. This system will also provide navigation to the nearest vacant slot to its users (drivers entering the car park) and make the process of parking more efficient. This system has an overall accuracy of 98%.
[Slot Finding, Image Processing, Vehicle parking]
Organizing Committee
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Provides a listing of current committee members and society officers.
[]
Technical program committee
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Provides a listing of current committee members and society officers.
[]
Keynote speakers
2017 Seventeenth International Conference on Advances in ICT for Emerging Regions
None
2017
Provides an abstract for each of the keynote presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.
[]
