1374
Proof-theoretic techniques for term rewriting theory
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
A bridge is presented between term-rewriting theory in computer science and proof theory in logic. It is shown that proof-theoretic tools are very useful for analyzing two basic attributes of term rewriting systems, the termination property and the Church-Rosser property. A counterexample is given to show that Knuth's critical pair lemma does not hold for conditional rewrite systems. Two restrictions on conditional systems under which the critical pair lemma holds are presented. One is considered a generalization of Bergstra-Klop's former result; the other is concerned with a generalization of Kaplan's and Jouannaud-Waldmann's systems.<<ETX>>
[conditional systems, Size measurement, term rewriting theory, proof theoretic techniques, Equations, Computer science, Bridges, Seminars, formal logic, Councils, computer science, Church-Rosser property, theorem proving, bridge, logic, Logic, termination property]
mu -definable sets of integers
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The mu -calculus is a language consisting of standard first-order finitary logic with a least fixed-point operator applicable to positive inductive definitions. The main theorem of this study is a set-theoretic characterization of the sets of integers definable in the mu -calculus. Another theorem used but not proved is a prenex normal form theorem for the mu -calculus.<<ETX>>
[formal languages, Educational institutions, standard first-order finitary logic, Reflection, Calculus, prenex normal form theorem, set theory, integer sets, positive inductive definitions, Upper bound, Negative feedback, Bismuth, least fixed-point operator, mu -definable sets of integers, mu -calculus, Logic]
Polymorphism, set theory, and call-by-value
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
Set-theoretic (or rather the more general topos-theoretic) models of polymorphic lambda-calculi are discussed under the assumption that the datatypes of the language are to be interpreted as sets and the operations as partial functions. It is shown that it is not possible to obtain a model in which function spaces are interpreted by the full partial function space, but that it is nevertheless possible to have models which incorporate a usefully large class of partial functions. The main result is that set-theoretic models do not exist, even constructively. This is a much stronger result than holds for the classical sound-order lambda calculus.<<ETX>>
[formal languages, Electric shock, Calculus, set theory, polymorphic lambda-calculi, classical sound-order lambda calculus, topos-theoretic, datatypes, formal logic, Councils, Set theory, Mathematical model, partial functions, call-by-value]
CCS with priority choice
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
An extension of Milner's CCS with a priority choice operator called prisum is investigated. This operator is very similar to the PRIALT construct of Occam. The binary prisum operator only allows execution of its second component in the case in which the environment is not ready to allow the first component to proceed. This dependency on the set of actions the environment is ready to perform goes beyond that encountered in traditional CCS. Its expression leads to a novel operational semantics in which transitions carry read-sets (of the environment) as well as the normal action symbols from CCS. A notion of strong bisimulation is defined on agents with priority by means of this semantics. It is a congruence and satisfies new equational laws (including a new expansion law) which are shown to be complete for finite agents with prisum. The laws are conservative over agents of traditional CCS.<<ETX>>
[priority choice operator, Chemical sensors, bisimulation, EMTP, Laboratories, operational semantics, Control systems, read-sets, equational laws, action symbols, Temperature sensors, formal logic, Carbon capture and storage, Occam, expansion law, formal languages, programming theory, finite agents, PRIALT construct, Application software, congruence, Computer science, Computer languages, CCS, binary prisum operator, Temperature control]
Linear logic without boxes
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
J.-Y. Girard's original definition of proof nets for linear logic involves boxes. The box is the unit for erasing and duplicating fragments of proof nets. It imposes synchronization, limits sharing, and impedes a completely local view of computation. The authors describe an implementation of proof nets without boxes. Proof nets are translated into graphs of the sort used in optimal lambda -calculus implementations; computation is performed by simple graph rewriting. This graph implementation helps in understanding optimal reductions in the lambda -calculus and in the various programming languages inspired by linear logic.<<ETX>>
[rewriting systems, Logic programming, Computational modeling, linear logic, proof nets, Linear programming, Encoding, Calculus, graph rewriting, Geometry, formal logic, lambda -calculus, Parallel processing, Concrete, theorem proving, Impedance, graph implementation]
A fully abstract denotational model for higher-order processes
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
A higher-order process calculus is defined in which one can describe processes which transmit as messages other processes; it may be viewed as a generalization of the lazy lambda -calculus. The authors present a denotational model for the language, obtained by generalizing the domain equation for S. Abramsky's (1990) model of the lazy lambda -calculus. It is shown to be fully abstract with respect to three different behavioural preorders. The first is based on observing the ability of processes to perform an action in all contexts, the second on testing, and the final one on satisfying certain kinds of modal formulae.<<ETX>>
[Performance evaluation, lambda calculus, lazy lambda -calculus, message transmission, domain equation, higher-order process calculus, testing, Calculus, Equations, fully abstract denotational model, modal formula satisfiability, Algebra, behavioural preorders, Communication channels, performability, Testing]
Subtyping and parametricity
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We study the interaction of subtyping and parametricity. We describe a logic for a programming language with parametric polymorphism and subtyping. The logic supports the formal definition and use of relational parametricity. We give two models for it, and compare it with other formal systems for the same language. In particular we examine the "Penn interpretation" of subtyping as implicit coercion. without subtyping, parametricity yields, for example, an encoding of abstract types and of initial algebras, with the corresponding proof principles of simulation and induction. With subtyping, we obtain partially abstract types and certain initial order-sorted algebras, and may derive proof principles for them.<<ETX>>
[Logic programming, Object oriented modeling, relational parametricity, abstract data types, formal systems, Encoding, type theory, algebra, Parametric statistics, subtyping, Computer science, formal logic, parametric polymorphism, Computer languages, Penn interpretation, initial order-sorted algebras, initial algebras, induction, logic programming, programming language, abstract types, Object oriented programming]
Finitely monotone properties
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
A characterization of definability by positive first order formulas in terms of Fraisse-Ehrenfeucht-like games is developed. Using this characterization, an elementary, purely combinatorial, proof of the failure of Lyndon's Lemma (1959) (that every monotone first order property is expressible positively) for finite models is given. The proof implies that first order logic is a bad candidate for the role of a uniform version of positive Boolean circuits of constant depth and polynomial size. Although Lyndon's Lemma fails for finite models, same similar characterization may be established for finitely monotone properties, and we formulate a particular open problem in this direction.
[Visualization, finitely monotone properties, Circuit simulation, Lattices, definability, game theory, Mathematics, formal logic, Interpolation, Boolean functions, positive first order formulas, first order logic, games, Explosives, finite models, positive Boolean circuits, Logic, Mathematical model, logic circuits]
Zero-one laws for Gilbert random graphs
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We look at a competitor of the Erdos-Renyi models of random graphs, one proposed by E. Gilbert (1961): given /spl delta/>0 and a metric space X of diameter >/spl delta/, scatter n vertices at random on X and connect those of distance </spl delta/ apart: we get a random graph G/sub n,/spl delta///sup X/. Question: for fixed X, /spl delta/, do we have 0-1 laws for FO logic? We prove that this is true if X is a circle.
[Head, Biological system modeling, Erdos-Renyi models, Biological tissues, graph theory, vertices, Scattering, Extraterrestrial measurements, Mathematics, Graph theory, Chemical processes, zero-one laws, metric space, Logic, Gilbert random graphs]
Large finite structures with few L/sup /spl kappa//-types
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
Far each /spl kappa//spl ges/3, we show that there is no recursive bound for the size of the smallest finite model of an L/sup /spl kappa//-theory in terms of its /spl kappa/-size. Here L/sup /spl kappa// denotes the /spl kappa/-variable fragment of first-order logic. An L/sup /spl kappa//-theory is a maximal consistent set of L/sup /spl kappa//-sentences, and the /spl kappa/-size of an L/sup /spl kappa//-theory is the number of L/sup /spl kappa//-types realized in its models. Our result answers a question of Dawar (1993). As a corollary, we obtain that for /spl kappa//spl ges/3 the so-called L/sup /spl kappa//-invariants, which characterize structures up to equivalence in L/sup /spl kappa//, cannot be recursively inverted.
[Vocabulary, equivalence, finite structures, L/sup /spl kappa//-types, Encoding, type theory, formal logic, Tree graphs, Polynomials, finite model, Logic, recursive bound, Context modeling]
Full abstraction for first-order objects with recursive types and subtyping
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
We present a new interpretation of typed object-oriented concepts in terms of well-understood, purely procedural concepts, that preserves observational equivalence. More precisely, we give compositional translations of (a) Ob/sub 1/spl mu//, an object calculus supporting method invocation and functional method update with first-order object types and recursive types, and (b) Ob/sub 1<:/spl mu//, an extension of Ob/sub 1/spl mu// with subtyping, that are fully abstract on closed terms. The target of the translations are a first-order /spl lambda/-calculus with records and recursive types, with and without subtyping. The translation of the calculus with subtyping is subtype-preserving as well.
[Computer languages, lambda calculus, typed, Flexible printed circuits, recursive types, object calculus, observational equivalence, Calculus, Encoding, object-oriented, lambda-calculus, subtyping]
Entailment of atomic set constraints is PSPACE-complete
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
The complexity of set constraints has been extensively studied over the last years and was often found quite high. At the lower end of expressiveness, there are atomic set constraints which are conjunctions of inclusions t/sub 1//spl sube/t/sub 2/ between first-order terms without set operators. It is well-known that satisfiability of atomic set constraints can be tested in cubic time. Also, entailment of atomic set constraints has been claimed decidable in polynomial time. We refute this claim. We show that entailment between atomic set constraints can express validity of quantified boolean formulas and is this PSPACE hard. For infinite signatures, we also present a PSPACE-algorithm for solving atomic set constraints with negation. This proves that entailment of atomic set constraints is PSPACE-complete for infinite signatures. In case of finite signatures, this problem is even DEXPTIME-hard.
[complexity, decidable, DEXPTIME-hard, Logic programming, quantified boolean formulas, computability, PSPACE-complete, PSPACE-algorithm, Boolean functions, decidability, satisfiability, Automata, Polynomials, polynomial time, atomic set constraints entailment, inclusions, Testing, computational complexity, PSPACE hard]
From the church-turing thesis to the first-order algorithm theorem
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
false
[Computer science, Concurrent computing, Parallel processing, Logic]
A dichotomy in the complexity of propositional circumscription
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
The inference problem for propositional circumscription is known to be highly intractable and, in fact, harder than the inference problem for classical propositional logic. More precisely, in its full generality this problem in /spl Pi//sub 2//sup P/-complete, which means that it has the same inherent computational complexity as the satisfiability problem for quantified Boolean formulas with two alternations (universal-existential) of quantifiers. We use T.J. Schaefer's (1978) framework of generalized satisfiability problems to study the family of all restricted cases of the inference problem for propositional circumscription. Our main result fields a complete classification of the "truly hard"(/spl Pi//sub 2//sup P/-complete) and the "easier" cases of this problem (reducible to the inference problem for classical propositional logic). Specifically, we establish a dichotomy theorem which asserts that each such restricted case is either /spl Pi//sub 2//sup P/-complete or is in co-NP. Moreover, we provide efficiently checkable criteria that tell apart the "truly hard" cases from the "easier" ones.
[quantified Boolean formulas, universal-existential quantifier alternations, propositional logic, inference, dichotomy theorem, intractable problem, computability, /spl Pi//sub 2//sup P/-complete problem, Reflection, generalized satisfiability problems, nonmonotonic reasoning, Computer science, co-NP-hard problems, efficiently checkable criteria, Prototypes, restricted problem cases, Polynomials, Logic, Informatics, propositional circumscription, computational complexity]
Temporal logic with forgettable past
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We investigate NLTL, a linear-time temporal logic with forgettable past. NLTL can be exponentially more succinct than LTL+Past (which in turn can be more succinct than LTL). We study satisfiability and model checking for NLTL and provide optimal automata-theoretic algorithms for these EXPSPACE-complete problems.
[automata theory, Automatic logic units, optimal automata-theoretic algorithms, temporal logic, computability, Computer science, NLTL, model checking, satisfiability, EXPSPACE-complete problems, Polynomials, linear-time temporal logic, computational complexity, forgettable past]
Abstract saturation-based inference
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Solving goals - like deciding word problems or resolving constraints - is much easier in some theory presentations than in others. What have been called "completion processes\
[proof ordering, abstract saturation-based inference, completion process, abstract definition, Transforms, saturation process, reduced system, Algebra, goal solving, nonformal proof, Constraint theory, canonical system, theorem proving, Logic, equational logic, general characterization, general setting, proof-theoretic setting, process modelling, proof system, redundancy criteria, problem solving, inference mechanisms, Equations, Computer science, Geometry, saturated system, deductive theory, Arithmetic]
A categorical semantics of quantum protocols
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Particular focus in this paper is on quantum information protocols, which exploit quantum-mechanical effects in an essential way. The particular examples we shall use to illustrate our approach will be teleportation (Benett et al., 1993), logic-gate teleportation (Gottesman and Chuang,1999), and entanglement swapping (Zukowski et al., 1993). The ideas illustrated in these protocols form the basis for novel and potentially very important applications to secure and fault-tolerant communication and computation (2001,1999,2000).
[Performance evaluation, Protocols, Force measurement, quantum information protocols, Quantum entanglement, Laboratories, categorical semantics, quantum gates, Teleportation, quantum entanglement, teleportation, fault tolerant computation, fault tolerant communication, Quantum computing, Measurement standards, Quantum mechanics, logic-gate teleportation, Communication channels, entanglement swapping, fault tolerant computing, protocols, quantum communication, quantum-mechanical effects]
On locality and uniform reduction
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Uniform reduction for pairs originates from abstract logic but it has not been studied much in the context of finite model theory. The paper demonstrates its relationship to locality. The first part of the paper is motivated by the question when first-order logic extended with quantifiers is Hanf-local. Two properties, tolerant Hanf-locality and separable Hanf-locality are defined, both of which ensure this if all quantifiers in question have the property. It is shown that all regular Hanf-local logics not tolerantly Hanf-local have weak version of uniform reduction for pairs. In the rest of the paper, relationship between different forms of locality, regularity and uniform reduction is studied in the class of finite directed trees.
[separable Hanf-locality, trees (mathematics), finite directed trees, Educational institutions, Mathematics, abstract logic, Complexity theory, Power system modeling, Statistics, Database languages, Computer science, formal logic, uniform reduction, finite model theory, Logic, Mathematical model, tolerant Hanf-locality, Context modeling]
A Congruence Rule Format for Name-Passing Process Calculi from Mathematical Structural Operational Semantics
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We introduce a mathematical structural operational semantics that yields a congruence result for bisimilarity and is suitable for investigating rule formats for name-passing systems. Indeed, we instantiate this general abstract model theory in a framework of nominal sets and extract from it a GSOS-like rule format for name-passing process calculi for which the associated notion of behavioural equivalence - given by a form of open bisimilarity - is a congruence
[nominal sets, Laboratories, Merging, GSOS-like rule format, Calculus, abstract model theory, set theory, Equations, mathematical structural operational semantics, Computer science, congruence rule format, Veins, process algebra, name-passing process calculi, category theory, behavioural equivalence, open bisimilarity, bisimulation equivalence, Logic, Power generation]
The Cost of Punctuality
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
In an influential paper titled "The benefits of relaxing punctuality" [2], Alur, Feder, and Henzinger introduced Metric Interval Temporal Logic (MITL) as a fragment of the real-time logic metric temporal logic (MTL) in which exact or punctual timing constraints are banned. Their main result showed that model checking and satisfiability for MITL are both EXPSPACE-Complete. Until recently, it was widely believed that admitting even the simplest punctual specifications in any linear-time temporal logic would automatically lead to undecidability. Although this was recently disproved, until now no punctual fragment of MTL was known to have even primitive recursive complexity (with certain decidable fragments having provably non-primitive recursive complexity). In this paper we identify a "co-flat' subset of MTL that is capable of expressing a large class of punctual specifications and for which model checking (although not satisfiability) has no complexity cost over MITL. Our logic is moreover qualitatively different from MITL in that it can express properties that are not timed-regular. Correspondingly, our decision procedures do not involve translating formulas into finite-state automata, but rather into certain kinds of reversal-bounded Turing machines. Using this translation we show that the model checking problem for our logic is EXPSPACE-Complete.
[Real time systems, punctual timing constraints, Costs, timing, Automatic logic units, punctuality cost, finite-state automata, computability, temporal logic, finite state machines, Computer science, real-time logic metric temporal logic, Turing machines, formal verification, model checking, satisfiability, Automata, punctual specifications, Timing, Time factors, linear-time temporal logic]
A Logic for Algebraic Effects
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We present a logic for algebraic effects, based on the algebraic representation of computational effects by operations and equations. We begin with the a-calculus, a minimal calculus which separates values, effects, and computations and thereby canonises the order of evaluation. This is extended to obtain the logic, which is a classical first-order multi-sorted logic with higher-order value and computation types, as in Levy's call-by-push-value, a principle of induction over computations, a free algebra principle, and predicate fixed points. This logic embraces Moggi's computational lambda-calculus, and also, via definable modalities, Hennessy-Milner logic, and evaluation logic, though Hoare logic presents difficulties.
[Laboratories, Calculus, algebra, algebraic operations, definable modalities, Concurrent computing, computational lambda-calculus, Algebra, minimal calculus, a-calculus, Logic functions, Informatics, lambda calculus, Logic programming, algebraic representation, Equations, Computer science, Computer languages, computational effects, first-order multi-sorted logic, call-by-push-value, evaluation logic, Hennessy-Milner logic, program logics, Hoare logic]
Applications of Game Semantics: From Program Analysis to Hardware Synthesis
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
After informally reviewing the main concepts from game semantics and placing the development of the field in a historical context we examine its main applications. We focus in particular on finite state model checking, higher order model checking and more recent developments in hardware design.
[Terminology, Law, finite state model checking, program verification, program diagnostics, higher order model checking, game theory, Application software, finite state machines, programming language semantics, game semantics, formal specification, Computer science, Computer languages, Processor scheduling, program analysis, hardware design, Hardware, hardware compilation, Logic, Legal factors, hardware synthesis, Context modeling]
An Intuitionistic Logic that Proves Markov's Principle
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We design an intuitionistic predicate logic that supports a limited amount of classical reasoning, just enough to prove a variant of Markov's principle suited for predicate logic. At the computational level, the extraction of an existential witness out of a proof of its double negation is done by using a form of statically-bound exception mechanism, what can be seen as a direct-style variant of Friedman's A-translation.
[Context, proof-as-program correspondence, Friedman A-translation, Inspection, intuitionistic logic, intuitionistic predicate logic, Calculus, Cognition, Grammar, Markov's principle, exceptions, Construction industry, formal logic, Markov processes, Markov principle, statically-bound exception mechanism]
Temporal Specifications with Accumulative Values
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
There is recently a significant effort to add quantitative objectives to formal verification and synthesis. We introduce and investigate the extension of temporal logics with quantitative atomic assertions, aiming for a general and flexible framework for quantitative-oriented specifications. In the heart of quantitative objectives lies the accumulation of values along a computation. It is either the accumulated summation, as with the energy objectives, or the accumulated average, as with the mean-payoff objectives. We investigate the extension of temporal logics with the prefix-accumulation assertions Sum(&#x03BD;) &#x2265; c and Avg(&#x03BD;) &#x2265; c, where v is a numeric variable of the system, c is a constant rational number, and Sum(&#x03BD;) and Avg(&#x03BD;) denote the accumulated sum and average of the values of &#x03BD; from the beginning of the computation up to the current point of time. We also allow the path-accumulation assertions LimlnfAvg(&#x03BD;) &#x2265; c and LimSupAvg(&#x03BD;) &#x2265; c, referring to the average value along an entire computation. We study the border of decidability for extensions of various temporal logics. In particular, we show that extending the fragment of CTL that has only the EX, EF, AX, and AG temporal modalities by prefix-accumulation assertions and extending LTL with path-accumulation assertions, result in temporal logics whose model-checking problem is decidable. The extended logics allow to significantly extend the currently known energy and mean-payoff objectives. Moreover, the prefix-accumulation assertions may be refined with "controlled-accumulation\
[rational number, temporal logics, formal specification, accumulative values, mean payoff objectives, quantitative verification, formal logic, formal verification, quantitative atomic assertions, Semantics, numeric variable, Numerical models, Labeling, formal synthesis, energy objectives, path-accumulation assertions, Computational modeling, Temporal logic, quantitative oriented specifications, prefix accumulation assertions, Automata, Syntactics, model checking problem, temporal specifications, accumulated summation, Periodic structures]
Lower Bounds for Existential Pebble Games and k-Consistency Tests
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
The existential k-pebble game characterizes the expressive power of the existential-positive k-variable fragment of first-order logic on finite structures. The winner of the existential k-pebble game on two given finite structures can easily be determined in polynomial time, where the degree of the polynomial is linear in k. We show that this linear dependence on the parameter k is necessary by proving an unconditional polynomial lower bound for determining the winner in the existential k-pebble game on finite structures. Establishing strong k-consistency is a well-known heuristic for solving the constraint satisfaction problem (CSP). By the game characterization of Kolaitis and Vardi our result implies a lower bound on every algorithm that decides if strong k-consistency can be established for a given CSP-instance.
[k-consistency tests, finite structures, k-consistency, first-order logic, Color, Switches, game theory, existential-positive k-variable fragment, constraint satisfaction problem, Existential pebble games, Complexity theory, Indexes, lower bounds, Computer science, formal logic, game characterization, constraint satisfaction problems, Games, existential pebble games, Polynomials, polynomial time, computational complexity, polynomial lower bound]
From Qualitative to Quantitative Proofs of Security Properties Using First-Order Conditional Logic
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Security protocols, such as key-exchange and key management protocols, are short, but notoriously difficult to prove correct. Flaws have been found in numerous protocols, ranging from the the 802.11 Wired Equivalent Privacy (WEP) protocol used to protect link-layer communications from eavesdropping and other attacks to standards and proposed standards for Secure Socket Layer to Kerberos. Not surprisingly, a great deal of effort has been devoted to proving the correctness of such protocols. There are two largely disjoint approaches. The first essentially ignores the details of cryptography by assuming perfect cryptography and an adversary that controls the network. The second approach applies the tools of modern cryptography to proving correctness, using more quantitative arguments.
[Protocols, cryptographic protocols, quantitative arguments, link-layer communications, perfect cryptography, Cognition, secure socket layer, security property, eavesdropping, Computer science, formal logic, quantitative proof, security protocols, Kerberos, key management protocol, Semantics, 802.11 wired equivalent privacy protocol, key-exchange protocol, WEP protocol, Polynomials, first-order conditional logic, Cryptography, qualitative proof]
Complexity Bounds for Sum-Product Logic via Additive Proof Nets and Petri Nets
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We investigate efficient algorithms for the additive fragment of linear logic. This logic is an internal language for categories with finite sums and products, and describes concurrent two-player games of finite choice. In the context of session types, typing disciplines for communication along channels, the logic describes the communication of finite choice along a single channel. We give a simple linear time correctness criterion for unit-free propositional additive proof nets via a natural construction on Petri nets. This is an essential ingredient to linear time complexity of the second author's combinatorial proofs for classical logic. For full propositional additive linear logic, including the units, we give a proof search algorithm that is linear-time in the product of the source and target formula, and an algorithm for proof net correctness that is of the same time complexity. We prove that proof search in first-order additive linear logic is NP-complete.
[natural construction, typing discipline, Additives, propositional additive linear logic, proof complexity, Petri nets, linear logic, NP-complete, linear time correctness criterion, formal logic, Semantics, two-player game, complexity bound, linear time complexity, search problems, classical logic, combinatorial proof, first-order additive linear logic, additive proof nets, session type, game theory, proof search algorithm, proof net correctness, sumproduct categories, sum-product logic, Games, Syntactics, unit-free propositional additive proof net, Time complexity, computational complexity, additive linear logic]
Constructive completeness for the linear-time μ-calculus
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We give a new proof of completeness for the linear-time μ-calculus w.r.t. Kozens's axiomatization. Our proof has the advantage of being constructive, i.e., it builds a proof for every valid formula.
[Image coding, Kozens axiomatization, Shape, Semantics, linear-time μ-calculus, Automata, temporal logic, Encoding, Calculus, Complexity theory, calculus, constructive completeness]
0-1 laws and decision problems for fragments of second-order logic
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
Fragments of existential second-order logic are investigated in which the patterns of first order quantifiers are restricted. The focus is on the class Sigma /sub 1//sup 1/ (Ackermann) of existential second-order sentences in which the first-order part belongs to the Ackermann class, i.e. it contains at most one universal first-order quantifier. All properties expressible by Sigma /sub 1//sup 1/ (Ackermann) sentences are NP-computable, and there are natural NP-complete properties, such as satisfiability, that are expressible by such sentences. It is established that the 0-1 law holds for the class Sigma /sub 1//sup 1/ (Ackermann), and it is shown that the associated decision problem is NEXPTIME-complete. It is also shown that the 0-1 law fails for other fragments of existential second-order logic in which first-order part belongs to certain prefix classes with an unsolvable decision problem.<<ETX>>
[Algorithm design and analysis, formal logic, Vocabulary, decision theory, NP-computable, first order quantifiers, second-order logic, fragments, decision problems, Logic, Ackermann class, 0-1 laws]
An algebra and a logic for NC/sup 1/
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
An algebra and a logic characterizing the complexity class NC/sup 1/, which consists of functions computed by uniform sequences of polynomial-size, log depth circuits, are presented. In both characterizations, NC/sup 1/ functions are regarded as functions from one class of finite relational structures to another. In the algebraic characterization, upward and downward tree recursion are applied to a class of simple functions. In the logical characterization, first-order logic is augmented by an operator for defining relations by primitive recursion. It is assumed that every structure has an underlying relation giving the binary representations of integers.<<ETX>>
[polynomial-size, finite relational structures, uniform sequences, NC/sup 1/, complexity class, first-order logic, binary representations, Mathematics, algebra, Complexity theory, integers, formal logic, Algebra, Turing machines, tree recursion, Logic circuits, log depth circuits, Character generation, Abstracts, Logic functions, Polynomials, logic]
Proving unprovability
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
A formal proof system for unprovability in the predicate calculi is developed. This system is shown to be complete with respect to the logic of finite structures. It can be used to extend the 'negation by failure' of Prolog, prevent infinite loops in a deductive data base or Prolog, or prove formulaes in nonmonotonic (default) logic.<<ETX>>
[logic of finite structures, Humans, deductive data base, nonmonotonic logic, Prolog, Calculus, unprovability, Computer science, formal proof system, logic programming, predicate calculi, theorem proving, Logic, Artificial intelligence, Network address translation, Arithmetic]
Partial correctness of C-MOS switching circuits: an exercise in applied logic
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
The possibility of extending some of the logical methods that have been recommended for the design of software to the design of hardware, in particular, of synchronous switching circuits implemented in CMOS, is explored. The objective is to design networks that are known by construction. Things that can go wrong with circuits designed in this way are examined. The application of the techniques is discussed.<<ETX>>
[software, Laboratories, synchronous switching circuits, Mathematics, Digital circuits, Switching circuits, Design engineering, Software design, CMOS switching circuits, switching circuits, Logic circuits, partial correctness, design, circuit CAD, Hardware, Manufacturing, Error correction, CMOS integrated circuits, applied logic]
A modest model of records, inheritance and bounded quantification
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
The authors give a formal semantics for the language Bounded Fun, which supports both parametric and subtype polymorphism. They show how to use partial equivalence relations to model inheritance in this language, which supports the notion of subtype and record types. A generalization of partial equivalence relations, known as omega -sets, is used in combination with modest sets to provide the first known model of Bounded Fun (with explicit polymorphism). Connections with previous work on the semantics of explicit parametric polymorphism is established by noting that the semantics of polymorphic types presented here (using dependent products) is isomorphic to that given by the intersection interpretation of polymorphism.<<ETX>>
[programming theory, Object oriented modeling, OWL, records, modest model, Educational institutions, inheritance, Calculus, International collaboration, polymorphism, bounded quantification, Computer science, Computer languages, formal semantics, Bounded Fun, Education, partial equivalence relations, Software engineering]
A fixed point of the second order lambda-calculus: observable equivalences and models
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
The author develops an operational model of an impredicative version of explicit polymorphism, namely, an extension of the second-order lambda-calculus, including a fixed-point combinator and a multisorted first-order algebra. He shows that the typical properties of the lambda -calculus are preserved, and he investigates novel aspects that arise from second-order type structure as well as the relationships with well-known, simply typed, PCF-like languages. A suitable theory of observably equivalent terms is defined, and its complexity is explored. A denotional model suggesting interesting extensions of a language is studied.<<ETX>>
[Software prototyping, models, programming theory, combinator, observable equivalences, Standardization, Calculus, Topology, programming languages, second order lambda-calculus, Programming profession, Algebra, fixed point, Prototypes, PCF-like languages, Functional programming, Logic, denotional model, Formal verification, explicit polymorphism]
Characterization of typings in polymorphic type discipline
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
Polymorphic type discipline for lambda -calculus is an extension of H.B. Curry's (1969) classical functionality theory, in which types can be universally quantified. An algorithm that, given a term M, builds a set of constraints, is satisfied. Moreover, all the typings for M (if any) are built from the set of constraints by substitutions. Using the set of constraints, some properties of polymorphic type discipline are proved.<<ETX>>
[formal logic, lambda -calculus, typings characterisation, substitutions, polymorphic type discipline, Constraint theory, functionality theory]
On the computational power of universally polymorphic recursion
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
ML/sup +/ is an extension of the functional language ML that allows the actual parameters of recursively called functions to have types that are generic instances of the (derived) types of corresponding formal parameters. It is shown that the polymorphism allowed by the original ML can be eliminated without loss of computational power, specifically, it is shown that its computational power (in all interpretations) is the same as that of finitely typed functional programs. It is proved that the polymorphism of ML/sup +/ cannot be eliminated, in that its computational power far exceeds that of finitely typed functional programs and therefore that of the original ML too.<<ETX>>
[formal logic, programming theory, universally polymorphic recursion, functional language, computational power, finitely typed functional programs, Mathematics, Computer science education, formal parameters, Equations, ML]
Combining algebra and higher-order types
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
The author studies the higher-order rewrite/equational proof systems obtained by adding the simply typed lambda calculus to algebraic rewrite/equational proof systems. He shows that if a many-sorted algebraic rewrite system has the Church-Rosser property, then the corresponding higher-order rewrite system which adds simply typed beta -reduction has the Church-Rossers property too. This result is relevant to parallel implementations of functional programming languages. The author also shows that provability in the higher-order equational proof system obtained by adding the simply typed beta and eta axions to some many-sorted algebraic proof system is effectively reducible to provability in that algebraic proof system. This effective reduction also establishes transformations between higher-order and algebraic equational proofs, which can be useful in automated deduction.<<ETX>>
[lambda calculus, Military computing, Computational modeling, Calculus, algebra, higher-order types, provability, programming languages, functional programming languages, Equations, formal logic, Information science, Algebra, higher-order rewrite, Church-Rosser property, Chromium, Writing, many-sorted algebraic rewrite system, equational proof systems, theorem proving]
Characterizing X-separability and one-side invertibility in lambda - beta - Omega -calculus
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
Given a finite set T identical to (T/sub 1/, . . . ,T/sub t/) of terms of the lambda - beta -K-calculus and a set X/sub T/ identical to (x/sub 1/, . . ., x/sub n/) of free variables (occurring in the elements of T), X/sub T/-separability is the problem of deciding whether there exists a simultaneous substitution for the elements of X/sub T/ transforming T into the set Z identical to (Z/sub 1/, . . . Z/sub t/) of arbitrary terms. The X/sub T/-separability problem is proved to be solvable for any approximation T/sup Hash / of the set T by terms in lambda - beta - Omega -normal form. Since the characterization is constructive, if the terms T/sup , Hash //sub i/ identical to lambda x/sub 1/ . . . x/sub n/. T/sup Hash //sub i/ (i=1, . . ., t) are closed then the sequence T/sup Hash //sub 1/, . . ., T/sup Hash //sub t/ induces a family of mappings (from n to t dimensions) whose surjectivity and right-invertibility becomes decidable. The left-invertibility of this family is proved to be decidable too.<<ETX>>
[Computer science, decidable, mappings, decidability, X-separability, lambda - beta - Omega -calculus, surjectivity, Calculus, Artificial intelligence, one-side invertibility, Equations, right-invertibility]
Efficient parallel algorithms for anti-unification and relative complement
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
Parallel algorithms and computational complexity results are given for two problems; computing the relative complement of terms and antiunification. The concepts of antiunification and relative complement are useful for theorem proving, logic programming, and machine learning. The relative complement problem is shown to be NP-complete.<<ETX>>
[Algorithm design and analysis, parallel algorithms, Logic programming, Computational modeling, Parallel machines, Phase change random access memory, NP-complete, machine learning, Parallel algorithms, Computational complexity, Concurrent computing, terms, relative complement, Machine learning, antiunification, logic programming, Polynomials, theorem proving, computational complexity]
Unification in free extensions of Boolean rings and Abelian groups
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
A complete unification algorithm is presented for the combination of two arbitrary equational theories E in T(F,X) and E/sup 1/ in T(F',X), where F and F' denote two disjoint sets of function symbols. The method adapts to unification of infinite trees. It is applied to two well-known open problems, when E is the theory of Boolean rings or the theory of Abelian groups, and E is the free theory. The interest to Boolean rings originates in VSLI verification.<<ETX>>
[Logic programming, infinite trees, Transforms, Very large scale integration, arbitrary equational theories, unification, Equations, Boolean rings, Computer science, Boolean functions, Algebra, Abelian groups, free extensions, Artificial intelligence]
Corrigendum: complete type interference for simple objects
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
An error has been pointed out in the author's paper (see Proc. 2nd IEEE Symp. on Logic in Computer Science, p.37-44 (1987)). It appears that there are programs without principal type schemes in the system in that paper.<<ETX>>
[Computer science, programming theory, simple objects, Difference equations, Computer bugs, Computer errors, Reasoning about programs, Educational institutions, complete type interference, Logic]
On the consistency of 'truly concurrent' operational and denotational semantics
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
The problem of the relationship between truly concurrent operational and denotational semantics is tackled by mapping syntactic terms on similar semantic domains in both approaches. Occurrence nets are associated to terms through structural operational semantics based on a set of rewriting rules; event structures are defined as denotations for terms, without resorting to categorical constructions. The proof of the equivalence of the two semantics relies on the direct correspondence between occurrence nets and event structures. R. Milner's (1980) calculus of communicating systems is used as a test case; truly concurrent denotional and operational semantics are given for it and proved consistent. This equivalence is established for the first time in true concurrency approach. It is proved that G. Winskel's (1982) categorical denotational semantics is equivalent to that given here.<<ETX>>
[Petri nets, truly concurrent operational semantics, Discrete event simulation, History, Guidelines, occurrence nets, Concurrent computing, formal logic, direct correspondence, calculus of communicating systems, Interleaved codes, theorem proving, rewriting rules, Carbon capture and storage, Mathematical model, event structures, Contracts, denotational semantics, Testing]
A category of labelled Petri nets and compositional proof system
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
An attempt is made to cast labeled Petri nets and other models in an algebraic framework. One aim is to utilize the framework of categorical l to cast labeled Petri nets and other models in an algebraic framework. The other aim is to utilize the framework of categorical logic to systematize specification languages and the derivation of proof systems for parallel processes. A category of labeled nets is presented, and its categorical constructions are used to establish a compositional proof system. A category of properties of nets is used in forming the proof system.<<ETX>>
[Petri nets, Laboratories, labelled Petri nets, compositional proof system, Specification languages, Guidelines, Concurrent computing, Computer science, formal logic, algebraic framework, directed graphs, Parallel processing, parallel processes, Logic, Labeling, Carbon capture and storage, category]
Petri nets are monoids: a new algebraic foundation for net theory
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
The composition and extraction mechanisms of Petri nets are at present inadequate. This problem is solved by viewing place/transition Petri nets as ordinary, directed graphs equipped with two algebraic operations corresponding to parallel and sequential composition of transitions. A distributive law between the two operations captures a basic fact about concurrency. Novel morphisms are defined, mapping single, atomic transitions into whole computations, thus relating system descriptions at different levels of abstraction. Categories equipped with products and coproducts (corresponding to parallel and nondeterministic compositions) are introduced for Petri nets with and without initial markings. It is briefly indicated how the approach yields function spaces and novel interpretations of duality and invariants. The results provide a formal basis for expressing the semantics of concurrent languages in terms of Petri nets and an understanding of concurrency in terms of algebraic structures over graphs and categories that should apply to other models and contribute to the conceptual unification of concurrency.<<ETX>>
[mapping, Petri nets, monoids, morphisms, duality, distributive law, algebraic foundation, Concurrent computing, Computer science, formal logic, extraction mechanism, net theory, directed graphs, Fires, composition mechanism, Contracts, invariants]
The existence of refinement mappings
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
Refinement mappings are used to prove that a lower-level specification correctly implements a higher-level one. The authors consider specifications consisting of a state machine (which may be infinite-state) that specifies safety requirements and an arbitrary supplementary property that specifies liveness requirements. A refinement mapping from a lower-level specification S/sub 1/ to higher-level one S/sub 2/ is a mapping from S/sub 1/'s state space to S/sub 2/'s state space that maps steps of S/sub 1/'s state machine steps to steps of S/sub 2/'s state machine and maps behaviors allowed by S/sub 1/ to behaviors allowed by S/sub 2/. It is shown that under reasonable assumptions about the specifications, if S/sub 1/ implements S/sub 2/, then by adding auxiliary variables to S/sub 1/ one can guarantee the existence of a refinement mapping. This provides a completeness result for a practical hierarchical specification method.<<ETX>>
[lower-level specification, safety requirements, liveness requirements, refinement mappings, automata theory, hierarchical specification method, Circuits, Writing, existence, state machine, Safety, State-space methods]
Relevance logic and concurrent composition
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
The operation of relativizing properties with respect to parallel environments often used in obtaining compositionality in theories for concurrency corresponds to a notion of (contraction-free) relevant deduction. The author considers program logics in which this notion of deduction is internalized by the corresponding implication. The idea is carried through for safety properties of a simple system of SCCS-type synchronous processes with an internal choice operator. They present two completeness results: first for a modal extension of positive propositional linear logic with respect to the equational class of algebras containing the safety testing quotient of the author's process system as its free member, and second for the free algebra itself.<<ETX>>
[System testing, positive propositional linear logic, parallel environments, equational class, Proposals, concurrent composition, Logic testing, Equations, SCCS-type synchronous processes, Computer science, Concurrent computing, formal logic, Algebra, relevance logic, relativizing properties, modal extension, logic programming, Logic functions, Safety, safety properties, program logics]
Bisimulations and divergence
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
Behavioral preorders based on the idea of bisimulation equivalence and providing explicit treatments of the phenomenon of divergence in communicating systems are investigated. Particular study is made of those preorders in the context of R. Milner's (1980) calculus of communicating systems. The precongruence relations generated by the preorders are characterized and axiomated on the classes of finite closed terms and sequential terms. A compositional verification technique based on the theory of the preorders is introduced and illustrated.<<ETX>>
[Context, Gold, compositional verification technique, Calculus, finite closed terms, calculus, Convergence, Computer science, formal logic, divergence, sequential terms, Character generation, Concrete, bisimulation equivalence, communicating systems, Artificial intelligence]
Priorities in process algebras
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
An operational semantics for an algebraic theory of concurrency is developed that incorporates a notion of priority into the definition of the execution of actions. An equivalence based on strong observational equivalences is defined and shown to be a congruence, and a complete axiomization is given for finite terms. Several examples highlight the novelty and usefulness of the approaches.<<ETX>>
[Protocols, programming theory, equivalence, operational semantics, algebra, priority, Counting circuits, concurrency, Computer science, Computer languages, process algebras, Algebra, finite terms, Hardware, algebraic theory, Carbon capture and storage]
A modal process logic
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
A novel logic is introduced for the introduction of nondeterministic and concurrent processes expressed in a process algebra. For a process algebra to be useful as a process language, it must possess compositionality, i.e. it should be possible to decompose the problem of correctness for a combined system with respect to a given specification of similar and simpler correctness problems for the components of the system. The logic presented allows such specifications to be expressed. It is an extension of process algebra in the sense that process constructs are included as connectives in the logic. Moreover, the formulas of the logic are given an operational interpretation based on which a refinement ordering between formulas is defined.<<ETX>>
[Process design, correctness, Educational institutions, Mathematics, Specification languages, Computer science, Concurrent computing, formal logic, Algebra, modal process logic, nondeterministic processes, Logic functions, compositionality, concurrent processes, operational interpretation, Carbon capture and storage]
On the arithmetic inexpressiveness of term rewriting systems
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
Unquantified Presburger arithmetic is proved to be nonaxiomatizable by a canonical (i.e. Noetherian and confluent) term-rewriting system, if Boolean connectives are not allowed in the left-hand sides of the rewrite rules. It is conjectured that the same is true if the number of Boolean connectives in left-hand sides of the rules is uniformly bounded by an arbitrary natural number.<<ETX>>
[Boolean functions, unquantified Presburger arithmetic, Computer applications, Differential equations, arithmetic inexpressiveness, theorem proving, Boolean connectives, Arithmetic, term rewriting systems]
Rigid E-unification is NP-complete
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
Rigid E-unification is a restricted kind of unification modulo equational theories, or E-unification, that arises naturally in extending P. Andrews' (1981) theorem-proving method of mating to first-order languages with equality. It is shown that rigid E-unification is NP-complete and that finite complete sets of rigid E-unifiers always exist. As a consequence, deciding whether a family of mated sets is an equational mating is an NP-complete problem. Some implications of this result regarding the complexity of theorem proving in first-order logic with equality are discussed.<<ETX>>
[unification modulo equational theories, first-order languages, complexity of theorem proving, first-order logic, theorem-proving method, NP-complete, Computational Intelligence Society, NP-complete problem, rigid E-unification, Equations, formal logic, Polynomials, theorem proving, Logic, mated sets]
Proof by consistency in equational theories
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
A method is proven for proving that equations are valid in the initial model of an equational variety. This proof by consistency procedure can be applied to equational theories that are represented as ground convergent rewrite systems. In contrast with so-called inductive completion procedures, the method requires no specific ordering on terms and can handle unorientable equations. The method is linear and refutationally complete, in that it refutes any equation which is not an inductive theorem.<<ETX>>
[Computer science, Computer languages, Algebra, Terminology, equational theories, Logic functions, proof by consistency, theorem proving, ground convergent rewrite systems, Equations]
Semantical paradigms: notes for an invited lecture
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
To help understand the reason for continuity in denotational semantics, the author offers some global comments on goodness-to-fit criteria between semantic domains and symbolic evaluators. The appendices provide the key parts of a proof that Scott domains give a computationally adequate and fully abstract semantics for lambda calculus with simple recursive types.<<ETX>>
[Insulation, Scott domains, Natural languages, continuity, Calculus, programming languages, Information systems, Computer science, formal logic, Computer languages, adequacy theorem, semantic domains, Program processors, Weapons, computationally adequate semantics, goodness-to-fit criteria, Robustness, data structures, Logic, symbolic evaluators, denotational semantics, lambda calculus with simple recursive types]
Categories of embeddings
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
A categorical generalization of the notion of domains, which is stable by (suitable) exponentiation is presented. The goal was originally to generalize J.Y. Girard's (1986) model of polymorphism to F omega . If this notion is specialized to the poset case, a novel Cartesian closed category of domains is obtained.<<ETX>>
[Computer science, formal logic, set theory, embeddings categories, Cartesian closed category of domains, Application software, poset]
A categorical semantics of constructions
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
An abstract framework is proposed for the description of the type dependency semantics. It is claimed that the notion of fibration introduced by A. Grothendieck in the 1960s is perfectly adapted to this goal and provides the greatest simplicity and generality. This semantics is extended to higher order, and an explanation is given of what a general definition for the semantics of the theory of constructions could be.<<ETX>>
[formal logic, type dependency semantics, categorical semantics, constructions, fibration, Logic]
Semantic parametricity in polymorphic lambda calculus
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
A semantic condition necessary for the parametricity of polymorphic functions is considered. One of its instances is the stability condition for elements of variable type in the coherent domains semantics. A larger setting is presented that does not use retract pairs and keeps intact a basic feature of a certain function-type constructor. Polymorphic lambda terms are semantically parametric because of normalization.<<ETX>>
[Stability, Logic programming, polymorphic functions, Formal languages, parametricity, polymorphic lambda calculus, Calculus, Equations, function-type constructor, formal logic, stability condition, semantically parametric, data structures, typed programming languages, coherent domains semantics, variable type, Context modeling]
Can LCF be topped? Flat lattice models of typed lambda calculus
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
G. Plotkin (1977) examined the denotational semantics of LCF (essentially typed lambda calculus with arithmetic and looping). He showed that the standard Scott semantics is computationally adequate but not fully abstract; with the addition of some parallel facilities, it becomes fully abstract, and with the addition of an extential operator, denotationally universal. This treatment is extended to Scott models built from flat lattices rather than flat cpo's. It is found that no extension of LCF can be denotationally universal. A fully abstract extension based on Godel numbering and synthetic analysis is the best that can be achieved. Operators defined by LCF-style rules cannot give fully abstract language. It is shown that Plotkin's program can be carried out for a nonconfluent evaluator.<<ETX>>
[flat lattices, confluence, Laboratories, Lattices, full abstraction, nonconfluent evaluator, Calculus, flat cpo, programming languages, LCF, Computer science, Concurrent computing, formal logic, Computer languages, typed lambda calculus, Godel numbering, Digital arithmetic, standard Scott semantics, operational extensionality, denotational semantics, Fixed-point arithmetic, synthetic analysis]
The topology of program termination
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
Denotational semantics is founded on a theory of higher order computation called domain theory, which formalizes a computation as a potentially infinite enumeration of finite elements that approximate the answer with progressively higher accuracy. Although existing formulations of domain theory provide an elegant framework for defining the abstract meaning of programs, these definitions are not effective because they fail to specify when computations terminate. A formulation of domain theory is presented that gives a natural topological characterization of termination: the evaluation of a program expression should terminate if and only if the expression denotes an element that is finite and maximal.<<ETX>>
[Embedded computing, programming theory, Encoding, Calculus, Topology, Finite element methods, Machinery, higher order computation, Equations, Computer languages, program termination, Turing machines, computation theory, domain theory]
Coherence and consistency in domains
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
Almost all of the categories normally used as a mathematical foundation for denotational semantics satisfy a condition known as consistent completeness. The authors explore the possibility of using different condition coherence, which has its origin in topology and logic. In particular, they concentrate on posets with principal ideas that are algebraic lattices and with coherent topologies. These form a Cartesian closed category which has fixed points for domain equations. It is shown that a universal domain exists. A categorical treatment of the construction of this domain is provided, and its relationship to other applications discussed.<<ETX>>
[posets, Cartesian closed category, programming theory, Military computing, coherent topologies, Lattices, topology, Topology, set theory, condition coherence, Equations, Computer languages, domain equations, consistent completeness, Writing, logic, Logic, denotational semantics, algebraic lattices]
Fully abstract denotational semantics for flat Concurrent Prolog
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
A denotational, hence, compositional semantics for a subset of Concurrent Prolog is developed and related to an operational semantics. The denotational semantics makes divergence and the resultant substitutions of finite computations together with the termination mode-success, failure, or deadlock-observable. Relative to this notion of observation it is proved that the denotational semantics is fully abstract in the sense that it records the minimal amount of extra information beyond the observables to make it compositional. Full abstraction is an important property because it quantifies the information that one needs in order to reason about individual program-parts independently. This is believed to be the first such result in the area of concurrent logic programming.<<ETX>>
[flat Concurrent Prolog, programming theory, Logic programming, Natural languages, operational semantics, concurrent logic programming, Debugging, Mathematics, parallel programming, Computer science, Concurrent computing, Computer languages, Embedded system, termination mode, System recovery, logic programming, compositional semantics, PROLOG, denotational semantics]
Proving termination properties of Prolog programs: a semantic approach
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
A method for proving termination properties of Prolog programs including program with cuts. Programs are viewed as functions mapping goals into finite or infinite sequences of answer substitutions. Associated with each program is a system of functional equations, the least fixed point of which is the meaning of the program. Various termination or nontermination properties as well as partial correctness statements can then be proved by reasoning with the program equations and using fixpoint or structural induction. The method is amenable to automatic implementation.<<ETX>>
[answer sequences, Logic programming, program verification, Lattices, Automatic logic units, structural induction, program with cuts, Equations, Computer science, answer substitutions, functional equations, Prolog programs, partial correctness statements, logic programming, program equations, PROLOG, termination properties, Contracts]
Complete axiomatizations of the algebras of finite, rational and infinite trees
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
Complete axiomizations for the algebras of infinite trees and infinite trees are presented. The axiomizations are parameterized by the alphabet of function symbols for both the finite trees and infinite trees. There are two main cases, depending on whether the number of function symbols is finite or infinite. In the former case an extra axiom is necessary to obtain completeness. The method of proof is an elimination of quantifiers. Although a full elimination of quantifiers is not possible, the method forms the basis of decision procedures for the theories of the corresponding algebras. As a corollary to the results in infinite trees, the elementary equivalence of the algebra of rational trees and the algebra of infinite trees is obtained.<<ETX>>
[equivalence, Logic programming, trees (mathematics), Data structures, Equations, algebra of infinite trees, formal logic, algebra of rational trees, Algebra, alphabet of function symbols, logic programming, Logic functions, Functional programming, equivalence classes]
Computational foundations of basic recursive function theory
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
The theory of computability often called basic recursive function theory is usually motivated and developed using Church's thesis. It is shown that there is an alternative computability theory in which some of the basic results on unsolvability become more absolute. Results on completeness become simpler, and many of the central concepts become more abstract. In this approach computations are viewed as mathematical objects, and the major theorems in recursion theory may be classified according to which axioms about computation are needed to prove them. The theory is a typed theory of functions over the natural numbers, and there are unsolvable problems in this setting independent of the existence of indexings. The unsolvability results are interpreted to show that the partial function concept serves to distinguish between classical and constructive type theories.<<ETX>>
[partial function, Computational modeling, computability, recursive function theory, Mathematics, recursive functions, completeness, unsolvability, Computer science, Computation theory, recursion theory, typed theory of functions, constructive type theories, Indexing, Context modeling]
Notational definition-a formal account
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
In the course of developing a mathematical theory or proof it is a common practice to introduce new notation to represent notation that is previously understood. The author presents a formal account that is intended to model the practice of introducing and using notational (abbreviate) definitions. The aim of this work is a pragmatic one: to provide a framework useful in the design and implementation of secure proof system interfaces which accommodate, as much as possible, conventional mathematical practice. A typed lambda -calculus is used to represent expressions of a given object language. A Delta -equation is introduced to model conventional definition equations.<<ETX>>
[object language, Delta -equation, abbreviate definitions, mathematical theory, Calculus, Mathematics, definition equations, Equations, formal logic, notational definitions, secure proof system interfaces, new notation, proof, typed lambda -calculus, Logic, Nupol system]
The strength of the subset type in Martin-Lof's type theory
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
The authors show that the exact formulation of the rules of type theory is important for rules of subset type. It turns out that there are propositions involving subsets that are trivially true in naive set theory, but which cannot be proved in type theory. They examine the probability of a type proposition that is important when modularizing program derivations.<<ETX>>
[Computer science, formal logic, Set theory, Mathematics, type theory, set theory, naive set theory, type proposition, subset type]
The notion of a framework and a framework for LTC
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
A precise notion of a formal framework, meant to capture the intuition of an open-ended range of deductive interpreted languages, is proposed. A particular framework called the logical theory of constructions (LTC) is developed as an example. A series of languages in the LTC framework is defined, demonstrating how a language can be thought of as gradually evolving.<<ETX>>
[Computer science, formal logic, deductive interpreted languages, formal languages, logical theory of constructions, Formal languages, Mathematics, Application software, Software engineering]
Fixed points vs. infinite generation
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
The author characterizes Rabin definability (see M.O. Rabin, 1969) of properties of infinite trees of fixed-point definitions based on the basic operations of a standard powerset algebra of trees and involving the least and greatest fixed-point operators as well as the finite union operator and functional composition. A strict connection is established between a hierarchy resulting from alternating the least and greatest fixed-point operators and the hierarchy induced by Rabin indices of automata. The characterization result is actually proved on a more general level, namely, for arbitrary powerset algebra, where the concept of Rabin automaton is replaced by the more general concept of infinite grammar.<<ETX>>
[infinite grammar, standard powerset algebra of trees, finite union operator, functional composition, infinite trees, Rabin automaton, automata theory, fixed-point operators, trees (mathematics), Rabin definability, Mathematics, Logic testing, Equations, Upper bound, Algebra, Automatic testing, grammars, Rabin indices of automata, Automata, Character generation, Power generation, Context modeling, fixed-point definitions]
A logic for reasoning about probabilities
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
A language for reasoning about probability is considered that allows statements such as 'the probability of E/sub 1/ is less than 1/3' and 'the probability of E/sub 1/ is at least twice the probability of E/sub 2/', where E/sub 1/ and E/sub 2/ are arbitrary events. The case is treated in which all events are measurable (i.e. represent measurable sets), as well as the more general case, which is also of interest in practice, where they may not be measurable. The measurable case is essentially a formalization of (the propositional fragment of) N. Nilson's (1986) probabilistic logic, while the general (nonmeasurable) case corresponds precisely to replacing probability functions by Dempster-Shafer belief functions. In both cases, an elegant complete axiomization is provided, and it is shown that the problem of deciding satisfiability is NP-complete.<<ETX>>
[Logic programming, probabilistic logic, probability, Probabilistic logic, Linear programming, NP-complete, probability functions, Information analysis, Computer science, complete axiomization, satisfiability, Dempster-Shafer belief functions, Artificial intelligence, Expert systems]
Weak alternating automata give a simple explanation of why most temporal and dynamic logics are decidable in exponential time
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
The authors give a very simple uniform explanation of the persistence of exponential decidability. They follow M. Vardi and P. Wolper's theory (1986) that given a formula gamma of a temporal or dynamic logic, it is important to construct an equivalent automation M/sub gamma /. They characterize the weak monadic theory of the tree; it turns out that weak alternating automata greatly simplify design procedures.<<ETX>>
[automata theory, temporal logic, equivalent automation, tree, exponential decidability, Business continuity, dynamic logics, Computer science, formal logic, decidability, Automata, Polynomials, dynamic logic, Logic, weak monadic theory, weak alternating automata]
On the existence of effective Hoare logics
[1988] Proceedings. Third Annual Symposium on Logic in Computer Science
None
1988
Every proof system for (partial) correctness yields an enumeration procedure for correctness assertions. Other researchers have proved results on the existence of (sound and complete) enumeration procedures for assertions about programs from an acceptable programming language where the assertion language is first-order logic. It is shown that some of the assumptions are stronger than necessary, whereas others must not be weakened. Two novel procedures are given that work for more interpretations with a smaller oracle than those known up to now.<<ETX>>
[formal logic, Computer languages, program verification, assertion language, correctness assertions, Natural languages, first-order logic, Concrete, Hoare logics, Logic, Informatics]
The mathematics of nonmonotonic reasoning
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
Summary form only given. Research on applications of logic to artificial intelligence has led to the invention of a few useful consequence relations that are not monotonic. They are needed for default reasoning formalization, reasoning about action, introspective reasoning, and negation by failure. The author defines nonmonotonic consequence relations and discusses their importance.<<ETX>>
[formal logic, negation by failure, mathematics, default reasoning formalization, reasoning about action, introspective reasoning, Mathematics, logic, Logic, artificial intelligence, nonmonotonic reasoning, consequence relations]
Computational consequences and partial solutions of a generalized unification problem
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A generalization of first-order unification, called semiunification, is studied with two goals in mind: (1) type-checking functional programs relative to an improved polymorphic type discipline; and (2) deciding the typability of terms in a restricted form of the polymorphic lambda -calculus.<<ETX>>
[partial solutions, computational consequences, Mathematics, typability, Equations, Computer science, formal logic, terms, generalized unification problem, semiunification, Writing, first-order unification, type-checking functional programs, restricted form, Functional programming, Logic, polymorphic lambda -calculus, improved polymorphic type discipline]
Type inference for record concatenation and multiple inheritance
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The author shows that the type inference problem for a lambda calculus with records, including a record concatenation operator, is decidable. He shows that this calculus does not have principal types but does have finite complete sets of type, that is, for any term M in the calculus, there exists an effectively generable finite set of type schemes such that every typing for M is an instance of one of the schemes in the set. The author shows how a simple model of object-oriented programming, including hidden instance variables and multiple inheritance, may be coded in this calculus. The author concludes that type inference is decidable for object-oriented programs, even with multiple inheritance and classes as first-class values.<<ETX>>
[lambda calculus, decidable, formal languages, multiple inheritance, object-oriented programming, Object oriented modeling, effectively generable finite set, classes, type inference problem, Educational institutions, Calculus, record concatenation operator, first-class values, type schemes, inference mechanisms, finite complete sets, Computer science, formal logic, typing, object-oriented programs, data structures, Safety, hidden instance variables]
Emil Post's contributions to computer science
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The work of mathematical logician Emil Post is surveyed from the viewpoint of its relevance to computer science. Computational logic and production systems are first discussed. This is followed by an examination of Post's work on finite combinatory processes and reducibility.<<ETX>>
[Production systems, Emil Post, computational logic, production systems, Calculus, Mathematics, mathematical logician, Computer science, formal logic, reviews, computer science, finite combinatory processes, reducibility, Karhunen-Loeve transforms, Logic]
Compositional model checking
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A method is described for reducing the complexity of temporal logic model checking in systems composed of many parallel processes. The goal is to check properties of the components of a system and then deduce global properties from these local properties. The main difficulty with this type of approach is that local properties are often not preserved at the global level. The authors present a general framework for using additional interface processes to model the environment for a component. These interface processes are typically much simpler than the full environment of the component. By composing a component with its interface processes and then checking properties of this composition, the authors can guarantee that these properties will be preserved at the global level. They give two example compositional systems based on the logic CTL.<<ETX>>
[complexity, Logic programming, local properties, Merging, temporal logic model checking, compositional systems, Explosions, Calculus, parallel processing, Asynchronous circuits, Computer science, formal logic, Parallel programming, Logic circuits, Automata, compositional model checking, global properties, CTL, parallel processes, Carbon capture and storage, interface processes]
Non trivial power types can't be subtypes of polymorphic types
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A new, limitative relation between the polymorphic lambda calculus and the kind of higher-order type theory embodied in the logic of topoi is established. It is shown that any embedding in a topos of the Cartesian closed category of (closed) types of a model of the polymorphic lambda calculus must place the polymorphic types well away from the power types sigma to Omega of the topos, in the sense that sigma to Omega is a subtype of a polymorphic type only in the case that sigma is empty (and hence sigma to Omega is terminal). As corollaries, strengthening of the Reynolds result on the nonexistence of set-theoretic models of polymorphism are obtained.<<ETX>>
[Cartesian closed category, Reynolds result, Terminology, logic of topoi, Laboratories, limitative relation, nontrivial power types, polymorphic lambda calculus, polymorphic types, Calculus, algebra, set theory, terminal, subtypes, empty, formal logic, higher-order type theory, Algebra, embedding, Logic, set-theoretic models, Integrated circuit modeling]
Structure and representation in LF
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
An important tool for controlling search in an object logic is the use of structured theory presentations. In order to apply these ideas to the setting of a logical framework, the authors study the behavior of structured theory presentations under representation in a framework, focusing on the problem of lifting presentations, from the object logic to the metalogic of the framework. The authors also consider imposing structure on logic presentations so that logical systems may themselves be defined in a modular fashion. This opens the way to a CLEAR-like language for defining both theories and logics in a logical framework.<<ETX>>
[metalogic, formal languages, Laboratories, lifting presentations, structured theory presentations, Encoding, representation, Computer science, formal logic, CLEAR-like language, LF, Logic, logical framework, object logic]
Nets and data flow interpreters
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The authors investigate and compare two ways of specifying stream relations (in particular, stream functions). The first uses relational programs, i.e., netlike program schemes in which the signature primitives are interpreted as relations over a given CPO. No stream domains are assumed; semantics is in fixed-point style. The second is through data flow nets, i.e., nets whose nodes are interpreted as processes (computational stations). The authors prove the existence of an adequate data flow interpreter for relational programs over all relations and its uniqueness. When dealing with functions the interpreter is modular and obeys the Kahn principle, the authors identify two kinds of anomalies. The first (meagerness anomaly) is caused by the defect of the used processes (computational stations) and holds in fact for arbitrary input-output behaviors. The second (ambiguity anomaly) is rooted in the semantics of relational nets over arbitrary CPO. It is unavoidable in any extension beyond functional behaviors.<<ETX>>
[signature primitives, CPO, stream relations, data flow nets, semantics, Concurrent computing, formal logic, defect, arbitrary input-output behaviors, Parallel processing, computational stations, Computer networks, Data flow computing, Functional programming, meagerness anomaly, stream functions, formal languages, relational programs, Kahn principle, data flow interpreters, used processes, Flow graphs, Equations, netlike program schemes, nodes, stream domains, uniqueness, relational nets, ambiguity anomaly, fixed-point style]
Unified algebras and institutions
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A framework for algebraic specification of abstract data types is introduced. It involves so-called unified algebras, where sorts are treated as values, so that operations can be applied to sorts as well as to the elements that they classify. An institution for unified algebras is defined and shown to be liberal. However, the ordinary forgetful functor does not forget any values in unified algebras, so the usual data constraints do not have any models. A more forgetful functor is introduced and used to define so-called bounded data constraints, which have the expected models.<<ETX>>
[forgetful functor, formal languages, Lattices, power algebra, formal specification, bounded data constraints, Computer science, institution, Algebra, unified specification, Constraint theory, category theory, sorts, unified algebras]
PARTHENON: a parallel theorem prover for nonHorn clauses
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A parallel resolution theorem prover, called Parthenon, that handles first-order logic is described. Parthenon is apparently the first general-purpose theorem prover to be developed for a multiprocessor. The system is based on a modification of D.H.D. Warren's SRI model (Int. Symp. on Logic Prog., pp.92-101, 1987) for OR-parallelism and implements a variant of D.W. Loveland's (J. ACM, vol.15, pp.236-51, 1968) model elimination procedure. It has been evaluated on various shared memory multiprocessors, including a 16-processor Encore Multimax. The authors have found that typical theorem-proving problems exhibit a great deal of potential parallelism. Parthenon has been able to exploit much of this parallelism, producing both impressive absolute run times and near-linear speed-up curves.<<ETX>>
[PARTHENON, Logic programming, parallel resolution theorem prover, first-order logic, model elimination procedure, shared memory multiprocessors, 16-processor Encore Multimax, parallel processing, OR-parallelism, near-linear speed-up curves, Computer science, formal logic, Warren, Inference mechanisms, SRI model, nonHorn clauses, Loveland, Parallel processing, absolute run times, theorem proving, general-purpose theorem prover, Context modeling]
Inheritance and explicit coercion
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A method is presented for providing semantic interpretations for languages which feature inheritance in the framework of statically checked, rich type disciplines. The approach is illustrated by an extension of the language Fun of L. Cardelli and P. Wegner (1985), which is interpreted via a translation into an extended polymorphic lambda calculus. The approach interprets inheritances in Fun as coercion functions already definable in the target of the translation. Existing techniques in the theory of semantic domains can then be used to interpret the extended polymorphic lambda calculus, thus providing many models for the original language. The method allows the simultaneous modeling of parametric polymorphism, recursive types, and inheritance, which has been regarded as problematic because of the seemingly contradictory characteristics of inheritance and type recursion on higher types. The main difficulty in providing interpretations for explicit type disciplines featuring inheritance is identified. Since interpretations follow the type-checking derivations, coherence theorems are required, and the authors prove them for their semantic method.<<ETX>>
[coherence theorems, recursive types, inheritance, Calculus, Mathematics, Proposals, extended polymorphic lambda calculus, formal logic, parametric polymorphism, Inference mechanisms, translation target, data structures, Object oriented programming, Fun, formal languages, Object oriented modeling, languages, Maintenance, Equations, semantic interpretations, Cardelli, semantic domains, statically checked, rich type disciplines, type recursion, explicit coercion, Wegner, coercion functions, translation, simultaneous modeling, interpreted]
Computing with recursive types
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A study is made of the complete adequacy for a lambda -calculus with simple recursive types. The set of types is built using the standard domain-theoretic constructors, namely, function space, sum, cartesian and strict product, and lifting. The recursive types allow the author to solve arbitrary systems of mutually recursive domain equations. Thus, he can define in this calculus types of integers, Booleans, lists and streams over these, and so on. The author can also define numerals, Boolean constants, simple arithmetic versions, of pure untyped terms. A precise description is given of the author's calculus, as well as some examples illustrating its expressiveness. A complete adequacy result for the lattice semantics is presented. The problem of designing a completely adequate evaluator for the CPO semantics is also examined.<<ETX>>
[recursive types, Lattices, Booleans, Calculus, sum, cartesian, mutually recursive domain equations, integers, formal logic, lambda -calculus, Impedance matching, lifting, pure untyped terms, domain-theoretic constructors, data structures, lattice semantics, Standards development, strict product, Mathematical programming, Testing, set of types, formal languages, streams, recursive functions, numerals, simple arithmetic versions, function space, Equations, Boolean constants, lists, arbitrary systems, CPO semantics, Fixed-point arithmetic]
Some complexity bounds for dynamic logics
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The class of so called Adian's structures with pairwise different exponents is considered. It is known that both deterministic dynamic logic (DDL) and context-free DDL (CF-DDL) have an unwind property in every structure Gamma in the class; thus they are equivalent in Gamma to first-order logic. None the less, it turns out that these three logics have different complexity bounds in the class. The main result is to prove polynomial upper bounds for DDL formulas. As a corollary, the authors find the DDL and CF-DDL are unequivalent to one another in the class. The proof remains valid even in the presence of elementary tests and rich tests.<<ETX>>
[Boats, deterministic dynamic logic, pairwise different exponents, Logic testing, complexity bounds, formal logic, context-free DDL, Upper bound, context-free languages, Chromium, Polynomials, polynomial upper bounds, Artificial intelligence, unwind property, Power generation, computational complexity]
Domains and logics
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The author's discovery of domains and domain-theoretic models for the lambda -calculus in 1969 is discussed, along with the research of others working in the area at that time.<<ETX>>
[logics, Logic programming, domain-theoretic models, domains, Mathematics, Topology, Finite element methods, Computer science, formal logic, Computer languages, lambda -calculus, 1969, Joining processes]
Faithful ideal models for recursive polymorphic types
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
Ideal models are explored for a programming language with recursive polymorphic types, variants of the model studied by D. MacQueen et al. (Inf. Control, vol.71, pp.95-130, 1986). The use of suitable ideals yields a close fit between models and programming language. Two of the authors' semantics of type expressions are faithfully, in the sense that programs that behave identically in all contexts have exactly the same types.<<ETX>>
[formal languages, type expressions, MacQueen, Calculus, semantics, Equations, close fit, Computer science, formal logic, Computer languages, recursive polymorphic types, data structures, programming language, Mathematical model, faithful ideal models]
Non-well-founded sets obtained from ideal fixed points
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
Motivated by ideas from the study of abstract data types, the authors show how to interpret non-well-founded sets as fixed points of continuous transformations of an initial continuous algebra. They consider a preordered structure closely related to the set HF of well-founded, hereditarily finite sets. By taking its ideal completion, the authors obtain an initial continuous algebra in which they are able to solve all of the usual systems of equations that characterize hereditarily finite, non-well-founded sets. In this way, they are able to obtain a structure which is isomorphic to HF/sub 1/, the non-well-founded analog to HF.<<ETX>>
[preordered structure, anti-foundation axiom, fixed points, abstract data types, continuous transformations, Calculus, Mathematics, Etching, set theory, Distributed computing, Equations, non-well-founded sets, hereditarily finite sets, initial continuous algebra, Algebra, Prototypes, Hafnium, protosets, Set theory, HF/sub 1/, Context modeling]
A game-theoretic modeling of concurrency
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A model is introduced for asynchronous concurrent communication, where each agent's perception of the system is represented by a game of interaction. The model combines strict fair merge with full recursion, and the main mathematical results provide evidence for the robustness and naturalness of his interpretation of recursive definitions of nondeterministic processes. The approach is closest to D. Park's (1980, 1983) whose ideas are starting points for this work.<<ETX>>
[parallel algorithms, strict fair merge, game theory, game of interaction, robustness, full recursion, Mathematics, Park, concurrency, Concurrent computing, formal logic, naturalness, System recovery, mathematical results, nondeterministic processes, agent perception, Robustness, Mathematical model, Standards development, game-theoretic modeling, recursive definitions, computational complexity, asynchronous concurrent communication]
Equality in lazy computation systems
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The author introduces a general class of lazy computation systems and defines a natural program equivalence for them. He proves that if an extensionality condition holds of each of the operators of a computational system, then the equivalence relation is a congruence, so that the usual kinds of equality reasoning are valid for it. This condition is a simple syntactic one and is easy to verify for the various lazy computation systems considered so far. Conditions are given under which the equivalence coincides with observational congruence. These results have important consequences for type theories.<<ETX>>
[observational congruence, Reasoning about programs, type theories, Computer science, formal logic, Computer languages, lazy computation systems, extensionality condition, computational system, natural program equivalence, data structures, equivalence relation, syntactic condition, equality reasoning, equivalence classes]
A fully abstract semantics for a functional language with logic variables
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
There is much interest in the declarative languages community in integrating logic variables into functional languages. The authors give a full semantic account of such a language. They present a Plotkin-style operational semantics for the language and an abstract semantics that expresses meanings as closure operators on a Scott domain. They also show that the denotational semantics is fully abstract with respect to the operational semantics.<<ETX>>
[declarative languages, formal languages, Scott domain, Logic programming, functional programming, Logic design, Plotkin-style operational semantics, Yarn, Equations, Computer science, logic variables, Programmable logic arrays, functional language, Writing, Interleaved codes, fully abstract semantics, Logic arrays, denotational semantics]
Fixpoint extensions of first-order logic and datalog-like languages
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
Datalog extensions with fixpoint semantics motivated by database queries and updates are studied. The authors suggest nontrivial fixpoint extensions of first-order logic with nondeterministic and/or noninflationary semantics. Certain properties of the language FO+IFP, such as the collapse of the hierarchy (based on the nesting of fixpoints) or the existential normal form, hold for these various logics. Their expressive power is characterized.<<ETX>>
[existential normal form, formal languages, Logic programming, first-order logic, noninflationary semantics, datalog-like languages, updates, expressive power, formal logic, FO+IFP, nontrivial fixpoint extensions, Databases, nondeterministic semantics, fixpoint semantics, Fires, datalog extensions, Polynomials, database queries, hierarchy collapse]
How complete is PER?
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The category of partial equivalence relations (PER) on the natural numbers has been used extensively in recent years to model various forms of higher-order type theory. It is known that PER can be viewed as a category of sets in a nonstandard model of intuitionistic Zermelo-Fraenkel set theory. The use of PER as a vehicle for modeling-type theory then arises from completeness properties of this category. The paper demonstrates these completeness properties, and shows that, constructively, some complete categories are more complete than others.<<ETX>>
[natural numbers, intuitionistic Zermelo-Fraenkel set theory, completeness properties, modeling-type theory, nonstandard model, set theory, complete categories, Vehicles, formal logic, Information science, higher-order type theory, Set theory, PER, partial equivalence relations, equivalence classes, number theory]
On the complexity of epistemic reasoning
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A study is made of the complexity of the decision problem for epistemic logics based on R. Montague's (1968) and R. Scott's (1970) semantics. The interest is in finding out how assumptions about the agents' reasoning power affect the complexity of reasoning about the agents' knowledge. A spectrum of assumptions is studied, and it is shown that the complexity of the logic under different assumptions is always in NP or PSPACE. The mental faculty that raises the complexity of the logic from NP to PSPACE is pinpointed. It is the ability to combine distinct items of knowledge.<<ETX>>
[NP, decision complexity, PSPACE, reasoning power, artificial intelligence, assumptions, logic complexity, formal logic, epistemic reasoning, epistemic logics, reasoning complexity, Logic, Artificial intelligence, Context modeling, computational complexity, knowledge]
Towards action-refinement in process algebras
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A simple process algebra which supports a form of refinement of an action by a process is presented and the question of an appropriate equivalence relation for it is addressed. The main result is that an adequate equivalence can be defined in a very intuitive manner and moreover can be axiomatized in much the same way as the standard behavioral equivalences.<<ETX>>
[Concurrent computing, Computer science, formal logic, action-refinement, process algebras, Algebra, Formal languages, equivalence relation, Carbon capture and storage, equivalence classes]
Characterizing complexity classes by higher type primitive recursive definitions
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
Higher type primitive recursive definitions (also known as Godel's system T) defining first-order functions can be classified into an infinite syntactic hierarchy. A definition is in the nth level of this hierarchy, a so-called rank-n definition, if and only if n is an upper bound on the levels of the types occurring in it. The author interprets these definitions over finite structures and shows that rank-2 definitions characterize PTIME, rank-3 definitions characterize PSPACE, and rank-4 definitions EXPTIME.<<ETX>>
[complexity classes, Godel system T, rank-n definition, upper bound, recursive functions, first-order functions, History, PSPACE, rank-2 definitions, rank-3 definitions, EXPTIME, Tellurium, Reactive power, Computer languages, rank-4 definitions, Upper bound, higher type primitive recursive definitions, PTIME, Sections, Automata, Writing, infinite syntactic hierarchy, computational complexity]
Computational lambda-calculus and monads
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The lambda -calculus is considered a useful mathematical tool in the study of programming languages. However, if one uses beta eta -conversion to prove equivalence of programs, then a gross simplification is introduced. The author gives a calculus based on a categorical semantics for computations, which provides a correct basis for proving equivalence of programs, independent from any specific computational model.<<ETX>>
[formal languages, beta eta -conversion, Logic programming, prove, categorical semantics, Reasoning about programs, Calculus, monads, programming languages, equivalence of programs, Computer science, formal logic, computational lambda-calculus, Computer languages, lambda -calculus, mathematical tool, Mathematical model, Contracts, Mathematical programming]
Axiomatizing net computations and processes
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
An algebraic axiomatization is proposed, where, given a net N, a term algebra P(N) with two operations of parallel and sequential composition is defined. The congruence classes generated by a few simple axioms are proved isomorphic to a slight refinement of classical processes. Actually, P(N) is a symmetric monoidal category, parallel composition is the monoidal operation on morphisms and sequential composition is morphism composition. Besides P(N), the authors introduce a category S(N) containing the classical occurrence and step sequences. The term algebras of P(N) and S(N) are in general incomparable, and thus they introduce two more categories, K(N) and T(N), providing a most concrete and a most abstract extremum, respectively. The morphisms of T(N) are proved isomorphic to the processes recently defined in terms of the swap transformation by E. Best and R. Devillers (Theor. Comput. Sci., vol.55, pp.87-136, 1987). Thus the diamond of the four categories gives a full account in algebraic terms of the relations between interleaving and partial ordering observations of place/transition net computations.<<ETX>>
[Petri nets, classical processes, classical occurrence, congruence classes, morphisms, step sequences, Concurrent computing, formal logic, axioms, Algebra, isomorphic, most abstract extremum, algebraic axiomatization, parallel composition, Best, Books, Contracts, formal languages, processes, partial ordering, most concrete, Devillers, sequential composition, symmetric monoidal category, swap transformation, term algebra, place/transition net computations, interleaving, diamond, morphism composition, Interleaved codes, Concrete, monoidal operation]
Elf: a language for logic definition and verified metaprogramming
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A description is given of Elf, a metalanguage for proof manipulation environments that are independent of any particular logical system. Elf is intended for metaprograms such as theorem provers, proof transformers, or type inference programs for programming languages with complex type systems. Elf unifies logic definition (in the style of LF, the Edinburgh logical framework) with logic programming (in the style of lambda Prolog). It achieves this unification by giving types an operational interpretation, much the same way that Prolog gives certain formulas (Horn clauses) an operational interpretation. Novel features of Elf include: (1) the Elf search process automatically constructs terms that can represent object-logic proofs, and thus a program need not construct them explicitly; (2) the partial correctness of metaprograms with respect to a given logic can be expressed and proved in Elf itself; and (3) Elf exploits Elliott's (1989) unification algorithm for a lambda -calculus with dependent types.<<ETX>>
[Ground penetrating radar, formal languages, Logic programming, Geophysical measurement techniques, type inference programs, Automatic logic units, proof transformers, Encoding, unification, logic definition, Computer science, proof manipulation environments, Elf search process, Computer languages, lambda -calculus, object-logic proofs, theorem provers, partial correctness of metaprograms, logic programming, Transformers, Internet, theorem proving, Contracts, Elf]
Stratified polymorphism
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The author considers a spectrum of predicative type abstraction disciplines based on type quantification with stratified levels. These lie in the vast middle ground between parametric abstraction and full impredicative abstraction. Stratified polymorphism has an attractive, unproblematic semantics, and has the potential of offering new approaches to type inference, without sacrificing useful expressive power. He shows that the functions representable in the finitely stratified lambda -calculus are precisely the superelementary functions, i.e., E/sub 4/ in A. Grzegorczyk's (Rozprawy Mate. IV, Warsaw, 1953) subrecursive hierarchy. He also defines methods of transfinite stratification and shows that stratification up to omega /sup omega / has a simple finitary representation, making it a potentially useful concept in programming language design. The author proves that the functions represented by stratified polymorphism up to omega /sup omega / are precisely the primitive recursive functions. He points out that these results imply that the equality problem for finitely stratified lambda -calculus is not superelementary, and that the equality problem for the calculus stratified up to omega /sup omega / is not primitive recursive.<<ETX>>
[equality problem, unproblematic semantics, parametric abstraction, Calculus, Mathematics, expressive power, formal logic, Inference mechanisms, primitive recursive functions, finitely stratified lambda -calculus, data structures, stratified polymorphism, type inference, formal languages, transfinite stratification, stratified levels, recursive functions, type quantification, subrecursive hierarchy, Computer science, superelementary functions, Computer languages, full impredicative abstraction, programming language design, predicative type abstraction disciplines]
On simultaneously determinizing and complementing omega -automata
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The authors give a construction to determine and complement simultaneously a Buchi automaton in infinite strings, with an exponential blowup in states and a linear blowup in the number of pairs. An exponential lower bound is already known. The previous best construction was double exponential. The present result permits exponentially improved essentially optimal decision procedures for various modal logics of programs. It also gives exponentially improved conversions between various kinds of omega automata.<<ETX>>
[Buchi automaton, exponential blowup, Computational modeling, automata theory, Mathematics, infinite strings, optimal decision procedures, exponential lower bound, Asynchronous circuits, Computer science, formal logic, Automatic testing, Automata, Character generation, modal logics of programs, Feedback amplifiers, omega -automata, Logic, Contracts]
On substitutional recursion over non-well-founded sets
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A class of recursive definitions is isolated, which encompasses all applications of nonwellfounded sets known to the author. These definitions are based on a result referred to in the literature as the substitution lemma, and accordingly are called substitutional recursive definitions (SRDs). A theory of fixed points of SRDs is developed in a number of directions, leading to a consideration of effective aspects of nonwellfounded sets. The novelty of the author's approach is that he gets at these fixed points without explicitly referring to the operators. Instead, he constructs systems of equations from the specification, replacing the variables by indeterminates for which he then solves. Over nonwellfounded sets, this approach to fixed points, which can be seen as a refinement of the usual iterative methods for inductive (and coinductive) definitions, is quite fruitful, yielding detailed information about fixed points.<<ETX>>
[iterative methods, fixed points, substitutional recursive definitions, Lattices, specification, recursive functions, set theory, Equations, Computer science, Pollution, inductive definitions, nonwellfounded sets, coinductive definitions, Set theory, Iterative methods, substitution lemma, recursive definitions]
Extending the lambda calculus with surjective pairing is conservative
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
Consideration is given to the equational theory lambda pi of lambda calculus extended with constants pi , pi /sub 0/, pi /sub 1/ and axioms for subjective pairing: pi /sub 0/( pi XY)=X, pi /sub 1/( pi XY)=Y, pi ( pi /sub 0/X)( pi /sub 1/X)=X. The reduction system that one obtains by reading the equations are reductions (from left to right) is not Church-Rosser. Despite this failure, the author obtains a syntactic consistency proof of lambda pi and shows that it is a conservative extension of the pure lambda calculus.<<ETX>>
[lambda calculus, formal languages, Roads, Ink, Calculus, Mathematics, surjective pairing, Equations, syntactic consistency proof, Computer science, formal logic, axioms, equational theory, reduction system, Writing, conservative extension, Functional programming]
RI: a logic for reasoning with inconsistency
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The authors present a logic, called RI (reasoning with inconsistency), that treats any set of clauses, either consistent or not, in a uniform way. In this logic, consequences of a contradiction are not nearly as damaging as in the standard predicate calculus, and meaningful information can still be extracted from an inconsistent set of formulas. RI has a resolution-based sound and complete proof procedure. It is a much richer logic than the predicate calculus, and the latter can be imitated within RI in several different ways (depending on the intended meaning of the predicate calculus formulas). The authors also introduce a novel notion of epistemic entailment and show its importance for investigating inconsistency in the predicate calculus.<<ETX>>
[Knowledge based systems, Lattices, Optimized production technology, predicate calculus, Calculus, Data mining, Research and development, artificial intelligence, Computer science, formal logic, Councils, reasoning with inconsistency, epistemic entailment, resolution based proof procedure, theorem proving, Logic, meaningful information, contradiction]
A small universal model for system executions
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The author shows that every consistent set of atomic relations has a unified model of size roughly O(n/sup 2/). This model can be used to give a simplified proof of completeness of some axioms. He gives several complexity results for deciding the theory of several classes of axiom sets, for both partial models and global-time models, showing many such variations to have the same complexity as transitive closure or matrix multiplication. The author shows that deciding disjunctive axioms is NP-complete for both the global-time and the standard model.<<ETX>>
[partial models, formal languages, global-time models, complexity results, simplified proof, system executions, Educational institutions, NP-complete, completeness, atomic relations, axiom sets, Computer science, formal logic, matrix multiplication, decidability, disjunctive axioms, universal model, unified model, consistent set, transitive closure, computational complexity]
Polynomially graded logic I. A graded version of system T
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
An investigation is made of a logical framework for programming languages which treats requirements on computation resources as part of the formal program specification. Resource bounds are explicit in the syntax of all programs. In a programming language based on this approach, compliance of a program with imposed resource bounds would be assured by verifying the syntactic correctness using a compiler with a static type checking feature. The principal innovation is the introduction of systems of logical inference, called polynomially graded logics. These logics make resource bounds part of every proposition and every deduction. The sample calculus presented is a restriction of Godel's system T to polynomial time resources. It is proved that the numerical functions representable in this calculus are exactly the PTIME functions.<<ETX>>
[Mathematics, Calculus, programming languages, PTIME functions, formal logic, every deduction, Program processors, Turing machines, syntactic correctness, proposition, Logic functions, Polynomials, static type checking, representable numerical functions, computation resources, Technological innovation, Logic programming, polynomially graded, Godel system T, logical inference, Computer languages, resource bounds, formal program specification, logical framework, Arithmetic, computational complexity, polynomial time resources]
A probabilistic powerdomain of evaluations
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A probabilistic power domain construction is given for the category of inductively complete partial orders. It is the partial order of continuous
[probabilistic parallel construct, probabilistic logic, Probability distribution, Moggi computational lambda calculus, semantics, programming languages, probabilistic powerdomain, Concurrent computing, Algebra, Sections, continuous, monad, Logic, inductively complete partial orders, formal languages, evaluations, Computational modeling, topology, Scott topology, probabilistic features, Topology, Equations, Computer science, Computer languages, recursive domain equations, integration, metalanguage]
Proof theory and semantics of logic programs
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The authors develop a resolution logic that is based on direct proofs rather than on proofs by refutations. The deductive system studied has clauses as its formulas and resolution as the sole inference rule. They analyze this deductive system using a novel representation of resolution proofs, called resolution graphs, and obtain a general completeness theorem: a clause is a logical consequence of a set of clauses if and only if it is either tautological or subsumed by a clause derivable from that set. In a previous paper (proc. 16th ACM Symp. on Principles of Prog. Lang., pp.134-42, 1989), the authors developed a model-theoretic compositional semantics for logic programs and investigated the fully abstract equivalences induced by various notions of composition. They continue that study here using the proof theory of resolution logic. This proof theory gives rise to various semantics for logic programs that reflect more operational details than does the model-theoretic semantics.<<ETX>>
[logic programs, Vocabulary, completeness theorem, tautological, clauses, formulas, notions of composition, Superluminescent diodes, resolution graphs, Mathematics, set theory, subsumed, model-theoretic compositional semantics, formal logic, resolution proofs, theorem proving, Mathematical model, logical consequence, Logic programming, set, inference mechanisms, fully abstract equivalences, proof theory, Computer science, resolution logic, deductive system, inference rule, direct proofs]
Axiomatizing operational equivalence in the presence of side effects
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The authors present a formal system for deriving assertions about programs with side effects. The assertions considered are the following: (i) the expression e diverges (i.e. fails to reduce to a value); and (ii) e/sub 0/ and e/sub 1/ are strongly isomorphic (i.e. reduce to the same value and have the same effect on memory up to production of garbage). The e, e/sub j/ are expressions of a first-order scheme- or Lisp-like language with the data operations atom, eq, car, cdr, cons, setcar, setcdr, the control primitives let and if, and recursive definition of function symbols.<<ETX>>
[data operations, formal languages, operational equivalence, operational semantics, Reasoning about programs, Calculus, recursive functions, control primitives, Tellurium, Electrooptic effects, Computer science, semantic consequence, recursive definition of function symbols, strongly isomorphic, Production, Abstracts, programs with side effects, let, memory model, equivalence classes, if, Contracts, Lisp-like language]
ECC, an extended calculus of constructions
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A higher-order calculus ECC (extended calculus of constructions) is presented which can be seen as an extension of the calculus of constructions by adding strong sum types and a fully cumulative type hierarchy. ECC turns out to be rather expressive so that mathematical theories can be abstractly described and abstract mathematics may be adequately formalized. It is shown that ECC is strongly normalizing and has other nice proof-theoretic properties. An omega -set (realizability) model is described to show how the essential properties of the calculus can be captured set-theoretically.<<ETX>>
[extended calculus of constructions, formal languages, strongly normalizing, Buildings, omega -set, abstract mathematics, strong sum types, Calculus, Mathematics, set theory, Computer science, formal logic, Computer languages, fully cumulative type hierarchy, proof-theoretic properties, Abstract algebra, Inference algorithms, Functional programming, Mathematical model, higher-order calculus ECC, realizability]
Negation as refutation
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
A refutation mechanism is introduced into logic programming, dual to the usual proof mechanism; then negation is treated via refutation. A four-valued logic is appropriate for the semantics: true, false, neither, both. Inconsistent programs are allowed, but inconsistencies remain localized. The four-valued logic is a well-known one, due to Belnap, and is the simplest example of the Ginsberg bilattice notion. An efficient implementation based on semantic tableaux is sketched; it reduces to SLD resolution when negations are not involved. The resulting system can give reasonable answers to queries that involve both negation and free variables. Also, it gives the same results as Prolog when there are no negations. Finally, an implementation in Prolog is given.<<ETX>>
[negation, Lattices, free variables, Superluminescent diodes, Mathematics, inconsistent programs, semantics, four-valued logic, Delay, Ginsberg bilattice notion, inconsistencies, dual, proof mechanism, SLD resolution, logic programming, Logic programming, false, Educational institutions, Prolog, queries, both, semantic tableaux, Computer science, structured logic design, Belnap, neither, refutation mechanism, true, many-valued logics]
A sufficient condition for the termination of the direct sum of term rewriting systems
[1989] Proceedings. Fourth Annual Symposium on Logic in Computer Science
None
1989
The author proves a conjecture by Rusinowitch (1987) stating that the direct sum of two terminating term-rewriting systems is terminating if one of the systems contains neither collapsing nor duplicating rules.<<ETX>>
[Computer science, termination, Sufficient conditions, rewriting systems, Mathematics, direct sum, collapsing rules, Stress, duplicating rules, term rewriting systems]
On subsumption and semiunification in feature algebras
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A generalization of term subsumption, or matching, to a class of mathematical structures called feature algebras is discussed. It is shown how these generalize both first-order terms and the feature structures used in computational linguistics. The notion of subsumption generalizes to a natural notion of homomorphism between elements of these algebras, and the authors characterize the notion, showing how it corresponds to a mapping which preserves partial information. In the setting of feature algebras, unification corresponds naturally to solving constraints involving equalities between strings of unary functions symbols, and semiunification also allows inequalities representing subsumption constraints. Their generalization allows the authors to show that the semiunification problem for finite feature algebras is undecidable. This implies that the corresponding problem for rational trees (cyclic terms) is also undecidable. Thus a partial solution to the decidability of this problem, which has been open for several years, is produced.<<ETX>>
[inequalities, cyclic terms, Laboratories, computational linguistics, mathematical structures, term subsumption, first-order terms, Algebra, decidability, Logic functions, Computational linguistics, unary functions symbols, subsumption constraints, Logic programming, Natural languages, partial information, Encoding, Logic design, unification, feature algebras, grammars, undecidable, semiunification, rational trees, homomorphism, Artificial intelligence]
Programming in equational logic: beyond strong sequentiality
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
The authors consider whether it is possible to devise a complete normalization algorithm that minimizes (rather than eliminates) the wasteful reductions for the entire class of regular systems. A solution is proposed to this problem using the concept of a necessary set of redexes. In such a set, at least one of the redexes must be reduced to normalize a term. An algorithm is devised to compute a necessary set for any term not in normal form, and it is shown that a strategy that repeatedly reduces all redexes in such a set is complete for regular programs. It is also shown that the algorithm is optimal among all normalization algorithms that are based on left-hand sides alone. This means that the algorithm is lazy (like Huet-Levy's) on strongly sequential parts of a program, relaxes laziness minimally to handle the other parts, and thus does not sacrifice generality for the sake of efficiency.<<ETX>>
[Computer science, Logic programming, necessary set of redexes, regular programs, logic programming, Linear programming, Electronic mail, equational logic, wasteful reductions, Equations, complete normalization algorithm, regular systems]
A new AC unification algorithm with an algorithm for solving systems of diophantine equations
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A novel AC-unification algorithm is presented. A combination technique for regular collapse-free theories is provided along the line developed by A. Boudet et al. (1989). The number of calls to the diophantine equations solver is bounded by the number of AC symbols times the number of shared variables. The rest of the algorithm being linear, this gives a much better idea of how the complexity of AC unification is related to the complexity of solving linear diophantine equations. The termination proof is surprisingly easy. Finally, systems of constraint linear diophantine equations can be solved, rather than one equation at a time, using an algorithm which extends Fortenbacher's algorithm to an arbitrary dimension. This allows a much more efficient use of the constraints than in the standard case.<<ETX>>
[formal logic, rewriting systems, regular collapse-free theories, diophantine equations solver, Binary search trees, associative-commutative unification, Inference algorithms, Helium, Equations, Fortenbacher algorithm, AC-unification algorithm, termination proof]
A linear semantics for allowed logic programs
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A declarative semantics for the class of allowed logic programs is proposed. Such a semantics is a logical theory, the linear completion of the program P, which differs from Clark's completion because the underlying logic is linear logic rather than classical logic. With respect to such a semantics, the soundness and completeness of SLDNF-resolution is proven. That is, it is proven that the computational notion of success of an allowed query Q for an allowed program P corresponds to the provability of an instantiation of Q in the linear completion of P, and the notion of failure to the provability of the (linear) negation of Q in the linear completion of P.<<ETX>>
[logic programs, logical theory, linear logic, soundness, completeness, Noise measurement, linear completion, formal logic, linear semantics, allowed program, computational notion, Bismuth, logic programming, SLDNF-resolution, allowed query, declarative semantics, Logic]
Proof transformations for equational theories
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
This study contrasts two kinds of proof systems for equational theories: the standard ones obtained by combining the axioms with the laws of equational logic, and alternative systems designed to yield decision procedures for equational problems. Novel matching algorithms for (among other theories) associativity, associativity plus commutativity, and associativity plus commutativity plus identity are presented, but the emphasis is not so much on individual theories but on the general method of proof transformation as a tool for showing the equivalence of different proof systems. After a study of proof translations defined by rewriting systems, equivalence tests based on the notion of resolvent theories are used to derive novel matching and, in some cases unification procedures for a number of equational theories. The combination of resolvent systems is investigated.<<ETX>>
[System testing, rewriting systems, equivalence tests, proof systems, proof transformation, Laboratories, unification procedures, Decision feedback equalizers, Equations, resolvent systems, proof translations, equational theories, matching algorithms, decision procedures, theorem proving, associativity plus commutativity, Logic, equational logic, equivalence classes, Monitoring, Contracts]
A categorical linear framework for Petri nets
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
This research brings together, in a methodical way, several approaches to giving a compositional theory of Petri nets using category theory and to the use of linear logic in specifying and reasoning about Petri nets. The authors construct categories of nets based on V.C.V. de Paiva's dialectica category models (1989) of linear logic in which they are able to exploit the structure of de Paiva's models to give constructions on categories of nets. Using a category of safe nets as an example, it is shown how this approach yields both existing and novel constructions on nets and their computational interpretation is discussed. The authors also indicate how more general categories of nets can be expressed in this framework.<<ETX>>
[Modular construction, Computational modeling, computational interpretation, Petri nets, linear logic, reasoning, Computer science, formal logic, specifying, safe nets, categorical linear framework, Ear, Logic functions, category theory, compositional theory]
Syntactic theories and unification
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
An investigation is made of the relationship between unifiability of a general equation of the form f( nu /sub 1/, . . ., nu /sub n/)=/sup ?/g( nu /sub n+1/, . . ., nu /sub m/), and of the syntacticness of the theory. After introducing the concept of general equations and its basic properties, the precise definition of syntactic theories is given. It is proven that a theory is syntactic if and only is the general equations have finite complete set of E-solutions. The result is constructive in the sense that from the E-solutions of the general equations, a resolvent presentation is computed. This is applied to several theories: in particular, in order to show that distributivity is not syntactic. The authors also prove that the theory of associativity and commutativity is syntactic, which allows one, by the combination of Nipkow's results (ibid., p.278-88, 1990) and the authors', to infer a novel matching algorithm where there is no need to solve linear diophantine equations.<<ETX>>
[Heart, Logic programming, finite complete set, Mathematics, distributivity, Equations, formal logic, matching algorithm, Sufficient conditions, unifiability, decidability, Vents, Abstract algebra, commutativity, resolvent presentation, Inference algorithms, E-solutions, associativity, syntactic theories]
A theory of nonmonotonic rule systems
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
The semantics for nonmonotonic rule systems are investigated. The notion of nonmonotonic formal systems is then introduced. Examples are given, along with applications of logic, logic programming, and common-sense reasoning.<<ETX>>
[theory of nonmonotonic rule systems, Decision making, formal systems, common-sense reasoning, Birds, Mathematics, Calculus, semantics, History, Computer science, formal logic, Statistical distributions, logic programming, logic, Logic, Positron emission tomography, Contracts]
Normal process representatives
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
The relevance of a form of cut elimination theorem for linear logic tensor theories to the concept of a process on a Petri net is discussed. The discussion is based on two definitions of processes given by E. Best and R. Devillers (1987). Their notions of process correspond to equivalence relations on linear logic proofs. It is noted that the cut reduced proofs form a process under the finer of these definitions. Using a strongly normalizing rewrite system and a weak Church-Rosser theorem, it is shown that each class of the coarser process definition contains exactly one of these finer classes which can therefore be viewed as a canonical or normal process representative. The relevance of these rewrite rules to the categorical approach of P. Degano et al. (1989) is also discussed.<<ETX>>
[cut reduced proofs, rewriting systems, Petri nets, canonical, coarser process definition, weak Church-Rosser theorem, strongly normalizing rewrite system, formal logic, equivalence relations, cut elimination theorem, Theorem proving, normal process representation, linear logic tensor theories, theorem proving, Logic, Petri net]
A constructive proof of Higman's lemma
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
G. Higman's lemma (1952) is a special case of the more general Kruskal's tree embedding theorem and the graph minor theorem. A direct constructive proof of the lemma with manifest computational content is presented. This is done by reducing the problem to a construction of certain sets of sequential regular expressions. A well-founded order on such sets is exhibited, and the lemma then follows by induction.<<ETX>>
[graph minor theorem, Higman's lemma, trees (mathematics), History, Computer science, Tree graphs, induction, constructive proof, well-founded order, sequential regular expressions, Polynomials, Concrete, theorem proving, Logic, direct constructive proof, tree embedding theorem, Arithmetic]
A decision procedure for a class of set constraints
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A set constraint is of the form exp/sub 1/ contains exp/sub 2/ where exp/sub 1/ and exp/sub 2/ are set expressions constructed using variables, function symbols, projection symbols, and the set union, intersection, and complement symbols. While the satisfiability problem for such constraints is open, restricted classes have been useful in program analysis. The main result is a decision procedure for definite set constraints which are of the restricted form a contains exp, where a contains only constants, variables, and function symbols, and exp is a positive set expression (that is, it does not contain the complement symbol). A conjunction of such constraints, whenever satisfiable, has a least model and the algorithm will output an explicit representation of this model. An additional feature of the algorithm is that it deals with another important class of set constraints. These are the solved form set constraints which have the form X/sub 1/=exp/sub 1/, . . ., X/sub n/=exp/sub n/, where the X/sub i/ are distinct variables and the exp/sub i/ are positive set expressions. A solved form constraint is always satisfiable and possesses a least and a greatest model. The algorithm can output explicit representations of both.<<ETX>>
[variables, class of set constraints, set expressions, Binary search trees, Reasoning about programs, projection symbols, Calculus, formal logic, Runtime, decidability, satisfiability problem, decision procedure, complement symbols, function symbols, set union, intersection, program analysis, solved form constraint, Cost function, Logic, least model]
The dynamic logic of permission
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
Intelligent legal information systems require the ability to represent two different notions of permission, one of which, free choice permission, cannot be adequately represented in standard modal logics. A logic that handles this modality by using ideas from dynamic logic is defined. The main result is the completeness of an axiomatization of the logic.<<ETX>>
[axiomatization, Law, modality, Knowledge based systems, free choice permission, Logic design, completeness, Information systems, Postal services, Computer science, formal logic, Permission, intelligent legal information systems, Intelligent systems, Legal factors, Contracts, dynamic logic of permission]
Type reconstruction in finite-rank fragments of the polymorphic lambda -calculus
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
It is proven that the problem of type reconstruction in the polymorphic lambda -calculus of rank two is polynomial-time equivalent to the problem of type reconstruction in ML, and is therefore DEXPTIME-complete. It is also proven that for every k>2, the problem of type reconstruction in the polymorphic lambda -calculus of rank k, extended with suitably chosen constants with types of rank one, is undecidable.<<ETX>>
[Computer science, formal logic, DEXPTIME-complete, polynomial-time equivalent, Polynomials, Calculus, type reconstruction, Computer science education, inference mechanisms, finite-rank fragments, polymorphic lambda -calculus, ML]
On the expression of monadic second-order graph properties without quantifications over sets of edges
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
For graphs of degree at most some fixed integer, the same properties can be expressed by monadic second-order formulas with and without quantifications over sets of edges, with and without auxiliary orientations. Similar results hold for partial k-trees for fixed k, and for graphs of tree-width at most k. These results are related to the possibility of testing graph properties in polynomial time for graphs generated by context-free graph-grammars of various types.<<ETX>>
[tree-width, expression, trees (mathematics), fixed integer, quantifications, Gas insulated transmission lines, fixed k, context-free graph-grammars, Upper bound, Tree graphs, partial k-trees, auxiliary orientations, context-free grammars, Polynomials, polynomial time, Colon, Joining processes, Contracts, Testing, monadic second-order graph properties]
A PER model of polymorphism and recursive types
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A model of Reynold's polymorphic lambda calculus is provided, which also allows the recursive definition of elements and types. The techniques uses a good class of partial equivalence relations (PERs) over a certain CPO. This allows the combination of inverse-limits for recursion and intersection for polymorphism.<<ETX>>
[formal languages, CPO, recursive types, Buildings, PER model, O-category, polymorphic lambda calculus, recursive functions, polymorphism, Equations, recursive definition, Computer science, intersection, partial orders, Logic, partial equivalence relations, equivalence classes, inverse-limits, recursion]
Well rewrite orderings
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A study is made of well (quasi) orderings which are described as rewrite orderings, and a family of well (quasi) orderings that extends the embedding or divisibility order of G. Higman (1952) is presented. For instance, the well (quasi) orderings proposed by the author may contain pairs of the form f(f(x))>f(g(f(x))). Conditions under which the transitive closures of a well-founded relation is a well-quasi-ordering are given. Finally, an attempt to extend the recursive path ordering is proposed.<<ETX>>
[Computer science, divisibility order, rewriting systems, quasi orderings, transitive closures, well rewrite orderings, embedding, recursive path ordering]
The classification of continuous domains
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
The long-standing problem of finding the maximal Cartesian closed categories of continuous domains is solved. The solution requires the definition of a new class of continuous domains, called FS-domains, which contains all retracts of SFP-objects. The properties of FS-domains are discussed.<<ETX>>
[Algorithm design and analysis, programming theory, SFP-objects, Lattices, Educational institutions, Topology, classification, FS-domains, Computer science, formal logic, Computer languages, Upper bound, Algebra, Bibliographies, maximal Cartesian closed categories, Concrete, continuous domains]
Solving inequations in terms algebras
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
Let T be the theory of term algebra over the relational symbols = or >or=, where >or= is interpreted as a lexicographic path ordering. The decidability of the purely existential fragment of T is shown. The proof is carried out in three steps. The first step consists of the transformation of any quantifier-free formula phi (i.e. all variables are free) into a solved form that has the same set of solutions as phi . Then the author shows how to decide the satisfiability of some particular problems called simple systems. A simple system is a formula which defines a total ordering on the terms occurring in it and which is closed under deduction. This last property means that if psi is a solved form of a simple system phi then psi must be a subformula of phi . The proof is completed by showing how to reduce the satisfiability of an arbitrary solved form to the satisfiability of finitely many simple systems.<<ETX>>
[quantifier-free formula, rewriting systems, lexicographic path ordering, Algebra, decidability, simple systems, terms algebras, Virtual manufacturing, relational symbols, Equations, inequations solving]
ALOGTIME and a conjecture of S.A. Cook
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
Using sequential, machine-independent characterizations of the parallel complexity classes AC/sup k/ and NC/sup k/, the author establishes a conjecture of S.A. Cook (1975) regarding polynomial size Frege proofs for a certain infinite family. A related result is established with constant formula-depth polynomial size Frege proofs for a system AV related to uniform AC/sup 0/ functions.<<ETX>>
[sequential, infinite family, Equations, parallel complexity classes, formal logic, machine-independent characterizations, ALOGTIME, polynomial size Frege proofs, Polynomials, theorem proving, Logic, Erbium, computational complexity]
Real-time logics: complexity and expressiveness
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A unifying framework for the study of real-time logics is developed. In analogy to the untimed case, the underlying classical theory of timed state sequences is identified, it is shown to be nonelementarily decidable, and its complexity and expressiveness are used as a point of reference. Two orthogonal extensions of PTL (timed propositional temporal logic and metric temporal logic) that inherit its appeal are defined: they capture elementary, yet expressively complete, fragments of the theory of timed state sequences, and thus are excellent candidates for practical real-time specification languages.<<ETX>>
[Real time systems, complexity, real-time specification languages, Delay effects, timed state sequences, temporal logic, nonelementarily decidable, PTL, Specification languages, timed extended temporal logic, timed propositional temporal logic, Computer science, real-time logics, decidability, real-time systems, Ear, expressiveness, Timing, Logic, Contracts, computational complexity, metric temporal logic]
Symbolic model checking: 10/sup 20/ states and beyond
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A general method that represents the state space symbolically instead of explicitly is described. The generality of the method comes from using a dialect of the mu-calculus as the primary specification language. A model-checking algorithm for mu-calculus formulas which uses R.E. Bryant's (1986) binary decision diagrams to represent relations and formulas symbolically is described. It is then shown how the novel mu-calculus model checking algorithm can be used to derive efficient decision procedures for CTL model checking, satisfiability of linear-time temporal logic formulas, strong and weak observational equivalence of finite transition systems, and language containment of finite omega -automata. This eliminates the need to describe complicated graph-traversal or nested fixed-point computations for each decision procedure. The authors illustrate the practicality of their approach to symbolic model checking by discussing how it can be used to verify a simple synchronous pipeline.<<ETX>>
[finite automata, complicated graph-traversal, Pipelines, temporal logic, PTL, Logic testing, binary decision diagrams, Boolean functions, satisfiability, specification languages, efficient decision procedures, observational equivalence, language containment, symbolic model checking, Contracts, specification language, CTL model checking, finite omega -automata, iterative squaring transformation, Scholarships, finite transition systems, computation tree logic, symbolic mu-calculus, Data structures, Explosions, State-space methods, nested fixed-point computations, synchronous pipeline, Computer science, mu-calculus, linear-time temporal logic formulas, decision procedure, US Department of Defense, model-checking algorithm]
Extensional PERs
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A search is conducted for a class of PERs (partial equivalence relations on the natural numbers) such that the resulting full subcategory has the expected properties of any good category of CPOs: it should be a CCC (Cartesian closed category) and every endomorphism should have a canonical fixed point. Moreover the reflection functor (usually called the lifting operation) should yield a good notion of partial map. The following topics are discussed: conventions, partial-map classifiers, ExPERS, ExPERS as domains, reflectivity of strict maps, multicorreflectivity of strict maps, the extensional natural numbers, domain equations, and intrinsic descriptions.<<ETX>>
[natural numbers, Cartesian closed category, endomorphism, extensional natural numbers, partial map, strict maps, Reflection, canonical fixed point, partial-map classifiers, reflectivity, Equations, CPOs, extensional PER, Reflectivity, domain equations, intrinsic descriptions, Turing machines, multicorreflectivity, lifting operation, ExPERS, conventions, reflection functor, partial equivalence relations, equivalence classes]
0-1 laws for infinitary logics
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
Asymptotic probabilities of properties expressible in a certain infinitary logic on finite structures are investigated. Sentences in this logic may have arbitrary disjunctions and conjunctions, but they involve only a finite number of distinct variables. It is shown that zero-one law holds for the infinitary logic considered, i.e. the asymptotic probability of every sentence in this logic exists and is equal to either zero or one. This result subsumes earlier work on asymptotic probabilities for various fixpoint logics and reveals the boundary of zero-one laws for infinitary logics.<<ETX>>
[Vocabulary, zero-one law, finite structures, distinct variables, fixpoint logics, probability, conjunctions, Complexity theory, Application software, Combinatorial mathematics, Computer science, formal logic, asymptotic probability, disjunctions, Databases, asymptotic probabilities, Logic, infinitary logics, 0-1 laws]
Completeness for typed lazy inequalities
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
Familiar beta eta -equational reasoning on lambda -terms is unsound for proving observational congruences when termination of the standard lazy interpreter is taken into account. A complete logic, based on sequents, for proving termination-observational congruences between simply-typed terms without constants is developed. It is shown that the theory, like that of beta eta -reasoning in the ordinary types lambda -calculus, is decidable. The authors examined the termination behavior of the functional language PCF under the standard interpreters.<<ETX>>
[typed lazy inequalities, decidable, functional programming, Laboratories, termination-observational congruences, Equations, sequents, Computer science, decidability, simply-typed terms without constants, standard lazy interpreter, functional language PCF, Logic, Contracts, beta eta -equational reasoning]
The theory of ground rewrite systems is decidable
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
Using tree automata techniques, it is proven that the theory of ground rewrite systems is decidable. Novel decision procedures are presented for most classic properties of ground rewrite systems. An example is presented to illustrate how these results could be used for specification and debugging.<<ETX>>
[rewriting systems, decidable, Transducers, theory of ground rewrite systems, automata theory, trees (mathematics), specification, Calculus, Encoding, Software debugging, Partial response channels, Tree graphs, Algebra, decidability, tree automata techniques, Automata, debugging, Polynomials, classic properties]
The semantics of reflected proof
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
The authors lay the foundations for reasoning about proofs whose steps include both invocations of programs to build subproofs (tactics) and references to representations of proofs themselves (reflected proofs). The main result is the definition of a single type of proof which can mention itself, using a novel technique which finds a fixed point of a mapping between metalanguage and object language. This single type contrasts with hierarchies of types used in other approaches to accomplish the same classification. It is shown that these proofs are valid, and that every proof can be reduced to a proof involving only primitive inference rules. The extension of the results to proofs from which programs (such as tactics) can be derive and to proofs that can refer to a library of definitions and previously proven theorems is shown. It is believed that the mechanism of reflection is fundamental in building proof development systems, and its power is illustrated with applications to automating reasoning and describing modes of computation.<<ETX>>
[reflected proof, inference rules, object language, references, Poles and towers, hierarchies, proof development systems, reasoning, Reflection, Calculus, library of definitions, semantics, inference mechanisms, classification, Computer languages, modes of computation, metalanguage, Libraries, invocations of programs, theorem proving]
Universal domains in the theory of denotational semantics of programming languages
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
The authors present a categorical generalization of a well-known result in model theory, the Fraisse-Jonsson theorem, by which they characterize large classes of reasonable categories if they contain universal homogeneous objects. As a first application, they derive from this, for various categories of bifinite domains and with embedding-projection pairs as morphisms, the existence and uniqueness of universal homogeneous objects, and they deduce C.A. Gunter and A. Jung's result (see Logic in Computer Science, Comput. Sci. Press, p.309-19 (1988)) from this. Various categories of stable bifinite domains which apparently have not been considered in the literature before are introduced, and universal homogeneous objects for these categories (with stable embedding-projection pairs) are obtained. For four categories of even domains it is shown that although these categories contain universal objects they do not contain universal homogeneous objects. Finally, it is shown that all the constructions can be performed effectively.<<ETX>>
[theory of denotational semantics, model theory, bifinite domains, Lattices, categorical generalization, Fraisse-Jonsson theorem, existence, universal domains, programming languages, morphisms, formal logic, Computer languages, embedding-projection pairs, uniqueness, reasonable categories, Concrete]
A constraint sequent calculus
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
An axiomatic approach that accounts for examples that come up in logic programming, symbolic computation, affine geometry, and elsewhere is presented. It is shown that if disjunction behaves in an intuitionistic fashion, notions of canonical form for positive constraints can be systematically extended to include negative constraints. As a consequence, completeness theorems involving positive and negative constraints can be proven in a general setting for constraint propagation.<<ETX>>
[Logic programming, Terminology, canonical form, Educational institutions, symbolic computation, constraint propagation, Calculus, formal logic, Computer languages, Computational geometry, Presses, axiomatic approach, affine geometry, logic programming, symbol manipulation, Constraint theory, Artificial intelligence, completeness theorems, constraint sequent calculus]
Effective domains and intrinsic structure
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
Topos theory is the categorical analog of constructive set theory; and conveniently, PERs (partial equivalence relations) do sit inside a topos-the category of PERs can be (loosely speaking) identified with the full subcategory of modest sets in Hyland's effective topos. (The effective topos is the topos-theoretic version of recursive realizability.) Working in the effective topos is especially attractive since not only can set-theoretic reasoning be used, but one also has a lot of category-theoretic and topos-theoretic machinery at one's disposal. That is the point of view taken in this research. The basic theory of Sigma -spaces is discussed. A convex power domain is also presented. Modal operators are outlined. Parallelism and sheaves are examined. Finally, the fixed-point classifier is presented.<<ETX>>
[set-theoretic reasoning, modal operators, category-theoretic, parallelism, Mathematics, recursive functions, set theory, Statistics, Machinery, Equations, topos-theoretic, Milling machines, sheaves, fixed-point classifier, effective topos, convex power domain, Set theory, recursive realizability, Logic, partial equivalence relations, category, equivalence classes, Sigma -spaces]
Explicit clock temporal logic
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
The authors present a single exponent decision procedure for the validity of XCTL formulas, and a double exponent decision procedure for the validity of XCTL formulas over finite state programs (model checking). The expressive power of XCTL is compared with that of some other logics proposed for the expression of real time properties. It is shown that it is incomparable with the expressive power of the recently proposed logic TPTL (timed propositional temporal logic).<<ETX>>
[Real time systems, finite automata, program verification, Scattering, temporal logic, explicit clock temporal logic, Mathematics, validity checking, Delay, timed propositional temporal logic, finite state programs, Upper bound, XCTL formulas, model checking, double exponent decision procedure, Timing, single exponent decision procedure, Logic, Clocks, computational complexity]
When is 'partial' adequate? A logic-based proof technique using partial specifications
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A technique is presented for ascertaining when a (finite-state) partial process specification is adequate, in the sense of being specified enough, for contexts in which it is to be used. The method relies on the automatic generation of a modal formula from the partial specification; if the remainder of the network satisfies this formula, then any process that meets the specification is guaranteed to ensure correct behavior of the overall system. Using the results, the authors develop compositional proof rules for establishing the correctness of networks of parallel processes and illustrate their use with several examples.<<ETX>>
[Context, Technological innovation, correctness, logic-based proof technique, compositional proof rules, Calculus, State-space methods, partial specifications, specification adequacy, formal specification, modal formula, Computer science, Concurrent computing, parallel processes, Carbon capture and storage, partial process specification]
Implicit definability on finite structures and unambiguous computations
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
The expressive power and the computational strength of first-order implicit definability on finite structures are studied. It is shown that every fixpoint query is a member of an implicitly definable pair of queries on finite structures. This turns out to be an optimal result, since in addition it is proven that there are natural fixpoint queries that are not implicitly definable on finite structures. First-order implicit definability on ordered finite structures is also investigated, and logical characterization of the complexity class UP intersection coUP is obtained in terms of it, where UP is the class of NP languages accepted by unambiguous Turing machines.<<ETX>>
[Vocabulary, formal languages, Logic programming, finite structures, complexity class, computational strength, optimal result, Computational complexity, implicit definability, expressive power, Interpolation, unambiguous Turing machines, Turing machines, Databases, fixpoint query, logical characterization, unambiguous computations, NP languages, computational complexity]
Conditional lambda-theories and the verification of static properties of programs
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A proof that a simple compiler correctly uses the static properties in its symbol table is presented. This is done by regarding the target code produced by the compiler as a syntactic variant of a lambda -term. In general, this lambda -term C may not be equal to the semantics S of the source program: they need to equal only when information in the symbol table is valid. Rules of inference for conditional lambda -judgements are presented, and their soundness is proven. These rules are then used to prove the correctness of a simple compiler that relies on a symbol table. The form of the proof suggests that such proofs may be largely mechanizable.<<ETX>>
[inference rules, Optimizing compilers, program verification, Induction generators, soundness, conditional lambda theories, Educational institutions, Calculus, symbol table, program compilers, lambda -term, Computer science, Program processors, Runtime, HOAL, induction, syntax directed transducers, higher order abstract assembly languages, static properties, compiler, conditional lambda -judgements]
Equation solving using modal transition systems
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
This research offers as its main contribution a complete treatment of equation solving within process algebra for equation systems of the following form: C/sub 1/(X) approximately P/sub 1/, . . ., C/sub n(X)/ approximately P/sub n/ where C/sub i/ are arbitrary contexts (i.e. derived operators) of some process algebra, P/sub i/ are arbitrary process (i.e. terms of the process algebra), approximately is the bisimulation equivalence, and X is the unknown process to be found (if possible). It is shown that the solution set to this equation may be characterized in terms of a distinctive modal transition system, and that a solution to the above equation systems may be readily extracted (when solutions exist) on this basis. In fact, the results have led to an implementation (in Prolog) of an automatic tool for solving equations in the finite-state case.<<ETX>>
[Transducers, derived operators, arbitrary contexts, finite-state case, Prolog, Mathematics, automatic tool, Equations, Computer science, formal logic, equation solving, modal transition systems, Algebra, process algebra, Bismuth, OFDM modulation, theorem proving, bisimulation equivalence, Carbon capture and storage, equation systems, Context modeling]
A logic of concrete time intervals
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A description is given of: (1) a finite-state model for asynchronous systems in which the time delays between the scheduling and occurrence of the events that cause state changes are constrained to fall between fixed numerical upper and lower time bounds; (2) a branching-time temporal logic suitable for describing the temporal and logical properties of asynchronous systems, for which the structures of (1) are the natural models; and (3) a functional verification system for asynchronous circuits which generates, from a Boolean circuit with general feedback and specified min/max rise and fall times for the gates, a finite-state structure as in (1), and then exhaustively checks a formal specification of that circuit in the language (2) against that finite-state model.<<ETX>>
[State feedback, finite automata, Delay effects, Boolean circuit with general feedback, temporal logic, state diagram generator, concrete time intervals, Inverters, time delays, lower time bounds, formal specification, asynchronous circuits, Asynchronous circuits, Logic circuits, Feedback circuits, scheduling, branching-time temporal logic, functional verification system, Concrete, Timing, Labeling, finite-state model, asynchronous systems]
Model-checking for real-time systems
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
This research extends CTL model-checking to the analysis of real-time systems, whose correctness depends on the magnitudes of the timing delays. For specifications, the syntax of CTL is extended to allow quantitative temporal operators. The formulas of the resulting logic, TCTL, are interpretation over continuous computation trees, trees in which paths are maps from the set of nonnegative reals to system states. To model finite-state systems the notion of timed graphs is introduced-state-transition graphs extended with a mechanism that allows the expression of constant bounds on the delays between the state transition. As the main result, an algorithm is developed for model checking, that is, for determining the truth of a TCTL formula with respect to a timed graph. It is argued that choosing a dense domain, instead of a discrete domain, to model time does not blow up the complexity of the model-checking problem. On the negative side, it is shown that the denseness of the underlying time domain makes TCTL II/sub 1//sup 1/-hard. The question of deciding whether a given TCTL formula is implementable by a timed graph is also undecidable.<<ETX>>
[Real time systems, timed graph, continuous computation trees, Digital systems, finite automata, temporal logic, finite-state systems, Control systems, Delay, timing delays, Tree graphs, Logic, Contracts, quantitative temporal operators, state-transition graphs, CTL model-checking, discrete domain, timed graphs, Computer science, model checking, Computer bugs, real-time systems, delays, TCTL formula, Timing, timed computational tree logic]
Modelling shared state in a shared action model
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
The I/O automation model of N.A. Lynch and M.R. Tuttle (1987) is extended to allow modeling of shared memory systems, as well as systems that include both shared memory and shared action communication. A full range of types of atomic accesses to shared memory is allowed, from basic reads and writes to read-modify-write. The extended model supports system description, verification, and analysis. As an example, E.W. Dijkstra's (1965) classical shared memory mutual exclusion algorithm is presented and proven correct.<<ETX>>
[Out of order, shared action communication, automata theory, Laboratories, read-modify-write, Read-write memory, atomic accesses to shared memory, Computer science, system description, shared memory mutual exclusion algorithm, Message passing, Automata, shared action model, Interleaved codes, shared memory systems, I/O automation model, Safety, Distributed algorithms, Contracts, verification, asynchronous concurrent systems]
Single-threaded polymorphic lambda calculus
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
The primary goal of this study is to devise a method to express mutations to state in a modern (higher order, polymorphic, nonstrict) functional language, without sacrificing referential transparency, and with a simple, easy-to-reason-about semantics. Although collectively these properties seem contradictory, a satisfactory solution is found. Aside from the fundamental property of referential transparency, the two key properties that the authors maximize are simplicity and expressiveness. The system must be easy to use: expressing mutations to state should be natural, and the resulting behavior should be easy to reason about.<<ETX>>
[Process design, referential transparency, formal languages, functional programming, Genetic mutations, high level languages, Calculus, simplicity, High level languages, Programming profession, Computer science, Computer languages, Linearity, functional language, expressiveness, Logic, Functional programming, single-threaded polymorphic lambda calculus]
Three logics for branching bisimulation
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
Three temporal logics are introduced which induce on labeled transition systems the same identifications as branching bisimulation. The first is an extension of Hennessy-Milner logic with a kind of unit operator. The second is another extension of Hennessy-Milner logic which exploits the power of backward modalities. The third is CTL* with the next-time operator interpreted over all paths, not just over maximal ones. A relevant side effect of the last characterization is that it sets a bridge between the state- and event-based approaches to the semantics of concurrent systems.<<ETX>>
[System testing, unit operator, Merging, branching bisimulation, state-based approaches, temporal logics, semantics, backward modalities, Bridges, formal logic, next-time operator, concurrent systems, event-based approaches, Concrete, labeled transition systems, Logic, Labeling, Hennessy-Milner logic]
On the power of bounded concurrency. III. Reasoning about programs
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
For pt.II by T. Hirst and D. Harel see Proc. 15th Coll. Trees in Algebra and programming. Lec. Notes in Comp. Sci., Springer (1990). The difficulty of reasoning about programs is addressed. Specifically, the question of whether the additional succinctness that bounded concurrency provides influences the complexity of reasoning about regular computation sequences on the propositional level is considered. The results concern dynamic, temporal, and process logics, and supply a strongly affirmative answer. In particular, triple-exponential time upper and lower bounds on deciding the validity of propositional dynamic logic with alternating automata enriched with bounded cooperative concurrency, and quadruple-exponential time bounds for deciding validity of branching-time and process logics with such automata are proven. In addition to constituting further evidence for the inherent exponential nature of bounded concurrency, the results appear to provide the first examples of natural decision problems that are elementary and yet have lower bounds that are higher than double-exponential time.<<ETX>>
[triple-exponential time, complexity, Protocols, alternating automata, temporal logic, Mathematics, temporal logics, parallel processing, Research and development, dynamic logics, Concurrent computing, regular computation sequences, quadruple-exponential time bounds, Logic, Computational modeling, propositional dynamic logic, bounded cooperative concurrency, Reasoning about programs, Computer science, bounded concurrency, process logics, Councils, Automata, bounds, reasoning about programs, validity, branching-time, computational complexity]
Reactive, generative, and stratified models of probabilistic processes
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
Reactive, generative, and stratified models are considered within the framework of PCCS, a specification language for probabilistic processes. A structural operational semantics of PCCS, given as a set of inference rules for each of the models, a notion of bisimulation semantics, and some conference proofs are presented.<<ETX>>
[inference rules, probability, PCCS, generative models, conference proofs, Probability distribution, stratified models, inference mechanisms, Concurrent computing, Computer science, formal logic, reactive models, USA Councils, Operating systems, probabilistic processes, bisimulation semantics, Pressing, specification languages, structural operational semantics, specification language]
New foundations for fixpoint computations
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A novel higher-order typed constructive predicate logic for fixpoint computations which exploits the categorical semantics of computations introduced by E. Moggi (1989) and contains a strong version of P. Martin-Lof's (1983) iteration type is introduced. The type system enforces a separation of computations from values. The logic contains a novel form of fixpoint induction and can express partial and total correctness statements about evaluation of computations to values. The constructive nature of the logic is witnessed by strong metalogical properties which are proved using a category-theoretic version of the logical relations method.<<ETX>>
[higher-order typed constructive predicate logic, correctness statements, Laboratories, iteration type, category-theoretic, categorical semantics, Calculus, Equations, formal logic, FIX logical system, fixpoint induction, type system, Logic, logical relations method, fixpoint computations]
The nonexistence of finite axiomatisations for CCS congruences
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
Equatorial axiomatizations for congruences over a simple sublanguage of R. Milner's (1980) process algebra CCS (calculus of communicating systems) are examined. It is shown that no finite set of equational axioms can completely characterize any reasonably defined congruence which is at least as strong as Milner's strong congruence. In the case of strong congruence, this means that the expansion theorem of CCS cannot be replaced by any finite collection of equational axioms. Moreover, the author isolates a source of difficulty in axiomatizing any reasonable noninterleaving semantic congruence, where the expansion theorem fails to hold.<<ETX>>
[formal languages, nonexistence, Calculus, sublanguage, Equations, Concurrent computing, Computer science, formal logic, CCS congruences, calculus of communicating systems, Algebra, process algebra, Writing, finite axiomatisations, noninterleaving semantic congruence, Interleaved codes, theorem proving, Carbon capture and storage, expansion theorem, equational axiomatizations]
Recursive types reduced to inductive types
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
A setting called complete partial ordering (CPO) categories and the notion of dialgebra are described. Free dialgebras on CPO-categories are shown to be the same as minimal invariant objects. In the case that the bifunctor is independent of its contravariant variable (hence construable as a covariant functor), it is shown that minimal invariant objects serve simultaneously as initial algebras and final coalgebras. The reduction to inductive types is shown in a two-step process. First let T be a bifunctor contravariant in its first variable, convariant in the second. For each A it is possible to consider the convariant functor that sends X to TAX. If FA denotes a minimal invariant object of this covariant functor, one for each A, then F becomes a contrainvariant functor. It is shown that the minimal invariant objects of F are minimal invariant objects of the original bifunctor T. Secondly, let T be a contrainvariant functor. It is shown that the square of the functor (necessarily covariant) has the same minimal invariant objects.<<ETX>>
[inductive types, bifunctor, covariant functor, dialgebras, complete partial ordering, CPO-categories, minimal invariant objects, formal logic, Upper bound, Algebra, contravariant variable, initial algebras, data structures, final coalgebras, minimal invariant object]
On the limits of efficient temporal decidability
[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science
None
1990
An analysis is made of the contribution of the temporal operators alone to the complexity of deciding temporal logics by suppressing the role the usual Boolean connectives play in determining lower bounds on the complexity of their decision procedures. Several temporal logics are exhibited which can state many properties useful in describing temporal systems and which restrict combinations of temporal and Boolean operators so as to be decidable in low deterministic polynomial time. It is also shown that relaxing any of the constraints placed on the syntax of these logics results in intractability, thereby demonstrating that there is a fine line separating tractably decidable sets of temporal formulas from intractable ones.<<ETX>>
[temporal operators, complexity, tractably decidable sets, temporal logic, temporal logics, temporal formulas, Boolean connectives, Application software, lower bounds, restricted initialized linear temporal logic, Boolean functions, decidability, satisfiability, restricted branching temporal logic, restricted linear temporal logic, Polynomials, Boolean operators, low deterministic polynomial time, Logic, temporal decidability, Erbium, Contracts, computational complexity]
A foundational delineation of computational feasibility
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A principle directly pertinent to feasibility, which justifies the identification of P-time with feasible computing, is proposed. It is shown that the computable functions justified on the basis of positive quantifier-free comprehension are precisely the functions computable in deterministic polynomial time. This shows that the class P-time arises naturally from a foundational analysis of feasibility, and that terms using exponentiation can be justified as meaningful only under the admission of infinite sets as completed totalities.<<ETX>>
[deterministic polynomial time, Head, Stability, infinite sets, computable functions, H infinity control, feasible computing, positive quantifier-free comprehension, Equations, formal logic, exponentiation, completed totalities, Quantum computing, identification, Automata, computational feasibility, Polynomials, Logic, P-time, Arithmetic, Testing, computational complexity]
Defaults and revision in structured theories
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
Starting from a logic which specifies how to make deductions from a set of sentences (a flat theory), a way to generalize this to a partially ordered bag of sentences (a structured theory) is given. The partial order is used to resolve conflicts. If phi occurs below psi , then psi is accepted only insofar as it does not conflict with phi . The study starts with a language L, a set of interpretations M and a satisfaction relation. The key idea is to define, for each structured theory, a preorder on interpretations. Models of the structured theory are defined to be maximal interpretations in the ordering. A revision operator that takes a structured theory and a sentence and returns a structured theory is defined. The consequence relation has the properties of weak monotonicity, weak cut, and weak reflexivity with respect to this operator, but fails their strong counterparts.<<ETX>>
[weak cut, formal languages, weak reflexivity, weak monotonicity, sentences, Educational institutions, language, Application software, structured theories, deductions, satisfaction relation, revision, formal logic, conflict resolution, maximal interpretations, consequence relation, defaults, flat theory, logic, Logic, partial order, revision operator, preorder]
Logic programs as types for logic programs
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
Optimistic type systems for logic programs are considered. In such systems types are conservative approximations to the success set of the program predicates. The use of logic programs to describe types is proposed. It is argued that this approach unifies the denotational and operational approaches to descriptive type systems and is simpler and more natural than previous approaches. The focus is on the use of unary-predicate programs to describe the types. A proper class of unary-predicate programs is identified, and it is shown that it is expensive enough to express several notions of types. An analogy with two-way automata and a correspondence with alternating algorithms are used to obtain a complexity characterization of type inference and type checking. This characterization is facilitated by the use of logic programs to represent types.<<ETX>>
[logic programs, automata theory, type checking, success set, alternating algorithms, formal logic, Program processors, logic programming, descriptive type systems, complexity characterization, type inference, optimistic type systems, Automatic programming, denotational, Logic programming, program predicates, operational, Logic design, Character recognition, Computational complexity, Programming profession, conservative approximations, Automata, two-way automata, Inference algorithms, Error correction, unary-predicate programs, computational complexity]
A computation model for executable higher-order algebraic specification languages
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
The combination of polymorphically typed lambda-calculi with first-order as well as higher-order rewrite rules is considered. The need of such a combination for exploiting the benefits of algebraically defined data types within functional programming is demonstrated. A general modularity result, which allows as particular cases primitive recursive functionals of higher types, transfinite recursion of higher types, and inheritance for all types, is proved. The class of languages considered is first defined, and it is shown how to reduce the Church-Rosser and termination properties of an algebraic functional language to a so-called principal lemma whose proof depends on the property to be proved and on the language considered. The proof of the principal lemma is then sketched for various languages. The results allow higher order rules defining the higher-order constants by a certain generalization of primitive recursion. A prototype of such primitive recursive definitions if provided by the definition of the map function for lists.<<ETX>>
[functional programming, inheritance, Calculus, formal logic, map function, specification languages, logic programming, polymorphically typed lambda-calculi, rewrite rules, Functional programming, termination properties, rewriting systems, transfinite recursion, formal languages, programming theory, executable higher-order algebraic specification languages, Computational modeling, Church-Rosser, Specification languages, Equations, Computer science, algebraic functional language, primitive recursive functionals, algebraically defined data types, principal lemma, computation model, lists]
Rabin measures and their applications to fairness and automata theory
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
Rabin conditions are a general class of properties of infinite sequences that encompass most known automata-theoretic acceptance conditions and notions of fairness. It is shown how to determine whether a program satisfies a Rabin condition by reasoning about single transitions instead of infinite computations. A concept, a Rabin measure, which in a precise sense expresses progress for each transition towards satisfaction of the Rabin condition, is introduced. When applied to termination problems under fairness constraints, Rabin measures constitute a simpler verification method than previous approaches, which often are syntax-dependent and require recursive applications of proof rules to syntactically transformed programs. Rabin measures also generalize earlier automata-theoretic verification methods. Combined with a result by S. Safra (1988), the result gives a method for proving that a program satisfies a nondeterministic Buchi automaton specification.<<ETX>>
[Rabin condition, fairness constraints, Scholarships, automata theory, infinite sequences, reasoning, Reasoning about programs, verification method, Computer science, formal logic, acceptance conditions, single transitions, Automata, Constraint theory, termination problems, Logic, nondeterministic Buchi automaton specification, Rabin measures]
On the deduction rule and the number of proof lines
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
Proof systems for propositional logic called simple deduction Frege systems, general deduction Frege systems, and nested deduction Frege systems, which augment Frege systems with variants of the deduction rule, are introduced. Upper bounds are given on the lengths of proofs in these systems compared to lengths in Frege proof systems. As an application, a near-linear simulation of the propositional Gentzen sequent calculus by Frege proofs is presented. It is shown that a general deduction Frege proof system provides at most quadratic speedup over Frege proof systems. A nested deduction Frege proof system provides at most quadratic speedup over Frege proof systems. A nested deduction Frege proof system provides at most a nearly linear speedup over Frege systems where by 'nearly linear' is meant that the ratio of proof lengths is O( alpha (n)), where alpha is the inverse Ackermann function. A nested deduction Frege system can linearly simulate the propositional sequent calculus, and hence a Frege proof system can simulate the propositional sequent calculus with proof lengths bounded by O(n alpha (n)). As a technical tool, the serial transitive closure problem is introduced. Given a directed graph and a list of closure edges in the transitive closure of the graph, the problem is to derive all the closure edges. A nearly linear bound is given on the number of steps in such a derivation when the graph is treelike.<<ETX>>
[nested deduction Frege systems, general deduction Frege systems, propositional logic, Length measurement, upper bounds, Calculus, Mathematics, serial transitive closure problem, formal logic, Tree graphs, deduction rule, inverse Ackermann function, directed graph, logic programming, linear bound, Polynomials, Logic, Velocity measurement, propositional Gentzen sequent calculus, quadratic speedup, proof lengths, Frege proof systems, proof lines, closure edges, Upper bound, simple deduction Frege systems, Artificial intelligence, computational complexity]
Logic programming in a fragment of intuitionistic linear logic
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
The intuitionistic notion of context is refined by using a fragment of J.-Y. Girard's (Theor. Comput. Sci., vol.50, p.1-102, 1987) linear logic that includes additive and multiplicative conjunction, linear implication, universal quantification, the of course exponential, and the constants for the empty context and for the erasing contexts. It is shown that the logic has a goal-directed interpretation. It is also shown that the nondeterminism that results from the need to split contexts in order to prove a multiplicative conjunction can be handled by viewing proof search as a process that takes a context, consumes part of it, and returns the rest (to be consumed elsewhere). Examples taken from theorem proving, natural language parsing, and database programming are presented: each example requires a linear, rather than intuitionistic, notion of context to be modeled adequately.<<ETX>>
[Logic programming, multiplicative conjunction, empty context, additive conjunction, intuitionistic linear logic, Natural languages, Linear programming, proof search, natural language parsing, Specification languages, Computer science, formal logic, of course exponential, Databases, erasing contexts, database programming, logic programming, context, linear implication, goal directed logic, theorem proving, universal quantification, Context modeling, nondeterminism]
A partial approach to model checking
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A model-checking method for linear-time temporal logic that avoids the state explosion due to the modeling of concurrency by interleaving is presented. The method relies on the concept of the Mazurkiewicz trace as a semantic basis and uses automata-theoretic techniques, including automata that operate on words of ordinality higher than omega . In particular, automata operating on words of length omega *n, n in omega are defined. These automata are studied, and an efficient algorithm to check whether such automata are nonempty is given. It is shown that when it is viewed as an omega *n automaton, the trace automaton can be substituted for the production automaton in linear-time model checking. The efficiency of the method of P. Godefroid (Proc. Workshop on Computer Aided Verification, 1990) is thus fully available for model checking.<<ETX>>
[Costs, automata theory, semantic basis, trace automaton, temporal logic, Probabilistic logic, Explosions, Logic design, concurrency modelling, linear-time model checking, interleaving, Mazurkiewicz trace, production automaton, Concurrent computing, words of ordinality, Automata, Aging, Interleaved codes, linear-time temporal logic]
Higher-order critical pairs
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A subclass of lambda -terms, called patterns, which have unification properties resembling those of first-order terms, is introduced. Higher-order rewrite systems are defined to be rewrite systems over lambda -terms whose left-hand sides are patterns: this guarantees that the rewrite relation is easily computable. The notion of critical pair is generalized to higher-order rewrite systems, and the analog of the critical pair lemma is proved. The restricted nature of patterns is instrumental in obtaining these results. The critical pair lemma is applied to a number of lambda -calculi and some first-order logic formalized by higher-order rewrite systems.<<ETX>>
[rewrite relation, System testing, rewriting systems, Terminology, Instruments, first-order logic, patterns, lambda -calculi, Equations, first-order terms, Postal services, formal logic, higher-order rewrite systems, lambda -terms, critical pair, Logic, left-hand sides, unification properties]
Partial objects in the calculus of constructions
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A typed framework for working with nonterminating computations is provided. The basic system is the calculus of constructions. It is extended using an original idea proposed by R. Constable and S.F. Smith (2nd Ann. IEEE Conf. on Logic in Comput. Sci., 1987) and implemented in Nuprl. From the computational point of view, an equivalent of the Kleene theorem for partial recursive functions over the integers within an index-free setting is obtained. A larger class of algebraic types is defined. Logical aspects need more examination, but a syntactic method for dealing with partial and total objects, leading to the notion of generic proof, is provided.<<ETX>>
[Nuprl, nonterminating computations, Kleene theorem, Calculus, partial objects, index-free setting, Convergence, integers, formal logic, algebraic types, calculus of constructions, partial recursive functions, Functional programming, Network address translation, Arithmetic, generic proof]
On the 0-1 law for the class of existential second order minimal Godel sentences with equality
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
It is proved that the 0-1 law does not hold for the class of existential second sentences whose first order part is in the minimal Godel class, i.e. has the quantifier prenex consisting of two universal quantifiers followed by just one existential quantifier. This completes the classification of existential second order sentences for which the 0-1 law holds. It is also proved that asymptotic probabilities of sentences as above form a dense subset of the unit interval.<<ETX>>
[0-1 law, existential second order minimal Godel sentences, dense subset, Mathematics, prenex, universal quantifiers, classification, existential quantifier, formal logic, unit interval, asymptotic probabilities, first order part, Logic, equality]
An inverse of the evaluation functional for typed lambda -calculus
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A functional p to e (procedure to expression) that inverts the evaluation functional for typed lambda -terms in any model of typed lambda -calculus containing some basic arithmetic is defined. Combined with the evaluation functional, p to e yields an efficient normalization algorithm. The method is extended to lambda -calculi with constants and is used to normalize (the lambda -representations of) natural deduction proofs of (higher order) arithmetic. A consequence of theoretical interest is a strong completeness theorem for beta eta -reduction. If two lambda -terms have the same value in some model containing representations of the primitive recursive functions (of level 1) then they are probably equal in the beta eta -calculus.<<ETX>>
[inverse, completeness theorem, typed lambda -terms, lambda -calculi, Calculus, normalization algorithm, recursive functions, formal logic, Computer languages, natural deduction proofs, evaluation functional, typed lambda -calculus, constants, Arithmetic]
Term declaration logic and generalised composita
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A generalization of a version of order-sorted logic and an abstract axiomatic setting for the treatment of substitution are given. The two ideas are shown to be related, an equational specification of term declaration logic being a presentation of a finitary generalized composition. The automatic approach to substitution is compared with some other approaches. The relationship between algebraic theories and standard equational logic is reviewed. One of the aims is to lay the foundations for a generalization of these connections to connections between term declaration logic and finitary generalized composita and a suitable generalization of algebraic theories.<<ETX>>
[substitution, abstract axiomatic setting, Mathematics, order-sorted logic, term declaration logic, Equations, Computer science, formal logic, Algebra, generalised composita, Logic functions, equational logic, equational specification, algebraic theories]
A compositional proof system for dynamic process creation
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A compositional proof systems for a parallel language, P, with dynamic process creation is presented. It is shown how a dynamic system of processes can be described in terms of specifications of the local processes which involve a characterization of their interface with the environment. The proof system formalizes reasoning about these interfaces on an abstraction level that is at least as high as that of the programming language. The programming language P is described, and two assertion languages, the local one and the global one, are defined. The proof system is described and its soundness and completeness are discussed.<<ETX>>
[assertion languages, compositional proof system, reasoning, Topology, History, inference mechanisms, dynamic system, specifications, Concurrent computing, formal logic, Computer languages, dynamic process creation, parallel language, local processes, logic programming, programming language, Object oriented programming, parallel languages, Testing]
Constructive negation for constraint logic programming
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
Constructive negation is an extension of the negation as failure rule to handle nonground negative subgoals in a constructive manner. It entails the following procedure: nodes of the subderivation for the nonground negative subgoal are collected as a disjunction and negated giving a formula equivalent to the negative subgoal. Constructive negation was formulated for logic programming in the Herbrand universe by introducing disequality constraints. A framework for constructive negation for constraint logic programming over arbitrary structures that is sound and complete with respect to the three-valued consequences of the completion of a program is described, and a simpler, more efficient form of constructive negation for the Herbrand universe is obtained. What makes a structure particularly suited to the use of constructive negation is characterized, and this suitability condition is shown for a number of structures and classes of structures.<<ETX>>
[suitability condition, Logic programming, Grounding, negation as failure rule, constructive negation, disjunction, three-valued consequences, Equations, Computer science, formal logic, subderivation, nodes, disequality constraints, logic programming, constraint logic programming, nonground negative subgoals, Impedance, Herbrand universe]
Specifying and proving serializability in temporal logic
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
Serializability of database transactions is first defined within the framework of linear temporal logic. For commutativity-based serializability, an alternative specification is given in a temporal logic whose semantic interpretation is especially tailored for reasoning about equivalence sequences of histories. The alternative specification method is given in ISTL* and is limited to the specification of concurrency control algorithms based on commutativity. A formal verification system for serializability that uses classical logic reasoning is provided. Within it, proving serializability of transactions executing a concurrency control algorithm is done along the same lines as proving properties of concurrent programs. Serializability for the multiversion-timestamp algorithm is verified.<<ETX>>
[Atomic measurements, multiversion-timestamp algorithm, Protocols, commutativity-based serializability, ISTL*, Interference, temporal logic, linear temporal logic, Concurrency control, histories, Transaction databases, History, concurrent programs, database theory, semantic interpretation, Computer science, formal verification, concurrency control algorithms, equivalence sequences, Database systems, classical logic reasoning, Logic, database transactions, Formal verification]
Freyd's hierarchy of combinator monoids
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
The Freyd hierarchy of monoids is introduced. The Freyd hierarchy is a fragment of type-free combinatory algebra lambda -calculus that has some remarkable properties, some of which are presented. One result characterizes the combinators in the hierarchy in terms of some simple ideas from the theory of rewrite rules. The computational/expressive power of the fragment is studied. This includes not only the functions computable by the combinators but also the varieties definable by combinator equations. Certain extraordinary connections between the lowest level of the hierarchy, combinatorics, and topology are also included.<<ETX>>
[rewriting systems, combinatorial mathematics, topology, Calculus, Topology, Combinatorial mathematics, Equations, formal logic, group theory, lambda -calculus, Algebra, Education, Resists, rewrite rules, combinator monoids, Freyd hierarchy, type-free combinatory algebra, combinatorics]
The fixed point property in synthetic domain theory
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
An elementary axiomatization of synthetic domain theory is presented, and it is shown that it is sufficient to deduce the fixed point property and solve domain equations. The aim is to show that an important theorem can be derived from an abstract axiomatization, rather than from a particular model. Also, by providing a common framework in which both PER and classical models can be expressed, this work builds a bridge between the two.<<ETX>>
[Performance evaluation, Integrated circuit synthesis, Educational institutions, classical models, Equations, Bridges, formal logic, Filters, domain equations, synthetic domain theory, fixed point property, PER, Testing]
Unification and anti-unification in the calculus of constructions
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
Algorithms for unification and anti-unification in the calculus of constructions, where occurrences of free variables (the variables subject to instantiation) are restricted to higher-order patterns, are presented. Most general unifiers and least common anti-instances are shown to exist and are unique up to a simple equivalence. The unification algorithm is used for logic program execution and type and term reconstruction in the current implementation of Elf and has shown itself to be practical.<<ETX>>
[unification algorithm, Logic programming, Terminology, free variables, Calculus, Computer science, formal logic, Computer languages, logic program execution, anti-instances, term reconstruction, anti-unification, calculus of constructions, logic programming, Internet, Artificial intelligence, Elf]
Semantics of pointers, referencing and dereferencing with intensional logic
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
Intensional logic is applied to the semantics of an Algol-like programming language. This approach associates with expressions their senses, or meanings relative to possible worlds, here interpreted as machine states. These meanings lie in the semantic domains of a higher order typed intensional logic. The advantage of the approach is that it preserves compositionality of the meaning function, even in opaque contexts. This study extends earlier work in this direction, by T.M.V. Janssen and P. Van Emde Boas (1977), to pointers, including dereferenced pointers on both sides of assignments. It is shown how this approach gives an elegant solution to the problem of pointer semantics which is simple, compositional, and implementation independent.<<ETX>>
[referencing, programming theory, Logic programming, senses, Calculus, dereferencing, semantics, expressions, meanings, Computer science, formal logic, Computer languages, Algol-like programming language, Councils, intensional logic, Packaging, logic programming, machine states, Functional programming, pointers]
Actions speak louder than words: proving bisimilarity for context-free processes
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
J.C.M. Baeten et al. (Lecture Notes in Computer Science, vol. 259, pp. 93-114, 1987) proved that bisimulation equivalence is decidable for irredundant context-free grammars. A much simpler and much more direct proof of this result is provided now. It uses a tableau decision method involving goal-directed rules. The decision procedure yields an upper bound on a tableau depth. Moreover, it provides the essential part of the bisimulation relation between two processes which underlies their equivalence. A second virtue is that it provides a sound and complete equational theory for such processes.<<ETX>>
[decidable, formal languages, Design methodology, Laboratories, tableau depth, upper bound, Calculus, tableau decision method, Equations, bisimilarity, Computer science, formal logic, Upper bound, context-free processes, equational theory, Algebra, decision procedure, Production, logic programming, context-free grammars, bisimulation equivalence, irredundant context-free grammars, goal-directed rules, Context modeling]
A first-order theory of types and polymorphism in logic programming
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A logic called typed predicate calculus (TPC) that gives declarative meaning to logic programs with type declarations and type inference is introduced. The proper interaction between parametric and inclusion varieties of polymorphism is achieved through a construct called type dependency, which is analogous to implication types but yields more natural and succinct specifications. Unlike other proposals where typing has extra-logical status, in TPC the notion of type-correctness has precise model-theoretic meaning that is independent of any specific type-checking or type-inference procedure. Moreover, many different approaches to typing that were proposed in the past can be studied and compared within the framework of TPC. Another novel feature of TPC is its reflexivity with respect to type declarations; in TPC, these declarations can be queried the same way as any other data. Type reflexivity is useful for browsing knowledge bases and, potentially, for debugging logic programs.<<ETX>>
[type-correctness, Proposals, Jacobian matrices, formal logic, parametric polymorphism, Program processors, knowledge bases, typed predicate calculus, logic programming, debugging, implication types, Protection, type inference, type dependency, browsing, Logic programming, first-order theory, type reflexivity, Debugging, inference mechanisms, Computer science, Inference algorithms, inclusion polymorphism, declarative meaning, type declarations]
Specification and refinement of probabilistic processes
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A formalism for specifying probabilistic transition systems, which constitute a basic semantic model for description and analysis of, e.g. reliability aspects of concurrent and distributed systems, is presented. The formalism itself is based on transition systems. Roughly a specification has the form of a transition system in which transitions are labeled by sets of allowed probabilities. A satisfaction relation between processes and specifications that generalizes probabilistic bisimulation equivalence is defined. It is shown that it is analogous to the extension from processes to modal transition systems given by K. Larsen and B. Thomsen (1988). Another weaker criterion views a specification as defining a set of probabilistic processes; refinement is then simply containment between sets of processes. A complete method for verifying containment between specifications, which extends methods for deciding containment between specifications, which extends methods for deciding containment between finite automata or tree acceptors, is presented.<<ETX>>
[Protocols, finite automata, probabilistic transition systems, probabilistic logic, allowed probabilities sets, reliability, Mathematics, Telecommunication computing, Electronic mail, probabilistic bisimulation equivalence, semantic model, satisfaction relation, Computer science, concurrent systems, probabilistic processes, Pressing, specification formalism, distributed systems, tree acceptors, Logic, Contracts]
Games semantics for linear logic
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
An attempt is made to relate various notions of duality used in mathematics with the denotational semantics of linear logic. The author proposes a naive semantics for linear logic that, in a certain sense, generalizes various notions such as finite-dimensional vector spaces, topological spaces, and J.-Y. Girard's (1987) coherence spaces. A game consists of a set of vectors (or strategies), a set of forms (or co-strategies) and an evaluation bracket. This is enough to interpret the connectives of full propositional linear logic, including exponentials.<<ETX>>
[mathematics, propositional linear logic, co-strategies, games semantics, Concurrent computing, formal logic, evaluation bracket, topological spaces, duality (mathematics), Logic, Books, denotational semantics, strategies, game theory, Vectors, finite-dimensional vector spaces, Game theory, duality, naive semantics, Equations, Linearity, Linear algebra, System recovery, exponentials, forms, coherence spaces]
An evaluation semantics for classical proofs
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
It is shown how to interpret classical proofs as programs in a way that agrees with the well-known treatment of constructive proofs as programs and moreover extends it to give a computational meaning to proofs claiming the existence of a value satisfying a recursive predicate. The method turns out to be equivalent to H. Friedman's (Lecture Notes in Mathematics, vol.699, p.21-28, 1978) proof by A-transition of the conservative extension of classical cover constructive arithmetic for II/sub 2//sup 0/ sentences. It is shown that Friedman's result is a proof-theoretic version of a semantics-preserving CPS-translation from a nonfunctional programming language back to a functional programming language. A sound evaluation semantics for proofs in classical number theory (PA) of such sentences is presented as a modification of the standard semantics for proofs in constructive number theory (HA). The results soundly extend the proofs-as-programs paradigm to classical logics and to programs with the control operator, C.<<ETX>>
[proofs-as-programs paradigm, Logic programming, classical cover constructive arithmetic, semantics-preserving CPS-translation, recursive predicate, constructive number theory, Computer science, formal logic, Computer languages, evaluation semantics, classical logics, functional programming language, control operator, logic programming, conservative extension, nonfunctional programming language, Functional programming, classical proofs, classical number theory, constructive proofs, Arithmetic]
A completeness theorem for Kleene algebras and the algebra of regular events
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A finitary axiomatization of the algebra of regular events involving only equations and equational implications that is sound for all interpretations over Kleene algebras is given. Axioms for Kleene algebra are presented, and some basic consequences are derived. Matrices over a Kleene algebra are considered. The notion of an automaton over an arbitrary Kleen algebra is defined and used to derive the classical results of the theory of finite automata as a result of the axioms. The completeness of the axioms for the algebra of regular events is treated. Open problems are indicated.<<ETX>>
[Algorithm design and analysis, Modular construction, finite automata, completeness theorem, Formal languages, Logic design, Equations, regular events, Computer science, formal logic, Kleene algebras, Algebra, Automata, Logic functions, Books, matrices]
Equational programming in lambda -calculus
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A system of equations in lambda -calculus is a pair ( Gamma , X) where Gamma is a set of formulas of Lambda (the equations) and X is a finite set of variables of Lambda (the unknowns). A system S=( Gamma , X) is said to be solvable in the theory T (T-solvable) if there exists a simultaneous substitution with closed lambda -terms for the unknowns that makes the formulas of Gamma theorems in the theory T. A class of systems for which the beta -solvability problem is decidable in polynomial time is defined. This class yields an equational programming language in which constraints on the code generated by the compiler can be specified by the user and (properties of) data structures can be described in an abstract way.<<ETX>>
[decidable, Automatic programming, unknowns, Data structures, Calculus, Mathematics, Equations, formal logic, equations, Computer languages, Program processors, lambda -calculus, decidability, equational programming language, logic programming, closed lambda -terms, Polynomials, polynomial time, data structures, simultaneous substitution, Functional programming, compiler, beta -solvability problem, computational complexity]
On computational open-endedness in Martin-Lof's type theory
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
Computational open-endedness in a type theory is defined as the property that theorems remain true under extensions to the underlying programming language. Some properties related to open-endedness that are relevant to machine implementations of type theory are established. A class of computation systems, specified by a simple but fairly general kind of structural operational semantics, with respect to which P. Martin-Lof's (6th Int. Congress for Logic, Methodology, and Philosophy of Science, p.153-175, 1982) type theory (and most of its descendants) is open-ended is defined. It is shown that any such system validates a useful form of type free reasoning about program equivalence and that symbolic computation procedures can be automatically derived from these specifications. The main result is the definition of a particular computation system that includes a collection of oracles sufficient to provide a classical semantics for Martin-Lof's type theory in which the excluded middle law holds.<<ETX>>
[excluded middle, computational open-endedness, Reasoning about programs, symbolic computation, type theory, Computer science, formal logic, Computer languages, computation systems, type free reasoning, program equivalence, oracles, structural operational semantics, programming language, Contracts]
Sequentiality and strong stability
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
It is shown that Kahn-Plotkin sequentiality can be expressed by a preservation property similar to stability and that this kind of generalized stability can be extended to higher order. The main result is the construction of a model where all morphisms are functions and, at ground types, these functions are sequential.<<ETX>>
[formal logic, Computer languages, Kahn-Plotkin sequentiality, Stability, strong stability, ground types, Switches, Coherence, preservation property, morphisms]
Toward a semantics for the QUEST language
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A model is given for the second-order lambda calculus extended with inheritance, bounded quantification, recursive types, constructors and kinds. This language, called mu -FunK, can be viewed as the core of the QUEST language defined by L. Cardelli (SRC Rep. 45, 1989). Types are interpreted as intervals of partial equivalence relations. Because of the properties of intervals and their ordering, all the type constructors are continuous functions. As a consequence a system where a kind is given to each constructor constant employed can be modeled. In such a model the meaning of operator mu , the constructor of recursive types, turns out to be just the minimal fixed-point operator.<<ETX>>
[formal languages, Object oriented modeling, recursive types, inheritance, Calculus, kinds, continuous functions, semantics, bounded quantification, mu -FunK, Computer science, formal logic, constructors, Runtime, minimal fixed-point operator, second-order lambda calculus, QUEST language, partial equivalence relations, Object oriented programming]
On the relationship between process algebra and input/output automata
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
The relationship between process algebra and input/output (I/O) automata models is investigated in a general setting of structured operational semantics. For a series of (approximations of) key properties of I/O automata, syntactic constraints on inference rules that guarantee these properties are proposed. A first result is that in a setting without assumptions about actions, trace and failure preorders are substitutive for any set of rules in a format due to R. de Simone (thesis, Univ. of Paris, 1984). Next, additional constraints that capture the notion of internal actions and guarantee substitutivity of the testing preorders of R. De Nicola and M. Hennessy (1984) and also of a preorder related to the failure semantics with fair abstraction of unstable divergence of J.A. Bergstra et al. (1988) are imposed. Subsequent constraints guarantee that input actions are always enabled and output actions cannot be blocked, two key features of I/O automata. The main result is that for any I/O calculus, i.e. a de Simone calculus that combines the constraints for internal, input and output actions, the quiescent trace preorder and the fair trace preorder are substitutive.<<ETX>>
[Protocols, automata theory, Laboratories, Control systems, Calculus, I/O automata, fair trace preorder, formal logic, Algebra, structured operational semantics, input/output automata, Automatic control, logic programming, failure semantics, syntactic constraints, Contracts, Testing, internal actions, quiescent trace preorder, inference rules, de Simone calculus, inference mechanisms, Computer science, process algebra, Automata]
Prop revisited: propositional formula as abstract domain for groundness analysis
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
The abstract domain Prop for analyzing variable groundness in logic programs is considered. This domain consists of (equivalence classes of) propositional formulas whose propositional variables correspond to program variables with truth assignments indicating which program variables are ground. Some ambiguity remains about precisely which formula should be included in Prop so that all interesting sets of program execution states (substitutions) have a unique representation. This ambiguity is clarified by characterizing, both semantically and syntactically, the appropriate definition of Prop. The use of propositional formulas for representing properties of substitutions of a different type than groundness, such as freeness and independence of variables, is discussed.<<ETX>>
[logic programs, Optimizing compilers, groundness analysis, abstract domain, Mathematics, propositional variables, independence, formal logic, Analytical models, variable groundness, substitutions, logic programming, freeness, Safety, propositional formula, Logic, Grounding, Prop, program variables, program execution states, Equations, Computer science, truth assignments, Concrete, equivalence classes]
Linearizing intuitionistic implication
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
An embedding of the implicational propositional intuitionistic logic (IIL) into the nonmodal fragment of intuitionistic linear logic (IMALL) is given. The embedding preserves cut-free proofs in a proof system that is a variant of IIL. The embedding is efficient and provides an alternative proof of the PSPACE-hardness of IMALL. It exploits several proof-theoretic properties of intuitionistic implication that analyze the use of resources in IIL proofs.<<ETX>>
[Availability, Embedded computing, cut-free proofs, intuitionistic linear logic, proof system, Laboratories, intuitionistic implication, Mathematics, Calculus, nonmodal fragment, Helium, implicational propositional intuitionistic logic, Computer science, formal logic, PSPACE-hardness, Ear, Logic]
A theory of testing for real-time
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A framework for generating testing preorders that relate processes on the basis of their timing behavior as well as their degree of relative nondeterminism is developed. The basic concepts of transition systems and testing are reviewed, and timed testing, which takes account of the delay exhibited by a process as it attempts to pass a test, is introduced. The framework is then applied to two different scenarios. In the first, relations are constructed that relate processes on the basis of all timing considerations. In the second, relations are constructed that relate processes on the basis of their relative speeds. In both cases, alternative denotational characterizations of the resulting preorders are presented, and examples are given to illustrate the utility of the approach.<<ETX>>
[Real time systems, System testing, Protocols, Process control, Licenses, timed testing, Delay, Computer science, formal logic, timing behavior, Algebra, real-time, Character generation, testing theory, transition systems, Timing, testing preorders, nondeterminism]
On first order database query languages
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
Using methods from model theory, the authors construct algorithms that, given any first-order predicate calculus query over a finite database, determine if they have a finite number of solutions or not, and if they do, list them all. This is done for languages that include function names (but no symbols for infinite relations) and for languages that include a name for the order of natural number or for the prefix order in a domain of strings over some alphabet (but no function symbols). The results prove some conjectures of M. Kiffer (Proc. Int. Conf. on Databases and Knowledge Bases, 1988, p.405-415).<<ETX>>
[algorithms, prefix order, formal languages, model theory, function names, Relational databases, query languages, Calculus, Electronic mail, alphabet, first order database query languages, Database languages, database theory, formal logic, finite database, natural number, Mathematical model, Logic, first-order predicate calculus query]
Predictive type universes and primitive recursion
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A category-theoretic explanation of predicative type universes and primitive recursion on them is given. Categories with display maps (cdm) (with canonical pullbacks) are used to model families. A slight generalization of an algebra, called an I-algebra, is given. Primitive recursion is defined, and the general definition of primitive recursion on a cdm which can justify the elimination rules for all the usual inductively defined datatypes, including universes, as an instance, is given. It is shown how operations may be reflected, allowing an I-algebra to be closed under type-forming operations. Universe hierarchies are built: an externally constructed one, and then a large type universe, itself closed under universe construction, in which universe hierarchies can be internally constructed. As an example, a hierarchy up to omega is constructed.<<ETX>>
[primitive recursion, predicative type universes, type-forming operations, Predictive models, Displays, elimination rules, explanation, families, formal logic, Equalizers, Algebra, universe hierarchies, Chromium, Writing, category theory, display maps, canonical pullbacks, I-algebra, inductively defined datatypes]
Parallel PCF has a unique extensional model
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
It is shown that the continuous function model is the unique extensional (but not necessarily pointwise ordered) model of the variant of the applied typed lambda calculus PCF that includes the parallel or operation. It is also shown that parallel PCF does not have extensional models that are not inequationally fully abstract or not even equationally fully abstract or extensional models that are not order-extensional.<<ETX>>
[Computer science, formal logic, parallel or operation, Algebra, parallel PCF, applied typed lambda calculus, Calculus, Logic, continuous function model, Artificial intelligence, Equations, unique extensional model]
Some results on the interpretation of lambda -calculus in operator algebras
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
J.-Y. Girard (Proc. ASL Meeting, 1988) proposed an interpretation of second order lambda -calculus in a C algebra and showed that the interpretation of a term is a nilpotent operator. By extending to untyped lambda -calculus the functional analysis interpretation for typed lambda -terms, V. Danos (Proc. 3rd Italian Conf. on Theor. Comput. Sci., 1989) showed that all and only strongly normalizable terms are interpreted by nilpotent operators; in particular all and only nonstrongly normalizable terms are interpreted by infinite sums of operators. It is shown that interpretation of lambda -terms always makes sense, by showing that lambda -terms are interpreted by weakly nilpotent operators in the sense of Girard. This result is obtained as a corollary of an aperiodicity property of execution of lambda -terms, which seems to be related to some basic property of environment machines.<<ETX>>
[Solid modeling, Computational modeling, typed lambda -terms, Calculus, Geometry, formal logic, Algebra, Tree graphs, second order lambda -calculus, interpretation, environment machines, operator algebras, untyped lambda -calculus, C algebra, nilpotent operator, Logic, Standards development, functional analysis interpretation]
Complexity bounds of Hoare-style proof systems
[1991] Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science
None
1991
A refinement of the result that there is no sound and relatively complete proof system for a programming language if its partial correctness theory is undecidable even in finite interpretations is presented. By taking into account the computational complexity of this problem, information about structural properties of proof systems for a given programming language is obtained. The key in the proofs is the notion of an interpretation independent proof system. It is shown that ordinary systems are interpretation independent, but that such systems are limited in their power. It is proven that they can deal successfully only with assertions whose sets of finite models are in NPTIME. Some assertions about programs from E.M. Clarke's (1979) language L4 have a more complex (but still decidable) set of finite models. This substantiates why it was difficult to give a satisfactory proof system for this language. The author explains which features of Clarke's proof system allow problems of such complexity to be treated.<<ETX>>
[Formal languages, interpretation independent proof system, NPTIME, L4, Encoding, Power system modeling, Computational complexity, Hoare-style proof systems, Computer science, formal logic, Computer languages, undecidable, finite interpretations, partial correctness theory, programming language, finite models, computational complexity]
Specifications in software development
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
Summary form only given. Various kinds of specifications used during software development are presented through examples. The focus is on the practical aspects of the nature and use of formal specifications. Some open research problems that should be of particular interest are mentioned.<<ETX>>
[Algebra, software development, Government, Logic, Artificial intelligence, formal specification, formal specifications, Programming profession]
Third order matching is decidable
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The problem of determining whether a term is an instance of another in the simply typed lambda -calculus, i.e. of solving the equation a=b where a and b are simply typed lambda -terms and b is ground, is addressed. An algorithm that decides whether a matching problem in which all the variables are at most third order has a solution is given. The main idea is that if the problem a=b has a solution, then it also has a solution whose depth is bounded by some integer s depending only on the problem a=b, so a simple enumeration of the substitutions whose depth is bounded by s gives a decision algorithm. This result can also be used to bound the depth of the search tree in Huet's semi-decision algorithm and thus to turn it into an always-terminating algorithm. The problems that occur in trying to generalize the proof given to higher-order matching are discussed.<<ETX>>
[Computer science, decidable, search tree, decidability, Ducts, algorithm theory, matching problem, always-terminating algorithm, Huet's semi-decision algorithm, Equations, Pattern matching, third order matching]
Retracts in simply type lambda beta eta -calculus
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
Retractions existing in all models of simply typed lambda -calculus are studied and related to other relations among types, such as isomorphisms, surjections, and injections. A formal system to deduce the existence of such retractions is shown to be sound and complete with respect to retractions definable by linear lambda -terms. Results aiming at a system complete with respect to the provable retractions tout court are established.<<ETX>>
[injections, lambda calculus, Time of arrival estimation, formal system, type lambda beta eta -calculus, Mathematics, Remuneration, linear lambda -terms, formal logic, lambda -calculus, isomorphisms, Ear, data structures, surjections, Virtual manufacturing, Mathematical model]
The Church-Rosser property for beta eta -reduction in typed lambda -calculi
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The Church-Rosser property (CR) for pure type systems with beta eta -reduction is investigated. It is proved that CR (for beta eta ) on the well-typed terms of a fixed type holds, which is the maximum one can expect in view of Nederpelt's (1973) counterexample. The proof is given for a large class of pure type systems that contains, e.g., LF F, F omega , and the calculus of constructions.<<ETX>>
[lambda calculus, pure type systems, Time of arrival estimation, Calculus, Mathematics, typed lambda -calculi, Computer science, formal logic, Reactive power, Lapping, Church-Rosser property, beta eta -reduction, calculus of constructions, Chromium, data structures]
Decidable problems in shallow equational theories
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
Results for syntactic theories are generalized to shallow theories. The main technique used is the computation by ordered completion techniques of conservative extensions of the starting shallow presentation which are, respectively, ground convergent, syntactic, and cycle-syntactic. In all cases, the property that variables occur at depth at most one appears to be crucial. shallow theories thus emerge as a fundamental nontrivial, union-closed subclass of equational theories for which all important questions are decidable.<<ETX>>
[ordered completion, shallow equational theories, syntactic, Algebra, decidability, ground convergent, equational theories, cycle-syntactic, Equations, syntactic theories]
Functional parametricity
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The authors consider the idea of treating a parametrized type as an arbitrary functor from some parametrizing category to a category of types, and giving elements semantics as natural transformations. They show that under reasonable hypotheses this is only possible when the parametrizing category is a groupoid. This suggests a semantics for a semiparametric form of polymorphism. They discuss the interpretation of this form of parametricity in a PER model, and show that it coincides with the ostensibly stronger form derived from dinaturality.<<ETX>>
[group theory, programming theory, groupoid, PER model, elements semantics, natural transformations, data structures, data types, parametrized type, polymorphism, parametrizing category, Context modeling]
Deterministic vs. nondeterministic transitive closure logic
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
It is shown that transitive closure logic (FO+TC) is strictly more powerful than deterministic transitive closure logic (FO+DTC) on unordered structures. In fact, on certain classes of graphs, such as hypercubes or regular graphs of large degree and girth, every query in (FO+DTC) is first-order expressible. On the other hand, there are simple (FO+pos TC) queries on these classes that cannot be defined by first-order formulas.<<ETX>>
[formal logic, Microwave integrated circuits, graphs, Turing machines, transitive closure logic, graph theory, query, Hypercubes, hypercubes, Logic, Database languages, computational complexity]
The lazy lambda calculus in a concurrency scenario
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The use of lambda calculus in richer settings, possibly involving parallelism, is examined in terms of its effect on the equivalence between lambda terms, focusing on S. Abramsky's (Ph.D thesis, Univ. of London, 1987) lazy lambda calculus. First, the lambda calculus is studied within a process calculus by examining the equivalence induced by R. Milner's (1992) encoding into the pi -calculus. Exact operational and denotational characterizations for this equivalence are given. Second, Abramsky's applicative bisimulation is examined when the lambda calculus is augmented with (well-formed) operators, i.e. symbols equipped with reduction rules describing their behavior. Then, maximal discrimination is obtained when all operators are considered; it is shown that this discrimination coincides with the one given by the above equivalence and that the adoption of certain nondeterministic operators is sufficient and necessary to induce it.<<ETX>>
[lambda calculus, bisimulation, equivalence, nondeterministic operators, parallelism, Calculus, Encoding, parallel programming, concurrency, Concurrent computing, Computer science, formal logic, Computer languages, lazy lambda calculus, concurrency control, Parallel processing, discrimination, Functional programming, equivalence classes, Testing]
Origins of the calculus of binary relations
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The genesis of the calculus of binary relations, which was introduced by A. De Morgan (1860) and was subsequently greatly developed by C.S. Peirce (1933) and E. Schroder (1895), is examined. Its further development, from the perspective of modern model theory, in the 1940s and 1950s is described.<<ETX>>
[Computer science, formal logic, development, calculus of binary relations, modern model theory, Calculus, Logic, Marine vehicles]
Observable algorithms on concrete data structures
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
A contribution to the investigation of sequentiality and full abstraction for sequential programming languages, focusing on the language PCF, is presented. Ideas of R. Cartwright and M. Felleisen (1992) on observable sequentiality are fit into the framework of concrete data structures and sequential algorithms. An extension of the category of sequential algorithms is shown to provide an order-extensional model of PCF. The key to this is the presence of errors in the semantic domains. The model of observable algorithms is fully abstract for an extension of PCF. This extension has errors too, as well as a control operation catch as found in languages such as Scheme or CommonLisp.<<ETX>>
[Tree data structures, formal languages, observable algorithms, Scheme, full abstraction, Data structures, CommonLisp, sequentiality, semantic domains, concrete data structures, PCF, order-extensional model, algorithm theory, Concrete, data structures, sequential programming languages, Error correction, Decision trees, errors, Arithmetic, sequential algorithms]
Logical hierarchies in PTIME
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
A generalized quantifier is n-ary if it binds any finite number of formulas, but at most n variables in each formula. It is proved that for each integer n, there is a property of finite models which is expressible in fixpoint logic, or even in DATALOG, but not in the extension of first-order logic by any set of n-ary quantifiers. It follows that no extension of first-order logic by a finite set of quantifiers captures all DATALOG-definable properties. Furthermore, it is proved that for each integer n, there is a LOGSPACE-computable property of finite models which is not definable in any extension of fixpoint logic by n-ary quantifiers. Hence, the expressive power of LOGSPACE, and a fortiori, that of PTIME, cannot be captured by adding to fixpoint logic any set of quantifiers of bounded arity.<<ETX>>
[Vocabulary, generalized quantifier, first-order logic, LOGSPACE-computable property, Mathematics, n-ary quantifiers, DATALOG, Database languages, expressive power, database theory, formal logic, PTIME, fixpoint logic, Polynomials, finite models, Logic]
A calculus of dataflow networks
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
A CCS-style calculus of dataflow networks with a standard structural operational semantics is defined. A version of weak bisimulation equivalence, called buffer bisimilarity, is defined for this calculus, and its equational theory is investigated. The main result is a completeness theorem for proving equations valid under buffer bisimilarity. The axioms have a familiar, category-theoretic flavor, in which a dataflow process with m input ports and n output ports is represented by an arrow from m to n in a category whose objects are the finite ordinals.<<ETX>>
[programming theory, equivalence, completeness theorem, buffer bisimilarity, Calculus, History, dataflow networks, Equations, Concurrent computing, Computer science, formal logic, Computer languages, equational theory, Communication channels, category theory, Computer networks, IP networks, Carbon capture and storage, equivalence classes]
The type and effect discipline
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The type and effect discipline, a framework for reconstructing the principal type and the minimal effect of expressions in implicitly typed polymorphic functional languages that support imperative constructs, is introduced. The type and effect discipline outperforms other polymorphic type systems. Just as types abstract collections of concrete values, effects denote imperative operations on regions. Regions abstract sets of possibly aliased memory locations. Effects are used to control type generalization in the presence of imperative constructs while regions delimit observable side effects. The observable effects of an expression range over the regions that are free in its type environment and its type; effects related to local data structures can be discarded during type reconstruction. The type of an expression can be generalized with respect to the variables that are not free in the type environment or in the observable effect.<<ETX>>
[formal languages, programming theory, types, Reconstruction algorithms, Data structures, type and effect discipline, polymorphic functional languages, effects, observable effects, Concrete, data structures, implicitly typed, Labeling, imperative constructs]
Horn programming in linear logic is NP-complete
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The question of developing a computational interpretation of J.-Y. Girard's (1987) linear logic and obtaining efficient decision algorithms for this logic, based on the bottom-up approach, is addressed. The approach taken is to start with the simplest natural fragment of linear logic and then expand it step-by-step. The smallest natural Horn fragment of Girard's linear logic is considered, and it is proved that this fragment is NP-complete. As a corollary, an affirmative solution for the problem of whether the multiplicative fragment of Girard's linear logic is NP-complete is obtained. Then a complete computational interpretation for Horn fragments enriched by two additive connectives and by the storage operator is given. Within the framework of this interpretation, it becomes possible to explicitly formalize and clarify the computational aspects of the fragments of linear logic in question and establish exactly the complexity level of these fragments.<<ETX>>
[complexity, Logic programming, Terminology, Natural languages, linear logic, Linear programming, Horn programming, NP-complete, Noise measurement, formal logic, Parallel programming, logic programming, Girard's linear logic, computational complexity]
Fixpoint logic vs. infinitary logic in finite-model theory
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The relationship between fixpoint logic and the infinitary logic L/sub infinity omega //sup omega / with a finite number of variables is studied. It is observed that the equivalence of two finite structures with respect to L/sub infinity omega //sup omega / is expressible in fixpoint logic. As a first application of this, a normal-form theorem for L infinity /sub omega //sup omega / on finite structures is obtained. The relative expressive power of first-order logic, fixpoint logic, and L/sub infinity omega //sup omega / on arbitrary classes of finite structures is examined. A characterization of when L/sub infinity omega //sup omega / collapses to first-order logic on an arbitrary class of finite structures is given.<<ETX>>
[equivalence, first-order logic, finite-model theory, Spatial databases, Complexity theory, Application software, Game theory, Combinatorial mathematics, Computer science, formal logic, normal-form theorem, fixpoint logic, Logic, equivalence classes, infinitary logic, Power generation]
Cutting planes and constant depth Frege proofs
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The cutting planes refutation system for propositional logic is an extension of resolution and is based on showing the nonexistence of solutions for families of integer linear inequalities. The author defines a modified system of cutting planes with limited extension and shows that this system can polynomially simulate constant-depth Frege proof systems. The principal tool to establish this result is an effective version of cut elimination for modified cutting planes with limited extension. Thus, within a polynomial factor, one can simulate classical propositional logic proofs using modus ponens by refutation-style proofs, provided the formula depth is bounded by a constant. Propositional versions of the Paris-Harrington theorem, Kanamori-McAloon theorem, and variants are proposed as possible candidates for combinatorial tautologies that may require exponential-size cutting planes and Frege proofs.<<ETX>>
[Operations research, nonexistence, propositional logic, cut elimination, Circuits, polynomial factor, resolution, integer linear inequalities, formal logic, Paris-Harrington theorem, Polynomials, theorem proving, modus ponens, Logic, Computational modeling, Educational institutions, Kanamori-McAloon theorem, Computational complexity, Computer science, refutation-style proofs, classical propositional logic proofs, constant depth Frege proofs, cutting planes refutation system, Meeting planning, Arithmetic]
A computational analysis of Girard's translation and LC
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
J.-Y. Girard's (1992) new translation from classical to constructive logic is explained. A compatible continuation-passing-style (CPS) translation is given and converted to a C-rewriting machine evaluator for control-operator programs and a set of reduction/computation rules sufficient to represent the evaluator. It is found necessary to add one reduction rule to M. Felleisen's (Ph.D. thesis, Indiana Univ., 1987) calculus (evaluation under lambda -abstraction). This reduction rule arises from a modified call-by-name CPS-translation. Turning to Girard's new classical logic LC, an intuitionistic term-extraction procedure is provided for it, producing CPS functional programs. Using the syntactic properties of this language, it is possible to give simple proofs for the evidence properties of LC. This work sheds light on the design space of CPS-translations and extends the relation between control-operator languages and classical logic.<<ETX>>
[rewriting systems, C-rewriting machine, Logic programming, Girard's translation, Control systems, Calculus, Logic design, Lighting control, reduction rule, control-operator languages, Equations, formal logic, continuation-passing-style, LC, Concrete, constructive logic, intuitionistic term-extraction procedure, classical logic]
Compiler verification in LF
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
A methodology for the verification of compiler correctness based on the LF logical framework as realized within the Elf programming language is presented. This technique is used to specify, implement, and verify a compiler from a simple functional programming language to a variant of the Categorical Abstract Machine (CAM).<<ETX>>
[CADCAM, program verification, Computer aided manufacturing, Elf programming language, Mechanical factors, program compilers, CAM, Computer science, formal logic, Computer languages, Program processors, functional programming language, LF logical framework, Categorical Abstract Machine, compiler correctness, verification]
The category of constraint systems is Cartesian-closed
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
A general definition of constraint systems utilizing Gentzen-style sequents is given. Constraint systems can be regarded as enriching the propositional Scott information systems with minimal first-order structure: the notion of variables, existential quantification, and substitution. Approximate maps that are generic in all but finitely many variables are taken as morphisms. It is shown that the resulting structure forms a category (called ConstSys). Furthermore, the structure of Scott information systems lifts smoothly to the first-order setting. In particular, it is shown that the category is Cartesian-closed, and other usual functors over Scott information systems (lifting, sums, Smyth power-domain) are also definable and recursive domain equations involving these functors can be solved.<<ETX>>
[Heart, Cartesian closure, variables, Logic programming, substitution, existential quantification, constraint theory, Analog computers, ConstSys, Smyth power-domain, Electronic mail, constraint systems, Power system modeling, Machinery, morphisms, Equations, Information systems, database theory, minimal first-order structure, Concurrent computing, Computer languages, recursive domain equations, Gentzen-style sequents, propositional Scott information systems]
Double-exponential complexity of computing a complete set of AC-unifiers
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
An algorithm for computing a complete set of unifiers for two terms involving associative-commutative function symbols is presented. It is based on a nondeterministic algorithm given by the authors in 1986 to show the NP-completeness of associative-commutative unifiability. The algorithm is easy to understand, and its termination can be easily established. Its complexity is easily analyzed and shown to be doubly exponential in the size of the input terms. The analysis also shows that there is a double-exponential upper bound on the size of a complete set of unifiers of two input terms. Since there is a family of simple associative-commutative unification problems which have complete sets of unifiers whose size is doubly exponential, the algorithm is optimal in its order of complexity in this sense.<<ETX>>
[Algorithm design and analysis, complexity, Logic programming, double-exponential, AC generators, History, Database languages, Equations, Computer science, associative-commutative function, Upper bound, NP-completeness, associative-commutative unification, Functional programming, Artificial intelligence, AC-unifiers, computational complexity, nondeterministic algorithm]
Monadic theory of term rewritings
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The monadic second-order theory of term rewritings is considered. It is shown that the monadic theory of the rewriting (or the suffix rewriting) of a ground rewrite system is undecidable. Furthermore, the first-order theory is undecidable for the prefix derivation according to a linear context-free grammar on linear terms. Nevertheless, a new notion on terms with variables is introduced: a term is entire if each of its subterms either is a variable, or is without variable or has the same variables as the term. It is shown that the monadic theory is decidable (respectively undecidable) for the prefix rewriting according to a rewrite system on entire terms, with an axiom (respectively without axiom).<<ETX>>
[rewriting systems, suffix rewriting, linear context-free grammar, Equations, decidability, Automata, Binary trees, ground rewrite system, term rewritings, context-free grammars, prefix derivation, monadic second-order theory, linear terms]
Axiomatizable classes of finite models and definability of linear order
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
It may happen that a first order formula with two free variables over a signature defines a linear order of some finite structure of the signature. Then, naturally, this finite structure is rigid, i.e. admits the single (trivial) automorphism. Also, the class of all the finite structures such that the formula defines a linear order on any of them, is finitely axiomatizable in the class of all finite structures (of the signature). It is shown that the inverse is not true, i.e. that there exists a finitely axiomatizable class of rigid finite structures, such that no first-order formula defines a linear order on all the structures of the class. To illustrate possible applications of the result in finite model theory, it is shown that Y. Gurevich's (1984) result that E.W. Beth's (1953) definability theorem fails for finite models is an immediate corollary.<<ETX>>
[linear order, axiomatizable, definability, first order formula, Relational databases, Electronic mail, Database languages, Computer science, formal logic, Ear, finite models, Safety, Logic, Integrated circuit modeling, Artificial intelligence, computational complexity]
Operational aspects of linear lambda calculus
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
It is proved that the standard sequent calculus proof system of linear logic is equivalent to a natural deduction style proof system. The natural deduction system is used to investigate the pragmatic problems of type inference and type safety for a linear lambda calculus. Although terms do not have a single most-general type (for either the standard sequent presentation or the natural deduction formulation), there is a set of most-general types that may be computed using unification. The natural deduction system also facilitates the proof that the type of an expression is preserved by any evaluation step. An execution model and implementation is described, using a variant of the three-instruction machine. A novel feature of the implementation is that garbage-collected nonlinear memory is distinguished from linear memory, which does not require garbage collection and for which it is possible to do secure update in place.<<ETX>>
[Neutron spin echo, natural deduction, Logic programming, Scholarships, proof system, linear logic, Linear programming, Calculus, Computer science, Concurrent computing, formal logic, sequent calculus proof system, Safety, theorem proving, Resource management, linear lambda calculus]
Zero-one laws for modal logic
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
It is shown that a 0-1 law holds for propositional modal logic, both for structure validity and for frame validity. In the case of structure validity, the result follows easily from the well-known 0-1 law for first-order logic. However, the proof gives considerably more information. It leads to an elegant axiomatization for almost-sure structure validity, and sharper complexity bounds. Since frame validity can be reduced to a II/sub 1//sup 1/ formula, the 0-1 law for frame validity helps delineate when 0-1 laws exist for second-order logics.<<ETX>>
[Vocabulary, 0-1 law, structure validity, first-order logic, modal logic, zero-one laws, complexity bounds, second-order logics, Computer science, formal logic, frame validity, propositional modal logic, Logic, almost-sure structure validity]
Asynchronous communication in process algebra
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The authors study the paradigm of asynchronous process communication, as contrasted with the synchronous communication mechanism that is present in process algebra frameworks such as CCS, CSP, and ACP. They investigate semantics and axiomatizations with respect to various observability criteria: bisimulation, traces and abstract traces. The aim is to develop a process theory that can be regarded as a kernel for languages based on asynchronous communication, like data flow, concurrent logic languages, and concurrent constraint programming.<<ETX>>
[Encapsulation, bisimulation, programming theory, Logic programming, asynchronous process communication, traces, semantics, process theory, Equations, Computer science, axiomatizations, Asynchronous communication, abstract traces, Algebra, process algebra, concurrency control, Communication channels, concurrent constraint programming, Interleaved codes, Carbon capture and storage, Kernel, observability, data flow, concurrent logic languages]
Disjunctive strictness analysis
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The problem of constructing a disjunctive strictness analysis for a higher-order, functional language is addressed. A system of disjunctive types for strictness analysis of typed lambda -calculus is introduced, and the types are used to define a program logic for strictness analysis. A disjunctive abstract interpretation is then obtained as a sound and complete model of the program logic. The results extend earlier work on using the tensor product of lattices to analyze disjunctive properties of programs by abstract interpretation.<<ETX>>
[Algorithm design and analysis, formal languages, programming theory, Logic programming, Lattices, disjunctive types, Educational institutions, Logic design, disjunctive strictness analysis, formal logic, Computer languages, Tensile stress, functional language, Writing, Inference algorithms, program logic, typed lambda -calculus]
New foundations for the geometry of interaction
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
A new formal embodiment of J.-Y. Girard's (1989) geometry of interaction program is given. The geometry of interaction interpretation considered is defined, and the computational interpretation is sketched in terms of dataflow nets. Some examples that illustrate the key ideas underlying the interpretation are given. The results, which include the semantic analogue of cut-elimination, stated in terms of a finite convergence property, are outlined.<<ETX>>
[programming theory, computational interpretation, computational geometry, Educational institutions, Convergence, dataflow nets, Geometry, geometry of interaction, Algebra, Feedback, Concrete, Computer networks, Logic]
Subtype inequalities
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The satisfiability problem for subtype inequalities in simple types is studied. The naive algorithm that solves this problem runs in nondeterministic exponential time for every predefined poset of atomic subtypings the satisfiability problem for subtype inequalities is PSPACE-hard. On the other hand, it is proved that if the poset of atomic subtypings is a disjoint union of lattices, then the satisfiability problem for subtype inequalities is solvable in PTIME. This result covers the important special case of the unification problem that can be obtained when the atomic subtype relation is equality.<<ETX>>
[nondeterministic exponential time, PSPACE-hard, Lattices, computability, Calculus, atomic subtype relation, Upper bound, PTIME, satisfiability problem, subtype inequalities, Polynomials, unification problem, Informatics, atomic subtypings]
Mixing list recursion and arithmetic
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
A procedure that constructs mechanically the appropriate lemmas for proving assertions about programs with arrays is described. A certain subclass of formulas for which the procedure is guaranteed to terminate and thus constitutes a decision procedure is exhibited. This subclass allows for ordering over integers but not for incrementation. A more general subclass that allows for incrementation, but without the termination property, is considered. It is also indicated how to apply the method to a still more general subclass that allows for full arithmetic. These results are extended to the case in which predicates have more than one list argument.<<ETX>>
[proving assertions, programming theory, Logic programming, Datalog, list recursion, Boundary conditions, arithmetic, incrementation, Vectors, recursive functions, ordering over integers, decidability, bottom-up evaluation, Character generation, decision procedure, Tail, theorem proving, termination property, Arithmetic]
Generalized quantifiers and pebble games on finite structures
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
Generalized quantifiers in the realm of finite structures are studied and combined with an infinitary logic L/sub infinity omega //sup omega / to obtain new logics that can be used to express polynomial-time properties that are not definable in the original logic. It is shown that equivalence of finite structures relative to the new logics can be characterized in terms of certain pebble games that are a variant of the Ehrenfeucht-Fraisse games. This time-theoretic characterization is combined with sophisticated combinatorial tools in order to investigate the scopes and limits of generalized quantifiers in finite model theory.<<ETX>>
[combinatorial tools, finite automata, polynomial-time properties, pebble games, finite structures, game theory, Mathematics, Ehrenfeucht-Fraisse games, Game theory, Computer science, formal logic, time-theoretic characterization, generalized quantifiers, Polynomials, finite model theory, Logic, infinitary logic]
Random worlds and maximum entropy
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
Given a knowledge base theta containing first-order and statistical facts, a principled method, called the random-worlds method, for computing a degree of belief that some phi holds given theta is considered. If the domain has size N, then one can consider all possible worlds with domain (1, . . ., N) that satisfy theta and compute the fraction of them in which phi is true. The degree of belief is defined as the asymptotic value of this fraction as N grows large. It is shown that when the vocabulary underlying phi and theta uses constants and unary predicates only, one can in many cases use a maximum entropy computation to compute the degree of belief. Making precise exactly when a maximum entropy calculation can be used turns out to be subtle. The subtleties are explored, and sufficient conditions that cover many of the cases that occur in practice are provided.<<ETX>>
[knowledge base, Pediatrics, expert systems, Military computing, Liver diseases, maximum entropy, Entropy, artificial intelligence, Sufficient conditions, degree of belief, random-worlds method, maximum entropy calculation, Antibiotics, knowledge representation, US Government, Expert systems, Marine vehicles, Contracts]
Strong sequentiality of left-linear overlapping term rewriting systems
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
G. Huet and J.J. Levy (INRIA Rep. 359, 1979) showed that for every strongly sequential orthogonal (i.e., left-linear and non-overlapping) term rewriting system, index reduction strategy is normalizing. Their result is extended to overlapping term rewriting systems. It is shown that index reduction is normalizing for the class of strongly sequential left-linear term rewriting systems in which every critical pair can be joined with root balanced reductions. This class includes all weakly orthogonal left-normal systems, for which a leftmost-outermost reduction strategy is normalizing.<<ETX>>
[rewriting systems, left-linear overlapping term rewriting systems, index reduction, Laboratories, Calculus, Tellurium, Petroleum, sequentiality, Utility programs, Writing, critical pair, weakly orthogonal left-normal systems, Logic, Functional programming, root balanced reductions]
An abstract standardisation theorem
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
An axiomatic version of the standardization theorem that shows the necessary basic properties between nesting of redexes and residuals is presented. This axiomatic approach provides a better understanding of standardization, and makes it applicable in other settings, such as directed acyclic graphs (dags) or interaction networks. conflicts between redexes are also treated. The axioms include stability in the sense given by G. Berry (Ph.D. thesis, Univ. of Paris, 1979), proving it to be an intrinsic notion of deterministic calculi.<<ETX>>
[formal logic, deterministic calculi, redexes, Stability, graph theory, Calculus, standardization theorem, directed acyclic graphs, axiomatic, interaction networks, Arithmetic, residuals]
Turning SOS rules into equations
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
A procedure is given for extracting from a GSOS specification of an arbitrary process algebra a complete axiom system for bisimulation equivalence (equational, except for possibly one conditional equation). The methods apply to almost all SOSs for process algebras that have appeared in the literature, and the axiomatizations compare reasonably well with most axioms that have been presented. In particular, they discover the L characterization of parallel composition. It is noted that completeness results for equational axiomatizations are tedious and have become rather standard in many cases. A generalization of extant completeness results shows that in principle this burden can be completely removed if one gives a GSOS description of a process algebra.<<ETX>>
[formal languages, Turning, Educational institutions, Equations, Computer science, GSOS, Algebra, process algebra, parallel composition, Interleaved codes, Hardware, bisimulation equivalence, Logic]
Progress measures, immediate determinacy, and a subset construction for tree automata
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
Using the concept of a progress measure, a simplified proof is given of M.O. Rabin's (1969) fundamental result that the languages defined by tree automata are closed under complementation. To do this, it is shown that for infinite games based on tree automata, the forgetful determinacy property of Y. Gurevich and L. Harrington (1982) can be strengthened to an immediate determinacy property for the player who is trying to win according to a Rabin acceptance condition. Moreover, a graph-theoretic duality theorem for such acceptance conditions is shown. Also presented is a strengthened version of S. Safra's (1988) determinization construction. Together these results and the determinacy of Borel games yield a straightforward method for complementing tree automata.<<ETX>>
[formal languages, automata theory, languages, trees (mathematics), progress measure, game theory, State-space methods, complementation, Computer science, Upper bound, subset construction, Tree graphs, Automata, immediate determinacy, Rabin acceptance condition, tree automata, Logic, infinite games, graph-theoretic duality theorem, Borel games, forgetful determinacy property, player]
Equivalences on observable processes
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The finest observable and implementable equivalence on concurrent processes is sought as part of a larger program to develop a theory of observable processes where semantics of processes are based on locally and finitely observable process behavior and all process constructs are allowed, provided their operational meaning is defined by realistically implementable transition rules. The structure of transition rules is examined, and several conditions that all realistically implementable rules should satisfy are proposed. It is shown that the ISOS contexts capture exactly the observable behavior of processes. This leads to the result that copy plus refusal equivalence is the finest implementable equivalence.<<ETX>>
[Concurrent computing, equivalence, transition rules, ISO, Delay effects, automata theory, observable processes, Educational institutions, semantics of processes, concurrent processes, equivalence classes, Testing]
References, local variables and operational reasoning
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
A.R. Meyer and K. Sieber (Proc. 15th ACM. Symp. on Principles of Programming Languages, 1988, p.191-208) gave a series of examples of programs that are operationally equivalent (according to the intended semantics of block-structured Algol-like programs) but are not given equivalent denotations in traditional denotational semantics. They propose various modifications to the denotational semantics that solve some of these discrepancies, but not all. The present authors approach the same problem, but from an operational rather than a denotational perspective. They present the first-order part of a new logic for reasoning about programs, and they use this logic to prove the equivalence of the Meyer-Sieber examples.<<ETX>>
[formal logic, programming theory, equivalence, Logic programming, local variables, logic for reasoning, Calculus, programs, equivalence classes, operational reasoning]
An engine for logic program analysis
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
An engine that is based on unfolding of semantic equations is presented. A main advantage of the unfolding engine is a uniform treatment of structural information in a program. In particular, reasoning about partially instantiated structures, an area where traditional algorithms have been weak, is greatly enhanced. It is shown that the engine is uniformly more accurate than the standard engine in the sense that, given an abstract domain, its output, for any program is more accurate than that of the standard engine.<<ETX>>
[Algorithm design and analysis, unfolding, semantic equations, reasoning, logic program analysis, inference mechanisms, Engines, Equations, Computer science, logic programming, structural information, Iterative algorithms, partially instantiated structures, Logic, unfolding engine]
Minimal model semantics for nonmonotonic modal logics
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
Intuitively clear Kripke-style semantics for nonmonotonic modal logic are provided. Minimal model semantics is defined, and soundness and completeness of the semantics for nonmonotonic modal logics are proved. It is shown how the semantics looks for some most popular or most interesting modal logics. Applications to finding expansions and comparing nonmonotonic logics based on different monotonic modal logics are presented. A few examples of using the semantics for obtaining intuitively clear proofs of some results of nonmonotonic modal logics are given.<<ETX>>
[formal logic, minimal model semantics, nonmonotonic modal logics, Formal languages, Knowledge representation, semantics, Logic, Kripke-style semantics]
There is no recursive axiomatization for feasible functionals of type 2
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The author shows a class of type-two feasible functionals, C/sub 2/, that satisfies Cook's conditions, (1990) and cannot be expressed as the lambda closure of type-one poly-time functions and any recursively enumerable set of type-two feasible functionals. Further, no class of total type-two functionals containing this class is representable as the lambda closure of a recursively enumerable set of type-two total computable functionals and type-one poly-time functions. The definition of C/sub 2/ provides a clear computational procedure for functionals of C/sub 2/. Using functionals of class C/sub 2/ a more general notion of polynomial-time reducibility between two arbitrary type-one functions can be introduced.<<ETX>>
[type-one poly-time functions, polynomial-time reducibility, recursively enumerable set, type-two feasible functionals, time complexity, Calculus, recursive functions, computational procedure, Computer science, lambda closure, Turing machines, recursive axiomatization, Polynomials, feasible functionals, computational complexity]
A constructive formalization of the catch and throw mechanism
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
The catch/throw mechanism, a programming construct for nonlocal exit, plays an important role when programmers handle exceptional situations. A constructive formalization that captures the mechanism in the proofs-as-programs notion is given. A modified version of LJ equipped with inference rules corresponding to the operations of catch and throw is introduced. Then it is shown that one can actually extract programs that made use of the catch/throw mechanism from proofs under a certain realizability interpretation. Although the catch/throw mechanism provides only a restricted access to the current continuation, the formulation remains constructive.<<ETX>>
[catch/throw mechanism, inference rules, programming theory, programming construct, Calculus, inference mechanisms, Programming profession, nonlocal exit, exceptional situations, Computer languages, Logic, proofs-as-programs, LJ, realizability]
Symbolic model checking for real-time systems
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
Finite-state programs over real-numbered time in a guarded-command language with real-valued clocks are described. Model checking answers the question of which states of a real-time program satisfy a branching-time specification. An algorithm that computes this set of states symbolically as a fixpoint of a functional on state predicates, without constructing the state space, is given.<<ETX>>
[Real time systems, Algorithm design and analysis, program verification, real-valued clocks, state space, formal specification, Boolean functions, real-numbered time, Safety, symbolic model checking, programming theory, Data structures, State-space methods, Power system modeling, branching-time specification, Computer science, guarded-command language, finite state programs, Upper bound, real-time program, real-time systems, automatic verification, CTL, state predicates, Clocks]
Solving systems of set constraints
[1992] Proceedings of the Seventh Annual IEEE Symposium on Logic in Computer Science
None
1992
It is shown that systems of set constraints that use all the standard set operations, especially unrestricted union and complement, can be solved. The centerpiece of the development is an algorithm that incrementally transforms a system of constraints while preserving the set of solutions. Eventually, either the system is shown to be inconsistent or all solutions can be exhibited. Most of the work is in proving that if this algorithm does not discover an inconsistency, then the system has a solution. This is done by showing that the system of constraints generated by the algorithm can be transformed into an equivalent set of equations that are guaranteed to have a solution. These equations are essentially tree automata.<<ETX>>
[Algorithm design and analysis, set operations, Logic programming, automata theory, unrestricted union, constraint theory, set theory, Upper bound, Automata, algorithm theory, set constraints, Inference algorithms, tree automata, complement]
Bisimulation and open maps
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
An abstract definition of bisimulation is presented. It allows a uniform definition of bisimulation across a range of different models for parallel computation presented as categories. As examples, transition systems, synchronization trees, transition systems with independence (an abstraction from Petri nets), and labeled event structures are considered. On transition systems, the abstract definition readily specialises to Milner's (1989) strong bisimulation. On event structures, it explains and leads to a revision of the history-preserving bisimulation of Rabinovitch and Traktenbrot (1988), and Goltz and van Glabeek (1989). A tie-up with open maps in a (pre)topos brings to light a promising new model, presheaves on categories of pomsets, into which the usual category of labeled event structures embeds fully and faithfully. As an indication of its promise, this new presheaf model has refinement operators, though further work is required to justify their appropriateness and understand their relation to previous attempts.<<ETX>>
[parallel computation, presheaves, Petri nets, simulation, abstract definition, pomsets, refinement operators, strong bisimulation, History, independence, pretopos, parallel processing, Concurrent computing, formal logic, transition systems, history-preserving bisimulation, categories, Logic, labeled event structures, open maps, Computational modeling, synchronization trees, Interleaved codes, category theory, presheaf model]
Type theory and recursion
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
Summary form only given. Type theory and recursion are analyzed in terms of intuitionistic linear type theory. This is compatible with a general recursion operator for the intuitionistic functions. The author considers second-order intuitionistic linear type theory whose primitive type constructions are linear and intuitionistic function types and second-order quantification.<<ETX>>
[primitive type constructions, Laboratories, intuitionistic linear type theory, intuitionistic function types, Calculus, recursive functions, type theory, Parametric statistics, intuitionistic function, second-order type theory, Power system modeling, Equations, Computer science, Computer languages, general recursion operator, Algebra, Ear, Logic, second-order quantification]
Functional unification of higher-order patterns
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The complete development of a unification algorithm for so-called higher-order patterns, a subclass of lambda -terms, is presented. The starting point is a formulation of unification by transformation, and the result a directly executable functional program. In a final development step, the result is adapted to lambda -terms in de Bruijn's (1972) notation. The algorithms work for both simply typed and untyped terms.<<ETX>>
[lambda calculus, functional unification algorithm, Automatic programming, Ground penetrating radar, programming theory, Logic programming, functional programming, Geophysical measurement techniques, Calculus, directly executable functional program, typed terms, untyped terms, Computer languages, transformation formulation, Inference mechanisms, lambda -terms, de Bruijn's notation, higher-order patterns, Inference algorithms, theorem proving]
Typing and subtyping for mobile processes
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The pi -calculus is a process algebra that supports process mobility by focusing on the communication of channels. R. Milner's (1991) presentation of the pi -calculus includes a type system assigning arities to channels and enforcing a corresponding discipline in their use. The authors extend Milner's language of types by distinguishing between the ability to read from a channel, the ability to write to a channel, and the ability both to read and to write. This refinement gives rise to a natural subtype relation similar to those studied in typed lambda -calculi. The greater precision of their type discipline yields stronger versions of some standard theorems about the pi -calculus. These can be used, for example, to obtain the validity of beta -reduction for the more efficient of Milner's encodings of the call-by-value lambda -calculus, for which beta -reduction does not hold in the ordinary pi -calculus. The authors define the syntax, typing, subtyping, and operational semantics of their calculus, prove that the typing rules are sound, apply the system to Milner's lambda -calculus encodings, and sketch extensions to higher-order process calculi and polymorphic typing.<<ETX>>
[operational semantics, precision, Mobile communication, Calculus, type theory, typing rules, Communication standards, formal logic, pi -calculus, Algebra, type system, Carbon capture and storage, call-by-value lambda -calculus, higher-order process calculi, Testing, process mobility, mobile processes, Buildings, soundness, beta -reduction, Topology, typed lambda -calculi, subtyping, Computer science, Computer languages, process algebra, polymorphic typing, subtype relation, arities, syntax, channel communication, channel read/write ability]
Adequacy for untyped translations of typed lambda -calculi
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
PCF is a simply typed lambda -calculus with ground types iota (natural numbers) and omicron (Booleans); there are no type variables and implies is the only type constructor. There is a natural way to translate any PCF term t into an untyped lambda -expression Lambda (t), such that if t is a program, i.e. a closed term of ground type (say integer type) and t implies /sub N/ n then Lambda (t) implies /sub beta / c/sub n/, where implies /sub N/ denotes call-by-name evaluation and c/sub n/ denotes the nth Church numeral. This paper contains a proof of the converse: if Lambda (t) implies /sub beta / c/sub n/ then t implies /sub N/ n; this tells us that the translation is adequate. The proof is semantic, and uses synthetic domain theory to reduce the question to the original Plotkin/Sazonov adequacy theorem for standard domain models of call-by-name PCF. This argument generalises easily to extensions of PCF which can be translated into the untyped lambda -calculus: we illustrate this by proving an analogous result for a 'second-order' PCF with type quantification. We also discuss how to extend the result to versions of PCF with recursive types and subtyping.<<ETX>>
[lambda calculus, semantic proof, recursive types, Church numeral, Plotkin/Sazonov adequacy theorem, Calculus, recursive functions, type theory, type quantification, typed lambda -calculi, subtyping, Computer science, Program processors, PCF, standard domain models, ground types, synthetic domain theory, untyped translations, type constructor, Australia, second-order calculus, untyped lambda -expression, call-by-name evaluation]
Decomposability, decidability and axiomatisability for bisimulation equivalence on basic parallel processes
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The authors prove the decidability of two subclasses of recursive processes involving a parallel composition operator with respect to bisimulation equivalence, namely, the so-called normed and live processes. To accomplish this, the authors first prove a unique decomposition result for (a generalization of) normed processes, in order to deduce a necessary cancellation law. The decidability proof leads to a complete axiomatization for these process classes.<<ETX>>
[basic parallel processes, Laboratories, Formal languages, simulation, parallel composition operator, recursive processes, Calculus, Mathematics, parallel processing, Equations, normed processes, Computer science, Reactive power, live processes, decidability, System recovery, decomposability, bisimulation equivalence, cancellation law, Standards development, process subclasses, axiomatisability]
Local and asynchronous beta-reduction (an analysis of Girard's execution formula)
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The authors build a confluent, local, asynchronous reduction on lambda -terms, using infinite objects (partial injections of Girard's (1988) algebra L*), which is simple (only one move), intelligible (semantic setting of the reduction), and general (based on a large-scale decomposition of beta ), and may be mechanized.<<ETX>>
[lambda calculus, mechanizabilty, Glass, single move reduction, partial injections, semantic setting, Geometry, large-scale decomposition, infinite objects, Algebra, Microscopy, L* algebra, Girard's execution formula, lambda -terms, Large-scale systems, Logic, confluent local asynchronous beta-reduction]
Database query languages embedded in the typed lambda calculus
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
It is shown how to naturally embed, in the typed lambda -calculus with equality, many database query languages, including the relational calculus/algebra, inflationary Datalog, and the complex object calculus/algebra. The embeddings considered are such that a database is a lambda -term coding list of tuples and a query is a lambda -term which when applied to the input database normalizes to the output database. In addition, if the query expressed is a PTIME query, then the normal form can be computed in a number of reduction steps polynomial in the size of the input database. It is also shown that, for all PTIME queries, there is such an embedding in the order-three typed lambda -calculus with equality.<<ETX>>
[Embedded computing, lambda calculus, output database, PTIME query, Instruments, relational algebra, Relational databases, query languages, Calculus, Database languages, relational calculus/algebra, database theory, complex object calculus/algebra, input database, typed lambda calculus, Algebra, database query languages, lambda term coding list, order-three typed lambda calculus, Polynomials, Robustness, tuples, Contracts, inflationary Datalog]
In and out of temporal logic
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
Two-way translations between various versions of temporal logic and between temporal logic over finite sequences and star-free regular expressions are presented. The main result is a translation from normal-form temporal logic formulas to formulas that use only future operators. The translation offers a new proof to a theorem claimed by D. Gabbay et al. (1980), stating that restricting temporal logic to the future operators does not impair its expressive power. The theorem is the basis of many temporal proof systems.<<ETX>>
[formal languages, normal-form temporal logic formulas, temporal logic, finite sequences, theorem proof, star-free regular expressions, temporal proof systems, Computer science, two-way translations, future operators, restricting temporal logic, Automata, theorem proving, Logic, Protection, logic translation]
Strong normalization for second order classical natural deduction
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The strong normalization theorem for second-order classical natural deduction is proved. The method used is an adaptation of the one of reducibility candidates introduced in a thesis by J.Y. Girard (Univ. Paris 7, 1972) for second-order intuitionistic natural deduction. The extension to the classical case requires, in particular, a simplification of the notion of reducibility candidates.<<ETX>>
[strong normalization theorem, lambda calculus, Filters, Logic programming, second-order intuitionistic natural deduction, H infinity control, reducibility candidates, Calculus, inference mechanisms, second order classical natural deduction]
Lambek grammars are context free
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
Basic categorial grammars are the context-free ones. Another kind of categorial grammars was introduced by J. Lambek (1958). These grammars are based on a syntactic calculus, known as the Lambek calculus. Chomsky (1963) conjectured that these grammars are also equivalent to context-free ones. Every basic categorial grammar (and thus every context-free grammar) is equivalent to a Lambek grammar. Conversely, some special kinds of Lambek grammars are context-free. These grammars use weakly unidirectional types, or types of order at most two. The main result of this paper says that Lambek grammars generate only context-free languages. Thus they are equivalent to context-free grammars and also to basic categorial grammars. The Chomsky conjecture, that all languages recognized by the Lambek calculus are context-free, is thus proved.<<ETX>>
[Lambek calculus, Chomsky conjecture, weakly unidirectional types, Calculus, Mathematics, syntactic calculus, Mars, categorial grammars, Text recognition, context-free languages, Lambek grammars, Bismuth, category theory, context-free grammars, Logic]
The unifiability problem in ground AC theories
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
It is shown that unifiability is decidable in theories presented by a set of ground equations with several associative-communicative symbols (ground AC theories). This result applies, for instance, to finitely presented commutative semigroups, and it extends the authors' previous work (P. Narendran and M. Rusinwithch, 1991) where they gave an algorithm for solving the uniform word problem in ground AC theories.<<ETX>>
[rewriting systems, decidable, uniform word problem, programming theory, Logic programming, Petri nets, unifiability problem, ground AC theories, AC generators, ground equations, Equations, finitely presented commutative semigroups, decidability, Chromium, associative-communicative symbols]
An exponential separation between the matching principle and the pigeonhole principle
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The combinatorial matching principle states that there is no perfect matching on an odd number of vertices. This principle generalizes the pigeonhole principle, which states that for a fixed bipartition of the vertices, there is no perfect matching between them. Therefore, it follows from recent lower bounds for the pigeonhole principle that the matching principle requires exponential-size bounded-depth Frege proofs. M. Ajtai (1990) previously showed that the matching principle does not have polynomial-size bounded-depth Frege proofs even with the pigeonhole principle as an axiom schema. His proof utilizes nonstandard model theory and is nonconstructive. We improve Ajtai's lower bound from barely superpolynomial to exponential, and eliminate the nonstandard model theory. Our lower bound is also related to the inherent complexity of particular search classes. In particular, oracle separations between the complexity classes PPA and PPAD and between PPA and PPP follow from our techniques.<<ETX>>
[PPA, nonconstructive model theory, combinatorial mathematics, complexity classes, axiom schema, PPAD, exponential-size bounded-depth Frege proofs, Drives, exponential separation, combinatorial matching principle, lower bounds, Computer science, PPP, inherent complexity, vertices bipartition, Polynomials, search classes, pigeonhole principle, oracle separations, computational complexity]
Self-synchronization of concurrent processes
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
Introduces a unary "self-synchronization" operation on concurrent processes that synchronizes concurrent transitions within a process. Standard parallel synchronization and communicating action refinement operations can be reduced to simple combinations of self-synchronization and unsynchronized noncommunicating operations. Modifying familiar fully abstract process semantics, so that actions are replaced by action multisets (steps), typically yields semantics that are fully abstract for processes with self-synchronization.<<ETX>>
[multiprocessing systems, multiprocessing programs, self-synchronization operation, unsynchronized noncommunicating operations, communicating action refinement operations, parallel synchronization operations, steps, Equations, Communication standards, synchronisation, Computer science, formal logic, Algebra, action multisets, concurrent transitions, fully abstract process semantics, concurrent processes, Carbon capture and storage]
Homomorphic tree embeddings and their applications to recursive program optimization
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The problems of stage-preserving linearization and one-boundedness are studied for a class of nonlinear single rule recursive programs, and syntactic characterizations are developed for both. The characterizations lead to a polynomial-time algorithm for the former and a linear-time algorithm for the latter. Stage-preserving linearization results in a significant improvement in evaluation efficiency, compared to a linearization that does not preserve stages. The class of nonlinear strips that are stage-preserving linearizable includes several classes of programs that can be linearized only using a mix of left and right linear rules, as well as programs that cannot be linearized using previously known techniques. The study makes use of a technique based on the notion of homomorphic tree embeddings.<<ETX>>
[programming theory, trees (mathematics), homomorphic tree embeddings, nonlinear strips, syntactic characterizations, one-boundedness, Application software, linear-time algorithm, Computer science, evaluation efficiency, deductive databases, nonlinear single rule recursive programs, Query processing, stage-preserving linearization, recursive program optimization, Polynomials, polynomial-time algorithm, Deductive databases]
On completeness of the mu -calculus
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The long-standing problem of the complete axiomatization of the propositional mu -calculus introduced by D. Kozen (1983) is addressed. The approach can be roughly described as a modified tableau method in the sense that infinite trees labeled with sets of formulas are investigated. The tableau method has already been used in the original paper by Kozen. The reexamination of the general tableau method presented is due to advances in automata theory, especially S. Safra's determinization procedure (1988), connections between automata on infinite trees and games, and experience with the model checking. A finitary complete axiom system for the mu -calculus is obtained. It can be roughly described as a system for propositional modal logic with the addition of a induction rule to reason about least fixpoints.<<ETX>>
[tableau method, mu -calculus completeness, infinite trees, automata theory, Calculus, least fixpoints, induction rule, formal logic, determinization procedure, modified tableau method, games, formula sets, Page description languages, Hardware, Logic, Carbon capture and storage, propositional mu -calculus, Informatics, trees (mathematics), Application software, inference mechanisms, Game theory, complete axiomatization, model checking, finitary complete axiom system, Automata, Software systems, propositional modal logic]
Relational properties of recursively defined domains
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
A mixed induction/coinduction property of relations on recursively defined domains is described, working within a general framework for relations on domains and for actions of type constructors on relations introduced by P.W. O'Hearn and R.D. Tennent (1993), and drawing upon P.J. Freyd's analysis (1991) of recursive types in terms of a simultaneous initiality/finality property. The utility of the mixed induction/coinducton property is demonstrated by deriving a number of families of proof principles from it. One instance of the relational framework yields a family of induction principles for admissible subsets of general recursively defined domains which extends the principle of structural induction for inductively defined sets. Another instance of the framework yields the coinduction principle studied elsewhere by the author, by which equalities between elements of recursively defined domains may be proved via bisimulations.<<ETX>>
[functional programming, recursive types, Laboratories, high level languages, recursively defined domains, general recursively defined domains, structural induction, coinduction principle, type theory, simultaneous initiality/finality property, type constructors, relational framework, bisimulations, Equations, mixed induction/coinduction property, inductively defined sets, data structures, relational properties, theorem proving, proof principles, functional languages]
Programs, grammars and arguments: a personal view of some connections between computation, language and logic
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The question of what is an effective process or algorithm arose form the statement of Hilbert's tenth problem. It was soon seen to be related to the question of which numerical functions N/sup n/ to N are computable. Among the early answers to this question the author singles out three. A numerical function is computable if and only if it is recursive, it is computable on a Turing machine, or it is definable in the untyped lambda -calculus. Some aspects of the relevance of these three notions of computability to linguistics and logic, in particular, categorial logic, are discussed.<<ETX>>
[numerical functions, lambda calculus, Humans, Turing machine, computability, Mathematics, computable, Zinc, Equations, recursive, categorial logic, formal logic, Turing machines, Algebra, numerical function, grammars, category theory, Concrete, untyped lambda-calculus, Logic, Arithmetic, Hilbert's tenth problem]
Automated production of traditional proofs for constructive geometry theorems
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The authors present a method that can produce traditional proofs for a class of geometry statements whose hypotheses can be described constructively and whose conclusions can be represented by polynomial equations of three kinds of geometry quantities: ratios of lengths, areas of triangles, and Pythagoras differences of triangles. This class covers a large portion of the geometry theorems about straight lines and circles. The method involves the elimination of the constructed points from the conclusion using a few basic geometry propositions. The authors' program, Euclid, implements this method and can produce traditional proofs of many hard geometry theorems. Currently, it has produced proofs of 400 nontrivial theorems entirely automatically, and the proofs produced are generally short and readable. This method seems to be the first one to produce traditional proofs for hard geometry theorems efficiently.<<ETX>>
[computational geometry, polynomial equations, Statistics, constructive geometry theorems, Computer science, geometry statements, Computational geometry, nontrivial theorems, Operating systems, Production, Logic functions, Solids, Polynomials, Timing, theorem proving, traditional proofs]
Verifying programs with unreliable channels
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The verification of a particular class of infinite-state systems, namely, systems consisting of finite-state processes that communicate via unbounded lossy FIFO channels, is considered. This class is able to model, e.g., link protocols such as the Alternating Bit Protocol and HDLC. For this class of systems, it is shown that several interesting verification problems are decidable by giving algorithms for verifying: the reachability problem (whether a finite set of global states is reachable from some other global state of the system); the safety property over traces, formulated as regular sets of allowed finite traces; and eventuality properties (whether all computations of a system eventually reach a given set of states). The algorithms are used to verify some idealized sliding-window protocols with reasonable time and space resources.<<ETX>>
[Algorithm design and analysis, decidable, Protocols, telecommunication channels, program verification, unbounded lossy FIFO channels, time resources, Data engineering, reachability problem, infinite-state system verification, Microwave integrated circuits, HDLC, decidability, Hardware, Safety, sliding-window protocols, protocols, Contracts, finite-state processes, programming theory, Alternating Bit Protocol, finite traces, traces, global states, space resources, unreliable channels, safety property, eventuality properties, Clocks]
Non-determinism in a functional setting
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The pure untyped lambda calculus augmented with an (erratic) choice operator is considered as an idealised nondeterministic functional language. Both the 'may' and the 'must' modalities of convergence are of interest. Following Abramsky's (1991) work on domain theory in logical form, we identify the denotational type that captures the computational situation delta =P(( delta to delta ) perpendicular to ), where P(-) is the Plotkin power-domain functor. We then carry out a systematic programme that hinges on three distinct interpretations of delta , namely process-theoretic, denotational, and logical. The main theme of the programme is the complementarity of the various interpretations of delta . This work may be seen as a step towards a rapprochement between the algebraic theory of processes in concurrency on the one hand, and the lazy lambda calculus as a foundation for functional programming on the other.<<ETX>>
[functional programming, Laboratories, convergence, computational situation, logical interpretation, Fasteners, Calculus, may modality, Convergence, Concurrent computing, Runtime, process-theoretic interpretation, lazy lambda calculus, complementarity, Plotkin power-domain functor, denotational type, Functional programming, idealised nondeterministic functional language, erratic choice operator, domain theory, lambda calculus, programming theory, pure untyped lambda calculus, Encoding, convergence modalities, logical form, must modality, denotational interpretation, concurrent processes, algebraic theory]
Some desirable conditions for feasible functionals of type 2
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
We consider functionals of type 2 as transformers between functions of type 1. An intuitively feasible functional must preserve the complexity of the input function in some broad sense. We show that the well quasi-order functional, which has been proposed by S.A. Cook (1990) as being intuitively feasible, fails to preserve the class of Kalmar elementary functions. For the basic feasible functionals (BFF), we show that there are arbitrarily large complexity classes of type 1 functions, under the classical definition of a complexity class, which contain polynomial-time functions and are closed under composition but are not preserved by the BFF. However, for a more natural definition of a complexity class of type 1 functions, BFF is shown to preserve all such complexity classes. BFF is the largest known class with this property. We prove BFF to be the largest class of type 2 functionals which satisfies Cook's conditions and the Ritchie-Cobham property, and preserves all classes of type 1 computable functions that contain polynomial-time functions and are closed under composition and limited recursion on notation. These results give some evidence that basic feasible functionals may be the right notion of type 2 feasibility.<<ETX>>
[well quasi-order functional, BFF, functions, basic feasible functionals, limited recursion, intuitively feasible functional, type 2 feasibility, Turing machines, composition, notation, Polynomials, input function complexity preservation, closure, complexity classes, Ritchie-Cobham property, Application software, Kalmar elementary functions, Computer science, functional equations, polynomial-time functions, type 1 functionals, Transformers, type 2 functionals, function transformers, type 1 computable functions, Arithmetic, computational complexity]
A coinduction principle for recursive data types based on bisimulation
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The concept of bisimulation from concurrency theory is used to reason about recursively defined data types. From two strong-extensionality theorems stating that the equality (resp. inequality) relation is maximal among all bisimulations, a proof principle for the final coalgebra of an endofunctor on a category of data types (resp. domains) is obtained. As an application of the theory developed, an internal full abstraction result for the canonical model of the untyped call-by-value lambda -calculus is proved. The operations notion of bisimulation and the denotational notion of final semantics are related by means of conditions under which both coincide.<<ETX>>
[bisimulation, proof principle, Laboratories, coinduction principle, recursive data types, Concurrent computing, Tail, equality relation, endofunctor, data structures, Network address translation, lambda calculus, parallel algorithms, strong-extensionality theorems, internal full abstraction result, concurrency theory, canonical model, recursive functions, Application software, untyped call-by-value lambda calculus, Computer science, recursively defined data types, Councils, final coalgebra, denotational notion]
A lambda calculus of objects and method specialization
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
An untyped lambda calculus, extended with object primitives that reflect the capabilities of so-called delegation-based object-oriented languages, is presented. A type inference system allows static detection of errors, such as message not understood, while at the same time allowing the type of an inherited method to be specialized to the type of the inheriting object. Type soundness, in the form of a subject-reduction theorem, is proved, and examples illustrating the expressiveness of the pure calculus are presented.<<ETX>>
[lambda calculus, object-oriented programming, Object oriented modeling, Scholarships, Optimization methods, Calculus, type theory, Equations, Computer science, type soundness, subject-reduction theorem, untyped lambda calculus, object primitives, Computer errors, object-oriented languages, type inference system, delegation-based object-oriented languages, Object oriented programming, Springs, inherited method, method specialization]
The order types of termination orderings on monadic terms, strings and multisets
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
Total well-founded orderings on monadic terms satisfying the replacement and full invariance properties are considered. It is shown that any such ordering on monadic terms in one variable and two unary function symbols must have order type omega , omega /sup 2/, or omega /sup omega /. It is further shown that a familiar construction gives rise to continuum many such orderings of order type omega . A new family of such orderings of order type omega is constructed, and it is shown that there are only four such orderings of order type omega /sup omega /, the two familiar recursive path orderings and two closely related orderings. It is shown that any total well-founded ordering on N/sup n/ that is preserved under vector addition must have order type omega /sup lambda / for some 1<or=k<or=n; if k<n, there are continuum many such orderings, and if k=n, there are only n-factorial, namely the n-factorial lexicographic orderings.<<ETX>>
[rewriting systems, continuum, vector addition, monadic terms, termination orderings, type theory, closely related orderings, order types, strings, multisets, full invariance properties, familiar recursive path orderings, Polynomials, unary function symbols, lexicographic orderings, total well-founded ordering]
Set constraints are the monadic class
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The authors investigate the relationship between set constraints and the monadic class of first-order formulas and show that set constraints are essentially equivalent to the monadic class. From this equivalence, they infer that the satisfiability problem for set constraints is complete for NEXPTIME. More precisely, it is proved that this problem has a lower bound of NTIME(c/sup n/log n/), for some c>0. The relationship between set constraints and the monadic class also gives decidability and complexity results for certain practically useful extensions of set constraints, in particular "negative" projections and subterm equality tests.<<ETX>>
[Algorithm design and analysis, Vocabulary, complexity, set theory, completeness, subterm equality tests, decidability, satisfiability problem, Abstracts, negative projections, set constraints, Constraint theory, NEXPTIME, Testing, first-order formulas, equivalence, Logic programming, constraint theory, monadic class, NTIME, lower bound, Computer science, Computer languages, Concrete, Inference algorithms, computational complexity]
Encoding the calculus of constructions in a higher-order logic
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The author presents an encoding of the calculus of constructions (CC) in a higher-order intuitionistic logic (I) in a direct way, so that correct typing in CC corresponds to intuitionistic provability in a sequent calculus for I. In addition, she demonstrates a direct correspondence between proofs in these two systems. The logic I is an extension of hereditary Harrop formulas (hh), which serve as the logical foundation of the logic programming language lambda Prolog. Like hh, I has the uniform proof property, which allows a complete nondeterministic search procedure to be described in a straightforward manner. Via the encoding, this search procedure provides a goal directed description of proof checking and proof search in CC.<<ETX>>
[higher-order logic, sequent calculus, lambda calculus, Logic programming, proof search, Encoding, Calculus, type theory, higher-order intuitionistic logic, proof checking, hereditary Harrop formulas, intuitionistic provability, nondeterministic search procedure, correct typing, logic programming language, calculus of constructions, lambda Prolog, logic programming, PROLOG]
On model checking for real-time properties with durations
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The verification problem for real-time properties involving duration constraints (predicates) is addressed. The duration of a state property, along an interval of a computation sequence of a real-time system, is the time the property is true. In particular, the global time spent in such an interval is the duration of the formula 'true'. The real-time logic TCTL is extended to a duration logic called SDTL in which duration constraints can be expressed. The problem of the verification of SDTL formulas with respect to a class of timed models of reactive systems is investigated. New model checking procedures are proposed for the most significant properties expressible in SDTL, including eventuality and invariance properties. Such results are provided for the two cases of discrete and dense time.<<ETX>>
[Real time systems, TCTL, duration constraints, state property, graph theory, reactive systems, Automatic logic units, temporal logic, Calculus, global time, Proposals, computation sequence, formal verification, real-time logic, durations, invariance, dense time, verification problem, duration logic, timed models, timed graphs, SDTL, SDTL formula verification, discrete time, real-time properties, eventuality, predicates, model checking, real-time systems]
A typed pattern calculus
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The theory of programming with pattern-matching function definitions has been studied mainly in the framework of first-order rewrite systems. The authors present a typed functional calculus that emphasizes the strong connection between the structure of whole pattern definitions and their types. In this calculus, type-checking guarantees the absence of runtime errors caused by nonexhaustive pattern-matching definitions. Its operational semantics is deterministic in a natural way, without the imposition of ad hoc solutions such as clause order or best fit. The calculus is designed as a computational interpretation of the Gentzen sequent proofs for the intuitionistic propositional logic. The basic properties connecting typing and evaluation, subject reduction, and strong normalization are proved. The authors believe that this calculus offers a rational reconstruction of the pattern-matching features found in successful functional languages.<<ETX>>
[functional programming, operational semantics, first-order rewrite systems, Calculus, type theory, calculus, formal logic, Information science, Runtime, typed functional calculus, typed pattern calculus, Functional programming, rewriting systems, runtime errors, Redundancy, rational reconstruction, Logic design, subject reduction, strong normalization, pattern-matching function definitions, intuitionistic propositional logic, Gentzen sequent proofs, Joining processes, Pattern matching, nonexhaustive pattern-matching definitions, functional languages]
Full abstraction for a shared variable parallel language
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
Gives a new denotational semantics for a shared variable parallel programming language and proves full abstraction. The semantics gives identical meanings to commands if and only if they induce the same partial correctness behavior in all program contexts. The meaning of a command is a set of transition traces, which record the ways in which a command may interact with and be affected by its environment. It is shown how to modify the semantics to incorporate new program constructs, to allow for different levels of granularity or atomicity, and to model fair infinite computation, in each case achieving full abstraction with respect to an appropriate notion of program behavior.<<ETX>>
[Parallel languages, fair infinite computation, Aerospace electronics, transition traces, program constructs, shared variable parallel programming language, Research and development, parallel programming, identical command meanings, parallel languages, Contracts, denotational semantics, programming theory, atomicity, program behavior, Government, full abstraction, Reasoning about programs, Equations, partial correctness behavior, program contexts, Computer science, granularity, System recovery, Context modeling]
Standard ML-NJ weak polymorphism and imperative constructs
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
Standard ML of New Jersey (SML-NJ) uses weak-type variables to restrict the polymorphic use of functions that may allocate reference cells, manipulate continuations, or use exceptions. However, the type system used in the SML-NJ compiler has not been presented in a form other than source code and has not been proved correct. A type system, in the form of typing rules and an equivalent algorithm, that appears to subsume the implemented algorithm is presented. Both use type variables of only a slightly more general nature than the compiler. One insight in the analysis is that the indexed type of a free variable is used in two ways, once in describing the applicative behavior of the variable itself and once in describing the larger term containing the variable. Taking this into account, an application rule that is more general than SML-NJ is formulated for applications of polymorphic functions to imperative arguments. The soundness of the type system is proved for imperative code using operational semantics.<<ETX>>
[polymorphic functions, operational semantics, high level languages, Control systems, Calculus, type theory, weak-type variables, program compilers, Program processors, Runtime, Prediction algorithms, Standard ML-NJ weak polymorphism, SML-NJ compiler, reference cells, application rule, lambda calculus, Scholarships, free variable, Standard ML of New Jersey, Programming profession, exceptions, Computer science, type variables, imperative arguments, continuations, Inference algorithms, imperative constructs, Board of Directors]
Rules of definitional reflection
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The author discusses two rules of definitional reflection: the logical version of definitional reflection, as used in the extended logic programming language GCLA, and the omega version of definitional reflection. The logical version is a left-introduction rule completely analogous to the left-introduction rules for logical operators in Gentzen-style sequent systems, whereas the omega version extends the logical version by a principle related to the omega rule in arithmetic. Correspondingly, the interpretation of free variables differs between the two approaches, resulting in different principles of closure of inference rules under substitution. This difference is crucial for the computational interpretation of definitional reflection.<<ETX>>
[Gentzen-style sequent systems, inference rules, programming theory, Logic programming, substitution, computational interpretation, extended logic programming language, arithmetic, Reflection, Calculus, History, inference mechanisms, logic programming languages, logical version, formal logic, GCLA, Databases, logic programming, first order logic, omega version, left-introduction rule, definitional reflection rules, Arithmetic, logical operators]
Imperfect information flow
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The view that computers are information processors is commonplace. They are used, for the most part successfully, throughout our society, as reliable links in the transmission of information and knowledge. Yet the formulation of a precise, qualitative conception of information and a theory of the transmission of information has proved elusive, despite the many other successes of computer science. The authors set out the motivation for and a skeleton of a new mathematical model of information flow, one that is compatible with less than perfect flow.<<ETX>>
[imperfect information flow, situation theory, Costs, Humans, formality, Mathematics, intentionality, Physics, Computer science, formal logic, information processors, context dependence, Hard disks, Skeleton, information theory, Logic, Mathematical model, Joints]
The genericity theorem and the notion of parametricity in the polymorphic lambda -calculus
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The authors focus on how polymorphic functions, which may take types as inputs, depend on types. These functions are generally understood to have an essentially constant meaning, in all models, on input types. It is shown how the proof theory of the polymorphic lambda -calculus suggests a clear syntactic description of this phenomenon. Under a reasonable condition, it is shown that identity of two polymorphic functions on a single type implies identity of the functions (equivalently, every type is a generic input).<<ETX>>
[lambda calculus, generic input, polymorphic functions, Laboratories, parametricity, function identity, Calculus, type theory, proof theory, Computer science, Computer languages, Runtime, syntactic description, genericity theorem, Logic, polymorphic lambda -calculus, input types]
On the unification problem for Cartesian closed categories
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
An axiomatization of the isomorphisms that hold in all Cartesian closed categories (CCCs), discovered independently by S.V. Soloviev (1983) and by K.B. Bruce and G. Longo (1985), leads to seven equalities. It is shown that the unification problem for this theory is undecidable, thus setting an open question. It is also shown that an important subcase, namely unification modulo the linear isomorphisms, is NP-complete. Furthermore, the problem of matching in CCCs is NP-complete when the subject term is irreducible. CCC-matching and unification form the basis for an elegant and practical solution to the problem of retrieving functions from a library indexed by types investigated by M. Rittri (1990, 1991). It also has potential applications to the problem of polymorphic higher-order unification, which in turn is relevant to theorem proving, logic programming, and type reconstruction in higher-order languages.<<ETX>>
[axiomatization, lambda calculus, programming theory, Logic programming, higher-order languages, Cartesian closed categories, Mathematics, Calculus, NP-complete, Equations, Convergence, Computer science, Computer languages, decidability, isomorphisms, logic programming, retrieving functions, polymorphic higher-order unification, Libraries, type reconstruction, unification problem, theorem proving, Mathematical programming, computational complexity]
Compositional analysis for concurrent constraint programming
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
A framework for the analysis of concurrent constraint programming (CCP) is proposed. The approach is based on simple denotational semantics that approximate the usual semantics in the sense that they give a superset of the input-output relation of a CCP program. Analyses based on these semantics can be easily and efficiently implemented using standard techniques from the analysis of logic programs.<<ETX>>
[Data analysis, programming theory, Logic programming, Computational modeling, simple denotational semantics, logic program analysis, Application software, compositional analysis, Programming profession, parallel programming, Information analysis, Concurrent computing, Computer science, Program processors, logic programming, concurrent constraint programming, input-output relation, Australia, constraint handling, CCP program]
Asymptotic probabilities of languages with generalized quantifiers
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The impact of adding certain families of generalized quantifiers to first-order logic (FO) on the asymptotic behavior of sentences is studied. All the results are stated and proved for languages disallowing free variables in the scope of generalized quantifiers. For a class K of finite structures closed under isomorphism, the quantifier Q/sub K/ is said to be strongly monotonic, sm, if membership in the class is preserved under a loose form of extensions. The first theorem (O/1 law for FO with any set of sm quantifiers) subsumes a previous criterion for proving that almost no graphs satisfy a given property. A O/1 law for FO with Hartig quantifiers (equicardinality quantifiers) and a limit law for a fragment of FO with Rescher quantifiers (expressing inequalities of cardinalities) are also established. It is also proved that the O/1 law fails for the extension of FO with Hartig quantifiers if the above syntactic restriction is relaxed, giving the best upper bound for the existence of a O/1 law for FO with Hartig quantifiers.<<ETX>>
[equicardinality quantifiers, graph theory, first-order logic, free variables, query languages, Mathematics, isomorphism, formal logic, asymptotic probabilities, theorem proving, Logic, limit law, finite structures, Rescher quantifiers, probability, strongly monotonic, upper bound, Mechanical factors, quantifier, syntactic restriction, Computer science, Upper bound, sentence asymptotic behavior, generalized quantifiers, cardinality inequality, Hartig quantifiers, Context modeling]
Infinitary logics and very sparse random graphs
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
The infinitary language obtained from the first-order language of graphs by closure under conjunctions and disjunctions of arbitrary sets of formulas, provided only finitely many distinct variables occur among the formulas, is considered. Let p(n) be the edge probability of the random graph on n vertices. It is shown that if p(n)<<n/sup -1/, then for every sigma belonging to the infinitary language the probability that sigma holds for the random graph on n vertices converges. Further, if p(n)=n/sup -a/, alpha >1, then the probability is either smaller than 2 raised to the power-n/sup d/ for some d>0, or it is asymptotic to the cn/sup -d/ for some c>0, d>or=0. Results on the difficulty of computing the asymptotic probability are given.<<ETX>>
[arbitrary sets, random graph, graph theory, vertices, Formal languages, conjunctions, formulas, Mathematics, Convergence, formal logic, asymptotic probability, graphs, Logic, infinitary logics, closure, formal languages, very sparse random graphs, first-order language, edge probability, probability, Application software, Computational complexity, Physics, Computer science, infinitary language, disjunctions]
Monadic second-order logic and hypergraph orientation
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
It is proved that in every undirected graph or, more generally, in every undirected hypergraph of bounded rank, one can specify an orientation of the edges or hyperedges by monadic second-order formulas using quantifications on sets of edges or hyperedges. The proof uses an extension to hypergraphs of the classical notion of a depth-first search spanning tree. Applications are given to the partially open problem of characterizing the classes of graphs (or hypergraphs) having decidable monadic theories, with and without quantifications on sets of edges (or hyperedges).<<ETX>>
[hyperedges, graph theory, hypergraph orientation, bounded rank, trees (mathematics), depth-first search spanning tree, edges, monadic second-order formulas, decidable monadic theories, quantifications, formal logic, graphs, Tree graphs, decidability, hypergraphs, monadic second-order logic, Logic, undirected graph, undirected hypergraph]
y=2x vs. y=3x
[1993] Proceedings Eighth Annual IEEE Symposium on Logic in Computer Science
None
1993
It is shown that no formula of first-order logic using linear ordering and the logical relation y=2x can define the property that the size of a finite model is divisible by 3. This answers a long-standing question that may be of relevance to certain open problems in circuit complexity.<<ETX>>
[circuit complexity, trees (mathematics), first-order logic, linear ordering, Mathematics, Complexity theory, logical relation, Computer science, formal logic, Logic circuits, descriptive complexity theory, full binary trees, Ear, formula, Polynomials, finite model, theorem proving, Informatics, computational complexity]
The expressive power of finitely many generalized quantifiers
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We consider extensions of first order logic (FO) and fixed [Bpoint logic (FP) by means of generalized quantifiers in the sense of P. Lindstrom (1966). We show that adding a finite set of such quantifiers to FP fails to capture PTIME, even over a fixed signature. We also prove a stronger version of this result for PSPACE, which enables us to establish a weak version of a conjecture formulated previously by Ph.G. Kolaitis and M.Y. Vardi (1992). These results are obtained by defining a notion of element type for bounded variable logics with finitely many generalized quantifiers. Using these, we characterize the classes of finite structures over which the infinitary logic L/sub /spl infin/wsup w/ extended by a finite set of generalized quantifiers Q and is no more expressive than first order logic extended by the quantifiers in Q.<<ETX>>
[Computational modeling, finite structures, Educational institutions, Extraterrestrial measurements, Time measurement, finitely many generalized quantifiers, PSPACE, Computational complexity, expressive power, fixed point logic, bounded variable logics, Computer science, formal logic, Q measurement, PTIME, first order logic, Polynomials, Hardware, Logic, computational complexity]
Generalized quantifiers for simple properties
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We consider extensions of fixed-point logic by means of generalized quantifiers in the context of descriptive complexity. By the well-known theorem of N. Immerman and M. Vardi, fixed-point logic captures PTime over linearly ordered structures. It fails, however, to express even most fundamental structural properties, like simple cardinality properties, in the absence of order. We concentrate on extensions by generalized quantifiers which serve to adjoin simple or basic structural properties. An abstract notion of simplicity is put forward which isolates those structural properties, that can be characterized in terms of a concise structural invariant. The key examples are provided by all monadic and cardinality properties in a very general sense. The main theorem establishes that no extension by any family of such simple quantifiers can cover all of PTime. These limitations are proved on the basis of the semantically motivated notion of simplicity; in particular there is no implicit bound on the arities of the generalized quantifiers involved. Quite to the contrary, the natural applications concern infinite families of quantifiers adjoining certain structural properties across all arities in a uniform way.<<ETX>>
[formal logic, PTime, cardinality properties, generalized quantifiers, monadic properties, fixed-point logic, descriptive complexity, linearly ordered structures, Logic, Database languages, computational complexity]
How to define a linear order on finite models
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We describe on a systematic investigation of the definability of linear order on classes of finite rigid structures. We obtain upper and lower bounds for the expressibility of linear order in various logics that have been studied extensively in finite model theory such as fixpoint logic (FP), partial fixpoint logic (PFP), infinitary logic /spl Lscrsub /spl infin/wsup w/ with a finite number of variables, as well as the closures of these logics under implicit definitions. Moreover, we show that the upper and lower bounds established here can not be improved dramatically, unless outstanding conjectures in complexity theory are resolved at the same time.<<ETX>>
[Vocabulary, linear order, finite rigid structures, Computational modeling, definability, upper bounds, Mathematics, Complexity theory, partial fixpoint logic, lower bounds, formal logic, closures, Turing machines, Databases, fixpoint logic, Polynomials, finite models, finite model theory, Logic, infinitary logic, computational complexity]
Finitary fairness
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Fairness is a mathematical abstraction: in a multiprogramming environment, fairness abstracts the details of admissible ("fair") schedulers; in a distributed environment, fairness abstracts the speeds of independent processors. We argue that the standard definition of fairness often is unnecessarily weak and can be replaced by the stronger, yet still abstract, notion of finitary fairness. While standard weak fairness requires that no enabled transition is postponed forever, finitary weak fairness requires that for every run of a system there is an unknown bound k such that no enabled transition is postponed more than k consecutive times. In general, the finitary restriction fin(F) of any given fairness assumption F is the union of all w-regular safety properties that are contained in F. The adequacy of the proposed abstraction is demonstrated in two ways. Suppose that we prove a program property under the assumption of finitary fairness. In a multiprogramming environment, the program then satisfies the property for all fair finite-state schedulers. In a distributed environment, the program then satisfies the property for all choices of lower and upper bounds on the speeds (or timings) of processors.<<ETX>>
[Context, mathematical abstraction, distributed processing, fair finite-state schedulers, Probability distribution, distributed environment, Distributed computing, finitary fairness, Computer science, formal logic, Upper bound, Processor scheduling, multiprogramming environment, Abstracts, multiprogramming, Safety, Timing, program property, Contracts]
A non-elementary speed-up in proof length by structural clause form transformation
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We investigate the effects of different types of translations of first-order formulas to clausal form on minimal proof length. We show that there is a sequence of unsatisfiable formulas <F/sub n/> such that the length of all refutations of non-structural clause forms of F/sub n/ is non-elementary (in the size of F/sub n/), but there are refutations of structural clause forms of F/sub n/ that are of elementary (at most triple exponential) length.<<ETX>>
[formal logic, structural clause form transformation, first-order formulas, structural clause forms, Algebra, proof length, minimal proof length, unsatisfiable formulas, Calculus, theorem proving, refutations, nonelementary speed-up]
Bisimulation is not finitely (first order) equationally axiomatisable
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
This paper considers the existence of finite equational axiomatisations of bisimulation over a calculus of finite state processes. To express even simple properties such as /spl mu/XE=/spl mu/XE[E/X] equationally it is necessary to use some notation for substitutions. Accordingly the calculus is embedded in a simply typed lambda calculus, allowing axioms such as the above to be written as equations of higher type rather than as equation schemes. Notions of higher order transition system and bisimulation are then defined and using them the nonexistence of finite axiomatisations containing at most first order variables is shown.<<ETX>>
[lambda calculus, bisimulation, finite automata, finite equational axiomatisations, Humans, Calculus, inference mechanisms, Equations, Computer science, Reactive power, typed lambda calculus, finite state processes, Writing, Logic]
Upper and lower bounds for tree-like cutting planes proofs
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We study the complexity of cutting planes (CP) refutations, and tree-like CP refutations. Tree-like CP proofs are natural and still quite powerful. In particular, the propositional pigeonhole principle (PHP) has been shown to have polynomial-sized tree-like CP proofs. Our main result shows that a family of tautologies, introduced in this paper requires exponential-sized tree-like CP proofs. We obtain this result by introducing a new method which relates the size of a CP refutation to the communication complexity of a related search problem. Because these tautologies have polynomial-sized Frege proofs, it follows that tree-like CP cannot polynomially simulate Frege systems.<<ETX>>
[polynomial-sized tree-like CP proofs, search problem, upper bounds, Search problems, Complexity theory, communication complexity, formal logic, Tree graphs, Frege systems, Polynomials, theorem proving, Logic, search problems, polynomially simulate, trees (mathematics), propositional pigeonhole principle, polynomial-sized Frege proofs, lower bounds, Upper bound, Councils, Ear, cutting planes refutations, tree-like cutting planes proofs, computational complexity, tree-like CP refutations]
Foundations of timed concurrent constraint programming
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We develop a model for timed, reactive computation by extending the asynchronous, untimed concurrent constraint programming model in a simple and uniform way. In the spirit of process algebras, we develop some combinators expressible in this model, and reconcile their operational, logical and denotational character. We show how programs may be compiled into finite-state machines with loop-free computations at each state, thus guaranteeing bounded response time.<<ETX>>
[Modular construction, loop-free computations, reactive computation, Control systems, Maintenance, finite state machines, denotational character, Equations, parallel programming, Concurrent computing, Computer science, Computer languages, process algebras, Algebra, timed concurrent constraint programming, Automata, Time factors, constraint handling, finite-state machines, bounded response time]
Domain theory and integration
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We present a domain-theoretic framework for measure theory and integration of bounded read-valued functions with respect to bounded Borel measures on compact metric spaces. The set of normalised Borel measures of the metric space can be embedded into the maximal elements of the normalised probabilistic power domain of its upper space. Any bounded Borel measure on the compact metric space can then be obtained as the least upper bound of an /spl omega/-chain of linear combinations of point valuations (simple valuations) on the zipper space, thus providing a constructive setup for these measures. We use this setting to develop a theory of integration based on a new notion of integral which generalises and shares all the basic properties of the Riemann integral. The theory provides a new technique for computing the Lebesgue integral. It also leads to a new algorithm for integration over fractals of iterated function systems.<<ETX>>
[bounded read-valued functions, measure theory, Fractals, Calculus, point valuations, set theory, zipper space, maximal elements, iterated function systems, Cost accounting, Convergence, fractals, Power measurement, domain-theoretic framework, Lebesgue integral, domain theory, constructive setup, linear combinations, probability, Riemann integral, Extraterrestrial measurements, Educational institutions, normalised probabilistic power domain, Upper bound, bounded Borel measures, compact metric spaces, normalised Borel measures, integration, Particle measurements, Solids, measurement theory, least upper bound]
Typability and type checking in the second-order /spl lambda/-calculus are equivalent and undecidable
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
The problems of typability and type checking exist for the Girard/Reynolds second-order polymorphic typed /spl lambda/-calculus (also known as "system F") when it is considered in the "Curry style" (where types are derived for pure /spl lambda/-terms). Until now the decidability of these problems for F itself has remained unknown. We first prove that type checking in F is undecidable by a reduction from semi-unification. We then prove typability in F is undecidable by a reduction from type checking. Since the reduction from typability to type checking in F is already known, the two problems in F are equivalent (reducible to each other). The results hold for both the usual /spl lambda/K-calculus and the more restrictive /spl lambda/I-calculus.<<ETX>>
[lambda calculus, Logic programming, type checking, Calculus, type theory, typability, Helium, Computer science, formal logic, decidability, undecidable, second-order polymorphic typed lambda calculus, second-order lambda calculus, semiunification, system F]
Axioms for knowledge and time in distributed systems with perfect recall
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
A distributed system, possibly asynchronous, is said to have perfect recall if at all times each processor's state includes a record of all its previous states. The completeness of a propositional modal logic of knowledge and time with respect to such systems is established. The logic includes modal operators for knowledge, and the linear time operators "next" and "until".<<ETX>>
[next, Protocols, knowledge axioms, time axioms, Laboratories, modal operators, distributed processing, temporal logic, Data structures, Concurrency control, completeness, temporal reasoning, previous states, linear time operators, distributed systems, until, propositional modal logic, Logic, asynchronous systems, Clocks, Testing, perfect recall]
A fully abstract semantics for concurrent graph reduction
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
This paper presents a fully abstract semantics for a variant of the untyped /spl lambda/-calculus with recursive [Bdeclarations. We first present a summary of existing work on full abstraction for the untyped /spl lambda/-calculus, concentrating on S. Abramsky (1989) and C.H.L. Ong (1988) work on the lazy /spl lambda/-calculus. Abramsky and Ong's work is based on leftmost outermost reduction without sharing. This is notably inefficient, and many implementations model share by reducing syntax graphs rather than syntax trees. Here we present a concurrent graph reduction algorithm for the /spl lambda/-calculus with recursive declarations, in a style similar to G. Berry and G. Boudol's chemical abstract machine. We adapt Abramsky and Ong's techniques, and present a program logic and denotational semantics for the /spl lambda/-calculus with recursive declarations, and show that the three semantics are equivalent.<<ETX>>
[lambda calculus, programming theory, leftmost outermost reduction, recursive declarations, Chemicals, Convergence, Computer science, formal logic, Computer languages, Tree graphs, untyped lambda calculus, chemical abstract machine, concurrent graph reduction, Trademarks, program logic, syntax graphs, Functional programming, Logic, fully abstract semantics, denotational semantics, Testing, syntax trees]
Normalised rewriting and normalised completion
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Introduces normalised rewriting, a new rewrite relation. It generalises former notions of rewriting modulo E, dropping some conditions on E. For example, E can now be the theory of identity, idempotency, the theory of Abelian groups, or the theory of commutative rings. We give a new completion algorithm for normalised rewriting. It contains as an instance the usual AC completion algorithm (AC being the set of equations containing the associativity and commutativity axioms), but also the well-known Buchberger's algorithm for computing standard bases of polynomial ideals. We investigate the particular case of completion of ground equations. In this case, we prove by a uniform method that completion modulo E terminates, for some interesting E. As a consequence, we obtain the decidability of the word problem for some classes of equational theories. We give implementation results which show the efficiency of normalised completion with respect to completion modulo AC.<<ETX>>
[idempotency, commutative rings, standard bases, ground equations, normalised rewriting, equations, polynomial ideals, decidability, identity, word problem, Abelian groups, Polynomials, normalised completion, rewrite relation, termination, rewriting systems, efficiency, Equations, commutativity axiom, Computer science, associativity axiom, AC completion algorithm, Buchberger's algorithm, equational theories, Pattern matching]
Automatic verification of finite-state concurrent systems
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Logical errors in finite-state concurrent systems such as sequential circuit designs and communication protocols are an important problem for computer scientists. A research group has developed a verification method called temporal logic model checking for this class of systems. In this approach specifications are expressed in a propositional temporal logic, while circuits and protocols are modeled as state-transition systems. An efficient search procedure is used to determine automatically if a specification is satisfied by some transition system. The technique has been used to find subtle errors in a number of non-trivial examples. During the last few years, the size of the state-transition systems that can be verified by model checking techniques has increased dramatically. By representing transition relations implicitly using binary decision diagrams (BDDs), we have been able to check some examples that would have required 10/sup 20/ states with the original algorithm. Various refinements of the BDD-based techniques have pushed the state count up to 10/sup 100/. By combining model checking with various abstraction techniques, we have been able to handle even larger systems. We focus on four of the most important directions for research: use of abstraction and symmetry to achieve an even greater reduction in the size of the state-space that must be explored by this method; development of model checking techniques that can handle parameterized designs without requiring each individual instance of the design to be verified; use of partial order semantics to avoid the state explosion problem that can occur in loosely coupled systems when concurrency is modeled by interleaving; determination of appropriate models and verification techniques for circuits and protocols with real-time constraints.<<ETX>>
[Protocols, parameterized designs, finite automata, decision theory, temporal logic, partial order semantics, finite state machines, specifications, abstraction techniques, Concurrent computing, formal logic, binary decision diagrams, Boolean functions, formal verification, transition relations, Logic circuits, state-transition systems, research group, multiprocessing systems, computer scientists, model checking techniques, communication protocols, search procedure, real-time constraints, Data structures, temporal logic model checking, Explosions, propositional temporal logic, BDD-based techniques, state explosion problem, Coupling circuits, automatic verification, Computer errors, Interleaved codes, logical errors, Sequential circuits, finite-state concurrent systems, sequential circuit designs]
The power of reflective relational machines
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
A model of database programming with reflection, called reflective relational machine, is introduced and studied. The reflection consists here of dynamic generation of queries in a host programming language. The main results characterize the power of the machine in terms of known complexity classes. In particular, the polynomial-time restriction of the machine is shown to express PSPACE, and to correspond precisely to uniform circuits of polynomial depth and exponential size. This provides an alternative, logic-based formulation of the uniform circuit model, more convenient for problems naturally formulated in logic terms. Since time in the polynomially-bounded machine coincides with time in the uniform circuit model, this also shows that reflection allows for more "intense" parallelism, which is not attainable otherwise (unless P=PSPACE). Other results concern the power of the reflective relational machine subject to restrictions on the number of variables used.<<ETX>>
[host programming language, exponential size, uniform circuit model, Relational databases, query languages, Database languages, query processing, Logic circuits, Polynomials, Dynamic programming, programming, Embedded computing, polynomial-time restriction, logic-based formulation, Logic programming, reflective relational machines, complexity classes, Computational modeling, reflection, Reflection, relational databases, PSPACE, database theory, polynomial depth, Computer languages, database programming, query generation, polynomially-bounded machine, computational complexity]
On the Church-Rosser property for expressive type systems and its consequences for their metatheoretic study
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We consider two alternative definitions for the conversion rule in pure type systems. We study the consequences of this choice for the metatheory and point out the related implementation issues. We relate two open problems by showing that if a PTS allows the construction of a fixed point combinator, then Church-Rosser for /spl betaspl eta/-reduction fails. We present a new formalization of Russell's paradox in a slight extension of Martin-Lof's inconsistent theory with Type:Type and show that the resulting term leads to a fix-point construction. The main consequence is that the corresponding system is non-confluent. This example shows that in some typed /spl lambda/-calculi, the Church-Rosser proof for the /spl betaspl eta/-reduction is not purely combinatorial anymore, as in pure /spl lambda/-calculus, but relies on the normalization and thus the logical consistency of the system.<<ETX>>
[expressive type systems, lambda calculus, logical consistency, pure type systems, Buildings, fixed point combinator, Calculus, Mathematics, type theory, metatheory, Computer science, formal logic, metatheoretic study, Church-Rosser property, conversion rule, theorem proving, Mathematical model, implementation issues]
Compositional verification of real-time systems
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Presents a compositional proof system for the verification of real-time systems. Real-time systems are modeled as timed transition modules, which explicitly model interaction with the environment and may be combined using composition operators. Composition rules are devised such that the correctness of a system may be determined from the correctness of its components. These proof rules are demonstrated on Fischer's mutual exclusion algorithm, for which mutual exclusion and bounded response are proven.<<ETX>>
[Real time systems, compositional verification, Vocabulary, compositional proof system, temporal logic, Specification languages, composition rules, Computer science, formal verification, real-time systems, composition operators, system correctness, timed transition modules, Timing, Logic, bounded response, real-time system, environmental interaction modelling, Contracts, proof rules, Fischer's mutual exclusion algorithm, metric temporal logic]
An axiomatisation of computationally adequate domain theoretic models of FPC
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Categorical models of the metalanguage FPC (a type theory with sums, products, exponentials and recursive types) are defined. Then, domain-theoretic models of FPC are axiomatised and a wide subclass of them-the absolute ones-are proved to be both computationally sound and adequate. Examples include: the category of cpos and partial continuous functions and functor categories over it.<<ETX>>
[Flexible printed circuits, formal languages, partial continuous functions, Laboratories, categorical models, axiomatisation, domain-theoretic models, type theory, Equations, Computer science, Computer languages, Councils, computationally adequate domain theoretic models, category theory, functor categories, category, metalanguage FPC, cpos]
Modularity of strong normalization and confluence in the algebraic-/spl lambda/-cube
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Presents the algebraic-/spl lambda/-cube, an extension of Barendregt's (1991) /spl lambda/-cube with first- and higher-order algebraic rewriting. We show that strong normalization is a modular property of all systems in the algebraic-/spl lambda/-cube, provided that the first-order rewrite rules are non-duplicating and the higher-order rules satisfy the general schema of Jouannaud and Okada (1991). This result is proven for the algebraic extension of the calculus of constructions, which contains all the systems of the algebraic-/spl lambda/-cube. We also prove that local confluence is a modular property of all the systems in the algebraic-/spl lambda/-cube, provided that the higher-order rules do not introduce critical pairs. This property and the strong normalization result imply the modularity of confluence.<<ETX>>
[critical pairs, lambda calculus, rewriting systems, higher-order rules, Computational modeling, Calculus, Mathematics, algebra, Equations, algebraic-/spl lambda/-cube, strong normalization, Computer languages, nonduplicating first-order rewrite rules, modularity, algebraic rewriting, calculus of constructions, local confluence, Informatics]
Negative set constraints with equality
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Systems of set constraints describe relations between sets of ground terms. They have been successfully used in program analysis and type inference. So far two proofs of decidability of mixed set constraints have been given: by R. Gilleron, S. Tison and M. Tommasi (1993) and A. Aiken, D. Kozen, and E.L. Wimmers (1993). However, both these proofs are long, involved and do not seem to extend to more general set constraints. Our approach is based on a reduction of set constraints to the monadic class given in a paper by L. Bachmair, H. Ganzinger, and U. Waldmann (1993). We first give a new proof of decidability of systems of mixed (positive and negative) set constraints. We explicitly describe a very simple algorithm working in NEXPTIME and we give in all detail a relatively easy proof of its correctness. Then, we sketch how our technique can be applied to get various extensions of this result. In particular we prove that the problem of consistency of mixed set constraints with restricted projections and unrestricted diagonalization is in NEXPTIME.<<ETX>>
[Algorithm design and analysis, program verification, ground terms, monadic class, Mathematics, type theory, set theory, proof of correctness, consistency, Computer science, formal logic, restricted projections, decidability, simple algorithm, Automata, program analysis, mixed set constraints, unrestricted diagonalization, Constraint theory, negative set constraints, equality, NEXPTIME, type inference]
Cyclic lambda graph rewriting
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Studies cyclic /spl lambda/-graphs. The starting point is to treat a /spl lambda/-graph as a system of recursion equations involving /spl lambda/-terms, and to manipulate such systems in an unrestricted manner, using equational logic, just as is possible for first-order term rewriting. Surprisingly, now the confluence property breaks down in an essential way. Confluence can be restored by introducing a restraining mechanism on the 'copying' operation. This leads to a family of /spl lambda/-graph calculi, which are inspired by the family of /spl lambdaspl sigma/-calculi (/spl lambda/-calculi with explicit substitution). However, these concern acyclic expressions only. In this paper we are not concerned with optimality questions for acyclic /spl lambda/-reduction. We also indicate how Wadsworth's (1978) interpreter can be simulated in the /spl lambda/-graph rewrite rules that we propose.<<ETX>>
[lambda calculus, rewriting systems, confluence, recursion equations, restraining mechanism, Mechanical factors, Calculus, /spl lambda/-graph calculi, Equations, cyclic lambda graph rewriting, Computer science, equations, Information science, explicit substitution, directed graphs, /spl lambda/-terms, copying operation, rewrite rules, Logic, equational logic, /spl lambdaspl sigma/-calculi, interpreter simulation]
On the parallel complexity of model checking in the modal mu-calculus
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
The modal mu-calculus is an expressive logic that can be used to specify safety and liveness properties of concurrent systems represented as labeled transition systems (LTSs). We show that Model Checking in the Modal Mu-Calculus (MCMMC)-the problem of checking whether an LTS is a model of a formula of the propositional modal mu-calculus-is P-hard even for a very restrictive version of the problem involving the alternation-free fragment. In particular, MCMMC is P-hard even if the formula is fixed and alternation-free, and the LTS is deterministic, acyclic, and has fan-in and fan-out bounded by 2. The reduction used is from a restricted version of the circuit value problem known as Synchronous Alternating Monotone Fanout 2 Circuit Value Problem. Specifically, we exhibit NC-algorithms for two potentially useful versions of the problem, both of which involve alternation-free formulas containing a constant number of fixed point operators: 1) the LTS is a finite tree with bounded fan-out; and 2) the formula is A-free and the LTS is deterministic and over an action alphabet of bounded size. In the course of deriving our algorithm for 2), we give a parallel constant-time reduction from the alternation-free modal mu-calculus to Datalog. We also provide a polynomial-time reduction in the other direction thereby establishing an interesting link between the two formalisms.<<ETX>>
[Datalog, Circuits, Model Checking in the Modal Mu-Calculus, finite tree, Production facilities, Calculus, parallel processing, Concurrent computing, formal logic, liveness properties, modal mu-calculus, logic programming, circuit value problem, Polynomials, propositional modal mu-calculus, Logic, parallel complexity, bounded fan-out, Marine safety, expressive logic, parallel constant-time reduction, Computer science, polynomial-time reduction, model checking, concurrent systems, labeled transition systems, Synchronous Alternating Monotone Fanout, safety properties, computational complexity, NC-algorithms]
Semantics of meta-logic in an algebra of programs
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Meta-programming is a powerful technique for extending and modifying the semantics of an existing object language. Along with the expressiveness, however, meta-programming puts forth some subtle semantic problems, among which the most critical is bound to the representation of object programs at the meta-level. We propose a semantic justification for a simple representation technique in the field of a generalised notion of meta-programming in logic. The generalisation consists in specifying the meta-programs with respect to object programs defined by program expressions. The expressions are defined via a rich suite of operations on logic programs. The technique allows one to build straightforward and concise meta-programs via the representation of object level variables by meta-level variables.<<ETX>>
[logic programs, Protocols, programming theory, Logic programming, meta-programming, object language, semantic justification, semantic problems, Knowledge representation, Reasoning about programs, object programs, program algebra, Programming environments, formal logic, Program processors, meta-logic semantics, Algebra, program expressions, object level variables, metalevel variables, logic programming, Transformers, Logic functions, Object oriented programming]
A semantics of object types
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We give a semantics for a typed object calculus, an extension of System F with object subsumption and method override. We interpret the calculus in a per model, proving the soundness of both typing and equational rules. This semantics suggests a syntactic translation from our calculus into a simpler calculus with neither subtyping nor objects.<<ETX>>
[object-oriented programming, Object oriented modeling, object type semantics, soundness, syntactic translation, object oriented language, Calculus, type theory, calculus, Equations, equational rules, subtyping, object subsumption, System F, object-oriented languages, typing, per model, object oriented programming, method override, typed object calculus]
Logical bilattices and inconsistent data
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
The notion of a bilattice was first proposed by Ginsberg (1988) as a general framework for many applications. This notion was further investigated and applied for various goals by Fitting (1989, 1990, 1991, 1993). In this paper, we develop proof systems which correspond to bilattices in an essential way. We then show how to use those bilattices for efficient inferences from possibly inconsistent data. For this, we incorporate certain ideas of Kifer and Lozinskii (1992) concerning inconsistencies, which happen to well suit the framework of bilattices. The outcome is a paraconsistent logic with many desirable properties.<<ETX>>
[Computer science, formal logic, Logic programming, proof systems, Lattices, uncertainty handling, paraconsistent logic, efficient inferences, Application software, inference mechanisms, inconsistent data, logical bilattices]
Terms, proofs and refinement
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We give a simple account of the connection between lambda terms and natural deduction proofs, showing how the terms can be rearranged into a form close to conventional proofs, and also to less conventional "top down" proofs. Creating proofs interactively by refinement can be seen as just keying in a lambda expression one symbol at a time in response to prompts from the machine. The aim is to convey some basic ideas to the uninitiated without technical or pragmatic detail.<<ETX>>
[lambda calculus, Calculus, Computer science, formal logic, natural deduction proofs, proofs, Writing, refinement, theorem proving, Logic, Time factors, Mirrors, lambda terms]
Type inference and extensionality
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
The polymorphic type assignment system F/sub 2/ is the type assignment counterpart of Girard's and Reynolds' (1972) system F. Though introduced in the early seventies, both the type inference and the type checking problems for F/sub 2/ remained open for a long time. Recently, an undecidability result was announced. Consequently, it is considerably interesting to find decidable restrictions of the system. We show a bounded type inference and a bounded type checking algorithm, both based on the study of the relationship between the typability of a term and the typability of terms that "properly" /spl eta/-reduce to it.<<ETX>>
[Shape, F, type checking, type theory, typability, Remuneration, Proposals, decidable restrictions, bounded type checking algorithm, formal logic, bounded type inference, decidability, type assignment counterpart, Inference algorithms, polymorphic type assignment system, extensionality, type inference]
On strong stability and higher-order sequentiality
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Proposes a definition (by reducibility) of sequentiality for the interpretations of higher-order programs and proves the equivalence between this notion and strong stability.<<ETX>>
[formal logic, higher-order sequentiality, programming theory, Stability, strong stability, higher-order programs, reducibility, Concrete, set theory, Game theory, stability]
Linear logic, totality and full completeness
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
I give a 'totality space' model for linear logic [4] derived by taking an abstract view of computations on a datatype. The model has similarities with both the coherence space model and game-theoretic models, but is based upon a notion of total object. Using this model, I prove a full completeness result. In other words, I show that the mapping of proofs to their interpretations (here collections of total objects uniform for a given functor) in the model is a surjection.<<ETX>>
[coherence space model, totality space model, linear logic, abstract data types, database management systems, Game theory, formal logic, datatype, full completeness, data structures, Logic, totality, game-theoretic models, total object]
Paths in the lambda-calculus. Three years of communications without understanding
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Since the rebirth of /spl lambda/-calculus in the late 1960s, three major theoretical investigations of /spl beta/-reduction have been undertaken: (1) Levy's (1978) analysis of families of redexes (and the associated concept of labeled reductions); (2) Lamping's (1990) graph-reduction algorithm; and (3) Girard's (1988) geometry of interaction. All three studies happened to make crucial (if not always explicit) use of the notion of a path, namely and respectively: legal paths, consistent paths and regular paths. We prove that these are equivalent to each other.<<ETX>>
[Algorithm design and analysis, redex families, lambda calculus, Law, legal paths, regular paths, graph theory, computational geometry, Displays, lambda-calculus, Geometry, labeled reductions, graph-reduction algorithm, consistent paths, interaction geometry, Joining processes, Legal factors, Logic devices, /spl beta/-reduction]
Categories, allegories and circuit design
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Relational languages such as RUBY are used to derive hardware circuits from abstract specifications of their behaviour. Much reasoning is done informally in RUBY using pictorial representations of relational terms. We formalise this use of pictures in circuit design. We show that pictures naturally form a unitary pretabular allegory. Homomorphisms of pictures correspond to adding new wires or circuit comments. Two pictures are mutually homomorphic if and only if they represent equal allegorical terms. We prove soundness and completeness results which guarantee that deriving circuits using pictures does not lead to errors. We illustrate the use of pictures by deriving the ripple adder implementation from a high level, behavioural specification.<<ETX>>
[Process design, relational algebra, pictorial representations, reasoning, ripple adder implementation, hardware circuits, Calculus, completeness, abstract specifications, Circuit testing, formal specification, pictures, Algebra, adders, Wires, circuit CAD, Hardware, Systolic arrays, categories, relational languages, Adders, circuit diagrams, Buildings, soundness, allegories, unitary pretabular allegory, high level behavioural specification, category theory, Circuit synthesis, RUBY, circuit design]
Systems of set constraints with negative constraints are NEXPTIME-complete
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
A system of set constraints is a system of expressions E/spl sube/F where E and F describe sets of ground terms over a ranked alphabet. Aiken et al. (1993) classified the complexity of such systems. In A. aiken et al. (1993), it was shown that if negative constraints Enot/spl sube/F were allowed, then the problem as decidable. This was done by reduction to a Diophantine problem, the nonlinear reachability problem, which was shown to be decidable. We show that nonlinear reachability is NP-complete. By bounding the reduction of A. aiken et al. (1993), we conclude that systems of set constraints allowing negative constraints are NEXPTIME-complete.<<ETX>>
[complexity, decidable, ground terms, NP-complete, set theory, nonlinear reachability problem, Diophantine problem, Tellurium, Cost accounting, negative constraints, Computer science, formal logic, decidability, ranked alphabet, Automata, set constraints, Polynomials, NEXPTIME-complete, Artificial intelligence, computational complexity]
A syntactic characterization of NP-completeness
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Fagin (1974) proved that NP is equal to the set of problems expressible in second-order existential logic (SO/spl exist/). We consider problems that are NP-complete via first-order projections (fops). These low-level reductions are known to have nice properties, including the fact that every pair of problems that are NP-complete via fops are isomorphic via a first-order definable isomorphism (E. Allender et al., 1993). However, before this paper, fewer than five natural problems had actually been shown to be NP-complete via fops. We give a necessary and sufficient syntactic condition for an SO/spl exist/ formula to represent a problem that is NP-complete via fops. Using this condition we prove syntactically that 29 natural NP-complete problems remain complete via fops.<<ETX>>
[Vocabulary, syntactic characterization, NP-complete problem, first-order definable isomorphism, Computer science, formal logic, Sufficient conditions, optimisation, second-order existential logic, NP-completeness, NP-complete problems, Logic, computational complexity, first-order projections]
Complexity transfer for modal logic
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We prove general theorems about the relationship between the complexity of multi-modal logics and the complexity of their uni-modal fragments. Halpern and Moses (1985) show that the complexity of a multi-modal logic without any interaction between the modalities may be higher than the complexity of the individual fragments. We show that under reasonable assumptions the complexity can increase only if the complexity of all the uni-modal fragments is below PSPACE. In addition, we completely characterize what happens if the complexity of all fragments is below PSPACE.<<ETX>>
[complexity, Educational institutions, modal logic, PSPACE, complexity transfer, Computer science, formal logic, Upper bound, multimodal logics, unimodal fragments, Computational linguistics, theorem proving, Logic, computational complexity]
A multiple-conclusion meta-logic
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
The theory of cut-free sequent proofs has been used to motivate and justify the design of a number of logic programming languages. Two such languages, /spl lambda/Prolog and its linear logic refinement, Lolli (J. Hodas and D. Miller, 1994), provide for various forms of abstraction (modules, abstract data types, higher-order programming) but lack primitives for concurrency. The logic programming language, LO (Linear Objects) (J. Andreoli and R. Pareschi, 1991) provides for concurrency but lacks abstraction mechanisms. We present Forum, a logic programming presentation of all of linear logic that modularly extends the languages /spl lambda/Prolog, Lolli, and LO. Forum, therefore, allows specifications to incorporate both abstractions and concurrency. As a meta-language, Forum greatly extends the expressiveness of these other logic programming languages. To illustrate its expressive strength, we specify in Forum a sequent calculus proof system and the operational semantics of a functional programming language that incorporates such nonfunctional features as counters and references.<<ETX>>
[multiple-conclusion meta-logic, LO, functional programming, references, Lolli, operational semantics, Calculus, specifications, Counting circuits, Forum, Concurrent computing, formal logic, cut-free sequent proofs, Typesetting, logic programming language, logic programming, PROLOG, Functional programming, programming theory, Logic programming, counters, abstract data types, Linear programming, logic programming languages, concurrency, abstractions, Computer science, linear logic refinement, lambda Prolog, functional programming language, higher-order programming, sequent calculus proof system, Linear Objects]
Higher-order narrowing
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Introduces several approaches for solving higher-order equational problems by higher-order narrowing, and gives some completeness results. The results apply to higher-order functional-logic programming languages and to higher-order unification modulo a higher-order equational theory. We lift the general notion of first-order narrowing to so-called higher-order patterns and argue that the full higher-order case is problematic. Integrating narrowing into unification (called 'lazy narrowing') can avoid these problems and can be adapted to the full higher-order case. For the second-order case, we develop a version where the needed second-order unification remains decidable. Finally, we discuss a method that combines both approaches by using narrowing on higher-order patterns with full higher-order constraints.<<ETX>>
[rewriting systems, programming theory, higher-order constraints, Logic programming, functional programming, higher-order unification, higher-order equational theory, completeness, logic programming languages, Equations, second-order unification, higher-order functional-logic programming languages, equations, Computer languages, decidability, higher-order patterns, lazy narrowing, higher-order narrowing]
Passivity and independence
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Most programming languages have certain phrases (like expressions) which only read information from the state and certain others (like commands) which write information to the state. These are called passive and active phrases respectively. Semantic models which make these distinctions have been hard to find. For instance, most semantic models have expression denotations that (temporarily) change the state. Common reasoning principles, such as the Hoare's assignment axiom, are not valid in such models. We define here a semantic model which captures the notions of "change\
[Hoare's assignment axiom, programming theory, Logic programming, Terminology, Interference, programming languages, independence, expressions, semantic model, linear logic model of state, Concurrent computing, formal logic, Computer languages, Disk drives, reasoning principles, pomset traces, passivity, phrases, sequential traces, programming, commands, expression denotations]
A modal logic for subjective default reasoning
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Introduces a logic endowed with a two-place modal connective that has the intended meaning of "if /spl alpha/, then normally /spl beta/". On top of providing a well defined tool for analyzing common default reasoning, such a logic allows nesting of the default operator. We present a semantic framework in which many of the known default proof systems can be naturally characterized, and prove soundness and completeness theorems for several such proof systems. Our semantics is a "neighborhood modal semantics\
[Legged locomotion, semantical analysis, intuitive interpretation, default operator nesting, probabilistic logic, default reasoning, subjective default reasoning, Watches, default proof systems, set theory, subjective defaults, modal logic, nonmonotonic reasoning, Computer science, probabilistic interpretations, Filters, two-place modal connective, set theoretic generalization, soundness theorems, neighborhood modal semantics, Logic, completeness theorems]
McColm's conjecture [positive elementary inductions]
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
G. McColm (1990) conjectured that positive elementary inductions are bounded in a class K of finite structures if every (FO+LFP) formula is equivalent to a first-order formula in K. Here (FO+LFP) is the extension of first-order logic with the least fixed point operator. We disprove the conjecture. Our main results are two model-theoretic constructions, one deterministic and the other randomized, each of which refutes McColm's conjecture.<<ETX>>
[Computer science, formal logic, Vocabulary, first-order formula, Building materials, positive elementary inductions, finite structures, model-theoretic constructions, first-order logic, Mathematics, Logic, least fixed point operator]
The groupoid model refutes uniqueness of identity proofs
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We give a model of intensional Martin-Lof type theory based on groupoids and fibrations of groupoids in which identity types may contain two distinct elements which are not even prepositionally equal. This shows that the principle of uniqueness of identity proofs is not derivable in the syntax.<<ETX>>
[Computer science, formal logic, uniqueness, intensional Martin-Lof type theory, identity proofs, computation theory, fibrations, syntax, type theory, Logic, groupoid model]
Linear types, approximation, and topology
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We enrich the *-autonomous category of complete lattices and maps preserving all suprema with the important concept of approximation by specifying a *-autonomous full subcategory LFS of linear FS-lattices. This is the greatest *-autonomous full subcategory of linked bicontinuous lattices. The modalities !() and ?() mediate a duality between the upper and lower powerdomains. The distributive objects in LFS give rise to the compact closed *-autonomous full subcategory CD of completely distributive lattices. We characterise algebraic objects in LFS by forbidden substructures 'a la Plotkin'.<<ETX>>
[forbidden substructures, linear logic, Lattices, formal logic, modalities, powerdomains, Logic, *-autonomous full subcategory LFS, algebraic objects, interaction orders, approximation theory, linear types, approximation, linked bicontinuous lattices, topology, Topology, linear FS-lattices, duality, complete lattices, Bridges, completely distributive lattices, compact closed *-autonomous full subcategory CD, Linear approximation, distributive objects, Plotkin]
The emptiness problem for intersection types
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We prove that it is undecidable whether a given intersection type is non-empty, i.e., whether there exists a closed term of this type.<<ETX>>
[formal logic, intersection types, lambda calculus, decidability, closed term, Automata, Calculus, type theory, emptiness problem, Logic, Informatics]
A trace based extension of linear time temporal logic
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
The propositional temporal logic of linear time (PTL) is interpreted over linear orders of order type (/spl omega/,/spl les/). In applications, these linear orders consist of interleaved descriptions of the infinite runs of a concurrent program. Recent research on partial order based verification methods suggests that it might be fruitful to represent such runs as partial orders called infinite traces. We design a natural extension of PTL called TrPTL to be interpreted directly over infinite traces. Using automata-theoretic techniques we show that the satisfiability problem for TrPTL is decidable. The automata that arise in this context turn out to be an attractive model of finite state concurrent programs. As a result, we also solve the model checking problem for TrPTL with respect to finite state concurrent programs.<<ETX>>
[interleaved descriptions, finite automata, automata theory, temporal logic, Mathematics, Concurrent computing, decidability, satisfiability problem, Logic, Labeling, infinite traces, programming theory, trace based extension, finite state concurrent programs, multiprocessing programs, linear time temporal logic, propositional temporal logic, infinite runs, concurrent program, partial order based verification methods, Automata, model checking problem, linear orders, TrPTL, Context modeling]
Rewrite techniques for transitive relations
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We propose inference systems for dealing with transitive relations in the context of resolution-type theorem proving. These inference mechanisms are based on standard techniques from term rewriting and represent a refinement of chaining methods. We establish their refutational completeness and also prove their compatibility with the usual simplification techniques used in rewrite-based theorem provers. A key to the practicality of chaining techniques is the extent to which so-called variable chainings can be restricted. We demonstrate that rewrite techniques considerably restrict variable chaining, though we also show that they cannot be completely avoided for transitive relations in general. If the given relation satisfies additional properties, such as symmetry, further restrictions are possible. In particular, we discuss (partial) equivalence relations and congruence relations.<<ETX>>
[rewrite techniques, rewriting systems, resolution-type theorem proving, congruence relations, Genetic mutations, inference systems, Reasoning about programs, inference mechanisms, transitive relations, Equations, Computer science, equivalence relations, Inference mechanisms, refutational completeness, chaining methods, theorem proving, Logic, equivalence classes]
A compositional proof system for the modal /spl mu/-calculus
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We present a proof system for determining satisfaction between processes in a fairly general process algebra and assertions of the modal /spl mu/-calculus. The proof system is compositional in the structure of processes. It extends earlier work on compositional reasoning within the modal /spl mu/-calculus and combines it with techniques from work on local model checking. The proof system is sound for all processes and complete for a class of finite-state processes.<<ETX>>
[finite-state processes, local model checking, compositional proof system, Turning, Calculus, Power system modeling, Computer science, formal logic, Algebra, Councils, process algebra, Logic functions, theorem proving, compositional reasoning, modal /spl mu/-calculus]
The declarative semantics of the Prolog selection rule
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We axiomatize the Prolog selection rule which always selects the leftmost literal in a goal. We introduce a new completion of a logic program which we call the l-completion of the program. The l-completion is formulated as a first-order theory in a language extended by new predicate symbols which express success, failure and left-termination of queries. The main results of the paper are the following. If a query succeeds, fails or is left-terminating under the Prolog selection rule, then the corresponding formula in the extended language is provable from the l-completion. Conversely, if a logic program and a query are correct with respect to some mode assignment and if one can prove in the l-completion that the query succeeds and is left-terminating, then the goal is successful and Prolog, using its depth first search, will compute an answer substitution for the goal. This result can even be extended to so called non-floundering queries.<<ETX>>
[predicate symbols, programming theory, Logic programming, first-order theory, Prolog selection rule, nonfloundering queries, queries, formal logic, query processing, extended language, leftmost literal, mode assignment, logic programming, PROLOG, declarative semantics, Joining processes, logic program, l-completion, depth first search]
Efficient inference of object types
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Abadi and Cardelli (1994) have investigated a calculus of objects. The calculus supports a key feature of object-oriented languages: an object can be emulated by another object that has more refined methods. Abadi and Cardelli presented four first-order type systems for the calculus. The simplest one is based on finite types and no subtyping, and the most powerful one has both recursive types and subtyping. Open until now is the question of type inference, and in the presence of subtyping "the absence of minimum typings poses practical problems for type inference". In this paper we give an O(n/sup 3/) algorithm for each of the four type inference problems and we prove that all the problems are P-complete.<<ETX>>
[object types, finite types, object-oriented programming, inference, recursive types, first-order type systems, Educational institutions, Calculus, type theory, Parallel algorithms, subtyping, Computer science, calculus of objects, Sections, Automata, P-complete, object-oriented languages, Inference algorithms, type inference]
Proof search in first-order linear logic and other cut-free sequent calculi
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
We present a general framework for proof search in first-order cut-free sequent calculi and apply it to the specific case of linear logic. In this framework, Herbrand functions are used to encode universal quantification, and unification is used to instantiate existential quantifiers so that the eigenvariable conditions are respected. We present an optimization of this procedure that exploits the permutabilities of the subject logic. We prove the soundness and completeness of several related proof search procedures. This proof search framework is used to show that provability for first-order MALL is in NEXPTIME, and first-order MLL is in NP. Performance comparisons based on Prolog implementations of the procedures are also given. The optimization of the quantifier steps in proof search can be combined effectively with a number of other optimizations that are also based on permutability.<<ETX>>
[eigenvariable conditions, Laboratories, proof search, Calculus, cut-free sequent calculi, calculus, unification, first-order linear logic, Herbrand functions, Computer science, formal logic, existential quantifiers, theorem proving, Logic, universal quantification, NEXPTIME, Prolog implementation]
Reflexive graphs and parametric polymorphism
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
The pioneering work on relational parametricity for the second order lambda calculus was done by Reynolds (1983) under the assumption of the existence of set-based models, and subsequently reformulated by him, in conjunction with his student Ma, using the technology of PL-categories. The aim of this paper is to use the different technology of internal category theory to re-examine Ma and Reynolds' definitions. Apart from clarifying some of their constructions, this view enables us to prove that if we start with a non-parametric model which is left exact and which satisfies a completeness condition corresponding to Ma and Reynolds "suitability for polymorphism\
[lambda calculus, second order lambda calculus, nonparametric model, relational parametricity, closed types, PER model, Calculus, type theory, polymorphism, set theory, set-based models, reflexive graphs, formal logic, parametric polymorphism, internal category theory, Space technology, parametric model, category theory, completeness condition, Indexing]
Rigid E/spl I.oarr/-unifiability is DEXPTIME-complete
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Proves that rigid E/spl I.oarr/-unifiability, a decision problem invented by Gallier et al. (1987) to extend first-order tableaux-like proof procedures to first-order logic with equality, is DEXPTIME-complete; and that, when restricted to monadic terms, it is PSPACE-complete.<<ETX>>
[decision problem, first-order logic, monadic terms, PSPACE-completeness, Data structures, Calculus, rigid E/spl I.oarr/-unifiability, Equations, DEXPTIME-completeness, Boolean functions, decidability, Logic, first-order tableaux-like proof procedures, equality, computational complexity]
A general semantics for Evaluation Logic
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
The semantics of Evaluation Logic proposed by Moggi (1994) relies on additional properties of monads. This paper proposes an alternative semantics, which drops all additional requirement on monads at the expense of stronger assumptions on the underlying category. These assumptions are satisfied by any topos, but not by the category of cpos. However, in the setting of Synthetic Domain Theory (J. Hyland, 1991) and (P.Taylor, 1991) it is possible to reconcile the needs of denotational semantics with those of logic.<<ETX>>
[Evaluation Logic semantics, programming theory, Logic programming, Synthetic Domain Theory, underlying category, type theory, set theory, monads, Acoustic reflection, Equations, topos, Computer science, formal logic, Computer languages, denotational semantics, cpos]
Language completeness of the Lambek calculus
Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science
None
1994
Proves that the Lambek calculus (J. Lambek, American Math. Monthly, vol. 65, no. 3, pp. 154-170, 1958), which is essentially a subsystem of noncommutative linear logic, is complete with respect to L-models, i.e. free semigroup models.<<ETX>>
[formal logic, group theory, noncommutative linear logic, formal languages, Lambek calculus, language completeness, L-models, Calculus, Mathematics, Logic, Artificial intelligence, free semigroup models]
A typed calculus of synchronous processes
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Proposes a typed calculus of synchronous processes based on the structure of interaction categories. Our aim has been to develop a calculus for concurrency that is canonical in the sense that the typed /spl lambda/-calculus is canonical for functional computation. We show strong connections between syntax, logic and semantics, analogous to the familiar correspondence between the typed /spl lambda/-calculus, intuitionistic logic and Cartesian closed categories.
[Logic programming, synchronous processes, typed calculus, Cartesian closed categories, intuitionistic logic, Educational institutions, Turning, interaction categories, Calculus, type theory, semantics, Programming profession, parallel programming, synchronisation, concurrency, Concurrent computing, formal logic, Algebra, process algebra, System recovery, syntax, canonical calculus, logic, /spl lambda/-calculus]
Normalization and extensionality
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
An investigation on the interaction between /spl beta/-reduction and /spl eta/-expansion is provided in a labelled /spl lambda/-calculus, where additional information, that is constituted by integers, can be considered as a type in an abstract sense. This leads to propose the splitting of the /spl beta/-rule into two parts: a restricted /spl beta/-rule (/spl beta//sup +/), strongly normalizing, and a reversed /spl eta/-rule (/spl eta//sup -/), which comes out to have different computational interpretations for reduction in untyped and typed calculi (static and dynamic allocation of computation resources, respectively). To motivate the opportunity of this splitting, the paper hints to new proofs of strong normalization theorems for some typed /spl lambda/-calculi in Curry style.
[restricted /spl beta/-rule, lambda calculus, labelled lambda-calculus, static allocation, Nails, reversed eta-rule, strong normalization theorems, typed calculi, Calculus, type theory, Remuneration, History, untyped calculi, dynamic allocation, computational interpretations, normalization, eta-expansion, extensionality, Labeling, Resource management, Argon, Contracts, /spl beta/-reduction, computation resources]
Hardware verification, Boolean logic programming, Boolean functional programming
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
One of the main obstacles to automatic verification of finite state systems (FSSs) is state explosion. In this respect automatic verification of an FSS M using model checking and binary decision diagrams (BDDs) has an intrinsic limitation: no automatic global optimization of the verification task is possible until a BDD representation for M is generated. This is because systems and specifications are defined using different languages. To perform global optimization before generating a BDD representation for M we propose to use the same language to define systems and specifications. We show that first order logic on a Boolean domain yields an efficient functional programming language that can be used to represent, specify and automatically verify FSSs, e.g. on a SUN Sparc Station 2 we were able to automatically verify a 64 bit commercial multiplier.
[Frequency selective surfaces, functional programming, Boolean logic programming, Binary decision diagrams, Automatic logic units, state explosion, diagrams, Boolean functional programming, commercial multiplier, specifications, binary decision diagrams, Boolean functions, optimisation, formal verification, logic programming, finite state systems, Hardware, Functional programming, algebraic specification, SUN Sparc Station 2, programming theory, Logic programming, Data structures, Explosions, Sun, global optimization, model checking, Boolean logic, automatic verification, functional programming language, first order logic, hardware verification, functional languages]
Games semantics for full propositional linear logic
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We present a model of propositional classical linear logic (all the connective except for the additive constants) where the formulas are seen as two person games in which connectives are used as tokens, while the proofs are interpreted as strategies for one player. We discuss the intimate connection between these games and the structure of proofs, and prove a full completeness theorem. The main technical innovation is a "double negation" interpretation of CLL into intuitionistic linear logic.
[IEEE news, Technological innovation, two person games, CLL, intuitionistic linear logic, game theory, full propositional linear logic, full completeness theorem, Educational institutions, Data structures, Game theory, connectives, games semantics, formal logic, CLL interpretation, technical innovation, proofs, Ear, double negation, Concrete, Logic, Context modeling, propositional classical linear logic]
The complexity of neutrals in linear logic
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
The main result announced in the paper is the proof of the existence of strongly independent (free) sets of linear logic formulas that are built up of only neutrals. The motivating application is a uniform and transparent technique for obtaining the exact computational characterization of constant only fragments of commutative and noncommutative linear logic. In particular, we prove the surprising results that: multiplicative additive fragments of constant only linear logic are PSPACE complete; all partial recursive predicates are directly definable in the full constant only linear logic.
[full constant only linear logic, partial recursive predicates, Vectors, strongly independent sets, formal logic, noncommutative linear logic, Boolean functions, constant only fragments, transparent technique, neutrals, linear logic formulas, exact computational characterization, multiplicative additive fragments, directly definable, theorem proving, proof, Logic, PSPACE complete, computational complexity]
New notions of reduction and non-semantic proofs of strong /spl beta/-normalization in typed /spl lambda/-calculi
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Two notions of reduction for terms of the /spl lambda/-calculus are introduced and the question of whether a /spl lambda/-term is /spl beta/-strongly normalizing is reduced to the question of whether a /spl lambda/-term is merely normalizing under one of the notions of reduction. This gives a method to prove strong /spl beta/-normalization for typed /spl lambda/-calculi. Instead of the usual semantic proof style based on Tait's realizability or Girard's "candidats de reductibilite\
[termination, intersection types, lambda calculus, programming theory, strong /spl beta/-normalization, decreasing metric, well-founded ordering, polymorphic extension, typed lambda-calculi, Cleaning, type theory, Computer science, semantic proof style, reduction, nonsemantic proofs]
Sequentiality, second order monadic logic and tree automata
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Given a term rewriting system R and a normalizable term t, a redex is needed if in any reduction sequence of t to a normal for m, this redex will be contracted. Roughly, R is sequential if there is an optimal reduction strategy in which only needed redexes are contracted. More generally, G. Huet and J.-J. Levy (1991) define the sequentiality of a predicate P on partially evaluated terms. We show that the sequentiality of P is definable in SkS, the second order monadic logic with k: successors, provided P is definable in SkS. We derive several known an new consequences of this remark: strong sequentiality, as defined by Huet and Levy, of a left linear (possibly overlapping) rewrite system is decidable; NV sequentiality, as defined by M. Oyamaguchi (1993), is decidable, even in the case of overlapping rewrite systems; sequentiality of any linear shallow rewrite system is decidable. Then we describe a direct construction of an automaton recognizing the set of terms that have needed redexes, which again, yields immediate consequences: strong sequentiality of possibly overlapping linear rewrite systems is decidable in EXPTIME; for strongly sequential rewrite systems, needed redexes can be read directly on the automaton.
[term rewriting system, normalizable term, possibly overlapping linear rewrite systems, automata theory, overlapping rewrite systems, EXPTIME, sequentiality, formal logic, predicate, decidability, NV sequentiality, strongly sequential rewrite systems, partially evaluated terms, Logic, linear shallow rewrite system, rewriting systems, trees (mathematics), optimal reduction strategy, redex, automaton, strong sequentiality, Automata, second order monadic logic, reduction sequence, tree automata, direct construction]
Configuration structures
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Configuration structures provide a model of concurrency generalising the families of configurations of event structures. They can be considered logically, as classes of propositional models; then, sub-classes can be axiomatised by formulae of simple prescribed forms. Several equivalence relations for event structures are generalized to configuration structures, and also to general Petri nets. Every configuration structure is shown to be ST-bisimulation equivalent to a prime event structure with binary conflict; this fails for the tighter history-preserving bisimulation. Finally, Petri nets without self-loops under the collective token interpretation are shown to be behaviourally equivalent to configuration structures, in the sense that there are translations in both directions respecting history-preserving bisimulation. This fails for nets with self-loops.
[programming theory, Petri nets, configuration structures, self-loops, bidirectional translations, binary conflict, History, parallel programming, Computer science, Concurrent computing, formal logic, equivalence relations, ST-bisimulation equivalence, propositional models, general Petri nets, concurrency model, Automata, event structure configuration families, simple prescribed forms, history-preserving bisimulation, behavioural equivalence, subclass axiomatization, collective token interpretation]
Uniform proofs and disjunctive logic programming
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
One formulation of the concept of logic programming is the notion of an abstract logic programming language. Central to its definition is a uniform proof, which enforces the requirements of inference direction, including goal-directedness, and the duality of readings, both declarative and procedural. We use this technology to investigate disjunctive logic programming (DLP), an extension of traditional logic programming that permits disjunctive program clauses. This extension has been considered by some to be inappropriately identified with logic programming because the indefinite reasoning introduced by disjunction violates the goal-oriented search directionality that is central to logic programming. We overcome this criticism by showing that the requirement of uniform provability can be realized in a logic which is more general than that of DLP under a modest, sound modification of programs. We use this observation to derive inference rules that capture the essential proof structure of InH-Prolog (Inheritance Near-Horn Prolog), a known proof procedure for DLP.
[Inheritance Near-Horn Prolog, abstract logic programming language, Calculus, Databases, indefinite reasoning, proof structure, logic programming, duality (mathematics), theorem proving, Books, uniform provability, search problems, disjunctive logic programming, disjunctive program clauses, goal-oriented search directionality, inference rules, programming theory, formal languages, Logic programming, uniform proofs, InH-Prolog, inference mechanisms, logic programming languages, Computer science, declarative programming, inference direction, duality of readings, procedural programming, goal-directedness, sound program modification]
Modal /spl mu/-types for processes
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Introduces a new paradigm for concurrency, called behaviours-as-types. In this paradigm, types are used to convey information about the behaviour of processes: while terms correspond to processes, types correspond to behaviours. We apply this paradigm to Winskel's (1994) process algebra. Its types are similar to Kozen's (1983) modal /spl mu/-calculus; hence, they are called modal /spl mu/-types. We prove that two terms having the same type denote two processes which behave in the some way, that is, they are bisimilar. We give a sound and complete compositional typing system for this language. Such a system naturally also recovers the notion of bisimulation on open terms, allowing us to deal with processes with undefined parts in a compositional manner.
[bisimulation, formal languages, Shape, modal /spl mu/-types, undefined parts, type theory, open terms, parallel programming, concurrency, Computer science, bisimilar processes, process behaviour, Algebra, Sockets, Message passing, process algebra, Logic, Artificial intelligence, modal /spl mu/-calculus, Plugs, behaviours-as-types]
Efficient on-the-fly model checking for CTL
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
This paper gives an on-the-fly algorithm for determining whether a finite-state system satisfies a formula in the temporal logic CTL. The time complexity of our algorithm matches that of the best existing "global algorithm" for model checking in this logic, and it performs as well as the best known global algorithms for the sublogics CTL and LTL. In contrast with these approaches, however, our routine constructs the state space of the system under consideration in a need-driven fashion and will therefore perform better in practice.
[Algorithm design and analysis, on-the-fly model checking, finite-state system, finite automata, LTL, temporal logic, time complexity, Encoding, State-space methods, global algorithm, Computer science, Automata, CTL, Safety, Performance analysis, Logic, computational complexity, sublogic]
Decision problems for second-order linear logic
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
The decision problem is studied for fragments of second order linear logic without modalities. It is shown that the structural rules of contraction and weakening may be simulated by second order propositional quantifiers and the multiplicative connectives. Among the consequences are the undecidability of the intuitionistic second order fragment of propositional multiplicative linear logic and the undecidability of multiplicative linear logic with first order and second order quantifiers.
[decision problem, decision theory, Laboratories, Petri nets, first order quantifiers, multiplicative connectives, formal logic, decidability, intuitionistic second order fragment, second order linear logic, contraction, Polynomials, Functional programming, weakening, propositional multiplicative linear logic, programming theory, Logic programming, Computational modeling, Computer simulation, second order propositional quantifiers, undecidability, Computer science, second-order linear logic, Linearity, structural rules, Ear, multiplicative linear logic]
The infinitary logic of sparse random graphs
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Let L/sub /spl infin//spl omega///sup /spl omega// be the infinitary language obtained from the first-order language of graphs by closure under conjunctions and disjunctions of arbitrary sets of formulas, provided only finitely many distinct variables occur among the formulas. Let p(n) be the edge probability of the random graph on n vertices. Previous articles have shown that when p(n) is constant or p(n)=n/sup -/spl alpha// and /spl alpha/>1, then every sentence in L/sub /spl infin//spl omega///sup /spl omega// has probability that converges as n gets large; however, when p(n)=n/sup -/spl alpha// and /spl alpha/<1 is rational, then there are first-order sentences whose probability does not converge. This article completes the picture for L/sub /spl infin//spl omega///sup /spl omega// and random graphs with edge probability of the form n/sup -/spl alpha//. It is shown that if /spl alpha/ is irrational, then every sentence in L/sub /spl infin//spl omega///sup /spl omega// has probability that converges to 0 or 1. It is also shown that if /spl alpha/=1, then there are sentences an the deterministic transitive closure logic (and therefore in L/sub /spl infin//spl omega///sup /spl omega//), whose probability does not converge.
[formal logic, sparse random graphs, formal languages, first-order language, random graph, edge probability, finitely many distinct variables, Logic, infinitary logic, deterministic transitive closure logic, Convergence]
Ptime canonization for two variables with counting
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We consider infinitary logic with two variable symbols and counting quantifiers, C/sup 2/, and its intersection with PTIME on finite relational structures. In particular we exhibit a PTIME canonization procedure for finite relational structures which provides unique representatives up to equivalence in C/sup 2/. As a consequence we obtain a recursive presentation for the class of all those queries on arbitrary finite relational structures which are both PTIME and definable in C/sup 2/. The proof renders a succinct normal form representation of this non-trivial semantically defined fragment of PTIME. Through specializations of the proof techniques similar results apply with respect to the logic L/sup 2/, infinitary logic with two variable symbols, itself.
[counting, finite relational structures, Vocabulary, counting quantifiers, equivalence, relational algebra, variable symbols, recursive presentation, PTIME canonization, normal form, queries, formal logic, Turing machines, Polynomials, Logic, infinitary logic, Clocks, computational complexity]
Origins and metamorphoses of the Trinity: logic, nets, automata
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Synthesis and verification of systems with finite state space are well established problems in logic and computer science and have a long history. Precise formulations are based on preliminary formalization of two languages: SPEC (for specifications), IMP (for implementations) and a (satisfaction) relation, sat, included in IMP x SPEC. Clearly, one can consider different languages which may reflect a variety of abstraction levels. It may well happen that an object at a given level may serve as implementation for a higher level and also as specification for a lower level. From this perspective the three level paradigm is instructive and there is a proliferation of its versions. Though many of them are relevant to the subject, in this lecture the author singles out only one to which he refers to as The Trinity, namely: at the highest level-specifications expressed as formulas based on second order monadic logic (SOML); at the intermediate level-formalization of transducers (i.e. transformers of input signals into output signals) via finite sequential automata; at the lower level-formalization of discrete synchronous hardware via logical nets.
[program verification, intermediate level, automata theory, Turning, abstraction levels, formal specification, specifications, formal logic, three level paradigm, transducer formalization, finite state space, Hardware, Logic, SOML, discrete synchronous hardware, preliminary formalization, Transducers, input signals, output signals, logical nets, The Trinity, systems verification, finite sequential automata, State-space methods, Game theory, Computer science, Automata, second order monadic logic, Signal synthesis, precise formulations, Arithmetic]
Paramodulation without duplication
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
The resolution (and paramodulation) inference systems are theorem proving procedures for first-order logic (with equality), but they can run exponentially long for subclasses which have polynomial-time decision procedures, as in the case of SLD resolution and the Knuth-Bendix completion procedure, both in the ground case. Specialized methods run in polynomial time, but have not been extended to the full first-order case. We show a form of paramodulation which does not copy literals, which runs in polynomial time for the ground case of the following four subclasses: Horn clauses with any selection rule, any set of unit equalities (this includes completion), equational Horn clauses with a certain selection rule, and conditional narrowing.
[first-order logic, resolution inference systems, Superluminescent diodes, polynomial-time decision procedures, Databases, theorem proving procedures, selection rule, SLD resolution, conditional narrowing, Polynomials, theorem proving, Logic, equality, Testing, Horn clauses, Data structures, inference mechanisms, Equations, duplication, unit equalities, Mesons, paramodulation, ground case, Knuth-Bendix completion procedure, equational Horn clauses, subclasses, computational complexity]
Control structures
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
'Action calculi' are a class of action structures with added structure. Each action calculus AC(/spl Kscr/) is determined by a set /spl Kscr/ of controls, equipped with reaction rules; calculi such as Petri nets, the typed /spl lambda/-calculus and the /spl pi/-calculus are obtained by varying /spl Kscr/. This paper defines for each /spl Kscr/ a category CS(/spl Kscr/), characterized by equational axioms, of action structures with added structure; they are called 'control structures' and provide models of the calculus AC(/spl Kscr/), which is initial in the category. The 'surface' of an action is defined; this is an abstract correlate of the syntactic notion of 'free name'. Three equational characterizations of the surface are found to be equivalent. This permits a non-syntactic treatment of the linkage among the components of an interactive system. Finally, control structures and their morphisms offer a means of classifying the variety of dynamic disciplines in models of concurrency, such as the mobility present in the /spl pi/-calculus but absent in other calculi.
[mobility, Petri nets, Laboratories, action calculi, typed /spl lambda/-calculus, nonsyntactic treatment, equational characterizations, Calculus, control structures, morphisms, Concurrent computing, equations, free name, syntactic notion, /spl pi/-calculus, Control system synthesis, interactive systems, interactive system component linkage, dynamic disciplines, action structures, Equations, Surface treatment, Computer science, Couplings, action surface, process algebra, abstract correlate, reaction rules, added structure, category theory, category, concurrency models, Integrated circuit modeling, equational axioms]
The semantic challenge of Verilog HDL
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
The Verilog hardware description language (HDL) is widely used to model the structure and behaviour of digital systems ranging from simple hardware building blocks to complete systems. Its semantics is based an the scheduling of events and the propagation of changes. Different Verilog models of the same device are used during the design process and it is important that these be 'equivalent'; formal methods for ensuring this could be commercially significant. Unfortunately, there is very little theory available to help. This self-contained tutorial paper explains the semantics of Verilog informally and poses a number of logical and semantic problems that are intended to provoke further research. Any theory developed to support Verilog is likely to be useful for the analysis of the similar (but more complex) language VHDL.
[Process design, Digital systems, Synthesizers, event scheduling, Laboratories, change propagation, hardware description languages, semantics, Sun, digital system structure, Counting circuits, VHDL, Processor scheduling, Prototypes, formal methods, Verilog hardware description language, Hardware design languages, logical problems, Testing, digital systems behaviour]
Timing behavior analysis for real-time systems
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We extend TCTL model-checking problem to timing behavior analysis problem for real-time systems and develop new techniques in solving it. The algorithm we present here accepts timed transition system descriptions and parametric TCTL formulas with timing parameter variables of unknown sizes and can give back general linear equations of timing parameter variables whose solutions make the systems working.
[Real time systems, Algorithm design and analysis, Protocols, parametric TCTL formulas, temporal logic, Cost accounting, Equations, timed transition system, Information analysis, TCTL model-checking problem, Information science, formal verification, timing parameter variables, Automata, real-time systems, general linear equations, Timing, Clocks, timing behavior analysis]
Compositionality via cut-elimination: Hennessy-Milner logic for an arbitrary GSOS
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We present a sequent calculus for proving that processes in a process algebra satisfy assertions in Hennessy-Milner logic. The main novelty lies in the use of the operational semantics to derive introduction rules (on the left and right of sequents) for the different operators of the process calculus. This gives a generic proof system applicable to any process algebra with an operational semantics specified in the GSOS format. We identify the desirable property of compositionality with cut-elimination, and we prove that this holds for a class of sequents. Further, we show that the proof system enjoys good completeness and /spl omega/-completeness properties relative to its intended model.
[sequent calculus, operational semantics, generic proof system, computability, Calculus, completeness, Computer science, formal logic, cut-elimination, Algebra, decidability, process algebra, satisfiability, arbitrary GSOS, Logic functions, compositionality, process calculus, Hennessy-Milner logic]
Ordering, AC-theories and symbolic constraint solving
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We design combination techniques for symbolic constraint solving in the presence of associative and commutative (AC) function symbols. This yields an algorithm for solving AC-RPO constraints (where AC-RPO is the AC-compatible total reduction ordering of Rubio and Nieuwenhuis, 1994), which was a missing ingredient for automated deduction strategies with AC-constraint inheritance. As in the AC-unification case, for this purpose we first study the pure case, i.e. we show how to solve AC-ordering constraints built over a single AC function symbol and variables. Since AC-RPO is an interpretation-based ordering, our algorithm also requires the combination of algorithms for solving interpreted constraints and non-interpreted constraints.
[Algorithm design and analysis, AC-theories, ordering, computability, interpretation-based ordering, Mathematics, automated deduction strategies, formal logic, Algebra, satisfiability, AC-RPO, Constraint theory, Polynomials, constraint handling, programming theory, Logic programming, combination techniques, interpreted constraints, AC-unification, AC-compatible total reduction ordering, Equations, Computer science, noninterpreted constraints, associative and commutative function symbols, symbolic constraint solving, AC-constraint inheritance]
Model-checking of causality properties
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
A temporal logic for causality (T/sub LC/) is introduced. The logic is interpreted over causal structures corresponding to partial order executions of programs. For causal structures describing the behavior of a finite fixed set of processes, a T/sub LC/-formula can, equivalently, be interpreted over their linearizations. The main result of the paper is a tableau construction that gives a singly-exponential translation from a T/sub LC/ formula /spl psi/ to a Streett automaton that accepts the set of linearizations satisfying /spl psi/. This allows both checking the validity of T/sub LC/ formulas and model-checking of program properties. As the logic T/sub LC/ does not distinguish among different linearizations of the same partial order execution, partial order reduction techniques can be applied to alleviate the state-space explosion problem of model-checking.
[program properties, System testing, partial order reduction techniques, Costs, Streett automaton, model-checking, automata theory, state-space explosion, temporal logic, Explosions, Specification languages, State-space methods, causality properties, singly-exponential translation, causal structures, Concurrent computing, tableau construction, Automatic testing, Automata, Interleaved codes, Logic, partial order executions]
Complete proof systems for first order interval temporal logic
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Different interval modal logics have been proposed for reasoning about the temporal behaviour of digital systems. Some of them are purely propositional and only enable the specification of qualitative time requirements. Others, such as ITL and the duration calculus, are first order logics which support the expression of quantitative, real-time requirements. These two logics have in common the presence of a binary modal operator 'chop' interpreted as the action of splitting an interval into two parts. Proof systems for ITL or the duration calculus have been proposed but little is known about their power. This paper present completeness results for a variant of ITL where 'chop' is the only modal operator. We consider several classes of models for ITL which make different assumptions about time and we construct a complete and sound proof system for each class.
[Real time systems, first order interval temporal logic, temporal behaviour, Digital systems, Delay effects, reasoning, specification, Calculus, interval modal logics, completeness results, inference mechanisms, Power system modeling, Computer science, formal logic, digital systems, first order logics, binary modal operator, complete proof systems, theorem proving, Logic, Time factors, duration calculus, qualitative time requirements, real-time requirements]
A logic of subtyping
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
The relation of inclusion between types has been suggested by the practice of programming, as it enriches the polymorphism of functional languages. We propose a simple (and linear) calculus of sequents for subtyping as logical entailment. This allows to derive a complete and coherent approach to subtyping from a few, logically meaningful, sequents. In particular, transitivity and anti-symmetry are derived from elementary logical principles, which stresses the power of sequents and Gentzen-style proof methods. Indeed, proof techniques based on cut-elimination are at the core of our results.
[elementary logical principles, logical entailment, Logic programming, high level languages, antisymmetry, Gentzen-style proof methods, Calculus, type theory, polymorphism, Stress, sequents, Computer science, subtyping logic, cut-elimination, transitivity, Set theory, Concrete, Functional programming, Object oriented programming, functional languages]
Tree canonization and transitive closure
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We prove that tree isomorphism is not expressible in the language (FO+TC+COUNT). This is surprising since in the presence of ordering the language captures NL, whereas tree isomorphism and canonization are in L (Lindell, 1992). Our proof uses an Ehrenfeucht-Fraisse game for transitive closure logic with counting. As a corresponding upper bound, we show that tree canonization is expressible in (FO+COUNT)[log n]. The best previous upper bound had been (FO+COUNT)[n/sup 0(1)/] (Dublish and Maheshwari, 1990). The lower bound remains true for bounded-degree trees, and we show that for bounded-degree trees counting is not needed in the upper bound. These results are the first separations of the unordered versions of the logical languages for NL, AC/sup 1/, and ThC/sup 1/. Our results were motivated by a conjecture in (Etessami and Immerman, 1995) that (FO+TC+COUNT+1LO)=NL, i.e., that a one-way local ordering sufficed to capture NL. We disprove this conjecture, but we prove that a two-way local ordering does suffice, i.e., (FO+TC+COUNT+2LO)=NL.
[counting, formal languages, Ehrenfeucht-Fraisse game, one-way local ordering, trees (mathematics), game theory, logical languages, upper bound, bounded-degree trees, lower bound, two-way local ordering, Computer science, formal logic, Upper bound, Tree graphs, tree canonization, Robustness, Logic, tree isomorphism, transitive closure, computational complexity]
Games and full abstraction for the lazy /spl lambda/-calculus
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We define a category of games /spl Gscr/, and its extensional quotient /spl Escr/. A model of the lazy X-calculus, a type-free functional language based on evaluation to weak head normal form, is given in /spl Gscr/, yielding an extensional model in /spl Escr/. This model is shown to be fully abstract with respect to applicative simulation. This is, so fear as we known, the first purely semantic construction of a fully abstract model for a reflexively-typed sequential language.
[lambda calculus, Head, formal languages, Computational modeling, full abstraction, fully abstract model, game theory, Educational institutions, extensional model, Calculus, programming languages, Game theory, weak head normal form, lazy X-calculus, reflexively-typed sequential language, type-free functional language, games, lazy lambda-calculus, purely semantic construction, extensional quotient]
Decidability of linear affine logic
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
The propositional linear logic is known to be undecidable. We prove that the full propositional linear affine logic containing all multiplicatives, additives, exponentials, and constants is decidable. The proof is based on a reduction of linear affine logic to sequents of specific "normal forms\
[formal logic, programming theory, decidability, propositional linear affine logic, normal forms, undecidable, multiplicatives, Kanovich computational interpretation, linear affine logic, Logic]
Structural cut elimination
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Presents new proofs of cut elimination for intuitionistic, classical and linear sequent calculi. In all cases, the proofs proceed by three nested structural inductions, avoiding the explicit use of multi-sets and termination measures on sequent derivations. This makes them amenable to elegant and concise implementations in Elf, a constraint logic programming language based on the LF logical framework.
[linear sequent calculus, programming theory, Logic programming, classical sequent calculus, cut admissibility, structural cut elimination, Data structures, Calculus, Application software, Computer science, process algebra, intuitionistic sequent calculus, LF logical framework, Constraint theory, constraint logic programming language, nested structural inductions, constraint handling, Elf]
Partial model checking
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
A major obstacle in applying finite-state model checking to the verification of large systems is the combinatorial explosion of the state space arising when many loosely coupled parallel processes are considered. The problem also known as the state-explosion problem has been attacked from various sides. This paper presents a new approach based on partial model checking where parts of the concurrent system are gradually removed while transforming the specification accordingly. When the intermediate specifications constructed in this manner can be kept small, the state-explosion problem is avoided. Experimental results with a prototype implemented in Standard ML, shows that for Milner's Scheduler-an often used benchmark-this approach improves on the published results on binary decision diagrams and is comparable to results obtained using generalized decision diagrams. Specifications are expressed in a variant of the modal /spl mu/-calculus.
[state-explosion problem, decision theory, Standard ML, Scheduler, generalized decision diagrams, diagrams, combinatorial explosion, formal logic, binary decision diagrams, Boolean functions, Prototypes, partial model checking, Logic, algebraic specification, large systems verification, concurrent system, finite-state model checking, Data structures, specification, Explosions, State-space methods, loosely coupled parallel processes, Standards publication, Equations, benchmark, Computer science, Councils, modal /spl mu/-calculus, computational complexity, functional languages]
Generalized quantifiers and 0-1 laws
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We study 0-1 laws for extensions of first-order logic by Lindstrom quantifiers. We state sufficient conditions on a quantifier Q expressing a graph property, for the logic FO[Q]-the extension of first-order logic by means of the quantifier Q-to have a 0-1 law. We use these conditions to show, in particular, that FO[Rig], where Rig is the quantifier expressing rigidity, has a 0-1 law. We also show that FO[Ham], where Ham is the quantifier expressing Hamiltonicity, does not have a 0-1 law. Blass and Harary pose the question whether there is a logic which is powerful enough to express Hamiltonicity or rigidity and which has a 0-1 law. It is a consequence of our results that there is no such regular logic (in the sense of abstract model theory) in the case of Hamiltonicity, but there is one in the case of rigidity. We also consider sequences of vectorized quantifiers, and show that the extensions of first-order logic obtained by adding such sequences generated by quantifiers that are closed under substructures have 0-1 laws.
[graph property, graph theory, first-order logic, vectorized quantifiers, H infinity control, abstract model theory, Combinatorial mathematics, Computer science, formal logic, sufficient conditions, generalized quantifiers, Hamiltonicity, Lindstrom quantifiers, Logic, 0-1 laws]
When do fixed point logics capture complexity classes?
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We give examples of classes of rigid structures which are of unbounded rigidity but least fixed point (Partial fixed point) logic can express all Boolean PTIME (PSPACE) queries on these classes. This shows that definability of linear order in FO+LEP although sufficient for it to capture Boolean PTIME queries, is not necessary even on the classes of rigid structures. The situation however appears very different for nonzero-ary queries. Next, we turn to the study of fixed point logics on arbitrary classes of structures. We completely characterize the recursively enumerable classes of finite structures on which PFP captures all PSPACE queries of arbitrary arities. We also state in some alternative forms several natural necessary and some sufficient conditions for PFP to capture PSPACE queries on classes of finite structures. The conditions similar to the ones proposed above work for LFP and PTIME also in some special cases but to prove the same necessary conditions in general for LFP to capture PTIME seems harder and remains open.
[fixed point logics, partial fixed point, complexity classes, rigid structures, unbounded rigidity, definability, Relational databases, PSPACE queries, nonzero-ary queries, least fixed point, database theory, Computer science, formal logic, Boolean functions, Boolean PTIME queries, Binary trees, Logic, computational complexity]
Complexity of normal default logic and related modes of nonmonotonic reasoning
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Normal default logic, the fragment of default logic obtained by restricting defaults to rules to the form /spl alpha/:M/spl beta///spl beta/. is the most important and widely studied part of default logic. In Annals of Pure and Applied Logic, vol. 67, pp. 269-324 (1994), we proved a basis theorem for extensions of recursive propositional logic normal default theories and hence for finite predicate logic normal default theories, i.e. we proved that every recursive propositional normal default theory possesses an extension which is recursively enumerable (r.e.) in 0'. In this paper, we show that this bound is tight. Specifically, we show that for every r.e. set A and every B which is r.e. in A, there is a recursive normal default theory <D,W> with a unique extension which is Turing-equivalent to A/spl oplus/B. A similar result holds for finite predicate logic normal default theories.
[complexity, Turing equivalence, recursively enumerable extensions, recursive propositional logic normal default theory extensions, recursive functions, nonmonotonic reasoning, nonmonotonic reasoning modes, normal default logic, finite predicate logic normal default theories, tight bound, Logic, Mathematical model, computational complexity]
On the verification problem of nonregular properties for nonregular processes
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Investigate the verification problem of infinite-state processes w.r.t. nonregular properties, i.e. nondefinable by finite-state /spl omega/-automata. We consider processes in the algebra PA (Process Algebra) which provides sequential and parallel (merge) composition, nondeterministic choice and recursion. The algebra PA integrates and strictly subsumes the algebras BPA (Basic Process Algebra, i.e. context-free processes) and BPP (Basic Parallel Processes). On the other hand, we consider properties definable in a new temporal logic called CLTL (Constrained Linear-Time Logic) which is an extension of the linear-time temporal logic LTL with two kinds of constraints on traces: constraints on the numbers of occurrences of states expressed using Presburger formulas (occurrence constraints), and constraints on the order of appearance of states expressed using finite-state automata (pattern constraints). Pattern constraints allow to capture all the /spl omega/-regular properties whereas occurrence constraints allow to define nonregular properties. Then, we present (un)decidability results concerning the verification problem for the different classes of processes mentioned above and different fragments of CLTL.
[nonregular properties, Protocols, finite automata, temporal logic, occurrence constraints, Calculus, Logic testing, parallel processing, infinite-state processes, pattern constraints, context-free processes, Algebra, context-free languages, decidability, formal verification, parallel composition, finite-state /spl omega/-automata, nondeterministic choice, Constrained Linear-Time Logic, linear-time temporal logic, recursion, verification problem, algebra PA, nonregular processes, traces, sequential composition, Specification languages, Basic Parallel Processes, process algebra, merge composition, Automata, Basic Process Algebra, CLTL, Presburger formulas]
Compositional testing preorders for probabilistic processes
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Transitions systems are well established as a semantic model for distributed systems. There are widely accepted preorders that serve as criteria for refinement of a more abstract transition system to a more concrete one. To reason about probabilistic phenomena such as failure rates, we need to extend models and methods that have proven successful for nonprobabilistic systems to a probabilistic setting. We consider a model of probabilistic transition systems, containing probabilistic choice and nondeterministic choice as independent concepts. We present a notion of testing for these systems. Our main contributions are denotational characterizations of the testing preorders. The characterizations are given in terms of chains for may testing and refusal chains for must testing, that are analogous to traces and failures in denotational models of CSP. Refinement corresponds to inclusion between chains and refusal chains modulo closure operations. The preorders are shown to be compositional. We also show that when restricted to nonprobabilistic systems, these preorders collapse to the standard simulation and refusal simulation.
[Algorithm design and analysis, System testing, program verification, probabilistic transition systems, compositional testing preorders, transitions systems, refinement calculus, distributed processing, standard simulation, Distributed computing, Analytical models, probabilistic choice, Failure analysis, distributed systems, nondeterministic choice, modulo closure operations, denotational characterizations, refusal chains, Performance analysis, Logic, Distributed algorithms, CSP, Computational modeling, probability, probabilistic phenomena, semantic model, abstract transition system, nonprobabilistic systems, probabilistic processes, Concrete, refusal simulation]
On the complexity of modular model checking
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
In modular verification the specification of a module consists of two parts. One part describes the guaranteed behavior of the module. The other part describes the assumed behavior of the environment with which the module is interacting. This is called the assume-guarantee paradigm. Even when one specifies the guaranteed behavior of the module in a branching temporal logic, the assumption in the assume-guarantee pair concerns the interaction of the environment with the module along each computation, and is therefore often naturally expressed in linear temporal logic. In this paper we consider assume-guarantee specifications in which the assumption is given by an LTL formula and the guarantee is given by a CTL formula. Verifying modules with respect to such specifications is called the linear-branching model-checking problem. We apply automata-theoretic techniques to obtain a model-checking algorithm whose running time is linear in the size of the module and the size of the CTL guarantee, but doubly exponential in the size of the LTL assumption. We also show that the high complexity in the size of the LTL specification is inherent by proving that the problem is EXPSPACE-complete. The lower bound applies even if the branching temporal guarantee is restricted to be specified in /spl forall/CTL, the universal fragment of CTL.
[complexity, modular model checking, Protocols, temporal logic, linear temporal logic, assume-guarantee specifications, State-space methods, assume-guarantee paradigm, formal specification, modular verification, Computer science, branching temporal logic, automata-theoretic techniques, EXPSPACE-complete, Logic, computational complexity]
Domain theory in stochastic processes
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We establish domain-theoretic models of finite-state discrete stochastic processes, Markov processes and vector recurrent iterated function systems. In each case, we show that the distribution of the stochastic process is canonically obtained as the least upper bound of an increasing chain of simple valuations in a probabilistic power domain associated to the process. This leads to various formulas and algorithms to compute the expected values of functions which are continuous almost everywhere with respect to Me distribution of the stochastic process. We prove the existence and uniqueness of the invariant distribution of a vector recurrent iterated function system which is used in fractal image compression. We also present a finite algorithm to decode the image.
[data compression, finite algorithm, finite automata, Stochastic processes, domain-theoretic models, vector recurrent iterated function system, Mathematics, fractal image compression, Application software, Distributed computing, Space stations, Iterative decoding, fractals, Computer science, finite-state discrete stochastic processes, Upper bound, Image coding, probabilistic power domain, Markov processes, vector recurrent iterated function systems, image coding]
Relativized logspace and generalized quantifiers over finite structures
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
The expressive power of first order logic with generalized quantifiers over finite ordered structures is studied. The following problem is addressed: Given a family Q of generalized quantifiers expressing a complexity class C, what is the expressive power of first order logic FO(Q) extended by the quantifiers in Q? From previously studied examples, one would expect that FO(Q) captures L/sup C/, i.e., logarithmic space relativized by an oracle in C. We show that this is not always true. However, we derive sufficient conditions on complexity class C such that FO(and) captures L/sup C/. These conditions are fulfilled by a large number of relevant complexity classes, in particular, for example, by NP. As an application of this result, it follows that first order logic extended by Henkin quantifiers captures L/sup NP/. This answers a question raised by Blass and Gurevich. Furthermore we show that for many families Q of generalized quantifiers (including the family of Henkin quantifiers), each FO(Q)-formula can be replaced by an equivalent FO(Q)-formula, with only two occurrences of generalized quantifiers.
[finite structures, complexity class, relativized logspace quantifiers, formal logic, sufficient conditions, Sufficient conditions, Henkin quantifiers, generalized quantifiers, logarithmic space, first order logic, Expert systems, Logic devices, computational complexity]
Higher-order unification via explicit substitutions
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Higher-order unification is equational unification for /spl beta//spl eta/-conversion, but it is not first-order equational unification, as substitution has to avoid capture. In this paper higher-order unification is reduced to first-order equational unification in a suitable theory: the /spl lambda//spl sigma/-calculus of explicit substitutions.
[Process design, /spl beta//spl eta/-conversion, lambda calculus, rewriting systems, Art, higher-order unification, capture, Calculus, explicit substitutions, Equations, formal logic, Computer languages, equational unification, first order rewriting system, first-order equational unification, Kernel]
A complete proof systems for QPTL
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
The paper presents an axiomatic system for quantified propositional temporal logic (QPTL), which is propositional temporal logic equipped with quantification over propositions (boolean variables). The advantages of this extended temporal logic is that its expressive power is strictly higher than that of the unquantified version (PTL) and is equal to that of SIS, as well as that of /spl omega/-automata. Another important application of QPTL is its use for formulating and verifying refinement relations between reactive systems. In fact, the completeness proof is based on the reduction of a QPTL formula into a Buchi automaton, and performing equivalence transformations on this automata, formally justifying these transformations.
[Buchi automaton, Computational modeling, automata theory, temporal logic, propositional temporal logic, Counting circuits, Computer science, quantified propositional temporal logic, QPTL, Boolean functions, Automata, complete proof systems, theorem proving, Logic, boolean variables, automata]
The Stone gamut: a coordinatization of mathematics
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We give a uniform representation of the objects of mathematical practice as Chu spaces, forming a concrete self dual bicomplete closed category and hence a constructive model of linear logic. This representation distributes mathematics over a two dimensional space called the Stone gamut. The Stone gamut is coordinatized horizontally by coherence, ranging from -1 for sets to 1 for complete atomic Boolean algebras (CABA's), and vertically by complexity of language. Complexity 0 contains only sets, CABA's, and the inconsistent empty set. Complexity 1 admits noninteracting set CABA pairs. The entire Stone duality menagerie of partial distributive lattices enters at complexity 2. Groups, rings, fields, graphs, and categories are all entered by level 16, and every category of relational structures and their homomorphisms eventually appears. The key is the identification of continuous functions and homomorphisms, which puts Stone Pontrjagin duality on a uniform basis by merging algebra and topology into a simple common framework.
[homomorphisms, mathematics coordinatization, linear logic, complete atomic Boolean algebras, Mathematics, set theory, History, language complexity, Concurrent computing, Boolean functions, Algebra, Logic functions, duality (mathematics), inconsistent empty set, two dimensional space, partial distributive lattices, Stone Pontrjagin duality, relational structures, continuous functions, Tensile stress, Stone gamut, uniform representation, Chu spaces, Set theory, category theory, Concrete, concrete self dual bicomplete closed category, constructive model, noninteracting set CABA pairs, Qualifications, computational complexity, Stone duality menagerie]
A fully abstract semantics for a concurrent functional language with monadic types
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
This paper presents a typed higher-order concurrent functional programming language, based on Moggi's monadic metalanguage and Reppy's Concurrent ML. We present an operational semantics for the language, and show that a higher-order variant of the traces model is fully abstract for may-testing. This proof uses a program logic based on Hennessy-Milner logic and Abramsky's domain theory in logical form.
[concurrent functional language, computational linguistics, operational semantics, monadic metalanguage, Concurrent computing, Algebra, typed higher-order concurrent functional programming, Functional programming, Carbon capture and storage, parallel languages, fully abstract semantics, monadic types, Network address translation, domain theory, lambda calculus, Logic programming, traces model, Equations, may-testing, Computer languages, logical form, program logic, Hennessy-Milner logic, functional languages, higher-order variant]
First-order queries on finite structures over the reals
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We investigate properties of finite relational structures over the reals expressed by first-order sentences whose predicates are the relations of the structure plus arbitrary polynomial inequalities, and whose quantifiers can range over the whole set of reals. In constraint programming terminology, this corresponds to Boolean real polynomial constraint queries on finite structures. The fact that quantifiers range over all reals seems crucial; however, we observe that each sentence in the first-order theory of the reals can be evaluated by letting each quantifier range over only a finite set of real numbers without changing its truth value. Inspired by this observation, we then show that when all polynomials used are linear, each query can be expressed uniformly on all finite structures by a sentence of which the quantifiers range only over the finite domain of the structure. In other words, linear constraint programming on finite structures can be reduced to ordinary query evaluation as usual in finite model theory and databases. Moreover, if only "generic" queries are taken into consideration, we show that this can be reduced even further by proving that such queries can be expressed by sentences using as polynomial inequalities only those of the simple form z<y.
[finite relational structures, Virtual colonoscopy, arbitrary polynomial inequalities, first-order queries, Relational databases, Electronic mail, query processing, Boolean functions, constraint programming terminology, Constraint theory, Polynomials, constraint handling, databases, polynomial inequalities, Logic programming, polynomials, finite structures, first-order theory, ordinary query evaluation, Linear programming, Boolean real polynomial constraint queries, Computer science, predicates, Query processing, first-order sentences]
Completeness of Kozen's axiomatisation of the propositional /spl mu/-calculus
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We consider the propositional /spl mu/-calculus as introduced by D. Kozen (1983). In that paper a natural proof system was proposed and its completeness stated as an open problem. We show that the system is complete.
[Computer science, Technological innovation, propositional /spl mu/-calculus, Automata, temporal logic, completeness of Kozen's axiomatisation, Calculus, theorem proving, Logic, Informatics, natural proof system]
Logically presented domains
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
We connect the theory of Scott-Ershov domains to first order model theory. The completeness property of domains is related to the model theoretic notion of saturation. In constraint programming this analogy is already used on the level of finite approximations. A simple relation to structures used in nonstandard analysis (ultra powers, Frechet powers) is obtained. This leads to natural logical presentations of domain constructions such as function space, products and the Smyth power domain. Sufficient conditions on models for constructing function spaces are given.
[Scott-Ershov domains, nonstandard analysis, domain constructions, finite approximations, set theory, formal logic, saturation, sufficient conditions, Sufficient conditions, Algebra, model theoretic notion, Constraint theory, constraint handling, Frechet powers, constraint programming, Mathematical programming, formal languages, Logic programming, function spaces, completeness property, function space, first order model theory, logically presented domains, Smyth power domain, natural logical presentations, ultra powers]
Experience using type theory as a foundation for computer science
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Type theory is an elegant organisation of the fundamental principles of a foundational theory of computing, with theory taken in the sense of a scientific theory as well as a deductive theory. This theory generates a research programme. I examine the elements of this programme and assess progress. A large number of people world wide have been pursuing the type theory aspects of this research programme, so we can survey a large body of work created over a 20 year period for hints of success and failure and challenge. I first look at a few successes. Some of the applications we have attempted have not worked out as expected, and we don't know whether the fault lies with the type theory or elsewhere. I first describe a failure that is clearly not the type theory, but the state of the foundations of computational mathematics. Then we look at problems closer to the structure of modern type theories-problems suggested by the success of classical set theory.
[programming theory, Logic programming, Reliability theory, Mathematics, type theory, Topology, Boolean algebra, predicate logic, Database languages, foundational issues, Computer science, formal logic, Computer languages, Physics computing, computer science, database query languages, programming language design, logic programming, Set theory, Circuit synthesis]
Once and for all [temporal logic]
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
It has long been known that past-time operators add no expressive power to linear temporal logics. In this paper, we consider the extension of branching temporal logics with past-time operators. Two possible views regarding the nature of past in a branching-time model induce two different such extensions. In the first view, past is branching and each moment in time may have several possible futures and several possible pasts. In the second view, past is linear and each moment in time may have several possible futures and a unique past. Both views assume that past is finite. We discuss the practice of these extensions as specification languages, characterize their expressive power, and examine the complexity of their model-checking and satisfiability problems.
[complexity, model-checking, Natural languages, branching temporal logics, temporal logic, Specification languages, expressive power, Computer science, branching-time model, decidability, satisfiability problems, specification languages, past-time operators, Page description languages, Logic, computational complexity]
Equality between functionals in the presence of coproducts
Proceedings of Tenth Annual IEEE Symposium on Logic in Computer Science
None
1995
Consider the simply-typed lambda calculus with sum-type constructors, and let Set be the standard set-theoretic model of this calculus over an infinite base set. We present a proof system for the calculus (which involves a rule for reasoning by cases) and prove it to be a complete axiomatization of the equational theory of Set. We also develop some results concerning the syntactic properties of the calculus and an interpretation in Set of the equational theory (in the language of the classical simply-typed calculus) of the full function hierarchy over one infinite and one finite base set.
[lambda calculus, functional, infinite base set, proof system, functional analysis, Calculus, Encoding, Helium, simply-typed lambda calculus, sum-type constructors, Equations, coproducts, full function hierarchy, functional equations, standard set-theoretic model]
Completing partial combinatory algebras with unique head-normal forms
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
In this note, we prove that having unique head-normal forms is a sufficient condition on partial combinatory algebras to be completable. As application, we show that the pca of strongly normalizing CL-terms as well as the pca of natural numbers with partial recursive function application can be extended to total combinatory algebras.
[natural numbers, Logic programming, Mathematics, Application software, partial combinatory algebras, partial recursive function application, pca, Computer science, formal logic, strongly normalizing CL-terms, Computer languages, Algebra, Computation theory, unique head-normal forms, Books, sufficient condition, Principal component analysis, Context modeling]
Confluence and preservation of strong normalisation in an explicit substitutions calculus
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
Explicit substitutions calculi are formal systems that implement /spl beta/-reduction by means of an internal substitution operator. In that calculi it is possible to delay the application of a substitution to a term or to consider terms with partially applied substitutions. The /spl lambda//sub /spl sigma//-calculus of explicit substitutions, proposed by M. Abadi et al. (1991), is a first-order rewriting system that implements substitution and renaming mechanism of /spl lambda/-calculus. However; /spl lambda//sub /spl sigma// does not preserve strong normalisation of /spl lambda/-calculus and it is not a confluent system. Typed variants of /spl lambda//sub /spl sigma// without composition are strongly normalising but not confluent, while variants with composition are confluent but do not preserve strong normalisation. Neither of them enjoys both properties. In this paper we propose the /spl lambda//sub /spl zeta//-calculus. This is, as far as we know, the first confluent calculus of explicit substitutions that preserves strong normalisation.
[lambda calculus, confluence, substitution, explicit substitutions calculus, formal systems, /spl lambda//sub /spl sigma//-calculus, /spl lambda//sub /spl zeta//-calculus, internal substitution operator, Calculus, explicit substitutions, Delay, renaming mechanism, preservation, first-order rewriting system, strong normalisation, Computer applications, /spl lambda/-calculus, Functional programming, partially applied substitutions, /spl beta/-reduction]
Game semantics and abstract machines
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
The interaction processes at work by M. Hyland and L. Ong (1994) (HO) and S. Abramsky et al. (1994) (AJM) new game semantics are two preexisting paradigmatic implementations of linear head reduction: respectively Krivine's abstract machine and Girard's interaction abstract machine. There is a simple and natural embedding of AJM-games to HO-games, mapping strategies to strategies and reducing AJM definability (or full abstraction) property to HO's one.
[abstract machines, AJM-games, game theory, Magnetic heads, Calculus, History, game semantics, interaction processes, Game theory, Machinery, Geometry, paradigmatic implementations, Utility programs, linear head reduction, Concrete, HO-games]
The subtyping problem for second-order types is undecidable
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We prove that the subtyping problem induced by Mitchell's containment relation (1988) for second-order polymorphic types is undecidable. It follows that type-checking is undecidable for the polymorphic lambda-calculus extended by an appropriate subsumption rule.
[subsumption rule, subtyping problem, Terminology, second-order types, containment relation, second-order polymorphic types, Iron, type theory, polymorphic lambda-calculus, type-checking]
Reactive modules
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We present a formal model for concurrent systems. The model represents synchronous and asynchronous components in a uniform framework that supports compositional (assume-guarantee) and hierarchical (stepwise refinement) reasoning. While synchronous models are based on a notion of atomic computation step, and asynchronous models remove that notion by introducing stuttering, our model is based on a flexible notion of what constitutes a computation step: by applying an abstraction operator to a system, arbitrarily many consecutive steps can be collapsed into a single step. The abstraction operator, which may turn an asynchronous system into a synchronous one, allows us to describe systems at various levels of temporal detail. For describing systems at various levels of spatial detail, we use a hiding operator that may turn a synchronous system into an asynchronous one. We illustrate the model with diverse examples from synchronous circuits, asynchronous shared-memory programs, and synchronous message passing.
[asynchronous models, Engineering profession, Scalability, Delay effects, Circuits, uniform framework, assume-guarantee, logic testing, reactive modules, synchronous models, Computer aided instruction, stepwise refinement, Message passing, Wires, concurrent systems, synchronous circuits, asynchronous shared-memory programs, Hardware, Adders, Contracts, synchronous message passing]
Basic paramodulation and decidable theories
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We prove that for sets of Horn clauses saturated under basic paramodulation, the word and unifiability problems are in NP, and the number of minimal unifiers is simply exponential (i). For Horn sets saturated wrt. a special ordering under the more restrictive inference rule of basic superposition, the word and unifiability problems are still decidable and unification is finitary (ii). We define standard theories, which include and significantly extend shallow theories. Standard presentations can be finitely closed under superposition and result (ii) applies. Generalizing shallow theories to the Horn case, we obtain (two versions of) a language we call Catalog, a natural extension of Datalog to include functions and equality. The closure under paramodulation is finite for Catalog sets, hence (i) applies. Since for shallow sets this closure is even polynomial, shallow unifiability is in NP, which is optimal: unifiability in ground theories is already NP-hard. We even go beyond: the shallow word problem is tractable and for Catalog sets S we prove decidability of the full first-order theory of T(F)/=/sub s/.
[Heart, Logic programming, Horn clauses, basic superposition, first-order theory, Knowledge based systems, Humans, Application software, unifiability problems, shallow theories, Equations, Catalog, decidability, inference rule, Constraint theory, minimal unifiers, Polynomials, basic paramodulation theories, basic decidable theories, Functional programming, Deductive databases]
Order-incompleteness and finite lambda models
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
Many familiar models of the type-free lambda calculus are constructed by order theoretic methods. This paper provides some basic new facts about ordered models of the lambda calculus. We show that in any partially ordered model that is complete for the theory of /spl beta/- or /spl beta//spl eta/-conversion, the partial order is trivial on term denotations. Equivalently, the open and closed term algebras of the type-free lambda calculus cannot be non-trivially partially ordered. Our second result is a syntactical characterization, in terms of so-called generalized Mal'cev operators, of those lambda theories which cannot be induced by any non-trivially partially ordered model. We also consider a notion of finite models for the type-free lambda calculus. We introduce partial syntactical lambda models, which are derived from Plotkin's syntactical models of reduction, and we investigate how these models can be used as practical tools for giving finitary proofs of term inequalities. We give a 3-element model as an example.
[partially ordered model, lambda calculus, Art, order-incompleteness, type-free lambda calculus, order theoretic methods, generalized Mal'cev operators, Calculus, Mathematics, term denotations, Algebra, 3-element model, finitary proofs, term inequalities, syntactical characterization, Cognitive science, Mathematical model, Plotkin's syntactical models, finite lambda models, closed term algebras, Mathematical programming]
A linear logical framework
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We present the linear type theory LLF as the formal basis for a conservative extension of the LF logical framework. LLF combines the expressive power of dependent types with linear logic to permit the natural and concise representation of a whole new class of deductive systems, namely those dealing with state. As an example we encode a version of Mini-ML with references including its type system, its operational semantics, and a proof of type preservation. Another example is the encoding of a sequent calculus for classical linear logic and its cut elimination theorem. LLF can also be given an operational interpretation as a logic programming language under which the representations above can be used for type inference, evaluation and cut-elimination.
[sequent calculus, linear logic, operational semantics, dependent types, Calculus, type theory, Proposals, expressive power, cut elimination theorem, cut-elimination, type preservation, logic programming language, type system, deductive systems, operational interpretation, Mini-ML, type inference, Logic programming, formal basis, linear type theory LLF, Encoding, Computer science, Computer languages, linear logical framework, Linearity, Ear, Concrete, Context modeling]
General decidability theorems for infinite-state systems
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
Over the last few years there has been an increasing research effort directed towards the automatic verification of infinite state systems. This paper is concerned with identifying general mathematical structures which can serve as sufficient conditions for achieving decidability. We present decidability results for a class of systems (called well-structured systems), which consist of a finite control part operating on an infinite data domain. The results assume that the data domain is equipped with a well-ordered and well-founded preorder such that the transition relation is "monotonic" (is a simulation) with respect to the preorder. We show that the following properties are decidable for well-structured systems: reachability; eventuality; and simulation. We also describe how these general principles subsume several decidability results from the literature about timed automata, relational automata, Petri nets, and lossy channel systems.
[infinite data domain, Petri nets, simulation, Control systems, Mathematics, Information management, infinite-state systems, sufficient conditions, decidability, transition relation, general mathematical structures, Automatic control, Safety, reachability, timed automata, decidability theorems, State-space methods, relational automata, Computer science, eventuality, lossy channel systems, Councils, Automata, automatic verification, well-structured systems, preorder]
On the complexity of abduction
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
In this paper we consider the complexity of the existence problem for explanations and for minimal explanations for abductive frameworks based on finite predicate programs. We find that although, in general, the problem is very complex, there are classes of frameworks for which the problem is much simpler.
[complexity, minimal explanations, finite predicate programs, abduction, Humans, Inspection, Mathematics, Electronic mail, Physics, Computer science, Chemistry, existence problem, Back, logic programming, abductive frameworks, Logic]
Solving linear equations over polynomial semirings
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We consider the problem of solving linear equations over various semirings. In particular, solving of linear equations over polynomial rings with the additional restriction that the solutions must have only non-negative coefficients is shown to be undecidable. Applications to undecidability proofs of several unification problems are illustrated, one of which, unification modulo one associative-commutative function and one endomorphism, has been a long-standing open problem. The problem of solving multiset constraints is also shown to be undecidable.
[multiset constraints, Logic programming, Linear programming, unification modulo one, undecidability proofs, Equations, Computer science, associative-commutative function, Algebra, polynomial semirings, Ear, Constraint theory, polynomial rings, Polynomials, unification problems, theorem proving, Pattern matching, one endomorphism, linear equations]
Linear logic, monads and the lambda calculus
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
Models of intuitionistic linear logic also provide models of Moggi's computational metalanguage. We use the adjoint presentation of these models and the associated adjoint calculus to show that three translations, due mainly to Moggi, of the lambda calculus into the computational metalanguage (direct, call-by-name and call-by-value) correspond exactly to three translations, due mainly to Girard, of intuitionistic logic into intuitionistic linear logic. We also consider extending these results to languages with recursion.
[lambda calculus, Computational modeling, intuitionistic linear logic, Laboratories, linear logic, adjoint presentation, call-by-name, Calculus, monads, Proposals, formal logic, Ear, Logic, Moggi's computational metalanguage, adjoint calculus, call-by-value]
On the expressive power of variable-confined logics
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
In this paper we study the comparative expressive power of variable-confined logics, that is, logics with a fixed finite number of variables. This is motivated by the fact that the number of variables is considered a logical resource in descriptive complexity theory. We consider the expressive power of the logics FO/sup k/ (first-order logic with k variables), LFP/sup k/ (LFP with k variables, appropriately defined), and /spl Lscr//sub /spl infin/w//sup k/ (infinitary logic with k variables) over classes of finite structures. While the definitions of FO/sup k/ and /spl Lscr//sub /spl infin/w//sup k/ are quite clear, it turns out that ramifying LFP is a more delicate matter. We define LFP/sup k/ in terms of systems of least fixpoints, i.e., instead of taking the least fixpoint of a single positive first-order formula, we consider simultaneous least fixpoints of a vector of positive first-order formulas. As evidence that LFP/sup k/, k/spl ges/1, is the right ramification of LFP we offer two main results. The first is a new proof of a theorem by A. Dawar et al. (1995) to the effect that equivalence classes of finite structures with respect to the logic /spl Lscr//sub /spl infin/w//sup k/ are expressible in FO/sup k/. The second result, novel and technically difficult, is a characterization for each k/spl ges/1 of the collapse of /spl Lscr//sub /spl infin/w//sup k/ to FO/sup k/ in terms of boundedness of LFP/sup k/. More precisely, we establish the following stronger version of McColm's second conjecture: /spl Lscr//sub /spl infin/w//sup k/=FO/sup k/ on a class C of finite structures if and only if LFP/sup k/ is uniformly bounded on C.
[finite structures, positive first-order formulas, variable-confined logics, least fixpoints, Complexity theory, fixed finite number, expressive power, single positive first-order formula, Computer science, Uniform resource locators, logical resource, descriptive complexity theory, simultaneous least fixpoints, Logic, equivalence classes, least fixpoint]
Integration in Real PCF
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
Real PCF is an extension of the programming language PCF with a data type for real numbers. Although a Real PCF definable real number cannot be computed in finitely many steps, it is possible to compute an arbitrarily small rational interval containing the real number in a sufficiently large number of steps. Based on a domain-theoretic approach to integration, we show how to define integration in Real PCF. We propose two approaches to integration in Real PCF. One consists in adding integration as primitive. The other consists in adding a primitive for maximization of functions and then recursively defining integration from maximization. In both cases we have an adequacy theorem for the corresponding extension of Real PCF. Moreover based on previous work on Real PCF definability, we show that Real PCF extended with the maximization operator is universal, which implies that it is also fully abstract.
[adequacy theorem, real PCF, domain-theoretic approach, Algebra, Integral equations, Differential equations, maximization, real numbers, maximization operator, programming languages, programming language PCF, data type]
Efficient model checking via the equational /spl mu/-calculus
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
This paper studies the use of an equational variant of the modal /spl mu/-calculus as a unified framework for efficient temporal logic model checking. In particular we show how an expressive temporal logic, CTL*, may be efficiently translated into the /spl mu/-calculus. Using this translation, one may then employ /spl mu/-calculus model-checking techniques, including on-the-fly procedures, BDD-based algorithms and compositional model-checking approaches, to determine if systems satisfy formulas in CTL*.
[unified framework, on-the-fly procedures, temporal logic, equational variant, Data structures, temporal logic model checking, Calculus, Encoding, Maintenance, equational /spl mu/-calculus, Surges, Equations, Computer science, CTL*, compositional model-checking approaches, Boolean functions, model checking, Automata, BDD-based algorithms, expressive temporal logic, Logic, modal /spl mu/-calculus]
Syntactic considerations on recursive types
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We study recursive types from a syntactic perspective. In particular, we compare the formulations of recursive types that are used in programming languages and formal systems. Our main tool is a new syntactic explanation of type expressions as functors. We also introduce a simple logic for programs with recursive types in which we carry out our proofs.
[Computer languages, Logic programming, recursive types, simple logic, proofs, formal systems, type expressions, programming languages]
Decidability problems for the prenex fragment of intuitionistic logic
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We develop a constraint-based technique which allows one to prove decidability and complexity results for sequent calculi. Specifically, we study decidability problems for the prenex fragment of intuitionistic logic. We introduce an analogue of Skolemization for intuitionistic logic with equality, prove PSPACE-completeness of two fragments of intuitionistic logic with and without equality and some other results. In the proofs, we use a combination of techniques of constraint satisfaction, loop-free sequent systems of intuitionistic logic and properties of simultaneous rigid E-unification.
[complexity, PSPACE-completeness, Automatic logic units, intuitionistic logic, Calculus, sequent calculi, Skolemization, constraint-based technique, formal logic, prenex fragment, decidability, constraint satisfaction, loop-free sequent systems, Polynomials]
Tarskian set constraints
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We investigate set constraints over set expressions with Tarskian functional and relational operations. Unlike the Herbrand constructor symbols used in recent set constraint formalisms, the meaning of a Tarskian function symbol is interpreted in an arbitrary first order structure. We show that satisfiability of Tarskian set constraints is decidable in nondeterministic doubly exponential time. We also give complexity results and open problems for various extensions of the language.
[Laboratories, complexity results, set expressions, Tarskian functional operations, set constraint formalisms, Tarskian relational operations, Tarskian set constraints, set theory, Application software, first order structure, Herbrand constructor symbols, nondeterministic doubly exponential time, Page description languages, Logic, Artificial intelligence]
An algebraic theory of process efficiency
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
This paper presents a testing-based semantic theory for reasoning about the efficiency of concurrent systems as measured in terms of the amount of their internal activity. The semantic preorders are given an algebraic characterization, and their optimality is established by means of a full abstractness result. They are also shown to subsume existing bisimulation-based efficiency preorders. An example is provided to illustrate the utility of this approach.
[System testing, algebraic characterization, internal activity, optimality, process efficiency, reasoning, bisimulation-based efficiency preorders, Computer science, semantic preorders, calculus of communicating systems, full abstractness result, concurrent systems, testing-based semantic theory, algebraic theory, Carbon capture and storage]
An Until hierarchy for temporal logic
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We prove there is a strict hierarchy of expressive power according to the Until depth of linear temporal logic (TL) formulas: for each k, there is a very natural property that is not expressible with k nestings of Until operators, regardless of the number of applications of other operators, but is expressible by a formula with Until depth k+1. Our proof uses a new Ehrenfeucht-Fraisse (EF) game designed specifically for TL. These properties can all be expressed in first-order logic with quantifier depth and size O(log k), and we use them to observe some interesting relationships between TL and first-order expressibility. We then use the EF game in a novel way to effectively characterize (1) the TL properties expressible without Until, as well as (2) those expressible without both Until and Next. By playing the game "on finite automata\
[finite automata, Ehrenfeucht-Fraisse game, first-order logic, automata recognizing languages, temporal logic, linear temporal logic, Logic design, semigroup-theoretic techniques, Character recognition, Until hierarchy, expressive power, Application specific integrated circuits, Automata, first-order expressibility]
A fully abstract domain model for the /spl pi/-calculus
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
Abramsky's domain equation for bisimulation and the author's categorical models for names combine to give a domain-theoretic model for the /spl pi/-calculus. This is set in a functor category which provides a syntax-free interpretation of fresh names, privacy visibility and non-interference between processes. The model is fully abstract for strong late bisimilarity and equivalence (bisimilarity under all name substitutions).
[functor category, abstract domain model, bisimulation, equivalence, categorical models, privacy visibility, Equations, fresh names, calculus of communicating systems, Tensile stress, syntax-free interpretation, /spl pi/-calculus, Lead, Concrete, strong late bisimilarity, non-interference, domain-theoretic model]
Symbolic protocol verification with queue BDDs
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
Symbolic verification based on Binary Decision Diagrams (BDDs) has proven to be a powerful technique for ensuring the correctness of digital hardware. In contrast, BDDs have not caught on as widely for software verification, partly because the data types used in software are more complicated than those used in hardware. In this work, we propose an extension of BDDs for dealing with dynamic data structures. Specifically, we focus on queues, since they are commonly used in modeling communication protocols. We introduce Queue BDDs (QBDDs) which include all the power of BDDs while also providing an efficient representation of queue contents. Experimental results show that QBDDs are well-suited for the verification of communication protocols.
[protocol verification, Protocols, Binary Decision Diagrams, Binary decision diagrams, Data structures, Encoding, State-space methods, digital hardware, dynamic data structures, Queue BDDs, Boolean functions, Automata, Software systems, verification of communication protocols, Hardware, data structures, symbolic verification, data types, Space exploration]
Complexity analysis based on ordered resolution
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We define order locality to be a property of clauses relative to a term ordering. This property is a kind of generalization of the subformula property for proofs where terms arising in proofs are bounded, under the given ordering, by terms appearing in the goal clause. We show that when a clause set is order local, then the complexity of its ground entailment problem is a function of its structure (e.g., full versus Horn clauses), and the ordering used. We prove that, in many cases, order locality is equivalent to a clause set being saturated under ordered resolution. This provides a means of using standard resolution theorem provers for testing order locality and transforming non-local clause sets into local ones. We have used the Saturate system to automatically establish complexity bounds for a number of nontrivial entailment problems relative to complexity classes which include polynomial and exponential time and co-NP.
[Horn clauses, Saturate system, order locality, co-NP, complexity analysis, clauses, non-local clause sets, subformula property, nontrivial entailment problems, Logic testing, Equations, exponential time, term ordering, standard resolution theorem provers, Polynomials, polynomial time, ordered resolution, ground entailment, computational complexity]
Model-checking of correctness conditions for concurrent objects
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
The notions of serializability, linearizability and sequential consistency are used in the specification of concurrent systems. We show that the model checking problem for each of these properties can be cast in terms of the containment of one regular language in another regular language shuffled using a semi-commutative alphabet. The three model checking problems are shown to be, respectively, in PSPACE, in EXPSPACE, and undecidable.
[semi-commutative alphabet, Protocols, concurrent objects, specification, Transaction databases, History, Application software, PSPACE, Delay, linearizability, regular language, Design optimization, decidability, undecidable, Computer bugs, Automata, System recovery, serializability, model checking problem, EXPSPACE, Testing]
Semantics of normal logic programs and contested information
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We propose C4, a four-valued semantics for normal, logic programs. Using this semantics, we define two types of entailment: strong and weak. We show that a normal, logic program strongly entails a sentence under C4 if, and only if, the program entails that sentence under the well founded semantics and it weakly entails a sentence if, and only if, the program entails that sentence under the two-valued stable model semantics in case the program has any stable models. We argue that this shows that the difference between the well founded semantics and the stable model semantics can be characterized in terms of their attitude to what we call contested information. We use this insight to propose a general theory of contested reasoning.
[entailment, four-valued semantics, Educational institutions, Multivalued logic, semantics, contested information, normal logic programs, Computer science, Waste materials, C4, contested reasoning, logic programming, two-valued stable model semantics, Samarium]
Subtyping dependent types
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
The need for subtyping in type-systems with dependent types has been realized for some years. But it is hard to prove that systems combining the two features have fundamental properties such as subject reduction. Here we investigate a subtyping extension of the system /spl lambda/P, which is an abstract version of the type system of the Edinburgh Logical Framework LF. By using an equivalent formulation, we establish some important properties of the new system /spl lambda/P/sub /spl les//, including subject reduction. Our analysis culminates in a complete and terminating algorithm which establishes the decidability of type-checking.
[Algorithm design and analysis, programming theory, Logic programming, Laboratories, dependent types, Encoding, Application software, type-checking, subtyping, type-systems, subject reduction, Computer science, Edinburgh Logical Framework, Computer languages, decidability, terminating algorithm]
On the expressive power of simply typed and let-polymorphic lambda calculi
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We present a functional framework for descriptive computational complexity, in which the Regular, First-order, Ptime, Pspace, k-Exptime, k-Expspace (k/spl ges/1), and Elementary sets have syntactic characterizations. In this framework, typed lambda terms represent inputs and outputs as well as programs. The lambda calculi describing the above computational complexity classes are simply or let-polymorphically typed with functionalities of fixed order. They consist of: order 0 atomic constants, order 1 equality among these constants, variables, application, and abstraction. Increasing functionality order by one for these languages corresponds to increasing the computational complexity by one alternation. This exact correspondence is established using a semantic evaluation of languages for each fixed order, which is the primary technical contribution of this paper.
[k-Exptime complexity, order 1 equality, Computational complexity, expressive power, functional framework, Ptime complexity, Computer science, simply typed lambda calculi, descriptive computational complexity, Algebra, let-polymorphic lambda calculi, Pspace complexity, k-Expspace complexity, semantic evaluation of languages, regular complexity, Logic, Functional programming, first-order complexity, order 0 atomic constants, computational complexity]
Counting module quantifiers on finite linearly ordered trees
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We give a combinatorial method for proving elementary equivalence in first-order logic FO with counting module n quantifiers D/sub n/. Inexpressibility results for FO(D/sub n/) with built-in linear order are also considered. We show that certain divisibility properties of word models are not definable in FO(D/sub n/). We also show that the height of complete n-ary trees cannot be expressed in FO(D/sub n/) with linear order. Interpreting the predicate y=nx as a complete n-ary tree, we show that the predicate y=(n+1)x cannot be defined in FO(D/sub n/) with linear order. This proves the conjecture of Niwinski and Stolboushkin (1993). We also discuss connection between our results and the well-known open problem in circuit complexity theory, whether ACC=NC/sup 1/.
[combinatorial mathematics, first-order logic, Mathematics, Complexity theory, inexpressibility results, circuit complexity theory, finite linearly ordered trees, elementary equivalence, Logic circuits, module quantifiers, Polynomials, complete n-ary trees, Context modeling, combinatorial method]
The Scott topology induces the weak topology
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
Given a probability measure on a compact metric space, we construct an increasing chain of valuations on the upper space of the metric space whose least upper bound is the measure. We then obtain the expected value of any Holder continuous function with respect to the measure up to any precision. We prove that the Scott topology induces the weak topology of the space of probability measures in the following general setting: Whenever a separable metric space is embedded into a subset of the maximal elements of an /spl omega/-continuous dcpo, which is a G/sub /spl delta// subset of the dcpo equipped with the Scott topology, we show that the space of probability measures of the metric space equipped with the weak topology is then embedded into a subspace of the maximal elements of the probabilistic power domain of the dcpo. We present a novel application in the theory of periodic doubling route to chaos.
[Chaos, probability measures, chaos, probability, Extraterrestrial measurements, Educational institutions, Fractals, Scott topology, probability measure, Topology, Cost accounting, upper space, metric space, Information geometry, Power measurement, Upper bound, periodic doubling route, Neural networks, Holder continuous function, probabilistic power domain, weak topology, compact metric space, least upper bound]
Relating word and tree automata
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
In the automata-theoretic approach to verification, we translate specifications to automata. Complexity considerations motivate the distinction between different types of automata. Already in the 60's, it was known that deterministic Buchi word automata are less expressive than nondeterministic Buchi word automata. The proof is easy and can be stated in a few lines. In the late 60's, Rabin proved that Buchi tree automata are less expressive than Rabin tree automata. This proof is much harder. In this work we relate the expressiveness gap between deterministic and nondeterministic Buchi word automata and the expressiveness gap between Buchi and Rabin tree automata. We consider tree automata that recognize derived languages. For a word language L, the derived language of L, denoted L/spl Delta/, is the set of all trees all of whose paths are in L. Since often we want to specify that all the computations of the program satisfy some property, the interest in derived languages is clear. Our main result shows that L is recognizable by a nondeterministic Buchi word automaton but not by a deterministic Buchi word automaton iff L/spl Delta/ is recognizable by a Rabin tree automaton and not by a Buchi tree automaton. Our result provides a simple explanation to the expressiveness gap between Buchi and Rabin tree automata. Since the gap between deterministic and nondeterministic Buchi word automata is well understood, our result also provides a characterization of derived languages that can be recognized by Buchi tree automata. Finally, it also provides an exponential determinization of Buchi tree automata that recognize derived languages.
[deterministic Buchi word automata, temporal logic, automata-theoretic approach, computational Complexity, Rabin tree automaton, Mathematics, nondeterministic Buchi word automata, Specification languages, derived languages, formal specification, Buchi tree automata, Computer science, Uniform resource locators, formal verification, Automata, word automata, tree automata, Logic]
Decision problems for semi-Thue systems with a few rules
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
For several decision problems about semi-Thue systems, we try to locate the frontier between the decidable and the undecidable from the point of view of the number of rules. We show that the the Termination Problem, the U-Termination Problem, the Accessibility Problem and the Common-Descendant Problem are undecidable for 3 rules semi-Thue systems. As a corollary we obtain the undecidability of the Post-Correspondence Problem for 7 pairs of words.
[decidable, termination problem, program verification, undecidable, semi-Thue systems, U-termination problem, common-descendant problem, Mathematics, post-correspondence problem, decision problems, accessibility problem, Radio access networks]
A generalization of Fagin's theorem
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
Fagin's theorem characterizes NP as the set of decision problems that are expressible as second-order existential sentences, i.e., in the form (/spl exist//spl Pi/)/spl phi/, where /spl Pi/ is a new predicate symbol, and /spl phi/ is first-order. In the presence of a successor relation, /spl phi/ may be assumed to be universal, i.e., /spl phi//spl equiv/(/spl forall/x~)/spl alpha/ where /spl alpha/ is quantifier-free. The PCP theorem characterizes NP as the set of problems that may be proved in a way that can be checked by probabilistic verifiers using O(log n) random bits and reading O(1) bits of the proof: NP=PCP[log n, 1]. Combining these theorems, we show that every problem D/spl isin/NP may be transformed in polynomial time to an algebraic version D/spl circ//spl isin/NP such that D/spl circ/ consists of the set of structures satisfying a second-order existential formula of the form (/spl exist//spl Pi/)(R/spl tilde/x~)/spl alpha/ where R/spl tilde/ is a majority quantifier-the dual of the R quantifier in the definition of RP-and /spl alpha/ is quantifier-free. This is a generalization of Fagin's theorem and is equivalent to the PCP theorem.
[NP, second-order existential sentences, probabilistic verifiers, NP-complete problem, probabilistic Turing machine, Computer science, Turing machines, Polynomials, Fagin's theorem, polynomial time, decision problems, PCP theorem, computational complexity]
The theory of hybrid automata
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We summarize several recent results about hybrid automata. Our goal is to demonstrate that concepts from the theory of discrete concurrent systems can give insights into partly continuous systems, and that methods for the verification of finite-state systems can be used to analyze certain systems with uncountable state spaces.
[hybrid automata theory, finite automata, Switches, finite-state systems, Continuous time systems, State-space methods, Digital control, discrete concurrent systems, Automata, Automatic control, uncountable state spaces, partly continuous systems, Temperature control, Labeling, Force control, Thermostats]
Partial-order methods for model checking: from linear time to branching time
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
Partial-order methods make it possible to check properties of a concurrent system by state-space exploration without considering all interleavings of independent concurrent events. They have been applied to linear-time model checking, but so far only limited results are known about their applicability to branching-time model checking. In this paper, we introduce a general technique for lifting partial-order methods from linear-time to branching-time logics. This technique is shown to be applicable both to reductions that are applied to the structure representing the program before running the model checking procedure, as well as to reductions that can be obtained when model checking is done in an automata-theoretic framework. The latter are extended to branching-time logics by using the model-checking framework based on alternating automata introduced by O. Bernholtz et al. (1994).
[branching time, automata-theoretic framework, Binary decision diagrams, concurrent system, temporal logic, State-space methods, linear-time model checking, branching-time model checking, Concurrent computing, partial-order methods, model checking, Automata, System recovery, Interleaved codes, state-space exploration, Logic, branching-time logics, Context modeling, linear time]
Reasoning about local variables with operationally-based logical relations
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
A parametric logical relation between the phrases of an Algol-like language is presented. Its definition involves the structural operational semantics of the language, but was inspired by recent denotationally-based work of O'Hearn and Reynolds on translating Algol into a predicatively polymorphic linear lambda calculus. The logical relation yields an applicative characterisation of contextual equivalence for the language and provides a useful (and complete) method for proving equivalences. Its utility is illustrated by giving simple and direct proofs of some contextual equivalences, including an interesting equivalence due to O'Hearn which hinges upon the undefinability of 'snapback' operations (and which goes beyond the standard suite of 'Meyer-Sieber' examples). Whilst some of the mathematical intricacies of denotational semantics are avoided, the hard work in this operational approach lies in establishing the 'fundamental property' for the logical relation-the proof of which makes use of a compactness property of fixpoint recursion with respect to evaluation of phrases. But once this property has been established, the logical relation provides a verification method with an attractively low mathematical overhead.
[lambda calculus, Laboratories, Fasteners, undefinability, Calculus, Algol-like language, snapback operations, operationally-based logical relations, verification method, fixpoint recursion, parametric logical relation, predicatively polymorphic linear lambda calculus, local variables, structural operational semantics, Concrete, contextual equivalences, Mathematical model, denotational semantics, Context modeling]
Locally linear time temporal logic
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We study linear time temporal logics of multiple agents, where the temporal modalities are local. These modalities not only refer to local next-instants and local eventuality, but also global views of agents at any local instant, which are updated due to communication from other agents. Thus agents also reason about the future, present and past of other agents in the system. The models for these logics are simple: runs of networks of synchronizing automata. Problems like gossiping in interconnection networks am naturally described in the logics proposed here. We present solutions to the satisfiability and model checking problems for these logics. Further since formulas are insensitive to different interleavings of runs, partial order based verification methods become applicable for properties described in these logics.
[synchronizing automata networks, local eventuality, multiple agents, satisfiability, Automata, model checking problems, locally linear time temporal logic, temporal logic, Interleaved codes, local next-instants, Safety, Logic]
A fully-abstract model for the /spl pi/-calculus
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
This paper provides both a fully abstract (domain-theoretic) model for the /spl pi/-calculus and a universal (set-theoretic) model for the finite /spl pi/-calculus with respect to strong late bisimulation and congruence. This is done by: considering categorical models, defining a metalanguage for these models, and translating the /spl pi/-calculus into the metalanguage. A technical novelty of our approach is an abstract proof of full abstraction: The result on full abstraction for the finite /spl pi/-calculus in the set-theoretic model is axiomatically extended to the whole /spl pi/-calculus with respect to the domain-theoretic interpretation. In this proof, a central role is played by the description of non-determinism as a free construction and by the equational theory of the metalanguage.
[fully abstract, categorical models, Calculus, Power system modeling, congruence, calculus of communicating systems, /spl pi/-calculus, strong late bisimulation, Differential equations, metalanguage, finite /spl pi/-calculus, Concrete, domain-theoretic, set-theoretic, universal, abstract proof of full abstraction]
A semantic view of classical proofs: type-theoretic, categorical, and denotational characterizations
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
Classical logic is one of the best examples of a mathematical theory that is truly useful to computer science. Hardware and software engineers apply the theory routinely. Yet from a foundational standpoint, there are aspects of classical logic that are problematic. Unlike intuitionistic logic, classical logic is often held to be non-constructive, and so, is said to admit no proof semantics. To draw an analogy in the proofs-as-programs paradigm, it is as if we understand well the theory of manipulation between equivalent specifications (which we do), but have comparatively little foundational insight of the process of transforming one program to another that implements the same specification. This extended abstract outlines a semantic theory of classical proofs based on a variant of Parigot's /spl lambda//spl mu/-calculus, but presented here as a type theory. After reviewing the conceptual problems in the area and the potential benefits of such a theory, we sketch the key steps of our approach in terms of the questions that we have sought to answer: Syntax: How should one circumscribe a coherent system of classical proofs? Is there a satisfactory Curry-Howard style representation theory? Categorical characterization: What is the "boolean algebra" of classical propositional proofs (as opposed to validity)? What manner of categories characterizes classical proofs the same way that cartesian closed categories capture intuitionistic propositional proofs? Complete denotational models: Are there good intensional game models of classical logic canonical for the circumscribed proofs?.
[Heart, Algorithm design and analysis, semantic, Logic programming, Laboratories, Calculus, type theory, formal logic, lambda /spl mu/-calculus, boolean algebra, cartesian closed categories, Hardware, Impedance, classical proofs, game models, Marine vehicles, Arithmetic, classical logic]
Simultaneous rigid E-unification and related algorithmic problems
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
The notion of simultaneous rigid E-unification was introduced in 1987 in the area of automated theorem proving with equality in sequent-based methods, for example the connection method or the tableau method. Recently, simultaneous rigid E-unification was shown undecidable. Despite the importance of this notion, for example in theorem proving in intuitionistic logic, very little is known of its decidable fragments. We prove decidability results for fragments of monadic simultaneous rigid E-unification and show the connections between this notion and some algorithmic problems of logic and computer science.
[algorithmic problems, connection method, tableau method, sequent-based methods, simultaneous rigid E-unification, decidable fragments, Automatic logic units, intuitionistic logic, Mathematics, automated theorem, Equations, Computer science, Matrices, monadic simultaneous rigid E-unification, theorem proving]
More about recursive structures: descriptive complexity and zero-one laws
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
This paper continues our work on infinite, recursive structures. We investigate the descriptive complexity of several logics over recursive structures, including first-order, second-order, and fixpoint logic, exhibiting connections between expressibility of a property and its computational complexity. We then address 0-1 laws, proposing a version that applies to recursive structures and using it to prove several non-expressibility results.
[recursive structures, TV, first-order logic, descriptive complexity, fixpoint logic logic, Computational complexity, zero-one laws, Computer science, second-order logic, Polynomials, Logic, 0-1 laws, Arithmetic, computational complexity, expressibility]
DATALOG SIRUPs uniform boundedness is undecidable
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
DATALOG is the paradigmatic database query language. If it is possible to eliminate recursion from a DATALOG program then it is uniformly bounded. Since uniformly bounded programs can be executed in parallel constant time, the possibility of automated boundedness detection is an important issue, and has been studied in many papers. In this paper we solve one of the most famous open problems in the theory of deductive databases (see e.g. P.C. Kanellakis, Elements of Relational Database Theory in Handbook of Theoretical Computer Science) showing that uniform boundedness is undecidable for single rule programs (called also sirups).
[automated boundedness detection, Relational databases, single rule programs, DATALOG, uniform boundedness, Computer science, deductive databases, Upper bound, theory of deductive databases, undecidable, parallel constant time, database query language, Logic, recursion]
The essence of parallel Algol
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We consider a parallel Algol-like language, combining the /spl lambda/-calculus with shared-variable parallelism. We provide a denotational semantics for this language, simultaneously adapting the possible worlds model of Reynolds and Oles (1981, 1982) to the parallel setting and generalizing the "transition traces" model to the procedural setting. This semantics supports reasoning about safety and liveness properties of parallel programs, and validates a number of natural laws of program equivalence based on noninterference properties of local variables. We also provide a relationally parametric semantics, to permit reasoning about relation-preserving properties of programs, and adapting work of O'Hearn and Tennent (1995) to the parallel setting. This semantics supports standard methods of reasoning about representational independence. The clean design of the programming language and its semantics supports the orthogonality of procedures and shared-variable parallelism.
[Encapsulation, parallel Algol, shared-variable parallelism, Interference, Read-write memory, liveness, semantics, ALGOL, parallel programs, Computer science, Computer languages, Parallel programming, safety, Parallel processing, Safety, /spl lambda/-calculus]
A modal /spl mu/-calculus for durational transition systems
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
Durational transition systems are finite transition systems where every transition is additionally equipped with a duration. We consider the problem of interpreting /spl mu/-formulas over durational transition systems. In case the formula contains only operations minimum, maximum, addition, and sequencing, we show that the interpretation ist not only computable but (up to a linear factor) as efficiently computable as the interpretation of /spl mu/-formulas over ordinary finite transition systems.
[finite automata, finite transition systems, Lattices, /spl mu/-formulas, Equations, sequencing, Upper bound, Automata, maximum, Safety, Logic, minimum, modal /spl mu/-calculus, durational transition systems, addition]
Higher dimensional transition systems
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We introduce the notion of higher dimensional transition systems as a model of concurrency providing an elementary, set-theoretic formalisation of the idea of higher dimensional transition. We show an embedding of the category of higher dimensional transition systems into that of higher dimensional automata which cuts down to an equivalence when we restrict to non-degenerate automata. Moreover, we prove that the natural notion of bisimulation for such structures is a generalisation of the strong history preserving bisimulation, and provide an abstract categorical account of it via open maps. Finally, we define a notion of unfolding for higher dimensional transition systems and characterise the structures so obtained as a generalisation of event structures.
[higher dimensional automata, Fitting, Buildings, higher dimensional transition, Humans, Topology, set theory, natural notion, History, concurrency, Computer science, Concurrent computing, nondegenerate automata, Automata, strong history preserving bisimulation, Interleaved codes, elementary set-theoretic formalisation, Concrete, embedding, event structures, higher dimensional transition systems, open maps, abstract categorical account]
Reduction-free normalisation for a polymorphic system
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We give a semantical proof that every term of a combinator version of system F has a normal form. As the argument is entirely formalisable in an impredicative constructive type theory a reduction-free normalisation algorithm can be extracted from this. The proof is presented as the construction of a model of the calculus inside a category of presheaves. Its definition is given entirely in terms of the internal language.
[presheaves, Calculus, type theory, calculus, internal language, Reactive power, semantical proof, Frequency shift keying, polymorphic system, combinator version, reduction-free normalisation, impredicative constructive type theory, Context modeling]
On the structure of queries in constraint query languages
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We study the structure of first-order and second-order queries over constraint databases. Constraint databases are formally modeled as finite relational structures embedded in some fixed infinite structure. We concentrate on problems of elimination of constraints, reducing quantification range to the active domain of the database and obtaining new complexity bounds. We show that for a large class of signatures, including real arithmetic constraints, unbounded quantification can be eliminated. That is, one can transform a sentence containing unrestricted quantification over the infinite universe to get an equivalent sentence in which quantifiers range over the finite relational structure. We use this result to get a new complexity upper bound on the evaluation of real arithmetic constraints. We also expand upon techniques for getting upper bounds on the expressiveness of constraint query languages, and apply it to a number of first-order and second-order query languages.
[finite relational structures, Object oriented databases, real arithmetic constraints, Object oriented modeling, Relational databases, constraint query languages, elimination of constraints, query languages, Database languages, complexity bounds, unbounded quantification, Upper bound, Algebra, constraint databases, Query processing, Logic functions, Polynomials, Arithmetic]
Games and full abstraction for FPC
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
We present a new category of games, /spl Gscr/, and build from it a cartesian closed category I and its extensional quotient /spl epsi/. /spl epsi/ represents an improvement over existing categories of games in that it has sums as well as products, function spaces and recursive types. A model of the language FPC, a sequential functional language with just this type structure, in /spl epsi/ is described and shown to be fully abstract.
[Flexible printed circuits, recursive types, computational linguistics, full abstraction, function spaces, Calculus, Game theory, Computer languages, category of games, FPC, denotational semantics, cartesian closed category, extensional quotient]
A temporal-logic approach to binding-time analysis
Proceedings 11th Annual IEEE Symposium on Logic in Computer Science
None
1996
The Curry-Howard isomorphism identifies proofs with typed /spl lambda/-calculus terms, and correspondingly identifies propositions with types. We show how this isomorphism can be extended to relate constructive temporal logic with binding-time analysis. In particular we show how to extend the Curry-Howard isomorphism to include the O ("next") operator from linear-time temporal logic. This yields the simply typed /spl lambda//sup O/-calculus which we prove to be equivalent to a multi-level binding-time analysis like those used in partial evaluation for functional programming languages. Further, we prove that normalization in /spl lambda//sup O/ can be done in an order corresponding to the times in the logic, which explains why /spl lambda//sup O/ is relevant to partial evaluation. We then extend /spl lambda//sup O/ to a small functional language, Mini-ML/sup O/, and give an operational semantics for it. Finally, we prove that this operational semantics correctly reflects the binding-times in the language, a theorem which is the functional programming analog of time-ordered normalization.
[Computer science, Data analysis, Logic programming, typed lambda-calculus, binding-time analysis, normalization, operational semantics, temporal logic, Functional programming, Curry-Howard isomorphism, functional programming languages]
Temporal linear logic specifications for concurrent processes
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
The aim of the paper is to develop comprehensive logical systems capable of handling both resource-sensitive and time-dependent properties of concurrent processes. As a language for specifying such properties, we introduce 'temporal linear logic' (TLL) an extension of linear logic with certain features of temporal logic. A semantic setting for TLL is given in terms of 'time-state universes'. TLL is proved to be fully adequate for 'time-state' concurrency models.
[comprehensive logical systems, temporal linear logic specifications, Logic programming, Petri nets, Indium tin oxide, Stochastic processes, temporal logic, Logic design, semantic setting, Game theory, formal specification, time-state universes, Concurrent computing, Computer science, Computer languages, time-dependent properties, Parallel processing, concurrent processes, concurrency models]
Ground reducibility is EXPTIME-complete
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We prove that ground reducibility is EXPTIME-complete in the general case. EXPTIME-hardness is proved by encoding the computations of an alternating Turing machine whose space is polynomially bounded. It is more difficult to show that ground reducibility belongs to DEXPTIME. We associate first an automaton with disequality constraints A/sub R,t/ to a rewrite system R and a term t. This automaton is deterministic and accepts a term u if and only if t is not ground reducible by R. The number of states of A/sub R,t/ is O(2/sup /spl par/R/spl par//spl times//spl par/t/spl par//) and the size of the constraints are polynomial in the size of R,t. Then we prove some new pumping lemmas, using a total ordering on the computations of the automaton. Thanks to these lemmas, we can give an upper bound to the number of distinct subtrees of a minimal successful computation of an automaton with disequality constraints. It follows that emptiness of such an automaton can be decided in time polynomial in the number of its states and exponential in the size of its constraints. Altogether, we get a simply exponential deterministic algorithm for ground reducibility.
[Algorithm design and analysis, pumping lemmas, total ordering, Poles and towers, EXPTIME-hardness, EXPTIME-complete, ground reducibility, upper bound, History, encoding, deterministic algorithm, deterministic algorithms, Upper bound, automaton, Turing machines, disequality constraints, Automata, Polynomials, Logic, alternating Turing machine, rewrite system, computational complexity]
A relational account of call-by-value sequentiality
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We construct a model for FPC, a purely functional, sequential, call-by-value language. The model is built from partial continuous functions, in the style of Plotkin, further constrained to be uniform with respect to a class of logical relations. We prove that the model is fully abstract.
[Computer science, Flexible printed circuits, formal languages, fully abstract, partial continuous functions, FPC, call-by-value sequentiality, Calculus, call-by-value language, functional languages]
An expressively complete linear time temporal logic for Mazurkiewicz traces
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
A basic result concerning LTL, the propositional temporal logic of linear time is that it is expressively complete; it is equal in expressive power to the first order theory of sequences. We present here a smooth extension of this result to the class of partial orders known as Mazurkiewicz traces. These partial orders arise in a variety of contexts in concurrency theory and they provide the conceptual basis for many of the partial order reduction methods that have been developed in connection with LTL-specifications. We show that LTrL, our linear time temporal logic, is equal in expressive power to the first order theory of traces when interpreted over (finite and) infinite traces. This result fills a prominent gap in the existing logical theory of infinite traces. LTrL also provides a syntactic characterisation of the so called trace consistent (robust) LTL-specifications. These are specifications expressed as LTL formulas that do not distinguish between different linearisations of the same trace and hence are amenable to partial order reduction methods.
[Mazurkiewicz traces, partial order reduction, Petri nets, LTL, linear time temporal logic, temporal logic, concurrency theory, propositional temporal logic, parallel programming, Concurrent computing, Computer science, partial orders, Robustness, Logic, Informatics, equivalence classes, infinite traces]
Combination of compatible reduction orderings that are total on ground terms
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
Reduction orderings that are compatible with an equational theory E and total on (the E-equivalence classes of) ground terms play an important role in automated deduction. This paper presents a general approach for combining such orderings: it shows how E/sub 1/-compatible reduction orderings total on /spl Sigma//sub 1/-ground terms and E/sub 2/-compatible reduction orderings total on /spl Sigma//sub 2/-ground terms can be used to construct an (E/sub 1//spl cup/E/sub 2/)-compatible reduction ordering total on (/spl Sigma//sub 1//spl cup//spl Sigma//sub 2/)-ground terms, provided that the signatures are disjoint and some other (rather weak) restrictions are satisfied. This work was motivated by the observation that it is often easier to construct such orderings for "small" signatures and theories separately, rather than directly for their union.
[Computer science, formal logic, rewriting systems, ground terms, reduction orderings, automated deduction, Polynomials, theorem proving, equivalence classes, Equations]
Strong normalization of explicit substitutions via cut elimination in proof nets
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
In this paper, we show the correspondence existing between normalization in calculi with explicit substitution and cut elimination in sequent calculus for linear logic, via proof nets. This correspondence allows us to prove that a typed version of the /spl lambda/x-calculus is strongly normalizing, as well as of all the calculi that can be translated to it keeping normalization properties such as /spl lambda//sub v/, /spl lambda//sub s/, /spl lambda//sub d/ and /spl lambda//sub f/. In order to achieve this result, we introduce a new notion of reduction in proof nets: this extended reduction is still confluent and strongly normalizing, and is of interest of its own, as it corresponds to more identifications of proofs in linear logic that differ by inessential details. These results show that calculi with explicit substitutions are really an intermediate formalism between lambda calculus and proof nets, and suggest a completely new way to look at the problems still open in the field of explicit substitutions.
[lambda calculus, /spl lambda/x-calculus, Computational modeling, cut elimination, linear logic, proof nets, Calculus, explicit substitutions, strong normalization, formal logic, Interpolation, calculi, Algebra, theorem proving, Logic]
On the forms of locality over finite models
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
Most proofs showing limitations of expressive power of first-order logic rely on Ehrenfeucht-Fraisse games. Playing the game often involves a nontrivial combinatorial argument, so it was proposed to find easier tools for proving expressivity bounds. Most of those known for first-order logic are based on its "locality\
[first-order logic, Relational databases, locality, Calculus, Application software, Proposals, relational databases, Database languages, expressive power, database theory, Computer science, formal logic, languages with aggregates, Aggregates, relational queries, Libraries, relational database languages, Logic, Gaifman's locality theorem, aggregate functions]
How much memory is needed to win infinite games?
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We consider a class of infinite two-player games on finitely coloured graphs. Our main question is: given a winning condition, what is the inherent blow-up (additional memory) of the size of the I/O automata realizing winning strategies in games with this condition. This problem is relevant to synthesis of reactive programs and to the theory of automata on infinite objects. We provide matching upper and lower bounds for the size of memory needed by winning strategies in games with a fixed winning condition. We also show that in the general case the LAR (latest appearance record) data structure of Gurevich and Harrington is optimal. Then we propose a more succinct way of representing winning strategies by means of parallel compositions of transition systems. We study the question: which classes of winning conditions admit only polynomial-size blowup of strategies in this representation.
[automata theory, polynomial-size blowup, data structure, Control systems, History, graph colouring, I/O automata, size of memory, winning strategies, two-player games, Polynomials, Logic, Informatics, finitely coloured graphs, game theory, Data structures, Size measurement, Game theory, reactive programs, Computer science, Automata, upper and lower bounds, latest appearance record, infinite games, computational complexity]
On the cubic bottleneck in subtyping and flow analysis
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We prove that certain data-flow and control-flow problems are 2NPDA-complete. This means that these problems are in the class 2NPDA and that they are hard for that class. The fact that they are in 2NPDA demonstrates the richness of the class. The fact that they are hard for 2NPDA can be interpreted as evidence they can not be solved in sub-cubic time-the cubic time decision procedure for an arbitrary 2NPDA problem has not been improved since its discovery in 1968.
[Algorithm design and analysis, sub-cubic time, data-flow, reachability analysis, control-flow, data flow analysis, 2NPDA-complete, type theory, cubic bottleneck, subtyping, directed graphs, Automata, Automatic control, context-free grammars, computational complexity, flow analysis]
Semantics of exact real arithmetic
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
In this paper, we incorporate a representation of the non-negative extended real numbers based on the composition of linear fractional transformations with non-negative integer coefficients into the Programming Language for Computable Functions (PCF) with products. We present two models for the extended language and show that they are computationally adequate with respect to the operational semantics.
[formal languages, exact real arithmetic, operational semantics, Educational institutions, Computer languages, PCF, extended language, digital arithmetic, Integer linear programming, Programming Language for Computable Functions, Digital arithmetic, Roundoff errors, extended real numbers, Functional programming, Mathematical model, linear fractional transformations]
Unique fixpoint induction for value-passing processes
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We investigate the use of unique fixpoint induction as a proof method for value-passing process languages with recursion. An intuitive generalisation of unique fixpoint induction based on loop invariants for symbolic graphs yields strong completeness results; we give an axiomatic characterisation of both late and early observational congruence for a class of fully parameterised processes. This new, generalised, rule is shown to be derivable from existing formulations of unique fixpoint induction for value-passing calculi, thereby providing original completeness results. An example of the use of this new rule is presented in detail.
[intuitive generalisation, process algebra, fixpoint induction, value-passing calculi, Telephony, symbolic graphs, loop invariants, Carbon capture and storage, inference mechanisms, process languages, recursion]
Automata, tableaus and a reduction theorem for fixpoint calculi in arbitrary complete lattices
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
Fixpoint expressions built from functional signatures interpreted over arbitrary complete lattices are considered. A generic notion of automaton is defined and shown, by means of a tableau technique, to capture the expressive power of fixpoint expressions. For interpretation over continuous and complete lattices when, moreover, the meet symbol /spl Lambda/ commutes in a rough sense with all other functional symbols, it is shown that any closed fixpoint expression is equivalent to a fixpoint expression built without the meet symbol /spl lambda/. This result generalizes Muller and Schupp's simulation theorem for alternating automata on the binary tree.
[reduction theorem, binary tree, automata theory, Lattices, alternating automata, Calculus, arbitrary complete lattices, Boolean algebra, tableaus, meet symbol, process algebra, Automata, Binary trees, fixpoint calculi, Logic, automata]
Continuation models are universal for /spl lambda//sub /spl mu//-calculus
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We show that a certain simple call-by-name continuation semantics of Parigot's /spl lambda//sub /spl mu//-calculus (1992) is complete. More precisely, for every /spl lambda//spl mu/-theory we construct a cartesian closed category such that the ensuing continuation-style interpretation of /spl lambda//sub /spl mu//, which maps terms to functions sending abstract continuations to responses, is full and faithful. Thus, any /spl lambda//sub /spl mu//-category in the sense of is isomorphic to a continuation model derived from a cartesian-closed category of continuations.
[cartesian-closed category, lambda calculus, lambda/sub mu/-calculus, Logic programming, functional programming, simple call-by-name continuation semantics, Calculus, continuation models, Equations, formal logic, Prototypes, Lab-on-a-chip, computation theory, abstract continuations, Concrete, continuation-style interpretation, Functional programming, Artificial intelligence, Arithmetic, cartesian closed category, continuation model]
Complexity of two-variable logic with counting
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
Let C/sub k//sup 2/ denote the class of first order sentences with two variables and with additional quantifiers "there exists exactly (at most, at least) m\
[Computer science, satisfiability, doubly exponential time, computability, first order sentences, Mathematics, Logic, NEXPTIME-complete, first order two-variable logic, Springs, two-variable logic, computational complexity]
Full abstraction for functional languages with control
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
This paper considers the consequences of relaxing the bracketing condition on 'dialogue games', showing that this leads to a category of games which can be 'factorized' into a well-bracketed substructure, and a set of classically typed morphisms. These are shown to be sound denotations for control operators, allowing the factorization to be used to extend the definability result for PCF to one for PCF with control operators at atomic types. Thus we define a fully abstract and effectively presentable model of a functional language with non-local control as part of a modular approach to modelling non-functional features using games.
[formal languages, full abstraction, dialogue games, definability result, Computer science, PCF, bracketing condition, classically typed morphisms, Prototypes, control operators, functional language, Logic, Testing, Arithmetic, functional languages]
First-order logic with two variables and unary temporal logic
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We investigate the power of first-order logic with only two variables over /spl omega/-words and finite words, a logic denoted by FO/sup 2/. We prove that FO/sup 2/ can express precisely the same properties as linear temporal logic with only the unary temporal operators: "next\
[first-order logic, temporal logic, computability, unary temporal operators, FO/sup 2/, Computational complexity, unary-TL, unary temporal logic, Computer science, formal logic, satisfiability, Polynomials, Logic, NEXP-complete, computational complexity]
Complete cuboidal sets in axiomatic domain theory
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We study the enrichment of models of axiomatic domain theory. To this end, we introduce a new and broader notion of domain, via, that of complete cuboidal set, that complies with the axiomatic requirements. We show that the category of complete cuboidal sets provides a general notion of enrichment for a wide class of axiomatic domain-theoretic structures.
[Shape, Logic programming, cuboidal sets, Laboratories, type theory, axiomatic domain theory, Equations, Tellurium, Computer science, Computer languages, process algebra, category theory, axiomatic domain-theoretic structures, Mathematical model, category]
On the complexity of reasoning in Kleene algebra
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We study the complexity of reasoning in Kleene algebra and *-continuous Kleene algebra in the presence of extra equational assumptions E; that is, the complexity of deciding the validity of universal Horn formulas E/spl rarr/s=t, where E is a finite set of equations. We obtain various levels of complexity based on the form of the assumptions E. Our main results are: for *-continuous Kleene algebra, if E contains only commutativity assumptions pq=qp, the problem is II/sub 1//sup 0/-complete; if E contains only monoid equations, the problem is II/sub 2//sup 0/-complete; for arbitrary equations E, the problem is II/sub 1//sup 1/-complete. The last problem is the universal Horn theory of the *-continuous Kleene algebras. This resolves an open question of Kozen (1994).
[Algorithm design and analysis, complexity, Kleene algebra, Logic design, Concurrency control, commutativity assumptions, Equations, Computer science, Algebra, process algebra, universal Horn formulas, monoid equations, Lead, Logic functions, equational assumptions, Safety, complexity of reasoning, Testing, computational complexity]
Believe it or not, AJM's games model is a model of classical linear logic
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
A general category of games is constructed. A subcategory of saturated strategies, closed under all possible codings in copy games, is shown to model reduction in classical linear logic.
[Visualization, Protocols, game theory, Minimax techniques, AJM's games model, Calculus, copy games, saturated strategies, encoding, codings, Game theory, Bridges, formal logic, classical linear logic, reduced order systems, general category, Reduced order systems, Logic, Testing, Context modeling]
Games and definability for system F
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We develop a game-theoretic model of the polymorphic /spl lambda/-calculus, system F, as a fibred category F. Our main result is that every morphism /spl sigma/ of the model defines a normal form s/sub /spl sigma// of system F, whose interpretation is /spl sigma/. Thus the model gives a precise, non-syntactic account of the calculus.
[lambda calculus, Laboratories, definability, game theory, Analog computers, Calculus, morphism, Yarn, fibred category, formal logic, polymorphic /spl lambda/-calculus, games, Functional programming, game-theoretic model, system F, Testing]
Quantitative analysis and model checking
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
Many notions of models in computer science provide quantitative information, or uncertainties, which necessitate a quantitative model checking paradigm. We present such a framework for reactive and generative systems based on a non-standard interpretation of the modal mu-calculus, where /spl mu/x./spl phi//vx./spl phi/ are interpreted as least/greatest fired points over the infinite lattice of maps from states to the unit interval. By letting formulas denote lower bounds of probabilistic evidence of properties, the values computed by our quantitative model checker can serve as satisfactory correctness guarantees in cases where conventional qualitative model checking fails. Since fixed point iteration in this infinite domain is computationally unfeasible, we establish that the computation of fixed points may be restated as a conventional, and on average efficient, optimization problem in linear programming; this holds for a fragment of the modal mu-calculus which subsumes CTL. Our semantics induces a state equivalence which is strictly in between probabilistic bisimulation and probabilistic ready bisimulation.
[quantitative model checking, optimization problem, Costs, Uncertainty, Protocols, infinite lattice of maps, state equivalence, probabilistic logic, infinite domain, fixed point iteration, Lattices, Probabilistic logic, Tellurium, lower bounds, Computer science, Information geometry, formal verification, model checking, process algebra, Linear algebra, modal mu-calculus, Hardware, quantitative analysis]
The complexity of subtype entailment for simple types
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
A subtyping /spl tau//spl les//spl tau/' is entailed by a set of subtyping constraints C, written C |=/spl tau//spl les//spl tau/', if every valuation (mapping of type variables to ground types) that satisfies C also satisfies /spl tau//spl les//spl tau/'. We study the complexity of subtype entailment for simple types over lattices of base types. We show that: deciding C |=/spl tau//spl les//spl tau/' is coNP-complete; deciding C |=/spl alpha//spl les//spl beta/ for consistent, atomic C and /spl alpha/, /spl beta/ atomic can be done in linear time. The structural lower (coNP-hardness) and upper (membership in coNP) bounds as well as the optimal algorithm for atomic entailment are new. The coNP-hardness result indicates that entailment is strictly harder than satisfiability, which is known to be in PTIME for lattices of base types. The proof of coNP-completeness gives an improved algorithm for deciding entailment and puts a precise complexity-theoretic marker on the intuitive "exponential explosion" in the algorithm. Central to our results is a novel characterization of C |=/spl alpha//spl les//spl beta/ for atomic, consistent C. This is the basis for correctness of the linear-time algorithm as well as a complete axiomatization of C |=/spl alpha//spl les//spl beta/ for atomic C by extending the usual proof rules for subtype inference. It also incorporates the fundamental insight for understanding the structural complexity bounds in the general case.
[axiomatization, structural complexity bounds, Lattices, computability, Calculus, Explosions, type theory, atomic entailment, inference mechanisms, Power system modeling, Cost accounting, linear-time algorithm, Computer science, Computer languages, coNP-completeness, complexity-theoretic marker, satisfiability, exponential explosion, subtype inference, Inference algorithms, subtype entailment complexity, Logic, Power generation, computational complexity]
Boolean expression diagrams
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
This paper presents a new data structure called Boolean Expression Diagrams (BEDs) for representing and manipulating Boolean functions. BEDs are a generalization of Binary Decision Diagrams (BDDs) which can represent any Boolean circuit in linear space and still maintain many of the desirable properties of BDDs. Two algorithms are described for transforming a BED into a reduced ordered BDD. One closely mimics the BDD apply-operator while the other can exploit the structural information of the Boolean expression. The efficacy of the BED representation is demonstrated by verifying that the redundant and non-redundant versions of the ISCAS 85 benchmark circuits are identical. In particular, it is verified that the two 16-bit multiplication circuits (c6288 and c6288nr) implement the same Boolean functions. Using BEDs, this verification problem is solved in less than a second, while using standard BDD techniques this problem is infeasible. BEDs are useful in applications where the end-result as a reduced ordered BDD is small, for example for tautology checking.
[Circuits, Buildings, Binary Decision Diagrams, reduced ordered, Binary decision diagrams, data structure, Boolean Expression Diagrams, Data structures, tautology checking, Information technology, Equations, decision tables, Boolean functions, data structures, Testing]
Bisimulation for labelled Markov processes
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
In this paper we introduce a new class of labelled transition systems-Labelled Markov Processes-and define bisimulation for them. Labelled Markov processes are probabilistic labelled transition systems where the state space is not necessarily discrete, it could be the reals, for example. We assume that it is a Polish space (the underlying topological space for a complete separable metric space). The mathematical theory of such systems is completely new from the point of view of the extant literature on probabilistic process algebra; of course, it uses classical ideas from measure theory and Markov process theory. The notion of bisimulation builds on the ideas of Larsen and Skou and of Joyal, Nielsen and Winskel. The main result that we prove is that a notion of bisimulation for Markov processes on Polish spaces, which extends the Larsen-Skou definition for discrete systems, is indeed an equivalence relation. This turns our to be a rather hard mathematical result which, as far as we know, embodies a new result in pure probability theory. This work heavily uses continuous mathematics which is becoming an important part of work on hybrid systems.
[Real time systems, bisimulation, labelled Markov processes, state space, Educational institutions, Extraterrestrial measurements, Mathematics, State-space methods, labelled transition systems, Physics, Computer science, Algebra, process algebra, Markov processes, category theory, Polish space, equivalence relation, Control theory, pure probability theory, state-space methods]
Discrimination by parallel observers
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
The main result of the paper is a proof of the following equivalence: two pure lambda terms are observationally equivalent in the lazy concurrent lambda calculus if they have the same Levy-Longo trees. It follows that contextual equivalence coincides with behavioural equivalence (bisimulation) as considered by Sangiorgi (1994). Another consequence is that the discriminating power of concurrent lambda contexts is the same as that of Boudol-Laneve's contexts with multiplicities (1996).
[lambda calculus, parallel algorithms, bisimulation, programming theory, lazy concurrent lambda calculus, trees (mathematics), parallel observers, Calculus, type theory, discriminating power, Equations, Levy-Longo trees, multiplicities, pure lambda terms, contextual equivalence, Prototypes, discrimination, behavioural equivalence, Informatics, concurrent lambda contexts]
Complexity of power default reasoning
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
This paper derives a new and surprisingly low complexity result for inference in a new form of Reiter's propositional default logic (1980). The problem studied here is the default inference problem whose fundamental importance was pointed out by Kraus, Lehmann, and Magidor (1980). We prove that "normal" default inference, in propositional logic, is a problem complete for co-NP(3), the third level of the Boolean hierarchy. Our result (by changing the underlying semantics) contrasts favorably with a similar result of Gottlob (1992), who proves that standard default inference is II/sub 2//sup P/-complete. Our inference relation also obeys all of the laws for preferential consequence relations set forth by Kraus, Lehmann, and Magidor (1990). In particular we get the property of being able to reason by cases and the law of cautious monotony. Both of these laws fail for standard propositional default logic. The key technique for our results is the use of Scott's domain theory to integrate defaults into partial model theory of the logic, instead of keeping defaults as quasiproof rules in the syntax. In particular, reasoning disjunctively entails using the Smyth powerdomain.
[complexity, Logic programming, propositional logic, Laboratories, propositional default logic, default inference problem, Smyth powerdomain, partial model theory, preferential consequence relations, Database languages, nonmonotonic reasoning, Computer science, formal logic, Boolean functions, Boolean hierarchy, underlying semantics, quasiproof rules, Database systems, standard propositional default logic, power default reasoning, Artificial intelligence, Deductive databases, computational complexity]
Automata-driven automated induction
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
This work investigates inductive theorem proving techniques for first-order functions whose meaning and domains can be specified by Horn Clauses built up from the equality and finitely many unary membership predicates. In contrast with other works in the area, constructors are not assumed to be free. Techniques originating from tree automata are used to describe ground constructor terms in normal form, on which the induction proofs are built up. Validity of (free) constructor clauses is checked by on original technique relying on the recent discovery of a complete axiomatisation of finite trees and their rational subsets. Validity of clauses with defined symbols or non-free constructor terms is reduced to the latter case by appropriate inference rules using a notion of ground reducibility for these symbols. We show how to check this property by generating proof obligations which can be passed over to the inductive prover.
[proof obligations, inductive theorem proving, Horn clauses, automata theory, automata-driven automated induction, Laboratories, Data structures, ground reducibility, first-order functions, inference mechanisms, Equations, finitely many unary membership predicates, Computer science, inductive prover, Automata, rational subsets, Modems, theorem proving, Horn Clauses, tree automata, Logic]
The monadic quantifier alternation hierarchy over graphs is infinite
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We show that in monadic second-order logic over finite directed graphs, a strict hierarchy of expressiveness is obtained by increasing the (second-order) quantifier alternation depth of formulas. thus, the "monadic analogue" of the polynomial hierarchy is found to be strict, which solves a problem of Fagin. The proof is based on automata theoretic concepts (rather than Ehrenfeucht-Fraisse games) and starts from a restricted class of graph-like structures, namely finite two-dimensional grids. We investigate monadic second-order definable sets of grids where the width of grids is a function of the height. In this context, the infiniteness of the quantifier alternation hierarchy is witnessed by n-fold exponential functions for increasing n. It is notable that these witness sets of the monadic hierarchy all belong to the complexity class NP, the first level of the polynomial hierarchy.
[automata theory, complexity class, automata theoretic concepts, Complexity theory, Noise measurement, Game theory, graph-like structures, formal logic, witness sets, Tree graphs, directed graphs, Automata, finite directed graphs, expressiveness, quantifier alternation depth, Polynomials, monadic second-order logic, Logic, Kernel, computational complexity]
Towards a mathematical operational semantics
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We present a categorical theory of 'well-behaved' operational semantics which aims at complementing the established theory of domains and denotational semantics to form a coherent whole. It is shown that, if the operational rules of a programming language can be modelled as a natural transformation of a suitable general form, depending on functorial notions of syntax and behaviour, then one gets the following for free: an operational model satisfying the rules and a canonical, internally fully abstract denotational model which satisfies the operational rules. The theory is based on distributive laws and bialgebras; it specialises to the known classes of well-behaved rules for structural operational semantics, such as GSOS.
[programming theory, formal languages, theory of domains, Laboratories, computational linguistics, operational semantics, abstract denotational model, Equations, natural transformation, Computer science, bialgebras, Computer languages, Algebra, category theory, categorical theory, operational model, Mathematical model, denotational semantics]
A partially deadlock-free typed process calculus
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We propose a novel static type system for a process calculus, which ensures both partial deadlock-freedom and partial confluence. The key novel ideas are: (1) introduction of the order of channel use as type information and (2) classification of communication channels into reliable and unreliable channels based on their usage and a guarantee of the usage by the type system. We can ensure that communication on reliable channels never causes deadlock and also that certain reliable channels never introduce nondeterminism. With the type system, for example, the simply typed /spl lambda/-calculus can be encoded into the deadlock-free and confluent fragment of our process calculus; we can therefore recover behavior of the typed /spl lambda/-calculus in the level of process calculi. We also show that typical concurrent objects can also be encoded into the deadlock-free fragment.
[lambda calculus, concurrent objects, partial confluence, typed /spl lambda/-calculus, Calculus, type theory, Distributed computing, deadlock-free, parallel programming, static type system, Concurrent computing, Information science, Computer languages, concurrency control, Communication channels, System recovery, process calculus, nondeterminism]
Set constraints with intersection
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
Set constraints are inclusions between expressions denoting sets of trees. The efficiency of their satisfiability test is a central issue in set-based program analysis, their main application domain. We introduce the class of set constraints with intersection (the only operators forming the expressions are constructors and intersection) and show that its satisfiability problem is DEXPTIME-complete. The complexity characterization continues to hold for negative set constraints with intersection (which have positive and negated inclusions). We reduce the satisfiability problem for these constraints to one over the interpretation domain of nonempty sets of trees. Set constraints with intersection over the domain of nonempty sets of trees enjoy the fundamental property of independence of negated conjuncts. This allows us to handle each negated inclusion separately by the entailment algorithm that we devise. We furthermore prove that set constraints with intersection are equivalent to the class of definite set constraints and thereby settle the complexity question of the historically first class for which the decidability question was solved.
[Performance evaluation, negated conjuncts, Logic programming, program testing, set-based program analysis, trees (mathematics), computability, set theory, formal logic, Upper bound, decidability, DEXPTIME-complete, Automatic testing, Automata, intersection, set constraints, negative set constraints, complexity characterization, satisfiability test, inclusions, computational complexity, negated inclusion]
A Kleene theorem for timed automata
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
In this paper we define timed regular expressions, and extension of regular expressions for specifying sets of dense-time discrete-valued signals. We show that this formalism is equivalent in expressive power to the timed automata of Alur and Dill by providing a translation procedure from expressions to automata and vice versa. the result is extended to /spl omega/-regular expressions (Buchi's theorem).
[Real time systems, automata theory, Kleene theorem, /spl omega/-regular expressions, Equations, expressive power, Concurrent computing, Algebra, Automata, Logic functions, timed automata, Clocks, timed regular expressions, dense-time discrete-valued signals]
Ramified higher-order unification
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
While unification in the simple theory of types (a.k.a. higher-order logic) is undecidable. we show that unification in the pure ramified theory of types with integer levels is decidable. Since pure ramified type theory is not very expressive, we examine the impure case, which has an undecidable unification problem already at order 2. In impure ramified higher-order logics, expressive predicative second-order subsystems of arithmetic or of inductive theories have concise axiomatisations; because of this and our decidability result for the pure case, we argue that ramified systems are expressive higher-order frameworks in which automated proof search should be practical.
[lambda calculus, Automatic programming, programming theory, Mathematics, Calculus, type theory, automated proof search, undecidable unification problem, expressive predicative second-order subsystems, expressive higher-order frameworks, pure ramified theory, Computer science, formal logic, inductive theories, decidability, undecidable, logic programming, integer levels, theorem proving, Logic, axiomatisations, ramified higher-order unification, Arithmetic]
The "Hardest" natural decidable theory
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We prove that any decision procedure for a modest fragment of L. Henkin's theory of pure propositional types requires time exceeding a tower of 2's of height exponential in the length of input. Until now the highest known lower bounds for natural decidable theories were at most linearly high towers of 2's and since mid-seventies it was an open problem whether natural decidable theories requiring more than that exist. We give the affirmative answer. As an application of this today's strongest lower bound we improve known and settle new lower bounds for several problems in the simply typed lambda calculus.
[lambda calculus, Poles and towers, Calculus, Encoding, natural decidable theory, propositional types, lower bound, Upper bound, typed lambda calculus, Turing machines, decidability, decision procedure, Set theory, computational complexity]
Induction and recursion on the partial real line via biquotients of bifree algebras
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
The partial real line is the continuous domain of compact real intervals ordered by reverse inclusion. The idea is that singleton intervals represent total real numbers, and that the remaining intervals represent partial real numbers. The partial real line has been used to model exact real number computation in the framework of the programming language Real PCF. We introduce induction principles and recursion schemes for the partial unit interval, which allows us to verify that Real PCF programs meet their specification. The theory is based on a domain-equation-like presentation of the partial unit interval, which we refer to as a biquotient of a bifree algebra.
[program verification, bifree algebras, biquotients, Educational institutions, specification, algebra, singleton intervals, Topology, exact real number computation, compact real intervals, Real PCF, Equations, partial unit interval, reverse inclusion, formal logic, Computer languages, Algebra, induction, recursion schemes, domain-equation-like presentation, partial real line, induction principles, recursion]
Linear higher-order pre-unification
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We develop an efficient representation and a pre-unification algorithm in the style of Huet (1975) for the linear /spl lambda/-calculus /spl lambda//sup /spl rarr//spl rArr/0&T/ which includes intuitionistic functions (/spl rarr/), linear functions (/spl rArr/), additive pairing (&), and additive unit (T). Applications lie in proof scorch, logic programming, and logical frameworks based on linear type theories. We also show that, surprisingly, a similar pre-unification algorithm does not exist for certain sublanguages.
[proof scorch, Mathematics, type theory, Proposals, representation, formal logic, linear higher-order pre-unification, additive unit, additive pairing, logic programming, linear type theories, linear functions, lambda calculus, programming theory, Logic programming, intuitionistic functions, logical frameworks, Logic design, Encoding, sublanguages, Equations, Computer science, Linearity, Ear, Writing, linear lambda calculus]
Two-variable logic with counting is decidable
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
We prove that the satisfiability and the finite satisfiability problems for C/sup 2/ are decidable. C/sup 2/ is first-order logic with only two variables in the presence of arbitrary counting quantifiers 3/sup /spl ges/m/,m/spl ges/1. It considerably extends L/sup 2/ plain first-order with only two variables, which is known to be decidable by a result of Mortimer's. Unlike L/sup 2/, C/sup 2/ does not have the finite model property.
[Vocabulary, decidable, Terminology, first-order logic, H infinity control, computability, Research and development, formal logic, Boolean functions, decidability, satisfiability, Page description languages, finite satisfiability, Logic, two-variable logic]
A logic for reasoning with higher-order abstract syntax
Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science
None
1997
Logical frameworks based on intuitionistic or linear logics with higher-type quantification have been successfully used to give high-level, modular, and formal specifications of many important judgments in the area of programming languages and inference systems. Given such specifications, it is natural to consider proving properties about the specified systems in the framework: for example, given the specification of evaluation for a functional programming language, prove that the language is deterministic or that the subject-reduction theorem holds. One challenge in developing a framework for such reasoning is that higher-order abstract syntax (HOAS), an elegant and declarative treatment of object-level abstraction and substitution, is difficult to treat in proofs involving induction. In this paper we present a meta-logic that can be used to reason about judgments coded using HOAS; this meta-logic is an extension of a simple intuitionistic logic that admits higher-order quantification over simply typed /spl lambda/-terms (key ingredients for HOAS) as well as induction and a notion of definition. The latter concept of a definition is a proof-theoretic device that allows certain theories to be treated as "closed" or as defining fixed points. The resulting meta-logic can specify various logical frameworks and a large range of judgments regarding programming languages and inference systems. We illustrate this point through examples, including the admissibility of cut for a simple logic and subject reduction, determinacy of evaluation, and the equivalence of SOS and natural semantics presentations of evaluation for a simple functional programming language.
[functional programming, linear logics, programming languages, formal specification, formal logic, Information science, subject-reduction theorem, higher-order abstract syntax, simply typed /spl lambda/-terms, object-level abstraction, Performance analysis, natural semantics presentations, Functional programming, higher-type quantification, Logic devices, equivalence, Logic programming, inference systems, logical frameworks, Specification languages, inference mechanisms, formal specifications, intuitionistic logics, Computer languages, logic for reasoning]
How to specify and verify the long-run average behaviour of probabilistic systems
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Long-run average properties of probabilistic systems refer to the average behaviour of the system, measured over a period of time whose length diverges to infinity. These properties include many relevant performance and reliability indices, such as system throughput, average response time, and mean time between failures. In this paper, we argue that current formal specification methods cannot be used to specify long-run average properties of probabilistic systems. To enable the specification of these properties, we propose an approach based on the concept of experiments. Experiments are labeled graphs that can be used to describe behaviour patterns of interest, such as the request for a resource followed by either a grant or a rejection. Experiments are meant to be performed infinitely often. and it is possible to specify their long-run average outcome or duration. We propose simple extensions of temporal logics based on experiments, and we present model-checking algorithms for the verification of properties of finite-state timed probabilistic systems in which both probabilistic and nondeterministic choice are present. The consideration, of system models that include nondeterminism enables the performance and reliability analysis of partially specified systems, such as systems in their early design stages.
[System testing, finite-state timed probabilistic systems, formal specification methods, average response time, Length measurement, behaviour patterns, Probabilistic logic, Throughput, Time measurement, Calculus, temporal logics, reliability indices, Logic testing, formal specification, Delay, labeled graphs, long-run average behaviour, Algebra, Failure analysis, system throughput, mean time between failures, model-checking algorithms, probabilistic systems, nondeterminism]
On proofs about threshold circuits and counting hierarchies
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
We define theories of Bounded Arithmetic characterizing classes of functions computable by constant-depth threshold circuits of polynomial and quasipolynomial size. Then we define certain second-order theories and show that they characterize the functions in the Counting Hierarchy. Finally we show that the former theories are isomorphic to the latter via the so-called RSUV-isomorphism.
[counting hierarchies, Circuit simulation, constant-depth threshold circuits, Mathematics, Complexity theory, threshold circuits, Computer science, Algebra, Bounded Arithmetic, RSUV-isomorphism, Digital arithmetic, Polynomials, computational complexity]
Type theory via exact categories
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Partial equivalence relations (and categories of these) are a standard tool in semantics of type theories and programming languages, since they often provide a cartesian closed category with extended definability. Using the theory of exact categories, we give a category-theoretic explanation of why the construction of a category of partial equivalence relations often produces a cartesian closed category. We show how several familiar examples of categories of partial equivalence relations fit into the general framework.
[Computer science, equivalence relations, Computer languages, Lattices, Logic functions, Calculus, type theory, exact categories, partial equivalence relations, type theories, cartesian closed category]
The first-order theory of ordering constraints over feature trees
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
The system FT/sub /spl les// of ordering constraints over feature trees has been introduced as an extension of the system FT of equality constraints over feature trees. We investigate the first-order theory of FT/sub /spl les// and its fragments, both over finite trees and over possibly infinite trees. We prove that the first-order theory of FT/sub /spl les// is undecidable, in contrast to the first-order theory of FT which is well-known to be decidable. We determine the complexity of the entailment problem of FT/sub /spl les// with existential quantification to be PSPACE-complete, by proving its equivalence to the inclusion problem of non-deterministic finite automata. Our reduction from the entailment problem to the inclusion problem is based on a new algorithm that, given an existential formula of FT/sub /spl les//, computes a finite automaton which accepts all its logic consequences.
[complexity, equivalence, Logic programming, finite automata, first-order theory, feature trees, constraints, Tellurium, Read only memory, Computer languages, undecidable, Automata, Constraint theory, Computational linguistics, non-deterministic finite automata, Labeling]
Fixed-point logics on planar graphs
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
We study the expressive power of inflationary fixed-point logic IFP and inflationary fixed-point logic with counting IFP+C on planar graphs. We prove the following results: (1) IFP captures polynomial time on 3-connected planar graphs, and IFP+C captures polynomial time on arbitrary planar graphs. (2) Planar graphs can be characterized up to isomorphism in a logic with finitely many variables and counting. This answers a question of Immerman (1987). (3) The class of planar graphs is definable in IFP. This answers a question of Dawar and Gradel.
[formal logic, IFP, Tree graphs, inflationary fixed-point logic, planar graphs, Polynomials, polynomial time, Logic, Tellurium, expressive power, IFP+C, isomorphism]
The fusion calculus: expressiveness and symmetry in mobile processes
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
We present the fusion calculus as a significant step towards a canonical calculus of concurrency. It simplifies and extends the /spl pi/-calculus. The fusion calculus contains the polyadic /spl pi/-calculus as a proper subcalculus and thus inherits all its expressive power. The gain is that fusion contains actions akin to updating a shared state, and a scoping construct for bounding their effects. Therefore it is easier to represent computational models such as concurrent constraints formalisms. It is also easy to represent the so called strong reduction strategies in the /spl lambda/-calculus, involving reduction under abstraction. In the /spl lambda/-calculus these tasks require elaborate encodings. Our results on the fusion calculus in this paper are the following. We give a structured operational semantics in the traditional style. The novelty lies in a new kind of action, fusion actions for emulating updates of a shared state. We prove that the calculus contains the /spl pi/-calculus as a subcalculus. We define and motivate the bisimulation equivalence and prove a simple characterization of its induced congruence, which is given two versions of a complete axiomatization for finite terms. The expressive power of the calculus is demonstrated by giving a straight-forward encoding of the strong lazy /spl lambda/-calculus, which admits reduction under /spl lambda/ abstraction.
[Costs, Computational modeling, Input variables, concurrent constraints, calculus of concurrency, fusion calculus, Calculus, Encoding, polyadic /spl pi/-calculus, Concurrent computing, fusion, calculus of communicating systems, /spl pi/-calculus, lazy /spl lambda/-calculus, reduction strategies, /spl lambda/-calculus]
A theory of recursive domains with applications to concurrency
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
We develop a 2-categorical theory for recursively defined domains. In particular we generalise the traditional approach based on order-theoretic structures to category-theoretic ones. A motivation for this development is the need of a domain theory for concurrency, with an account of bisimulation. Indeed, the leading examples throughout the paper are provided by recursively defined presheaf models for concurrent process calculi. Further we use the framework to study (open-map) bisimulation.
[bisimulation, Costs, Logic programming, recursively defined domains, 2-categorical theory, recursive domains theory, concurrent process calculi, Equations, Concurrent computing, Computer languages, order-theoretic structures, Pressing, category theory, Assembly, recursively defined presheaf models]
Invertibility in /spl lambda//spl eta/
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
This paper investigates invertibility properties of subjective and bijective terms in the closed term model of /spl lambda//spl eta/. With the help of insolvable terms, it will be shown that some special subjective terms are right-invertible and that all bijective terms are invertible.
[bijective, lambda calculus, subjective, Time of arrival estimation, /spl lambda/ calculus, Calculus, Encoding, Decoding, insolvable terms, Equations, invertibility properties]
Logic and over-simplification
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
The author looks at the development of BAN logic, and with hindsight, considers the oversimplifications that were made.
[Shape, Logic programming, Scattering, Calculus, Cryptographic protocols, formal logic, Body sensor networks, oversimplifications, BAN logic, Authentication, Computer errors, Bones, Computer networks, logic]
The Horn mu-calculus
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
The Horn /spl mu/-calculus is a logic programming language allowing arbitrary nesting of least and greatest fixed points. The Horn /spl mu/-programs can naturally express safety and liveness properties for reactive systems. We extend the set-based analysis of classical logic programs by mapping arbitrary /spl mu/-programs into "uniform" /spl mu/-programs. Our two main results are that uniform /spl mu/-programs express regular sets of trees and that emptiness for uniform /spl mu/-programs is EXPTIME-complete. Hence we have a nontrivial decidable relaxation for the Horn /spl mu/-calculus. In a different reading, the results express a kind of robustness of the notion of regularity: alternating Rabin tree automata preserve the same expressiveness and algorithmic complexity if we extend them with pushdown transition rules (in the same way Buchi extended word automata to canonical systems).
[Logic programming, reactive systems, alternating Rabin tree automata, liveness, EXPTIME-complete, robustness, Electronic switching systems, pushdown transition rules, algorithmic complexity, arbitrary nesting, logic programming language, Automata, safety, logic programming, Horn /spl mu/-calculus, nontrivial decidable relaxation, Informatics, Testing]
Secure implementation of channel abstractions
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Communication in distributed systems often relies on useful abstractions such as channels, remote procedure calls, and remote method invocations. The implementations of these abstractions sometimes provide security properties, in particular through encryption. In this paper we study those security properties, focusing on channel abstractions. We introduce a simple high-level language that includes constructs for creating and using secure channels. The language is a variant of the join-calculus and belongs to the same family as the pi-calculus. We show how to translate the high-level language into a lower-level language that includes cryptographic primitives. In this translation, we map communication on secure channels to encrypted communication on public channels. We obtain a correctness theorem for our translation; this theorem implies that one can reason about programs in the high-level language without mentioning the subtle cryptographic protocols used in their lower-level implementation.
[Art, cryptographic protocols, pi-calculus, cryptographic primitives, cryptography, security properties, Communication system security, High level languages, channel abstractions, Cryptographic protocols, correctness theorem, Network servers, Operating systems, encryption, Communication system operations and management, remote method invocations, remote procedure calls, Robustness, Cryptography, join-calculus]
On the boundedness problem for two-variable first-order logic
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
A positive first-order formula is bounded if the sequence of its stages converges to the least fixed point of the formula within a fixed finite number of steps independent of the input structure. The boundedness problem for a fragment C of first-order logic is the following decision problem: given a positive formula in L, is it bounded? In this paper, we investigate the boundedness problem for two-variable first-order logic FO/sup 2/. As a general rule, FO/sup 2/ is a well-behaved fragment of first-order logic, since it possesses the finite-model property and has a decidable satisfiability problem. Nonetheless, our main result asserts that the boundedness problem for FO/sup 2/ is undecidable, even when restricted to negation-free and equality-free formulas /spl phi/(X, x) in which x is the only free variable and X is a monadic relation symbol that occurs within the scopes of universal quantifiers only. This undecidability result contrasts sharply with earlier results asserting the decidability of boundedness for monadic Datalog programs, which amounts to the decidability of boundedness for negation-free and equality-free existential first-order formulas /spl psi/(X, x) in which x is the only free variable and X is a monadic relation symbol. We demonstrate that our main result has certain applications to circumscription, the most well-developed formalism of nonmonotonic reasoning. Specifically, using the undecidability of boundedness for FO/sup 2/, we show that it is an undecidable problem to tell whether the circumscription of a given FO/sup 2/-formula is equivalent to a first-order formula. In contrast, the circumscription of every FO/sup 1/-formula is equivalent to a first-order formula.
[finite-model property, decidable satisfiability problem, circumscription, Vocabulary, decision problem, positive first-order formula, equality-free formulas, two-variable first-order logic, monadic Datalog programs, Computational complexity, nonmonotonic reasoning, Computer science, decidability, monadic relation symbol, Logic, boundedness, boundedness problem]
Bisimulation in name-passing calculi without matching
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
We study barbed equivalence in name-passing languages where there is no matching construct for testing equality between names. We concentrate on the /spl pi/-calculus with capability types and subtypes, of which the untyped /spl pi/-calculus without matching is a special case. We give a coinductive characterisation of typed barbed equivalence, and present "bisimulation up-to" techniques to enhance the resulting coinductive proof method. We then use these techniques to prove some process equalities that fail in the ordinary /spl pi/-calculus.
[Heart, barbed equivalence, Object oriented modeling, process equalities, coinductive characterisation, Remuneration, subtypes, Couplings, typed barbed equivalence, Computer languages, process algebra, /spl pi/-calculus, name-passing languages, capability types, Carbon capture and storage, Protection, equality, Testing]
Light affine logic
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Much effort has been recently devoted to the study of polytime formal (and especially logical) systems. The purpose of such systems is manyfold. On the theoretical side, they provide a better understanding of what is the logical essence of polytime reduction (and other complexity classes). On the practical side, via the well known Curry-Howard correspondence, they yield sophisticated typing systems, where types provide (statically) an accurate upper bound on the complexity of the computation. Even more, the type annotations give essential information on the "efficient way" to reduce the term. The most promising of these logical systems is Girard's light linear logic. In this paper, we introduce a slight variation of LLL, by adding full weakening (for this reason, we call it light affine logic). This modification does not alter the good complexity properties of LLL: cut-elimination is still polytime. On the other side, the logical system is much simpler: we reduce it from 21 to just 11 rules, and with simpler, traditional sequents. Rephrasing Girard, we could thus say that the abuse of contraction may have damaging complexity effects, but the abstinence from weakening leads to inessential syntactical complications.
[light affine logic, complexity, complexity classes, upper bound, Explosions, Encoding, Girard's light linear logic, Curry-Howard correspondence, Concrete, polytime formal systems, typing systems, Logic, computational complexity]
An axiomatics for categories of transition systems as coalgebras
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
We consider a finitely branching transition system as a coalgebra for an endofunctor on the category Set of small sets. A map in that category is a functional bisimulation. So, we study the structure of the category of finitely branching transition systems and functional bisimulations by proving general results about the category H-Coalg of H-coalgebras for an endofunctor H on Set. We give conditions under which H-Coalg is complete, cocomplete, symmetric monoidal closed, regular, and has a subobject classifier.
[coalgebra, Logic programming, Laboratories, category H-Coalg, Mathematics, Jacobian matrices, Computer languages, finitely branching, process algebra, Automata, transition system, functional bisimulation, subobject classifier, symmetric monoidal]
Calculus in coinductive form
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Coinduction is often seen as a way of implementing infinite objects. Since real numbers are typical infinite objects, it may not come as a surprise that calculus, when presented in a suitable way, is permeated by coinductive reasoning. What is surprising is that mathematical techniques, recently developed in the context of computer science, seem to be shedding a new light on some basic methods of calculus. We introduce a coinductive formalization of elementary calculus that can be used as a tool for symbolic computation, and geared towards computer algebra and theorem proving. So far, we have covered parts of ordinary differential and difference equations, Taylor series, Laplace transform and the basics of the operator calculus.
[Laplace equations, Taylor series, symbolic computation, Calculus, calculus, coinduction, Computer science, Algebra, process algebra, Integral equations, Tail, computer algebra, theorem proving]
Coinductive techniques for operational equivalence of interaction nets
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
In this paper we study a notion of operational equivalence for interaction nets, following the recent success of applying methods based on bisimulation to functional and object oriented programming languages. We set up notions of contextual equivalence and bisimilarity and show that they coincide. A coinduction principle then gives a simple and robust way of showing when two interaction nets are contextually equivalent. We include several examples to demonstrate the usefulness of the approach, in particular for optimizing interaction nets.
[bisimulation, object-oriented programming, operational equivalence, Computational modeling, object oriented programming languages, Electrical capacitance tomography, coinductive techniques, Equations, bisimilarity, Computer languages, contextual equivalence, interaction nets, functional languages]
Recursive types in games: axiomatics and process representation
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
This paper presents two basic results on game-based semantics of FPC, a metalanguage with sums, products, exponentials and recursive types. First we give an axiomatic account of the category of games G, offering a fundamental structural analysis of the category as well as a transparent way to prove computational adequacy. As a consequence we obtain an intensional full-abstraction result through a standard definability argument. Next we extend the category G by introducing a category of games G/sub i/ with optimised strategies; we show that the denotational semantics in G/sub i/ gives a compilation of FPC terms into core Pict codes (the asynchronous polyadic /spl pi/-calculus without summation). The process representation follows a pioneering idea of Hyland and Ong (1995). However we advance their representation by introducing semantically well-founded optimisation techniques; we also extend the setting to encompass the rich type structure of FPC. The resulting code gives basic insight on the relationship between the abstract, categorical, types and their possible implementations.
[process representation, Flexible printed circuits, Logic programming, recursive types, abstract data types, type structure, Reasoning about programs, Calculus, Electrical capacitance tomography, Game theory, Hip, definability argument, Computer languages, axiomatics, game-based semantics, /spl pi/-calculus, FPC]
Completeness of type assignment systems with intersection, union, and type quantifiers
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
This paper develops type assignment systems for intersection and union types, and type quantifiers. The known system for these types is not semantically complete. We introduce a certain class of typing statements, called stable statements, which include all statements without type quantifiers, and we show that the known system is complete for stable statements if we add two axiom schemas expressing the distributive laws of intersection over union and existential quantifier, respectively. All the results are obtained in a systematic way with sequent calculi for type assignment and the cut-elimination for them.
[formal logic, typing statements, intersection, type quantifiers, stable statements, sequent calculi, union, Logic, axiom schemas, type assignment systems]
Convergence results for relational Bayesian networks
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Relational Bayesian networks are an extension of the method of probabilistic model construction by Bayesian networks. They define probability distributions on finite relational structures by conditioning the probability of a ground atom r(a/sub 1/, ..., a/sub n/) on first-order properties of a/sub 1/, ..., a/sub n/ that have been established by previous random decisions. In this paper we investigate from a finite model theory perspective the convergence properties of the distributions defined in this manner. A subclass of relational Bayesian networks is identified that define distributions with convergence laws for first-order properties.
[finite relational structures, Probability distribution, Distributed computing, Convergence, Fault diagnosis, convergence laws, Intelligent networks, Bayesian methods, probability distributions, relational Bayesian networks, Computer networks, Random variables, Bayes methods, Bayesian networks, Computational intelligence, Monitoring]
Efficient representation and validation of proofs
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
This paper presents a logical framework derived from the Edinburgh Logical Framework (LF) that can be used to obtain compact representations of proofs and efficient proof checkers. These are essential ingredients of any application that manipulates proofs as first-class objects, such as a Proof-Carrying Code system, in which proofs are used to support easy validation of properties of safety-critical or untrusted code. Our framework, which we call LF/sub i/, inherits from LF the capability to encode various logics in a natural way. In addition, the LF/sub i/ framework allows proof representations without the high degree of redundancy that is characteristic of LF representations. The missing parts of LF/sub i/ proof representations can be reconstructed during proof checking by an efficient reconstruction algorithm. We also describe an algorithm that can be used to strip the unnecessary parts of an LF representation of a proof. The experimental data that we gathered in the context of a Proof-Carrying Code system shows that the savings obtained from using LF/sub i/ instead of LF can make the difference between practically useless proofs of several megabytes and manageable proofs of tens of kilobytes.
[Strips, Government, proof checkers, Reconstruction algorithms, first-class objects, Edinburgh Logical Framework, Operating systems, Computer bugs, proofs, compact representations, proof representations, Safety, System software, theorem proving, Logic, Contracts, Software engineering]
On counting logics and local properties
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
The expressive power of first-order logic over finite structures is limited in two ways: it lacks a recursion mechanism, and it cannot count. Overcoming the first limitation has been a subject of extensive study. A number of fixpoint logics have been introduced, and shown to be subsumed by an infinitary logic L/sub /spl infin//spl omega///sup /spl omega//. This logic is easier to analyze than fixpoint logics, and it still lacks counting power, as it has a 0-1 law. On the counting side, there is no analog of L/sub /spl infin//spl omega///sup /spl omega//. There are a number of logics with counting power, usually introduced via generalized quantifiers. Most known expressivity bounds are based on the fact that counting extensions of first-order logic preserve the locality properties. This paper has three main goals. First, we introduce a new logic L/sub /spl infin//spl omega//*(C) that plays the same role for counting as L/sub /spl infin//spl omega///sup /spl omega// does for recursion-it subsumes a number of extensions of first-order logic with counting, and has nice properties that make it easy to study. Second, we give a simple direct proof that L/sub /spl infin//spl omega//*(C) expresses only local properties: those that depend on the properties of small neighborhoods, but cannot grasp a structure as a whole. This is a general way of saying that a logic lacks a recursion mechanism. Third, we consider a finer analysis of locality of counting logics. In particular, we address the question of how local a logic is, that is, how big are those neighborhoods that local properties depend on. We get a uniform answer for a variety of logics between first-order and L/sub /spl infin//spl omega//*(C). This is done by introducing a new form of locality that captures the tightest condition that the duplicator needs to maintain in order to win a game. We use this technique to give bounds on outputs of L/sub /spl infin//spl omega//*(C)-definable queries. We also specialize some of the results for structures of small degree.
[0-1 law, Computational modeling, finite structures, fixpoint logics, first-order logic, recursion mechanism, locality properties, Database languages, expressive power, Counting circuits, formal logic, Aggregates, Collaboration, generalized quantifiers, Logic, infinitary logic]
A congruence theorem for structured operational semantics of higher-order languages
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
In this paper we describe the promoted tyft/tyxt rule format for defining higher-order languages. The rule format is a generalization of Groote and Vaandrager's tyft/tyxt format in which terms are allowed as labels on transitions in rules. We prove that bisimulation is a congruence for any language defined in promoted tyft/tyxt format and demonstrate the usefulness of the rule format by presenting promoted tyft/tyxt definitions for the lazy /spl lambda/-calculus, CHOCS and the /spl pi/-calculus.
[bisimulation, formal languages, higher-order languages, CHOCS, congruence, Information systems, tyft/tyxt rule format, Computer science, Computer languages, Algebra, lazy /spl lambda/-calculus, /spl pi/-calculus, Functional programming, Testing]
A stability theorem in rewriting theory
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
One key property of the /spl lambda/-calculus is that there exists a minimal computation (the head-reduction) M/spl rarr//sup e/V from a /spl lambda/-term M to the set of its head-normal forms. Minimality here means categorical "reflectivity" i.e. that every reduction path M/spl rarr//sup f/W to a head-normal form W factors (up to redex permutation) to a path M/spl rarr//sup e/V/spl rarr//sup h/W. This paper establishes a stability a la Berry or poly-reflectivity theorem [D, La, T] which extends the minimality property to rewriting systems with critical pairs. The theorem is proved in the setting of axiomatic rewriting systems where sets of head-normal forms are characterised by their frontier property in the spirit of J. Glauert and Z. Khasidashvili (1996).
[rewriting systems, Stability, Computational modeling, rewriting theory, minimal computation, Petri nets, stability theorem, Calculus, poly-reflectivity theorem, Computer science, head-normal forms, Turing machines, axiomatic rewriting systems, reduction path, Concrete, Carbon capture and storage, minimality]
Compositional analysis of expected delays in networks of probabilistic I/O automata
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Probabilistic I/O automata (PIOA) constitute a model for distributed or concurrent systems that incorporates a notion of probabilistic choice. The PIOA model provides a notion of composition, for constructing a PIOA for a composite system from a collection of PIOAs representing the components. We present a method for computing completion probability and expected completion time for PIOAs. Our method is compositional, in the sense that it can be applied to a system of PIOAs, one component at a time, without ever calculating the global state space of the system (i.e. the composite PIOA). The method is based on symbolic calculations with vectors and matrices of rational functions, and it draws upon a theory of observables, which are mappings from delayed traces to real numbers that generalize the classical "formal power series" from algebra and combinatorics. Central to the theory is a notion of representation for an observable, which generalizes the classical notion "linear representation" for formal power series. As in the classical case, the representable observables coincide with an abstractly defined class of "rational" observables; this fact forms the foundation of our method.
[linear representation, Government, Interconnected systems, symbolic calculations, State-space methods, Electronic mail, global state space, formal power series, Delay, Computer science, Intelligent networks, probabilistic automata, completion probability, vectors, Algebra, rational functions, Automata, concurrent systems, probabilistic I/O automata, Timing, matrices]
Higher dimensional multigraphs
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
We introduce the notion of higher dimensional multigraph. This notion extends that of multigraph, which underlies multicategories and is essentially equivalent to the notion of context-free grammar. We develop the definition and explain how it gives a semantically coherent category theoretic approach to the notion of higher order context-free grammar. It also gives a conceptual framework in which one can study rewrites, and rewrites of rewrites, etcetera, for proofs of sequent calculus. The definition involves a subtle interaction between geometry and linearly defined syntax; we explore the latter here, outlining the geometric intuition.
[sequent calculus, Logic programming, rewrites, Calculus, category theoretic, Statistics, Machinery, context-free grammar, Computer science, Geometry, Computer languages, Tensile stress, Algebra, higher dimensional multigraph, multicategories, geometric intuition, context-free grammars, Robustness]
Existential second-order logic over strings
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Existential second-order logic (ESO) and monadic second-order logic (MSO) have attracted much interest in logic and computer science. ESO is a much more expressive logic over word structures than MSO. However, little was known about the relationship between MSO and syntactic fragments of ESO. We shed light on this issue by completely characterizing this relationship for the prefix classes of ESO over strings, (i.e., finite word structures). Moreover, we determine the complexity of model checking over strings, for all ESO-prefix classes. We also give a precise characterization of those ESO-prefix classes which are equivalent to MSO over strings, and of the ESO-prefix classes which are closed under complementation on strings.
[ESO, complexity, equivalent, monadic, Complexity theory, expressive logic, ESO-prefix classes, Computer science, formal logic, existential, model checking, finite word structures, Automata, second-order logic, complementation on strings, Logic]
L.E.J. Brouwer's intuitionism: a revolution in two installments
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
There are two main periods in Brouwer's foundational activities. The first one is covered by the dissertation of 1907 and subsequent papers. The second one starts in 1918 with the introduction of choice sequences. Both periods have their own specific characteristics. The first period is less mature, with a stronger critical component, the second is more the scholarly presentation of a program and its consequences. In this paper we will try to sketch the development of ideas and notions in both period and the technical realization of the foundational aspects. An extensive treatment of the topics of this paper will be published in a volume on "History and philosophical significance of proof theory".
[Drilling, formal logic, Art, Biographies, Humans, intuitionism, Mathematics, technical realization, Rivers, History, choice sequences, Fellows]
Linear vs. branching time: a complexity-theoretic perspective
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
The discussion of the relative merits of linear versus branching time frameworks goes back to early 1980s. One of the beliefs dominating this discussion has been that "while specifying is easier in LTL (linear-temporal logic), verification is easier for CTL (branching-temporal logic)". Indeed, the restricted syntax of CTL limits its expressive power and many important behaviours (e.g., strong fairness) can not be specified in CTL. On the other hand, while model checking for CTL can be done in time that is linear in the size of the specification, it takes time that is exponential in the specification for LTL. A closer examination of the the issue reveals, however, that the computational superiority of the branching time framework is perhaps illusory. In this talk we will compare the complexity of branching-time verification vs. Linear-time verification in many scenarios, and show that linear-time verification is not harder and often is even easier than branching-time verification. This suggests that the tradeoff between branching and linear time is not a simple tradeoff between complexity and expressiveness.
[complexity, branching-time verification, linear-time verification, LTL, temporal logic, Uniform resource locators, linear-temporal logic, Boolean functions, branching-temporal logic, Ear, expressiveness, CTL, Logic]
On model checking for non-deterministic infinite-state systems
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
We demonstrate that many known algorithms for model checking infinite-state systems can be derived uniformly from a reachability procedure that generates a "covering graph\
[Protocols, Computational modeling, Petri nets, Explosions, State-space methods, infinite-state systems, covering graph, decidability, model checking, reachability procedure, Automata, Communication channels, Broadcasting, Safety, Token networks, safety properties, cache coherency protocol]
The logical role of the four-valued bilattice
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
In his well-known paper "How computer should think" (1977) Belnap argues that four-valued semantics is a very suitable setting for computerized reasoning. In this paper we vindicate this thesis by showing that the logical role that the four-valued structure has among Ginsberg's well-known bilattices is similar to the role that the two-valued algebra has among Boolean algebras.
[Heart, four-valued bilattice, four-valued semantics, Lattices, Multivalued logic, computerized reasoning, Boolean algebra, Application software, Computer science, bilattices, multivalued logic, Logic functions, Artificial intelligence]
Fragments of existential second-order logic without 0-1 laws
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
We prove that there is a Monadic /spl Sigma//sub 1//sup 1/ (Minimal Scott without equality) sentence without an asymptotic probability. Our result entails that the 0-1 law fails for the logics /spl Sigma//sub 1//sup 1/(FO/sup 2/) and /spl Sigma//sub 1//sup 1/ (Minimal Godel without equality). Therefore we achieve the classification of first-order prefix classes with or without equality. According to the existence of the 0-1 law for the corresponding /spl Sigma//sub 1//sup 1/ fragment. In addition, our counterexample can be viewed as a single explanation of the failure of the 0-1 law of all the fragments of existential second-order logic for which the failure is already known.
[formal logic, Vocabulary, Minimal Godel, Minimal Scott, Logic, existential second-order logic, 0-1 laws, Bars]
Linear logic with boxes
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Interaction nets provide a graphical paradigm of computation based on net rewriting. By encoding the cut-elimination process of linear logic they have proved successful in understanding the dynamics of reduction in the /spl lambda/-calculus. G. Gonthier et al. (1992) gave an optimal infinite system of interaction nets for linear logic by removing the global boxes. However efficient implementations of optimal reduction have had to break away from the interaction net paradigm. Here we give an efficient new finite interaction net encoding of linear logic which is not optimal, but overcomes many of the inefficiencies caused by the bookkeeping operations in the implementations of optimal reduction. We code the global operations on boxes (contraction, weakening, dereliction, commutative cut) in a local way, keeping the box structure, which results in a system allowing a great deal of sharing with an extremely low overhead. We believe that this implementation is the most faithful of all the extant interaction net encodings of linear logic.
[boxes, cut-elimination process, lambda calculus, finite interaction net encoding, linear logic, Lamps, net rewriting, Encoding, Application software, Read only memory, Computer science, Geometry, formal logic, optimal infinite system, Ear, interaction nets, Computational efficiency, Logic, bookkeeping operations]
A fully abstract game semantics for general references
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
A games model of a programming language with higher-order store in the style of ML-references is introduced. The category used for the model is obtained by relaxing certain behavioural conditions on a category of games previously used to provide fully abstract models of pure functional languages. The model is shown to be fully abstract by means of factorization arguments which reduce the question of definability for the language with higher-order store to that for its purely functional fragment.
[higher-order store, fully abstract, game theory, games model, Educational institutions, Calculus, ML-references, Computer languages, factorization arguments, Prototypes, programming language, category, Joining processes]
Realizability for constructive theory of functions and classes and its application to program synthesis
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
This paper gives a q-realizability interpretation for Feferman's constructive theory T/sub 0/ of functions and classes by using a set completion program without doubling variables, and proves its soundness. This result solves an open problem proposed by Feferman in 1979. Moreover by using this interpretation we can prove a program extraction theorem for T/sub 0/, which enables us to use constructive sets of T/sub 0/ for program synthesis.
[program extraction theorem, programming theory, set completion program, q-realizability interpretation, constructive theory, program synthesis, Programming theory]
A logical characterization of bisimulation for labeled Markov processes
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
This paper gives a logical characterization of probabilistic bisimulation for Markov processes. Bisimulation can be characterized by a very weak modal logic. The most striking feature is that one has no negation or any kind of negative proposition. Bisimulation can be characterized by several inequivalent logics; we report five in this paper and there are surely many more. We do not need any finite branching assumption yet there is no need of infinitely conjunction. We give an algorithm for deciding bisimilarity of finite state systems which constructs a formula that witnesses the failure of bisimulation.
[bisimulation, labeled Markov processes, Educational institutions, Continuous time systems, State-space methods, Tellurium, probabilistic bisimulation, Computer science, formal logic, logical characterization, inequivalent logics, Markov processes, finite state systems, Logic]
Ordering finite variable types with generalized quantifiers
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Let Q be a finite set of generalized quantifiers. By L/sup k/(Q) we denote the k-variable fragment of FO(Q), first order logic extended with Q. We show that for each k, there is a PFP(Q)-definable linear pre-order whose equivalence classes in any finite structure 21 are the L/sup k/(Q)-types in 21. For some special classes of generalized quantifiers Q, we show that such an ordering of L/sup k/(Q)-types is already definable in IFP(Q). As applications of the above results, we prove some generalizations of the Abiteboul-Vianu theorem. For instance, we show that for any finite set Q of modular counting quantifiers, P=PSPACE if, and only if, IFP(Q)=PFP(Q) over finite structures. On the other hand, we show that an ordering of L/sup k/(Q)-types is not always definable in IFP(Q). Indeed, we construct a single, polynomial time computable quantifier P such that the equivalence relation /spl equiv//sup k,P/, and hence ordering on L/sup k/(P)-types, is not definable in IFP(P).
[Vocabulary, polynomial time computable, generalizations, generalized quantifiers, Relational databases, Polynomials, Mathematics, equivalence relation, Logic, equivalence classes, finite variable types, finite structure]
Process operations in extended dynamic logic
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Modal logic becomes action logic by adding programs as in propositional dynamic logic or the /spl mu/-calculus. Modal languages can be seen as decidable fragments of first-order logic that admit a natural bisimulation, and hence enjoy a good model theory. Recently, much stronger 'guarded fragments' of first-order logic have been identified that enjoy the same pleasant features. The latter can serve as richer action languages as well. We will develop the logic of guarded fragments as a form of process theory. In particular, moving from sequential to parallel process operations correlates with moving to first-order fragments that are close to, or perhaps just over the decidable-undecidable fence.
[Scattering, decidable fragments, first-order logic, Logic design, natural bisimulation, process operations, modal logic, guarded fragments, process theory, Logic testing, formal logic, Interpolation, Transformers, extended dynamic logic, action logic]
Freedom, weakness, and determinism: from linear-time to branching-time
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Model checking is a method for the verification of systems with respect to their specifications. Symbolic model-checking, which enables the verification of large systems, proceeds by calculating fixed-point expressions over the system's set of states. The /spl mu/-calculus is a branching-time temporal logic with fixed-point operators. As such, it is a convenient logic for symbolic model-checking tools. In particular, the alternation-free fragment of /spl mu/-calculus has a restricted syntax, making the symbolic evaluation of its formulas computationally easy. Formally, it takes time that is linear in the size of the system. On the other hand, specifiers find the /spl mu/-calculus inconvenient. In addition, specifiers often prefer to use Linear-time formalisms. Such formalisms, however, cannot in general be translated to the alternation-free CL-calculus, and their symbolic evaluation involves nesting of fixed-points, resulting in time complexity that is quadratic in the size of the system. In this paper we characterize linear-time properties that can be specified in the alternation-free /spl mu/-calculus. We show that a linear-time property can be specified in the alternation-free /spl mu/-calculus if it can be recognized by a deterministic Buchi automation. We study the problem of deciding whether a linear-time property, specified by either an automaton or an LTL formula, can be translated to an alternation-free /spl mu/-calculus formula, and describe the translation, when exists.
[System testing, model-checking, Engineering profession, symbolic evaluation, temporal logic, time complexity, /spl mu/-calculus, deterministic Buchi automation, Uniform resource locators, Software design, alternation-free fragment, Automata, symbolic model-checking, Hardware, Error correction, Logic, Mathematical model, Contracts, branching-time]
Completeness of a relational calculus for program schemes
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
The relational calculus MU/sub 2/, presented in de Roever's dissertation as a framework for describing and proving properties of programs, was conjectured by David Park to be complete. In this paper we confirm Park's conjecture.
[Computational modeling, relational algebra, program schemes, Calculus, Boolean algebra, completeness, MU/sub 2/, relational calculus]
Embedded finite models, stability theory, and the impact of order
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
We extend bounds on the expressive power of first-order logic over finite structures and over ordered finite structures, by generalizing to the situation where the finite structures are embedded in an infinite structure M, where M satisfies some simple combinatorial properties studied in model-theoretic stability theory. We first consider first-order logic over finite structures embedded in a stable structure, and show that it has the same generic expressive power as first-order logic on unordered finite structures. It follows from this that having the additional structure of, for example, an abelian group or an equivalence relation, does not allow one to define any new generic queries. We also consider first-order logic over finite structures living within any model M that lacks the independence property and show that its expressive power is bounded by first-order logic over finite ordered structures. This latter result gives an enormous class of structures in which the expressive power of first-order logic is sharply limited; it shows that common queries such as parity and connectivity cannot be defined for finite structures living within structures from this huge class. It also gives a pure combinatorial property of an interpreted structure M that is sufficient to extend results on first-order logic on ordered structures to first-order logic on finite structures embedded in M.
[independence property, ordered finite structures, Stability, finite structures, embedded finite models, first-order logic, parity, abelian group, model-theoretic stability theory, Mathematics, expressive power, unordered finite structures, formal logic, combinatorial property, stability theory, connectivity, Machine learning, bounds, equivalence relation, Logic, Mathematical model]
Herbrand's theorem, automated reasoning and semantic tableaux
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
We overview recent results related to Herbrand's theorem and tableau-like methods of automated deduction and prove some new results. Based on an analysis and discussion of these results, new research directions are suggested.
[Boolean functions, tableau-like methods, Terminology, automated reasoning, automated deduction, Data structures, Logic, inference mechanisms, Computational complexity, Herbrand's theorem, semantic tableaux]
Monadic logic and automata: recent developments
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
This tutorial surveys selected recent results on the connection between monadic second-order logic and finite automata. As a unifying idea, the role of automata as normal forms of monadic formulas is pursued. In the first part we start from an automata-theoretic interpretation of existential monadic second-order formulas and in this framework explain the monadic quantifier alternation hierarchy over finite graphs. In the second part, infinite models, in particular /spl omega/-words, are considered. We analyze the logical significance of central constructions in /spl omega/-automata theory and sketch new proofs of decidability results in monadic second-order logic.
[finite automata, monadic formulas, State-space methods, Tree graphs, Automata, second-order logic, /spl omega/-automata theory, infinite models, decidability results, finite graphs, /spl omega/-words, Logic, Kernel, Context modeling]
The relation between second-order unification and simultaneous rigid E-unification
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
Simultaneous rigid E-unification, or SREU for short, is a fundamental problem that arises in global methods of automated theorem proving in classical logic with equality. In order to do proof search in intuitionistic logic with equality one has to handle SREU as well. Furthermore, restricted forms of SREU are strongly related to word equations and finite tree automata. It was recently shown that second-order unification has a very natural reduction to simultaneous rigid E-unification, which constituted probably the most transparent undecidability proof of SREU. Here we show that there is also a natural encoding of SREU in second-order unification. It follows that the problems are logspace equivalent. So second-order unification plays the same fundamental role as SREU in automated reasoning in logic with equality. We exploit this connection and use finite tree automata techniques to present a very elementary undecidability proof of second-order unification, by reduction from the halting problem for Turing machines. It follows from that proof that second-order unification is undecidable for all nonmonadic second-order term languages having at least two second-order variables with sufficiently high arities.
[undecidability proof, finite tree automata, simultaneous rigid E-unification, intuitionistic logic, proof search, halting problem, Encoding, Decision feedback equalizers, Equations, second-order unification, word equations, Turing machines, natural encoding, nonmonadic second-order term languages, Automata, automated theorem proving, Polynomials, Skeleton, theorem proving, Logic, equality, classical logic]
Phase semantics and verification of concurrent constraint programs
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
The class CC of concurrent constraint programming languages and its non-monotonic extension LCC based on linear constraint systems can be given a logical semantics in Girard's intuitionistic linear logic for a variety of observables. In this paper we settle basic completeness results and we show how the phase semantics of linear logic can be used to provide simple and very concise "semantical" proofs of safety properties for GC or LCC programs.
[Protocols, concurrent constraint programming languages, Logic programming, Computational modeling, intuitionistic linear logic, logical semantics, Linear programming, Search problems, Calculus, linear constraint systems, completeness results, Concurrent computing, Computer languages, phase semantics, non-monotonic extension, logic programming, Safety, safety properties, Propagation delay]
Decision problems in ordered rewriting
Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science
None
1998
A term rewrite system (TRS) terminates if its rules are contained in a reduction ordering >. In order to deal with any set of equations, including inherently non-terminating ones (like commutativity), TRS have been generalised to ordered TRS (E, >), where equations of E are applied in whatever direction agrees with >. The confluence of terminating TRS is well-known to be decidable, but for ordered TRS the decidability of confluence has been open. Here we show that the confluence of ordered TRS is decidable if ordering constraints for > can be solved in an adequate way, which holds in particular for the class of LPO orderings. For sets E of constrained equations, confluence is shown to be undecidable. Finally, ground reducibility is proved undecidable for ordered TRS.
[Logic programming, decidability, confluence, ordered rewriting, reduction ordering, commutativity, ground reducibility, Large scale integration, term rewrite system, decision problems, Equations, ordering constraints]
Reasoning about common knowledge with infinitely many agents
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
Complete axiomatizations and exponential-time decision procedures are provided for reasoning about knowledge and common knowledge when there are infinitely many agents. The results show that reasoning about knowledge and common knowledge with infinitely many agents is no harder than when there are finitely many agents, provided that we can check the cardinality of certain set differences G G' where G and G' are sets of agents. Since our complexity results are independent of the cardinality of the sets G involved, they represent improvements over the previous results even with the sets of agents involved are finite. Moreover, our results make clear the extent to which issues of complexity and completeness depend on how the sets of agents involved are represented.
[complexity, finitely many agents, complexity results, reasoning, Mathematics, infinitely many agents, completeness, Application software, inference mechanisms, Game theory, Distributed computing, Tellurium, cardinality, set differences, Computer science, common knowledge, complete axiomatizations, exponential-time decision procedures, Software agents, Internet, US Department of Defense, Artificial intelligence, computational complexity]
Cartesian closed double categories, their lambda-notation, and the pi-calculus
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We introduce the notion of cartesian closed double category to provide mobile calculi for communicating systems with specific semantic models: One dimension is dedicated to compose systems and the other to compose their computations and their observations. Also, inspired by the connection between simply typed /spl lambda/-calculus and cartesian closed categories, we define a new typed framework, called double /spl lambda/-notation, which is able to express the abstraction/application and pairing/projection operations in all dimensions. In this development, we take the categorical presentation as a guidance in the interpretation of the formalism. A case study of the /spl pi/-calculus, where the double /spl lambda/-notation straightforwardly handles name passing and creation, concludes the presentation.
[lambda calculus, mobile calculi, lambda-notation, pi-calculus, typed /spl lambda/-calculus, Mobile communication, type theory, Topology, semantic models, name passing, cartesian closed double categories, Computer science, Algebra, typed framework, Tiles, Interactive systems, /spl pi/-calculus, Telephony, cartesian closed categories, communicating systems, Logic]
Proving security protocols correct
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
Security protocols use cryptography to set up private communication channels on an insecure network. Many protocols contain flaws, and because security goals are seldom specified in detail, we cannot be certain what constitutes a flaw. Thanks to recent work by a number of researchers, security protocols can now be analyzed formally. The paper outlines the problem area, emphasizing the notion of freshness. It describes how a protocol can be specified using operational semantics and properties proved by rule induction, with machine support from the proof tool Isabelle. The main example compares two versions of the Yahalom protocol. Unless the model of the environment is sufficiently detailed, it cannot distinguish the correct protocol from a flawed version. The paper attempts to draw some general lessons on the use of formalisms. Compared with model checking, the inductive method performs a finer analysis, but the cost of using it is greater.
[Costs, telecommunication channels, Laboratories, operational semantics, Independent component analysis, cryptography, Security, Cryptographic protocols, rule induction, security protocols, model checking, proof tool Isabelle, machine support, Communication channels, Computer networks, Performance analysis, theorem proving, Cryptography, protocols, Web server, private communication channels, Yahalom protocol]
Full completeness of the multiplicative linear logic of Chu spaces
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We prove full completeness of multiplicative linear logic (MLL) without MIX under the Chu interpretation. In particular we show that the cut-free proofs of MLL theorems are in a natural bijection with the binary logical transformations of the corresponding operations on the category of Chu spaces on a two-letter alphabet.
[binary logical transformations, cut-free proofs, Humans, Calculus, Electrical capacitance tomography, formal logic, full completeness, Chu spaces, two-letter alphabet, theorem proving, Logic, multiplicative linear logic, natural bijection]
Region analysis and the polymorphic lambda calculus
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We show how to translate the region calculus of M. Tofte and J.P. Talpin (1997), a typed lambda calculus that can statically delimit the lifetimes of objects, into an extension of the polymorphic lambda calculus called F/sub #/. We give a denotational semantics of F/sub #/, and use it to give a simple and abstract proof of the correctness of memory deallocation.
[region calculus, lambda calculus, region analysis, polymorphic lambda calculus, Calculus, type theory, Electrical capacitance tomography, programming language semantics, Computer languages, typed lambda calculus, Memory management, memory deallocation correctness, denotational semantics]
Plausibility measures and default reasoning: an overview
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We introduce a new approach to modeling uncertainty based on plausibility measures. This approach is easily seen to generalize other approaches to modeling uncertainty, such as probability measures, belief functions, and possibility measures. We then consider one application of plausibility measures: default reasoning. In recent years, a number of different semantics for defaults have been proposed, such as preferential structures, /spl epsiv/-semantics, possibilistic structures, and /spl kappa/-rankings, that have been shown to be characterized by the same set of axioms, known as the KLM properties. While this was viewed as a surprise, we show here that it is almost inevitable. In the framework of plausibility measures, we can give a necessary condition for the KLM axioms to be sound, and an additional condition necessary and sufficient to ensure that the KLM axioms are complete. This additional condition is so weak that it is almost always met whenever the axioms are sound. In particular, it is easily seen to hold for all the proposals made in the literature. Finally, we show that plausibility measures provide an appropriate basis for examining first-order default logics.
[belief functions, default reasoning, first-order default logics, Extraterrestrial measurements, Birds, semantics, Proposals, uncertainty, nonmonotonic reasoning, Computer science, formal logic, plausibility measures, Possibility theory, Algebra, Logic, possibility measures, Contracts]
Counting and addition cannot express deterministic transitive closure
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
An important open question in complexity theory is whether the circuit complexity class TC/sup 0/ is (strictly) weaker than LOGSPACE. This paper considers this question from the viewpoint of descriptive complexity theory. TC/sup 0/ can be characterized as the class of queries expressible by the logic FOC(<, +, /spl times/), which is first-order logic augmented by counting quantifiers on ordered structures that have addition and multiplication predicates. We show that in first-order logic with counting quantifiers and only an addition predicate it is not possible to express "deterministic transitive closure" on ordered structures. As this is a LOGSPACE-complete problem, this logic therefore fails to capture LOGSPACE. It also directly follows from our proof that in the presence of counting quantifiers, multiplication cannot be expressed in terms of addition and ordering alone.
[circuit complexity, complexity theory, Laboratories, circuit complexity class, LOGSPACE, first-order logic, LOGSPACE-complete problem, Complexity theory, Read only memory, Computer science, formal logic, Logic circuits, descriptive complexity theory, ordered structures, Polynomials, quantifiers, deterministic transitive closure]
On the expressive power of CTL
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We show that the expressive power of the branching time logic CTL coincides with that of the class of bisimulation invariant properties expressible in so-called monadic path logic: monadic second order logic in which set quantification is restricted to paths. In order to prove this result, we first prove a new composition theorem for trees. This approach is adapted from the approach of Hafer and Thomas in their proof that CTL coincides with the whole of monadic path logic over the class of full binary trees.
[monadic path logic, trees (mathematics), temporal logic, branching time logic CTL, Game theory, composition theorem, trees, Read only memory, expressive power, set quantification, full binary trees, Binary trees, Software systems, Hardware, CTL, bisimulation equivalence, monadic second order logic, Logic, bisimulation invariant properties]
Paramodulation with non-monotonic orderings
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
All current completeness results for ordered paramodulation require the term ordering > to be well-founded, monotonic and total(izable) on ground terms. Here we introduce a new proof technique where the only properties required for > are well foundedness and the subterm property: The technique is a relatively simple and elegant application of some fundamental results on the termination and confluence of ground term rewrite systems (TRS). By a careful further analysis of our technique, we obtain the first Knuth-Bendix completion procedure that finds a convergent TRS for a given set of equations E and a (possibly non-totalizable) reduction ordering p whenever it exists. Note that being a reduction ordering is the minimal possible requirement on >, since a TRS terminates if, and only if, it is contained in a reduction ordering.
[termination, rewriting systems, Logic programming, confluence, ground term rewrite systems, Large scale integration, Mathematics, completeness results, subterm property, Electrical capacitance tomography, proof technique, Equations, nonmonotonic reasoning, Postal services, nonmonotonic orderings, paramodulation, Constraint theory, Knuth-Bendix completion procedure, theorem proving]
First-order logic vs. fixed-point logic in finite set theory
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
The ordered conjecture states that least fixed-point logic LFP is strictly more expressive than first-order logic FO on every infinite class of ordered finite structures. It has been established that either way of settling this conjecture would resolve open problems in complexity theory. In fact, this holds true even for the particular instance of the ordered conjecture on the class of BIT-structures, that is, ordered finite structures with a built-in BIT predicate. Using a well known isomorphism from the natural numbers to the hereditarily finite sets that maps BIT to the membership relation between sets, the ordered conjecture on BIT-structures can be translated to the problem of comparing the expressive power of FO and LFP in the context of finite set theory. The advantage of this approach is that we can use set-theoretic concepts and methods to identify certain fragments of LFP for which the restriction of the ordered conjecture is already hard to settle, as well as other restricted fragments of LFP that actually collapse to FO. These results advance the state of knowledge about the ordered conjecture on BIT-structures and contribute to the delineation of the boundary where this conjecture becomes hard to settle.
[ordered conjecture, complexity theory, Vocabulary, finite set theory, ordered finite structures, least fixed-point logic, first-order logic, fixed-point logic, set theory, Read only memory, Tellurium, Computer science, formal logic, Sufficient conditions, BIT-structures, Set theory, Logic, Marine vehicles, computational complexity]
A fragment calculus-towards a model of separate compilation, linking and binary compatibility
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We propose a calculus describing compilation and linking in terms of operations on fragments, i.e. compilation units, without reference to their specific contents. We believe this calculus faithfully reflects the situation within modern programming systems. Binary compatibility in Java prescribes conditions under which modification of fragments does not necessitate recompilation of importing fragments. We apply our calculus to formalize binary compatibility, and demonstrate that several interpretations of the language specification are possible, each with different ramifications. We choose a particular interpretation, justify our choice, formulate and prove properties important for language designers and code library developers.
[Java, binary compatibility, linking, Educational institutions, Calculus, Electrical capacitance tomography, Security, program compilers, process algebra, separate compilation, fragment calculus, Libraries, Joining processes]
Proof techniques for cryptographic processes
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
Contextual equivalences for cryptographic process calculi can be used to reason about correctness of protocols, but their definition suffers from quantification over all possible contexts. Here, we focus on two such equivalences, may-testing and barbed equivalence, and investigate tractable proof methods for them. To this aim, we develop an 'environment-sensitive' labelled transition system, where transitions are constrained by the knowledge the environment has of names and keys. On top of the new transition system, a trace equivalence and a co-inductive weak bisimulation equivalence are defined, both of which avoid quantification over contexts. Our main results are soundness of trace semantics and of weak bisimulation with respect to may-testing and barbed equivalence, respectively. This leads to more direct proof methods for equivalence checking. The use of such methods is illustrated via a few examples concerning implementation of secure channels by means of encrypted public channels. We also consider a variant of the labelled transition system that gives completeness, but is less handy to use.
[barbed equivalence, trace semantics, equivalences, cryptography, Electronic switching systems, Calculus, Cryptographic protocols, may-testing, tractable proof methods, process algebra, bisimulation equivalence, trace equivalence, Cryptography, process calculi, cryptographic, weak bisimulation]
On Hoare logic and Kleene algebra with tests
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We show that Kleene algebra with tests subsumes propositional Hoare logic. Thus the specialized syntax and deductive apparatus of Hoare logic are inessential and can be replaced by simple equational reasoning. We show using this reduction that propositional Hoare logic is PSPACE-complete.
[Logic programming, Kleene algebra, PSPACE-complete, Encoding, equational reasoning, Logic testing, Equations, Computer science, formal logic, Algebra, Logic functions, syntax, Page description languages, Dynamic programming, Principal component analysis, Hoare logic]
Logics with aggregate operators
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We study adding aggregate operators, such as summing up elements of a column of a relation, to logics with counting mechanisms. The primary motivation comes from database applications, where aggregate operators are present in all real life query languages. Unlike other features of query languages, aggregates are not adequately captured by the existing logical formalisms. Consequently, all previous approaches to analyzing the expressive power of aggregation were only capable of producing partial results, depending on the allowed class of aggregate and arithmetic operations. We consider a powerful counting logic, and extend it with the set of all aggregate operators. We show that the resulting logic satisfies analogs of Hanf's and Gaifman's theorems, meaning that it can only express local properties. We consider a database query language that expresses all the standard aggregates found in commercial query languages, and show how it can be translated into the aggregate logic, thereby providing a number of expressivity bounds, that do not depend on a particular class of arithmetic functions, and that subsume all those previously known. We consider a restricted aggregate logic that gives us a tighter capture of database languages, end also use it to show that some questions on expressivity of aggregation cannot be answered without resolving some deep problems in complexity theory.
[Relational databases, query languages, Mathematics, Complexity theory, arithmetic functions, Database languages, formal logic, arithmetic operations, counting mechanisms, Logic, expressivity bounds, complexity theory, database languages, local properties, real life query languages, Spatial databases, Application software, aggregate operators, Computer science, Aggregates, counting logic, database query language, restricted aggregate logic, aggregate logic, commercial query languages, Arithmetic, computational complexity]
Logics with counting, auxiliary relations, and lower bounds for invariant queries
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We study the expressive power of counting logics in the presence of auxiliary relations such as orders and pre-orders. The simplest such logic, first-order with counting, captures the complexity class TC/sup 0/ over ordered structures. We also consider first-order logic with arbitrary unary quantifiers, and infinitary extensions. The main result of the paper is that all the counting logics above, in the presence of pre-orders that are almost-everywhere linear orders, exhibit a very tame behavior normally associated with first-order properties of unordered structures. This is in sharp contrast with the expressiveness of these logics in the presence of linear orders: such a tame behavior is not the case even for first-order logic with counting, and the most powerful logic we consider can express every property of ordered structures. The results attest to the difficulty of proving separation results for the ordered case, in particular, to proving the separation of TC from NP. To prove the main results, we use locality techniques from finite-model theory, modifying the main notions of locality along the way.
[locality techniques, invariant queries, Circuits, Laboratories, complexity class, first-order logic, finite-model theory, Encoding, Complexity theory, Database languages, lower bounds, Sorting, formal logic, Turing machines, Neural networks, logics with counting, unary quantifiers, auxiliary relations, ordered structures, Polynomials, Logic, computational complexity]
On the verification of broadcast protocols
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We analyze the model-checking problems for safety and liveness properties in parameterized broadcast protocols. We show that the procedure suggested previously for safety properties may not terminate, whereas termination is guaranteed for the procedure based on upward closed sets. We show that the model-checking problem for liveness properties is undecidable. In fact, even the problem of deciding if a broadcast protocol may exhibit an infinite behavior is undecidable.
[Protocols, Petri nets, Electronic mail, Application software, Tellurium, Postal services, Computer science, formal logic, Upper bound, decidability, formal verification, upward closed sets, model-checking problem, liveness properties, safety, Broadcasting, Safety, model-checking problems, protocols, broadcast protocols verification]
Towards a theory of bisimulation for local names
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
A.M. Pitts and I.D.B. Stark (1998) have proposed the v-calculus as a language for investigating the interaction of unique name generation and higher-order functions. They developed a sound model based on logical relations, but left completeness as an open problem. In this paper, we develop a complete model based on bisimulation for a labelled transition system semantics. We show that bisimulation is complete, but not sound, for the v-calculus. We also show that by adding assignment to the v-calculus, bisimulation becomes sound and complete. The analysis used to obtain this result illuminates the difficulties involved in finding fully abstract models for v-calculus proper.
[bisimulation, formal languages, unique name generation, v-calculus, local names, higher-order functions, labelled transition system semantics, Electronic switching systems, completeness, fully abstract models, Privacy, Employment, Mobile agents, bisimulation theory, Communication channels, bisimulation equivalence, Cryptography, Testing]
A new approach to abstract syntax involving binders
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
The Fraenkel-Mostowski permutation model of set theory with atoms (FM-sets) can serve as the semantic basis of meta-logics for specifying and reasoning about formal systems involving name binding, /spl alpha/-conversion, capture avoiding substitution, and so on. We show that in FM-set theory one can express statements quantifying over 'fresh' names and we use this to give a novel set-theoretic interpretation of name abstraction. Inductively defined FM-sets involving this name abstraction set former (together with cartesian product and disjoint union) can correctly encode object-level syntax module e-conversion. In this way, the standard theory of algebraic data types can be extended to encompass signatures involving binding operators. In particular, there is an associated notion of structural recursion for defining syntax-manipulating functions (such as capture avoiding substitution, set of free variables, etc.) and a notion of proof by structural induction, both of which remain pleasingly close to informal practice.
[Algorithm design and analysis, algebraic data types, formal languages, meta-logics, name binding, Laboratories, binders, Fraenkel-Mostowski permutation model, reasoning, formal systems, set theory, Proposals, inference mechanisms, Machinery, formal logic, abstract syntax, Reactive power, Computer languages, object-level syntax module, Set theory, Concrete, capture avoiding substitution, FM-sets, /spl alpha/-conversion]
Type inference for recursive definitions
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We consider type systems that combine universal types, recursive types, and object types. We study type inference in these systems under a rank restriction, following Leivant's notion of rank. To motivate our work, we present several examples showing how our systems can be used to type programs encountered in practice. We show that type inference in the rank-k system is decidable for k/spl les/2 and undecidable for k/spl ges/3. (Similar results based on different techniques are known to hold for System F, without recursive types and object types.) Our undecidability result is obtained by a reduction from a particular adaptation (which we call "regular") of the semi-unification problem and whose undecidability is, interestingly, obtained by methods totally different from those used in the case of standard (or finite) semi-unification.
[Java, lambda calculus, decidable, Calculus, type theory, recursive functions, Electrical capacitance tomography, Read only memory, Tellurium, type systems, undecidability, Radio access networks, Information analysis, Computer science, Computer languages, decidability, recursive definitions, type inference]
Elementary axioms for categories of classes
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We axiomatize a notion of "classic structure" on a regular category, isolating the essential properties of the category of classes together with its full subcategory of sets. Like the axioms for a topos, our axiomatization is very simple, but has powerful consequences. In particular, we show that our axiomatized categories provide a sound and complete class of models for intuitionistic Zermelo-Fraenkel set theory.
[regular category, axiomatization, intuitionistic Zermelo-Fraenkel set theory, formal languages, Pulleys, Buildings, Mathematics, Electrical capacitance tomography, set theory, Equations, topos, Computer science, Geometry, classic structure, axioms, Set theory, category theory, categories of classes, Logic, Informatics, elementary axioms]
Linear types and non-size-increasing polynomial time computation
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We propose a linear type system with recursion operators for inductive datatypes which ensures that all definable functions are polynomial time computable. The system improves upon previous such systems in that recursive definitions can be arbitrarily nested, in particular no predicativity or modality restrictions are made.
[Law, recursion operators, polynomial time computation, Data structures, type theory, recursive functions, Electrical capacitance tomography, definable functions, Runtime, polynomial time computable, linear type system, Polynomials, inductive datatypes, Logic, recursive definitions, Legal factors]
Parikh's theorem in commutative Kleene algebra
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
Parikh's theorem says that, the commutative image of every context free language is the commutative image of some regular set. Pilling has shown that this theorem is essentially a statement about least solutions of polynomial inequalities. We prove the following general theorem of commutative Kleene algebra, of which Parikh's and Pilling's theorems are special cases: Every finite system of polynomial inequalities f/sub i/(x/sub 1/,...,x/sub n/)/spl les/x/sub i/, 1/spl les/i/spl les/n, over a commutative Kleene algebra K has a unique least solution in K/sup n/; moreover, the components of the solution are given by polynomials in the coefficients of the f/sub i/. We also give a closed-form solution in terms of the Jacobian matrix of the system.
[polynomial inequalities, Adaptive systems, polynomials, Parikh's theorem, context free language, closed-form solution, Tellurium, Computer science, Jacobian matrices, formal logic, finite system, Jacobian matrix, Algebra, context-free languages, commutative image, unique least solution, Polynomials, commutative Kleene algebra]
Weak bounded arithmetic, the Diffie-Hellman problem and Constable's Class K
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
The bounded arithmetic theory C/sub 2//sup 0/, which is closely related to the complexity class DLogTime-uniform TC/sup 0/, is extended by a function symbol and axioms for integer division, which is not known to be in DLogTime-uniform TC/sup 0/. About this extended theory C/sub 2//sup 0/[div], two main results are proved: (1). The Z/sub 1//sup b/-definable functions of C/sub 2//sup 0/[div] are exactly Constable's class K, a function algebra whose precise complexity-theoretic nature is yet to be determined. This also yields the new upper bound K/spl sube/uniform NC/sup 2/. (2). The /spl Delta//sub 1//sup b/-theorems C/sub 2//sup 0/[div] do not have Craig-interpolants of polynomial circuit size, unless the Diffie-Hellman key exchange protocol is insecure.
[Diffie-Hellman key exchange protocol, cryptography, upper bound, Diffie-Hellman problem, complexity class DLogTime-uniform TC/sup 0/, complexity-theoretic nature, weak bounded arithmetic, integer division, axioms, function algebra, polynomial circuit size, function symbol, Constable's Class K, protocols, Artificial intelligence, Arithmetic, computational complexity]
Pattern matching as cut elimination
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We present a typed pattern calculus with explicit pattern matching and explicit substitutions, where both the typing rules and the reduction rules are modeled on the same logical proof system, namely Gentzen sequent calculus for minimal logic. Our calculus is inspired by the Curry-Howard isomorphism, in the sense that types, both for patterns and terms, correspond to propositions, terms correspond to proofs, and term reduction corresponds to sequent proof normalization performed by cut elimination. The calculus enjoys subject reduction, confluence, preservation of strong normalization w.r.t. a system with meta-level substitutions and strong normalization for well-typed terms. As a consequence, it can be seen as an implementation calculus for functional formalisms defined with meta-level operations for pattern matching and substitutions.
[sequent proof normalization, pattern matching, confluence, cut elimination, Calculus, type theory, Electrical capacitance tomography, typing rules, reduction rules, substitutions, term reduction, typed pattern calculus, theorem proving, Logic, Functional programming, Network address translation, Embedded computing, meta-level substitutions, Computational modeling, Gentzen sequent calculus, Encoding, Curry-Howard isomorphism, strong normalization, logical proof system, meta-level operations, minimal logic, Pattern matching]
Subtyping recursive types in kernel Fun
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
The problem of defining and checking a subtype relation between recursive types was studied in Armadio and Cardelli (1993) for a first order type system, but for second order systems, which combine subtyping and parametric polymorphism, only negative results are known. This paper studies the problem of subtype checking for recursive types in system kernel Fun, a typed /spl lambda/-calculus with subtyping and bounded second order polymorphism. Along the lines of Armadio and Cardelli (1993), we study the definition of a subtype relation over kernel Fun recursive types, and then we present a subtyping algorithm which is sound and complete with respect to this relation. We show that the natural extension of the techniques introduced in Armadio and Cardelli (1993) to compare first order recursive types gives a non complete algorithm. We prove the completeness and correctness of a different algorithm, which also admits an efficient implementation.
[Java, lambda calculus, correctness, typed lambda-calculus, recursive types, recursive functions, completeness, Programming profession, first order recursive types, Character generation, Open systems, kernel Fun, Kernel]
A superposition decision procedure for the guarded fragment with equality
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We give a new decision procedure for the guarded fragment with equality. The procedure is based on resolution with superposition. We argue that this method will be more useful in practice than methods based on the enumeration of certain finite structures. It is surprising to see that one does not need any sophisticated simplification and redundancy elimination method to make superposition terminate on the class of clauses that is obtained from the clausification of guarded formulas. Yet the decision procedure obtained is optimal with regard to time complexity. We also show that the method can be extended to the loosely guarded fragment with equality.
[TV, decision theory, finite structures, time complexity, Decision feedback equalizers, guarded formulas, Equations, formal logic, guarded fragment, superposition decision procedure, Logic, equality, computational complexity]
Parametric quantitative temporal reasoning
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We define Parameterized Real-Time Computation Tree Logic (PRTCTL), which allows quantitative temporal specifications to be parameterized over the natural numbers. Parameterized quantitative specifications are quantitative specifications in which concrete timing information has been abstracted away. Such abstraction allows designers to specify quantitative restrictions on the temporal ordering of events without having to use specific timing information from the model. A model checking algorithm for the logic is given which is polynomial for any fixed number of parameters. A subclass of formulae are identified for which the model checking problem is linear in the length of the formula and size of the structure. PRTCTL is generalised to allow quantitative reasoning about the number of occurrences of atomic events.
[Atomic measurements, Process design, parametric quantitative temporal reasoning, quantitative temporal specifications, Delay effects, polynomials, timing, atomic events, temporal logic, Time measurement, formal specification, quantitative reasoning, temporal reasoning, parameterized real-time computation tree logic, model checking algorithm, polynomial, Concrete, Polynomials, temporal ordering, Timing, Logic, Contracts]
The two-variable guarded fragment with transitive relations
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We consider the restriction of the guarded fragment to the two-variable case where, in addition, binary relations may be specified as transitive. We show that (i) this very restricted form of the guarded fragment without equality is undecidable and that (ii) when allowing non-unary relations to occur only in guards, the logic becomes decidable. The latter subclass of the guarded fragments the one that occurs naturally when translating multi-modal logics of the type Kg/sub 4/ S/sub 4/ or S5 into first-order logic. We also show that the loosely guarded fragment without equality and with a single transitive relation is undecidable.
[formal logic, multi-modal logics, decidability, first-order logic, Logic, transitive relations, binary relations, two-variable guarded fragment]
On bunched predicate logic
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We present the logic of bunched implications, BI, in which a multiplicative (or linear) and an additive (or intuitionistic) implication live side-by-side. The propositional version of BI arises from an analysis of the proof-theoretic relationship between conjunction and implication, and may be viewed as a merging of intuitionistic logic and multiplicative, intuitionistic linear logic. The predicate version of BI includes, in addition to usual additive quantifiers, multiplicative (or intensional) quantifiers /spl forall//sub new/, and /spl exist//sub new/, which arise from observing restrictions on structural rules on the level of terms as well as propositions. Moreover, these restrictions naturally allow the distinction between additive predication and multiplicative predication for each propositional connective. We provide a natural deduction system, a sequent calculus, a Kripke semantics and a BHK semantics for BI. We mention computational interpretations, based on locality and sharing, at both the propositional and predicate levels. We explain BI's relationship with intuitionistic logic, linear logic and other relevant logics.
[sequent calculus, BHK semantics, Costs, additive predication, Merging, BI, intuitionistic logic, Calculus, propositional connective, History, formal logic, natural deduction system, bunched predicate logic, Bismuth, Logic, bunched implications, multiplicative predication, Kripke semantics]
Two-variable descriptions of regularity
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We prove that the class of all languages that are definable in /spl Sigma//sub 1//sup 1/(FO/sup 2/), that is, in (non-monadic) existential second-order logic with only two first-order variables, coincides with the regular languages. This provides an alternative logical description of regularity to both the traditional one in terms of monadic second-order logic, due to Buchi and Trakhtenbrot, and the more recent ones in terms of prefix fragments of /spl Sigma//sub 1//sup 1/, due to Eiter, Gottlob and Gurevich. Our result extends to more general settings than words. Indeed, definability in /spl Sigma//sub 1//sup 1/(FO/sup 2/) coincides with recognizability by appropriate notions of automata on a large class of objects, including /spl omega/-words, trees, pictures and, more generally, all weakly deterministic, triangle-free transition systems.
[Vocabulary, formal languages, automata theory, regular languages, prefix fragments, definability, triangle-free transition systems, Electrical capacitance tomography, regularity, trees, pictures, formal logic, Tree graphs, two-variable descriptions, Automata, first-order variables, monadic second-order logic, /spl omega/-words, Logic, automata, existential second-order logic]
The higher-order recursive path ordering
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
This paper extends the termination proof techniques based on reduction orderings to a higher-order setting, by adapting the recursive path ordering definition to terms of a typed lambda-calculus generated by a signature of polymorphic higher-order function symbols. The obtained ordering is well-founded, compatible with p-reductions and with polymorphic typing, monotonic with respect to the function symbols, and stable under substitution. It can therefore be used to prove the strong normalization property of higher-order calculi in which constants can be defined by higher-order rewrite rules. For example, the polymorphic version of Godel's recursor for the natural numbers is easily oriented. And indeed, our ordering is polymorphic, in the sense that a single comparison allows to prove the termination property of all monomorphic instances of a polymorphic rewrite rule. Several other non-trivial examples are given which exemplify the expressive power of the ordering.
[lambda calculus, rewriting systems, termination proof techniques, Logic programming, typed lambda-calculus, Design methodology, reduction orderings, Godel's recursor, Large scale integration, type theory, higher-order rewrite rules, higher-order setting, higher-order calculi, formal verification, polymorphic typing, function symbols, theorem proving, monomorphic instances, Functional programming, termination property, Pattern matching, higher-order recursive path ordering, polymorphic higher-order function symbols]
Working with arms: Complexity results on atomic representations of Herbrand models
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
An Atomic Representation of a Herbrand Model (ARM) is a finite set of (not necessarily ground) atoms over a given Herbrand universe. Each ARM represents a possibly infinite Herbrand interpretation. This concept has emerged independently in different branches of Computer Science as a natural and useful generalization of the concept of finite Herbrand interpretation. It was shown that several recursively decidable problems on finite Herbrand models (or interpretations) remain decidable on ARMs. The following problems are essential when working with ARMs: Deciding the equivalence of two ARMs, deciding subsumption between ARMS, and evaluating clauses over ARMS. These problems were shown to be decidable, but their computational complexity has remained obscure so far. The previously published decision algorithms require exponential space. In spite of this, by developing new decision procedures, we are able to prove that all mentioned problems are coNP-complete.
[Logic programming, recursively decidable problems, complexity results, Tellurium, Read only memory, atomic representations, Radio access networks, decidability, Herbrand models, knowledge representation, logic programming, coNP-complete, theorem proving, Arm, Herbrand universe, computational complexity]
Modular temporal logic
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
D. Therien and T. Wilke (1996) characterized the Until hierarchy of linear temporal logic in terms of aperiodic monoids. Here, a temporal operator able to count modulo q is introduced. Temporal logic augmented with such operators is found decidable as it is shown to express precisely the solvable regular languages. Natural hierarchies are shown to arise when modular and conventional operators are interleaved. Modular operators are then cast as special cases of more general "group" temporal operators which, added to temporal logic, allow capturing any regular language L in much the same way that the syntactic monoid of L is constructed from groups and aperiodic monoids in the sense of Krohn-Rhodes.
[temporal operators, formal languages, Buildings, regular languages, Formal languages, temporal logic, linear temporal logic, Until hierarchy, regular language, Counting circuits, Computer science, group theory, syntactic monoid, decidability, Logic, modular temporal logic, aperiodic monoids]
Full abstraction and universality via realisability
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We construct fully abstract realisability models of PCF. In particular, we prove a variant of the Longley-Phoa Conjecture by showing that the realisability model over an untyped /spl lambda/-calculus with arithmetic is fully abstract for PCF. Further we consider the extension of our results to a general sequential functional programming language SFPL giving rise to universal realisability models for SFPL.
[lambda calculus, Computational modeling, abstract realisability, untyped /spl lambda/calculus, Calculus, Equations, Computer languages, PCF, sequential functional programming language, /spl lambda/-calculus, Functional programming, Principal component analysis, Arithmetic, Context modeling]
Guarded fixed point logic
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
Guarded fixed point logics are obtained by adding least and greatest fixed points to the guarded fragments of first-order logic that were recently introduced by H. Andreka et al. (1998). Guarded fixed point logics can also be viewed as the natural common extensions of the modal p-calculus and the guarded fragments. We prove that the satisfiability problems for guarded fixed point logics are decidable and complete for deterministic double exponential time. For guarded fixed point sentences of bounded width, the most important case for applications, the satisfiability problem is EXPTIME-complete.
[decidable, fixed points, first-order logic, deterministic double exponential time, Automatic logic units, Knowledge representation, modal p-calculus, computability, guarded fixed point logic, EXPTIME-complete, Application software, guarded fragments, Logic testing, Computer science, formal logic, Databases, satisfiability problems, Software systems, Hardware, natural common extensions, Artificial intelligence, bounded width, computational complexity]
Abstract syntax and variable binding
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We develop a theory of abstract syntax with variable binding. To every binding signature we associate a category of models consisting of variable sets endowed with compatible algebra and substitution structures. The syntax generated by the signature is the initial model. This gives a notion of initial algebra semantics encompassing the traditional one; besides compositionality, it automatically verifies the semantic substitution lemma.
[category of models, variable binding, Proposals, semantic substitution lemma, abstract syntax, Computer languages, Algebra, Tree graphs, process algebra, Integral equations, Production, Concrete, Logic, Carbon capture and storage, compatible algebra, initial algebra semantics, substitution structures]
Some decision problems of enormous complexity
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We present some new decision and comparison problems of unusually high computational complexity. Most of the problems are strictly combinatorial in nature; others involve basic logical notions. Their complexities range from iterated exponential time completeness to /spl isin//sub 0/ time completeness to /spl theta/(/spl Omega//sup /spl omega//,0) time completeness to /spl theta/(/spl Omega//sub /spl omega//,0) time completeness. These three ordinals are well known ordinals from proof theory, and their associated complexity classes represent new levels of computational complexity for natural decision problems. Proofs will appear in an extended version of this manuscript to be published elsewhere.
[natural decision problems, Terminology, decision theory, logical notions, Formal languages, Mathematics, iterated exponential time completeness, Computational complexity, proof theory, Turing machines, Polynomials, decision problems, computational complexity]
Extensional equality in intensional type theory
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We present a new approach to introducing an extensional propositional equality in Intensional Type Theory. Our construction is based on the observation that there is a sound, intensional setoid model in Intensional Type theory with a proof-irrelevant universe of propositions and /spl eta/-rules for /spl Pi/and /spl Sigma/-types. The Type Theory corresponding to this model is decidable, has no irreducible constants and permits large eliminations, which are essential for universes.
[decidable, decidability, extensional propositional equality, proof-irrelevant universe, Tin, type theory, Electrical capacitance tomography, Informatics, intensional type theory, Network address translation]
Some computational properties of intersection types
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
This paper presents a new method for comparing computation-properties of /spl lambda/-terms typeable with intersection types with respect to terms typeable with Curry types. In particular, strong normalization and /spl lambda/-definability are investigated. A translation is introduced from intersection typing derivations to Curry typeable terms; the main feature of the proposed technique is that the translation is preserved by /spl beta/-reduction. This allows to simulate a computation starting from a term typeable in the intersection discipline by means of a computation starting from a simply typeable term. Our approach naturally leads to prove strong normalization in the intersection system by means of purely syntactical techniques. In addition, the presented method enables us to give a proof of a conjecture proposed by Leivant in 1990, namely that all functions uniformly definable using intersection types are already definable using Curry types.
[intersection types, lambda calculus, Curry types, lambda-definability, Calculus, Electrical capacitance tomography, Remuneration, Read only memory, lambda-terms, strong normalization]
Semantical analysis of higher-order abstract syntax
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
A functor category semantics for higher-order abstract syntax is proposed with the following aims: relating higher order and first order syntax, justifying induction principles, suggesting new logical principles to reason about higher-order syntax.
[Reactive power, Computer languages, formal languages, semantical analysis, first order syntax, higher-order abstract syntax, semantic networks, Calculus, Encoding, functor category semantics, induction principles, logical principles]
A fully abstract game semantics for finite nondeterminism
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
A game semantics of finite nondeterminism is proposed. In this model, a strategy may make a choice between different moves in a given situation; moreover, strategies carry extra information about their possible divergent behaviour. A Cartesian closed category is built and a model of a simple, higher-order nondeterministic imperative language is given. This model is shown to be fully abstract, with respect to an equivalence based on both safety and liveness properties, by means of a factorization theorem which states that every nondeterministic strategy is the composite of a deterministic strategy with a nondeterministic oracle.
[Cartesian closed category, formal languages, equivalence, game theory, Educational institutions, game semantics, deterministic strategy, Yarn, Tellurium, Physics, Concurrent computing, Computer languages, Operating systems, liveness properties, safety, category theory, finite nondeterminism, nondeterministic oracle, equivalence classes]
Weak bisimulation and open maps
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
A systematic treatment of weak bisimulation and observational congruence on presheaf models is presented. The theory is developed with respect to a "hiding" functor from a category of paths to observable paths. Via a view of processes as bundles, we are able to account for weak morphisms (roughly only required to preserve observable paths) and to derive a saturation monad (on the category of presheaves over the category of paths). Weak morphisms may be encoded as strong ones via the Kleisli construction associated to the saturation monad. A general notion of weak open-map bisimulation is introduced, and results relating various notions of strong and weak bisimulation are provided. The abstract theory is accompanied by fine concrete study of two key models for concurrency, the interleaving model of synchronisation trees and the independence model of labelled event structures.
[observational congruence, presheaf models, Laboratories, saturation monad, Read only memory, Concurrent computing, abstract theory, observable paths, synchronisation trees, Concrete, bisimulation equivalence, tree data structures, Kleisli construction, open maps, weak bisimulation, labelled event structures]
Concurrent games and full completeness
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
A new concurrent form of game semantics is introduced. This overcomes the problems which had arisen with previous, sequential forms of game semantics in modelling Linear Logic. It also admits an elegant and robust formalization. A Full Completeness Theorem for Multiplicative-Additive Linear Logic is proved for this semantics.
[Polarization, Logic programming, completeness theorem, Computational modeling, linear logic, concurrent, concurrency theory, Electronic switching systems, game semantics, Computer science, Concurrent computing, Geometry, formal logic, Computer languages, Ear, Informatics]
Non-deterministic games and program analysis: An application to security
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We present a unifying framework for using game semantics as a basis for program analysis. Also, we present a case study of the techniques. The unifying framework presents games-based program analysis as an abstract interpretation of an appropriate games category in the category of non-deterministic games. The case study concerns an application to security.
[programming theory, Data security, program diagnostics, game theory, Educational institutions, game semantics, games category, security, security of data, Information security, Ear, Tail, program analysis]
Correctness of multiplicative proof nets is linear
Proceedings. 14th Symposium on Logic in Computer Science
None
1999
We reformulate Danos contractibility criterion in terms of a sort of unification. As for term unification, a direct implementation of the unification criterion leads to a quasi-linear algorithm. Linearity is obtained after observing that the disjoint-set union-find at the core of the unification criterion is a special case of union-find with a real linear time solution.
[term unification, Danos contractibility, Switches, Inspection, Educational institutions, Electrical capacitance tomography, Remuneration, unification, Computer science, formal logic, multiplicative proof nets, Tree graphs, Linearity, Ear, disjoint-set union-find, theorem proving, Logic]
Logic, complexity, and games
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
Summary form only given. The author summarizes his proposed talk on an approach to the P = NP question via the correspondence between logic and complexity. The main focus will be on the possible use of Ehrenfeucht-Fra-sse games.
[Polynomials, Complexity theory, Logic, Computational complexity, Game theory]
More past glories [temporal logic]
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We continue in the same vein as O. Lichtenstein et al. (1985) in "The Glory of the Past\
[automata based temporal reasoning, rewriting systems, syntactic rewrites, past connectives, automata theory, past formulas, temporal logic, temporal formulas, set theory, programming language semantics, normal form, Machinery, temporal reasoning, Computer science, complete axiomatization, Veins, computer science, Automata, PCTL*, past-time operators, Safety, Logic]
A decision procedure for term algebras with queues
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
In software verification, it is often required to prove statements about heterogeneous domains containing elements of various sorts, such as counters, stacks, lists, trees and queues. Any domain with counters, stacks, lists, and trees (but not queues) can be easily seen as a special case of the term algebra, and hence a decision procedure for term algebras can be applied to decide the first-order theory of such a domain. We present a quantifier-elimination procedure for the first-order theory of term algebras extended with queues. The complete axiomatization and decidability of this theory can be immediately derived from the procedure.
[Protocols, decision theory, program verification, software verification, Electrical capacitance tomography, statement proving, trees, Counting circuits, Algebra, decidability, Hardware, theorem proving, Logic, queueing theory, counters, first-order theory, stacks, term algebras, heterogeneous domains, quantifier-elimination procedure, Computer science, complete axiomatization, decision procedure, lists, System recovery, Queueing analysis]
A static calculus of dependencies for the /spl lambda/-cube
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
Dependency analysis aims at identifying how different parts of a program depend on each other. It is the kernel of many issues in program analysis such as dead-code, binding time, strictness, program slicing etc. We address the problem of dependency analysis in the context of typed /spl lambda/-calculus. We consider all systems of the /spl lambda/-cube and extend them conservatively by the addition of new typing rules in order to determine which parts of a /spl lambda/-term may contribute to its evaluation. We show how typing information can be used to statically identify dependencies.
[static calculus, typing information, lambda calculus, dependency analysis, lambda cube, Buildings, Interference, typed /spl lambda/-calculus, Calculus, type theory, typing rules, Data mining, dead-code, dependencies, Connectors, binding time, program analysis, system monitoring, strictness, Performance analysis, Logic, /spl lambda/-cube, program slicing, /spl lambda/-term]
Imperative programming with dependent types
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
The article enriches imperative programming with a form of dependent types. We start by explaining some motivations for this enrichment and mentioning some major obstacles that need to be overcome. We then present the design of a source level dependently typed imperative programming language Xanadu, forming both static and dynamic semantics and then establishing the type soundness theorem. We also present realistic examples, which have all been verified in a prototype implementation, in support of the practicality of Xanadu. We claim that the language design of Xanadu is novel and it serves as an informative example that demonstrates a means to combine imperative programming with dependent types.
[realistic examples, Natural languages, dynamic semantics, high level languages, dependent types, type theory, type soundness theorem, Proposals, programming language semantics, language design, program compilers, Programming profession, source level dependently typed imperative programming language, Computer languages, Runtime, prototype implementation, Prototypes, Xanadu, Dynamic programming, Functional programming, Pattern matching, Assembly, informative example]
A modality for recursion
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We propose a modal logic that enables us to handle self-referential formulae, including ones with negative self-references, which on one hand, would introduce a logical contradiction, namely Russell's paradox, in the conventional setting, while on the other hand, are necessary to capture a certain class of programs such as fixed point combinators and objects with so-called binary methods in object oriented programming. Our logic provides a basis for axiomatic semantics of such a wider range of programs and a new framework for natural construction of recursive programs in the proofs-as-programs paradigm.
[natural construction, proofs-as-programs paradigm, Logic programming, fixed point combinators, Data structures, type theory, Electronic mail, negative self-references, programming language semantics, modal logic, Convergence, formal logic, recursive programs, self-referential formulae, axiomatic semantics, theorem proving, binary methods, object oriented programming, Network address translation, recursion, logical contradiction]
Probabilistic game semantics
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
A category of HO/N-style games and probabilistic strategies is developed where the possible choices of a strategy are quantified so as to give a measure of the likelihood of seeing a given play. A 2-sided die is shown to be universal in this category, in the sense that any strategy breaks down into a composition between some deterministic strategy and that die. The interpretative power of the category is then demonstrated by delineating a Cartesian closed subcategory which provides a fully abstract model of a probabilistic extension of Idealized Algol.
[probabilistic game semantics, Uncertainty, probability, fully abstract model, game theory, Cartesian closed subcategory, interpretative power, Idealized Algol, programming language semantics, deterministic strategy, Game theory, Machinery, Image reconstruction, ALGOL, Tensile stress, 2-sided die, HO/N-style games, probabilistic extension, category theory, Random variables, probabilistic strategies]
Some strategies for proving theorems with a model checker abstract of invited talk
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
false
[Out of order, Protocols, Coherence, Cost accounting]
A theory of bisimulation for a fragment of Concurrent ML with local names
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
Concurrent ML is an extension of Standard ML with /spl pi/-calculus-like primitives for multi-threaded programming. CML has a reduction semantics, but to date there has been no labelled transitions semantics provided for the entire language. We present a labelled transition semantics for a fragment of CML called /spl mu/vCML which includes features not covered before: dynamically generated local channels and thread identifiers. We show that weak bisimulation for /spl mu/vCML is a congruence, and coincides with barbed bisimulation congruence. We also provide a variant of D. Sangiorgi's (1993) normal bisimulation for /spl mu/vCML, and show that this too coincides with bisimulation.
[Optimizing compilers, Standard ML, Communication system control, local names, CML fragment, /spl mu/vCML, Calculus, Electrical capacitance tomography, Yarn, ML language, dynamically generated local channels, thread identifiers, Concurrent computing, multi-threaded programming, Program processors, bisimulation theory, /spl pi/-calculus-like primitives, bisimulation equivalence, Carbon capture and storage, multi-threading, Concurrent ML, reduction semantics, programming language semantics, Equations, barbed bisimulation congruence, Communication channels, normal bisimulation, labelled transitions semantics, weak bisimulation]
Assigning types to processes
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
In wide area distributed systems it is now common for higher-order code to be transferred from one domain to another; the receiving host may initialise parameters and then execute the code in its local environment. We propose a fine-grained typing system for a higher-order /spl pi/-calculus which can be used to control the effect of such migrating code on local environments. Processes may be assigned different types depending on their intended use. This is in contrast to most of the previous work on typing processes where all processes are typed by a unique constant type, indicating essentially that they are well-typed relative to a particular environment. Our process type takes a form of an interface limiting the resources to which it has access, and the types at which they may be used. Allowing resource names to appear both in process types and process terms, as interaction ports, complicates the typing system considerably. For the development of a coherent typing system, we use a kinding technique, similar to that used by the subtyping of the system F, and order-theoretic properties of our subtyping relation. Various examples illustrate the use of our fine-grained typing system for distributed systems. As a specific application we define a new typed behavioural equivalence for the higher-order /spl pi/-calculus. The expressiveness of our types enables us to state and prove interesting identities between typed processes.
[resource names, subtyping relation, order-theoretic properties, Communication system control, interaction ports, distributed processing, Control systems, Calculus, type theory, typed processes, coherent typing system, typed behavioural equivalence, pi calculus, process type, fine-grained typing system, type assignment, local environments, higher-order /spl pi/-calculus, kinding technique, receiving host, concurrency theory, process terms, wide area distributed systems, typing processes, subtyping, higher-order code, unique constant type, migrating code, local environment, naming services, equivalence classes, type expressiveness]
View-based query processing and constraint satisfaction
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
View-based query processing requires answering a query posed to a database only on the basis of the information on a set of views, which are again queries over the same database. This problem is relevant in many aspects of database management, and has been addressed by means of two basic approaches: query rewriting and query answering. In the former approach, one tries to compute a rewriting of the query in terms of the views, whereas in the latter, one aims at directly answering the query based on the view extensions. We study view based query processing for the case of regular-path queries, which are the basic querying mechanisms for the emergent field of semistructured data. Based on recent results, we first show that a rewriting is in general a co-NP function wrt to the size of view extensions. Hence, the problem arises of characterizing which instances of the problem admit a rewriting that is PTIME. A second contribution of the work is to establish a tight connection between view based query answering and constraint satisfaction problems, which allows us to show that the above characterization is going to be difficult. As a third contribution, we present two methods for computing PTIME rewritings of specific forms. The first method, which is based on the established connection with constraint satisfaction problems, gives us rewritings expressed in Datalog with a fixed number of variables. The second method, based on automata-theoretic techniques, gives us rewritings that are formulated as unions of conjunctive regular-path queries with a fixed number of variables.
[regular-path queries, automata theory, Datalog, querying mechanisms, query processing, Reactive power, database management, view based query processing, Databases, Warehousing, query rewriting, co-NP function, automata-theoretic techniques, rewriting systems, semistructured data, constraint theory, Data warehouses, Remuneration, Computer science, query answering, constraint satisfaction problems, view extensions, Query processing, PTIME rewritings, conjunctive regular-path queries, computational complexity]
Complete axioms for categorical fixed-point operators
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We give an axiomatic treatment of fixed-point operators in categories. A notion of iteration operator is defined embodying the equational properties of iteration theories. We prove a general completeness theorem for iteration operators, relying on a new, purely syntactic characterisation of the free iteration theory. We then show how iteration operators arise in axiomatic domain theory. One result derives them from the existence of sufficiently many bifree algebras (exploiting the universal property Freyd introduced in his notion of algebraic compactness). Another result shows that, in the presence of a parameterized natural numbers object and an equational lifting monad, any uniform fixed-point operator is necessarily an iteration operator.
[parameterized natural numbers, iteration operator, completeness theorem, free iteration theory, complete axioms, categorical fixed-point operators, axiomatic domain theory, Equations, formal logic, National electric code, category theory, equational lifting monad, syntactic characterisation, Informatics, bifree algebra]
A general notion of realizability
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We present a general notion of realizability, encompassing both standard Kleene style realizability over partial combinatory algebras and Kleene style realizability over more general structures, including all partial cartesian closed categories. We show how the general notion of realizability can be used to get models of dependent predicate logic, thus obtaining as a corollary (the known result) that the category Equ of equilogical spaces models dependent predicate logic. Moreover, we characterize when the general notion of realizability gives rise to a topos.
[combinatorial mathematics, Lattices, standard Kleene style realizability, dependent predicate logic modelling, Equ, type theory, Electrical capacitance tomography, partial combinatory algebras, equilogical spaces, topos, formal logic, partial cartesian closed categories, Algebra, general structures, category theory, Logic, Assembly, Principal component analysis]
A syntactical analysis of non-size-increasing polynomial time computation
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
A purely syntactical proof is given that all functions definable in a certain affine linear typed /spl lambda/-calculus with iteration in all types are polynomial time computable. The proof also gives explicit polynomial bounds that can easily be calculated.
[lambda calculus, syntactical analysis, functions, polynomial time computation, Size measurement, Data structures, type theory, explicit polynomial bounds, Postal services, Sorting, Upper bound, Polynomials, affine linear typed lambda calculus, computational complexity]
A complete axiomatization of interval temporal logic with infinite time
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
Interval temporal logic (ITL) is a formalism for reasoning about time periods. To date no one has proved completeness of a relatively simple ITL deductive system supporting infinite time and permitting infinite sequential iteration comparable to /spl omega/-regular expressions. We give a complete axiomatization for such a version of quantified ITL over finite domains and can show completeness by representing finite-state automata in ITL and then translating ITL formulas into them. The axiom system (and completeness) is extended to infinite time.
[Chaos, Real time systems, infinite time, finite-state automata, temporal logic, Calculus, interval temporal logic, /spl omega/-regular expressions, finite state machines, quantified ITL, axiom system, temporal reasoning, infinite sequential iteration, finite domains, Reactive power, complete axiomatization, ITL formulas, Automata, simple ITL deductive system, theorem proving, Logic, time periods, computational complexity, completeness proving]
Game semantics and subtyping
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
While game semantics has been remarkably successful at modelling, often in a fully abstract manner a wide range of features of programming languages, there has to date been no attempt at applying it to subtyping. We show how the simple device of explicitly introducing error values in the syntax of the calculus leads to a notion of subtyping for game semantics. We construct an interpretation of a simple /spl lambda/-calculus with subtyping and show how the range of the interpretation of types is a complete lattice, thus yielding an interpretation of bounded quantification.
[lambda calculus, Scholarships, Lattices, game theory, Data structures, complete lattice, Calculus, type theory, programming language semantics, game semantics, programming languages, bounded quantification, subtyping, Computer languages, syntax, error values, Mathematical model, type interpretation]
Definability and compression
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
A compression algorithm takes a finite structure of a class K as input and produces a finite structure of a different class K' as output. Given a property P on the class K defined in a logic /spl Lscr/, we study the definability of property P on the class K'. We consider two compression schemas on unary ordered structures (words), compression by runlength encoding and the classical Lempel-Ziv. First-order properties of strings are first-order on runlength compressed strings, but this fails for images, i.e. 2-dimensional strings. We present simple first-order properties of strings which are not first-order definable on strings compressed with the Lempel-Ziv compression schema. We show that all properties of strings that are first-order definable on strings are definable on Lempel-Ziv compressed strings in FO(TC), the extension of first-order logic with the transitive closure operator. We define a subclass /spl Fscr/ of the first-order properties of strings such that if L is defined by a property in /spl Fscr/, it is also first-order definable on the Lempel-Ziv compressed strings. Monadic second-order properties of strings are dyadic second order definable on Lempel-Ziv compressed strings.
[unary ordered structures, runlength encoding, data compression, class finite structure, runlength codes, Lempel-Ziv compression schema, monadic second-order properties, definability, first-order logic, Data structures, Encoding, Computational Intelligence Society, Compression algorithms, formal logic, Image coding, Boolean functions, strings, Logic, first-order properties, transitive closure operator, Pattern matching]
Computational complexity of some problems involving congruences on algebras
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We prove that several problems concerning congruences on algebras are complete for nondeterministic log-space. These problems are: determining the congruence on a given algebra generated by a set of pairs, and determining whether a given algebra is simple or subdirectly irreducible. We also consider the problem of determining the smallest fully invariant congruence on a given algebra containing a given set of pairs. We prove that this problem is complete for nondeterministic polynomial time.
[Image converters, Mathematics, algebra, set theory, Computational complexity, Equations, subdirectly irreducible algebra, Computer science, Algebra, nondeterministic log-space, algebras, smallest fully invariant congruence, nondeterministic polynomial time, Polynomials, congruences, computational complexity]
A decision procedure for the existential theory of term algebras with the Knuth-Bendix ordering
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
The authors show the decidability of the existential theory of term algebras with any Knuth-Bendix ordering. They achieve this by giving a procedure for solving Knuth-Bendix ordering constraints. As for complexity, NP-hardness of the set of satisfiable quantifier-free formulas can be shown in the same way as by R. Nieuwenhuis (1993). The algorithm presented does not give an NP upper bound; we point out parts of our algorithm that may cause nonpolynomial behavior.
[complexity, NP upper bound, decision theory, nonpolynomial behavior, computability, algebra, existential theory, term algebras, Equations, Computer science, NP-hardness, Reactive power, Upper bound, Knuth-Bendix ordering, Algebra, decidability, decision procedure, satisfiable quantifier-free formulas, Chromium, Constraint theory, ordering constraints, computational complexity]
Efficient and flexible matching of recursive types
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
Equality and subtyping of recursive types have been studied in the 1990s by: R.M. Amadaio and L. Cardelli (1993); D. Kozen et al. (1993); M. Brandt and F. Henglein (1997) and others. Potential applications include automatic generation of bridge code for multi-language systems and type-based retrieval of software modules from libraries. J. Auerbach et al. (1998) advocate a highly flexible combination of matching rules for which there, until now, are no efficient algorithmic techniques. We present an efficient decision procedure for a notion of type equality that includes unfolding of recursive types, and associativity and commutativity of product types, as advocated by Auerbach et al. For two types of size at most n, our algorithm decides equality in O(n/sup 2/) time. The algorithm iteratively prunes a set of type pairs, and eventually it produces a set of pairs of equal types. In each iteration, the algorithm exploits a so-called coherence property of the set of type pairs produced in the preceding iteration. The algorithm takes O(n) iterations, each of which takes O(n) time, for a total of O(n/sup 2/) time.
[algorithmic techniques, multi-language systems, decision theory, iterative pruning, flexible matching, type theory, set theory, type-based retrieval, bridge code, commutativity, type pairs, equal types, recursive type matching, associativity, automatic generation, search problems, Java, product types, Information retrieval, recursive functions, software modules, Application software, preceding iteration, Programming profession, subtyping, Bridges, Computer science, Computer languages, Software libraries, matching rules, type equality, coherence property, decision procedure, Iterative algorithms, Joining processes, computational complexity]
Back and forth between guarded and modal logics
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
Guarded fixed point logic /spl mu/GF extends the guarded fragment by means of least and greatest fixed points, and thus plays the same role within the domain of guarded logics as the modal /spl mu/-calculus plays within the modal domain. We provide a semantic characterisation of /spl mu/GF within an appropriate fragment of second-order logic, in terms of invariance under guarded bisimulation. The corresponding characterisation of the modal /spl mu/-calculus, due to D. Janin and I. Walukiewicz (1999), is lifted from the modal to the guarded domain by means of model theoretic translations. At the methodological level, these translations make the intuitive analogy between modal and guarded logics available as a tool in the analysis of the guarded domain.
[Heart, modal logics, fixed points, guarded fixed point logic, /spl mu/GF, Calculus, model theoretic translations, calculus, guarded bisimulation, formal logic, modal domain, Automata, guarded fragment, second-order logic, intuitive analogy, semantic characterisation, invariance, bisimulation equivalence, theorem proving, Logic, modal /spl mu/-calculus, Context modeling]
Satisfiability testing: recent developments and challenge problems
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
false
[Computer science, Software testing, Protocols, Processor scheduling, Measurement standards, Particle measurements, Application software, Computational complexity, Distributed algorithms, Physics]
The curry-howard correspondence in set theory
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
false
[Computer science, Computer languages, Computer aided instruction, Logic programming, Control system synthesis, Set theory, Calculus, Electronic mail, Functional programming]
Models for name-passing processes: interleaving and causal
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We study syntax-free models for name-passing processes. For interleaving semantics, we identify the indexing structure required of an early labelled transition system to support the usual /spl pi/-calculus operations, defining indexed labelled transition systems. For non-interleaving causal semantics, we define indexed labelled asynchronous transition systems, smoothly generalizing both our interleaving model and the standard asynchronous transition systems model for CCS-like calculi. In each case we relate a denotational semantics to an operational view for bisimulation and causal bisimulation respectively. This is a first step towards a uniform understanding of the semantics and operations of name-passing calculi.
[interleaving model, name-passing calculi, early labelled transition system, standard asynchronous transition systems model, indexed labelled transition systems, uniform understanding, pi calculus, name-passing processes, indexing structure, bisimulation equivalence, theorem proving, non-interleaving causal semantics, CCS-like calculi, denotational semantics, causal bisimulation, syntax-free models, operational view, indexed labelled asynchronous transition systems, /spl pi/-calculus operations, programming language semantics, calculus of communicating systems, interleaving semantics, Chromium, Interleaved codes, naming services]
On first-order topological queries
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
One important class of spatial database queries is the class of topological queries, i.e. queries invariant under homeomorphisms. We study topological queries expressible in the standard query language on spatial databases, first-order logic with various amounts of arithmetic. Our main technical result is a combinatorial characterization of the expressive power of topological first-order logic on regular spatial databases.
[regular spatial databases, invariant queries, first-order topological queries, topology, first-order logic, Relational databases, visual databases, query languages, arithmetic, Spatial databases, Database languages, spatial database queries, spatial databases, expressive power, query processing, formal logic, Presses, topological first-order logic, Logic, homeomorphisms, combinatorial characterization, standard query language, Arithmetic]
The role of decidability in first order separations over classes of finite structures
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We establish that the decidability of the first order theory of a class of finite structures C is a simple and useful condition for guaranteeing that the expressive power of FO+LFP properly extends that of FO on C, unifying separation results for various classes of structures that have been studied. We then apply this result to show that it encompasses certain constructive pebble game techniques which are widely used to establish separations between FO and FO+LFP, and demonstrate that these same techniques cannot succeed in performing separations from any complexity class that contains DLOGTIME.
[Computer science, decidability, finite structures, complexity class, Educational institutions, Polynomials, Logic, first order separations, constructive pebble game techniques, expressive power, computational complexity, first order theory]
A model for impredicative type systems, universes, intersection types and subtyping
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We introduce a novel model based on coherence spaces for interpreting large impredicative type systems such as the Extended Calculus of Constructions (ECC). Moreover we show that this model is well-suited for interpreting intersection types and subtyping too, and we illustrate this by interpreting a variant of ECC with an additional intersection type binder. Furthermore, we propose a general method for interpreting the impredicative level in a non-syntactical way, by allowing the model to be parametrized by an arbitrarily large coherence space in order to interpret inhabitants of impredicative types. As an application, we show that uncountable types such as the type of real numbers or Zermelo-Frankel sets can safely be axiomatized on the impredicative level of, say, ECC, without harm for consistency.
[intersection types, ECC, intersection type binder, Calculus, type theory, set theory, set axiomatization, calculus, subtyping, Extended Calculus of Constructions, uncountable types, Zermelo-Frankel sets, Coherence, Writing, universes, real numbers, theorem proving, arbitrarily large coherence space, impredicative type systems, coherence spaces]
Approximating labeled Markov processes
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We study approximate reasoning about continuous-state labeled Markov processes. We show how to approximate a labeled Markov process by a family of finite-state labeled Markov chains. We show that the collection of labeled Markov processes carries a Polish space structure with a countable basis given by finite state Markov chains with rational probabilities. The primary technical tools that we develop to reach these results are: a finite-model theorem for the modal logic used to characterize bisimulation; and a categorical equivalence between the category of Markov processes (with simulation morphisms) with the /spl omega/-continuous dcpo Proc, defined as the solution of the recursive domain equation Proc=/spl Pi//sub Labels/ P/sub Prob/(Proc). The correspondence between labeled Markov processes and Proc yields a logic complete for reasoning about simulation for continuous-state processes.
[bisimulation, rational probability, Drives, uncertainty handling, finite-state labeled Markov chains, finite state Markov chains, modal logic, approximate reasoning, continuous-state labeled Markov processes, recursive domain equation, labeled Markov process approximation, continuous-state processes, bisimulation equivalence, Logic, Flexible manufacturing systems, Collaborative software, probability, Polish space structure, State-space methods, inference mechanisms, Equations, Physics, Computer science, Stochastic systems, finite-model theorem, Markov processes, category theory, logic]
Resource-bounded continuity and sequentiality for type-two functionals
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We define notions of resource-bounded continuity and sequentiality for type-two functionals with total inputs, and prove that in the resource-bounded model there are continuous functionals which cannot be efficiently simulated by sequential functionals. We also show that for some naturally defined classes of continuous functionals, an efficient simulation is possible.
[decision tree complexity, Surface-mount technology, Computational modeling, Computer simulation, simulation, computability, Mathematics, History, Computational complexity, resource-bounded continuity, continuous functionals, sequentiality, Computer science, Computer languages, Boolean functions, resource-bounded model, sequential functionals, type-two functionals, decision trees, Decision trees, computational complexity]
How to optimize proof-search in modal logics: a new way of proving redundancy criteria for sequent calculi
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We present a bottom-up decision procedure for propositional modal logic K based on the inverse method. The procedure is based on the "inverted" version of a sequent calculus. To restrict the search space; we prove a number of redundancy criteria for derivations in the sequent calculus. We introduce a new technique of proving redundancy criteria, based on the analysis of tableau-based derivations in K. Moreover another new technique is used to prove completeness of proof-search with a strong notion of subsumption. This technique is based on so-called traces. A new formalization of the inverse method in the form of a path calculus considerably simplifies all proofs as compared to the previously published presentations of the inverse method. Experimental results reported elsewhere demonstrate that our method is competitive with many state-of-the-art implementations of K.
[bottom-up decision procedure, redundancy criteria, Optimization methods, inverse method, Knowledge representation, path calculus, Data structures, Calculus, sequent calculi, tableau-based derivations, completeness, Computer science, formal logic, Boolean functions, optimisation, Inverse problems, subsumption, theorem proving, propositional modal logic, search space, Logic, proof search optimization, search problems]
Dominator trees and fast verification of proof nets
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We consider the following decision problems. PROOFNET: given a multiplicative linear logic (MLL) proof structure, is it a proof net? ESSNET: given an essential net (of an intuitionistic MLL sequent), is it correct? The authors show that linear-time algorithms for ESSNET can be obtained by constructing the dominator tree of the input essential net. As a corollary, by showing that PROOFNET is linear-time reducible to ESSNET (by the trip translation), we obtain a linear-time algorithm for PROOFNET. We show further that these linear-time algorithms can be optimized to simple one-pass algorithms: each node of the input structure is visited at most once. As another application of dominator trees, we obtain linear time algorithms for sequentializing proof nets (i.e. given a proof net, find a derivation for the underlying MLL sequent) and essential nets.
[Polarization, decision theory, Laboratories, proof nets, Electronic switching systems, underlying MLL sequent, linear time algorithms, ESSNET, linear-time algorithm, simple one-pass algorithms, dominator trees, formal logic, essential net, optimisation, Tree graphs, formal verification, theorem proving, Logic, Assembly, Tree data structures, trip translation, linear-time reducible, trees (mathematics), input structure, fast verification, intuitionistic MLL sequent, input essential net, decision problems, multiplicative linear logic, PROOFNET, MLL proof structure]
Automatic structures
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We study definability and complexity issues for automatic and /spl omega/-automatic structures. These are, in general, infinite structures but they can be finitely presented by a collection of automata. Moreover they admit effective (in fact automatic) evaluation of all first-order queries. Therefore, automatic structures provide an interesting framework for extending many algorithmic and logical methods from finite structures to infinite ones. We explain the notion of (/spl omega/-)automatic structures, give examples, and discuss the relationship to automatic groups. We determine the complexity of model checking and query evaluation on automatic structures for fragments of first-order logic. Further we study closure properties and definability issues on automatic structures and present a technique for proving that a structure is not automatic. We give model-theoretic characterisations for automatic structures via interpretations. Finally we discuss the composition theory of automatic structures and prove that they are closed under finitary Feferman-Vaught-like products.
[complexity, automata theory, composition theory, first-order queries, first-order logic, Automatic logic units, infinite structures, Cost accounting, formal logic, Databases, logical methods, algorithmic methods, model theory, finite structures, definability, Knowledge representation, query evaluation, State-space methods, Application software, closure properties, group theory, automatic groups, model checking, automatic structures, Automata, computational complexity]
Precongruence formats for decorated trace preorders
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
This paper explores the connection between semantic equivalences and preorders for concrete sequential processes, represented by means of labelled transition systems, and formats of transition system specifications using Plotkin's (1981) structural approach. For several preorders in the linear time-branching time spectrum a format is given, as general as possible, such that this preorder is a precongruence for all operators specifiable in that format. The formats are derived using the modal characterizations of the corresponding preorders.
[linear time-branching time spectrum, process algebra, semantic equivalence, Chromium, concrete sequential processes, transition system specifications, precongruence formats, structural approach, bisimulation equivalence, labelled transition systems, decorated trace preorders]
Paramodulation with built-in abelian groups
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
A new technique is presented for superposition with first order clauses with built-in abelian groups (AG). Compared with previous approaches, it is simpler, and no inferences with the AG axioms or abstraction rules are needed. Furthermore, AG-unification is used instead of the computationally more expensive unification modulo associativity and commutativity. Due to the simplicity and restrictiveness of our inference system, its compatibility with redundancy notions and constraints, and the fact that standard term orderings like RPO can be used, we believe that our technique will become the method of choice for practice, as well as a basis for new theoretical developments like logic-based complexity and decidability analysis.
[superposition, inference, Electrical capacitance tomography, constraints, decidability analysis, Postal services, formal logic, AG axioms, logic-based complexity, Quantum computing, decidability, AG-unification, Constraint theory, Polynomials, Standards development, standard term orderings, rewriting systems, abstraction rules, term rewriting, redundancy notions, built-in abelian groups, first order clauses, Large scale integration, inference mechanisms, Equations, group theory, paramodulation, Modules (abstract algebra), compatibility, computational complexity]
Virtual symmetry reduction
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We provide a general method for ameliorating state explosion via symmetry reduction in certain asymmetric systems, such as systems with many similar, but not identical, processes. The method applies to systems whose structures (i.e., state transition graphs) have more state symmetries than arc symmetries. We introduce a new notion of "virtual symmetry" that strictly subsumes earlier notions of "rough symmetry" and "near symmetry" (Emerson and Trefler, 1999). Virtual symmetry is the most general condition under which the structure of a system is naturally bisimilar to its quotient by a group of state symmetries. We give several example systems exhibiting virtual symmetry that are not amenable to symmetry reduction by earlier techniques: a one-lane bridge system, where the direction with priority for crossing changes dynamically; an abstract system with asymmetric communication network; and a system with asymmetric resource sharing motivated from the drinking philosophers problem. These examples show that virtual symmetry reduction applies to a significantly broader class of asymmetric systems than could be handled before.
[asymmetric systems, near symmetry, state transition graphs, graph theory, state explosion, temporal logic, asymmetric resource sharing, Explosions, drinking philosophers problem, bisimilarity, arc symmetries, resource allocation, symmetry, rough symmetry, Computational efficiency, Communication networks, Logic, Resource management, Labeling, virtual symmetry reduction, Contracts, asymmetric communication network, state symmetries, one-lane bridge system]
Better is better than well: on efficient verification of infinite-state systems
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
Many existing algorithms for model checking of infinite-state systems operate on constraints which are used to represent (potentially infinite) sets of states. A general powerful technique which can be employed for proving termination of these algorithms is that of well quasi-orderings. Several methodologies have been proposed for derivation of new well quasi-ordered constraint systems. However, many of these constraint systems suffer from a "constraint explosion problem\
[well quasi-ordered constraint systems, Protocols, program verification, automata theory, Petri nets, temporal logic, Termination of employment, Broadcasting, Constraint theory, constraint handling, broadcast protocols, infinite-state systems verification, symbolic model checking, constraint explosion problem, better quasi-orderings, Explosions, Power system modeling, clocks, model checking, lossy channel systems, integral relational automata, Automata, algorithm termination, timed Petri nets, Clocks]
Concurrent omega-regular games
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
We consider two-player games which are played on a finite state space for an infinite number of rounds. The games are concurrent, that is, in each round, the two players choose their moves independently and simultaneously; the current state and the two moves determine a successor state. We consider omega-regular winning conditions on the resulting infinite state sequence. To model the independent choice of moves, both players are allowed to use randomization for selecting their moves. This gives rise to the following qualitative modes of winning, which can be studied without numerical considerations concerning probabilities: sure-win (player 1 can ensure winning with certainty); almost-sure-win (player 1 can ensure winning with probability 1); limit-win (player 1 can ensure winning with probability arbitrarily close to 1); bounded-win (player 1 can ensure winning with probability bounded away from 0); positive-win (player 1 can ensure winning with positive probability); and exist-win (player 1 can ensure that at least one possible outcome of the game satisfies the winning condition). We provide algorithms for computing the sets of winning states for each of these winning modes. In particular, we solve concurrent Rabin-chain games in n/sup O/(m) time, where n is the size of the game structure and m is the number of pairs in the Rabin-chain condition. While this complexity is in line with traditional turn-based games, our algorithms are considerably more involved. This is because concurrent games violate two of the most basic properties of turn-based games: concurrent games are not determined, but rather exhibit a more general duality property which involves multiple modes of winning; and winning strategies for concurrent games may require infinite memory.
[successor state, concurrent omega-regular games, winning condition, current state, History, finite state machines, game structure, concurrent games, omega-regular winning conditions, concurrent Rabin-chain games, Rabin-chain condition, randomization, finite state space, winning strategies, two-player games, Safety, probabilities, qualitative modes, bounded-win, positive-win, Engineering profession, probability, game theory, State-space methods, limit-win, infinite memory, general duality property, infinite state sequence, Automata, exist-win, winning states, winning modes, almost-sure-win, computational complexity]
Approximate pattern matching is expressible in transitive closure logic
Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science
None
2000
A sartorial query language facilitates the formulation of queries to a (string) database. One step towards an implementation of such a query language can be taken by defining a logical formalism expressing a known solution for the particular problem at hand. The simplicity of the logic is a desired property because the simpler the logic that the query language is based on, the more efficiently it can be implemented. We introduce a logical formalism for expressing approximate pattern matching. The formalism uses properties of the dynamic programming approach; a minimizing path of a dynamic programming table is expressed by using a formula in an extension of first-order logic (FO). We consider the well-known problems of k mismatches and k differences. Assuming first that k is given as a part of the input, those problems are expressed by using deterministic transitive closure logic (FO(DTC)) and transitive closure logic (FO(TC)), respectively. We believe that in the general case the k differences is not expressible in FO(DTC), and show that solving this question in the affirmative is at least as hard as separating LOGSPACE from NLOGSPACE. We show, however, that if k is fixed, the k differences problem can be expressed by an FO(DTC)formula.
[pattern matching, first-order logic, LOGSPACE, Multimedia databases, query languages, Mathematics, set theory, Database languages, NLOGSPACE, formal logic, approximate pattern matching, Dynamic programming, query formulation, logical formalism, Logic programming, string database, Image retrieval, dynamic programming approach, minimizing path, dynamic programming, dynamic programming table, database theory, Computer science, Image databases, sartorial query language, logic simplicity, string matching, Music information retrieval, deterministic transitive closure logic, Pattern matching, computational complexity]
A continuum of theories of lambda calculus without semantics
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
In this paper, we give a topological proof of the following result: there exist 2&#x02135;(&#x02135;/sub 0/) lambda theories of the untyped lambda calculus without a model in any semantics based on D.S. Scott's (1972, 1981) view of models as partially ordered sets and of functions as monotonic functions. As a consequence of this result, we positively solve the conjecture, stated by O. Bastonero and X. Gouy (1999) and by C. Berline (2000), that the strongly stable semantics is incomplete.
[lambda calculus, models, monotonic functions, strongly stable semantics, functions, lambda theories, topological proof, Lattices, Calculus, Topology, set theory, Equations, Algebra, partially ordered sets, untyped lambda calculus, incomplete semantics, Mathematical model, Context modeling]
Focus games for satisfiability and completeness of temporal logic
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Introduce a simple game-theoretic approach to satisfiability checking of temporal logic, for LTL (linear time logic) and CTL (computation tree logic), which has the same complexity as using automata. The mechanisms involved are both explicit and transparent, and underpin a novel approach to developing complete axiom systems for temporal logic. The axiom systems are naturally factored into what happens locally and what happens in the limit. The completeness proofs utilise the game-theoretic construction for satisfiability: if a finite set of formulas is consistent then there is a winning strategy (and therefore construction of an explicit model is avoided).
[focus games, complexity, Costs, LTL, temporal logic, computability, Calculus, linear time logic, completeness, explicit model, Logic, Books, Informatics, Plugs, Testing, computation tree logic, game theory, Game theory, winning strategy, consistent finite formula set, Automata, satisfiability checking, CTL, Impedance, automata, explicit transparent mechanisms, game-theoretic construction, computational complexity, axiom systems]
Relating levels of the mu-calculus hierarchy and levels of the monadic hierarchy
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
As is already known from the work of D. Janin & I. Walukiewicz (1996), the mu-calculus is as expressive as the bisimulation-invariant fragment of monadic second-order logic. In this paper, we relate the expressiveness of levels of the fixpoint alternation depth hierarchy of the mu-calculus (the mu-calculus hierarchy) with the expressiveness of the bisimulation-invariant fragment of levels of the monadic quantifiers alternation-depth hierarchy (the monadic hierarchy). From J. van Benthem's (1976) results, we know already that the fixpoint free fragment of the mu-calculus (i.e. polymodal logic) is as expressive as the bisimulation-invariant fragment of monadic /spl Sigma//sub 0/ (i.e. first-order logic). We show that the /spl nu/-level of the mu-calculus hierarchy is as expressive as the bisimulation-invariant fragment of monadic /spl Sigma//sub 1/ and that the /spl nu//spl mu/-level of the mu-calculus hierarchy is as expressive as the bisimulation-invariant fragment of monadic /spl Sigma//sub 2/, and we show that no other level /spl Sigma//sub k/ (for k>2) of the monadic hierarchy can be related similarly with any other level of the mu-calculus hierarchy. The possible inclusion of all the mu-calculus in some level /spl Sigma//sub k/ of the monadic hierarchy, for some k>2, is also discussed.
[1st-order logic, mu-calculus hierarchy, fixpoint alternation depth hierarchy, /spl nu/-level, Calculus, Electronic switching systems, Computational Intelligence Society, monadic 2nd-order logic, bisimulation-invariant fragment, monadic quantifiers alternation-depth hierarchy, polymodal logic, Upper bound, process algebra, /spl nu//spl mu/-level, expressiveness, Polynomials, bisimulation equivalence, Logic, monadic /spl Sigma//sub 2/, monadic hierarchy, fixpoint free fragment, monadic /spl Sigma//sub 1/, monadic /spl Sigma//sub 0/]
Relating semantic and proof-theoretic concepts for polynomial time decidability of uniform word problems
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Compares three approaches to polynomial-time decidability for uniform word problems for quasi-varieties. Two of the approaches, by T. Evans (1951) and S. Burris (1995), respectively, are semantic, referring to certain embeddability and axiomatizability properties. The third approach is more proof-theoretic in nature, inspired by D. McAllester's (1993) concept of local inference. We define two closely related notions of locality for equational Horn theories and show that both of the criteria of Evans and Burris lie in between these two concepts. In particular, the variant we call "stable locality" is shown to subsume both Evans' and Burris's methods.
[polynomial-time decidability, formal languages, Horn clauses, embeddability properties, Lattices, Encoding, inference mechanisms, stable locality, Equations, Counting circuits, Geometry, Algebra, decidability, proof-theoretic concepts, quasi-varieties, local inference, Polynomials, Dynamic programming, theorem proving, semantic concepts, uniform word problems, equational Horn theories, axiomatizability properties, computational complexity]
On ordering constraints for deduction with built-in Abelian semigroups, monoids and groups
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
It is crucial for the performance of ordered resolution or paramodulation-based deduction systems that they incorporate specialized techniques to work efficiently with standard algebraic theories E. Essential ingredients for this purpose are term orderings that are E-compatible, for the given E, and algorithms deciding constraint satisfiability for such orderings. In this paper, we introduce a uniform technique providing the first such algorithms for some orderings for Abelian semigroups, Abelian monoids and Abelian groups, which we believe will lead to reasonably efficient techniques for practice. The algorithms are optimal since we show that, for any well-founded E-compatible ordering for these E, the constraint satisfiability problem is NP-hard, even for conjunctions of inequations, and that our algorithms are in NP.
[Abelian monoids, built-in Abelian semigroups, constraint theory, automated deduction, computability, optimal algorithms, Large scale integration, symbolic constraints, inference mechanisms, group theory, E-compatible term orderings, constraint satisfiability, NP-hard problem, Kuiper belt, Abelian groups, paramodulation-based deduction systems, inequation conjunctions, Constraint theory, ordered resolution, ordering constraints, computational complexity, algebraic theories]
Eliminating definitions and Skolem functions in first-order logic
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
In any classical first-order theory that proves the existence of at least two elements, one can eliminate definitions with a polynomial bound on the increase in proof length. The author considers how in any classical first-order theory strong enough to code finite functions, including sequential theories, one can also eliminate Skolem functions with a polynomial bound on the increase in proof length.
[proof length, first-order logic, finite functions, sequential theories, Skolem functions, Computer science, formal logic, Upper bound, Constraint theory, classical first-order theory, Polynomials, theorem proving, Logic, polynomial bound, Arithmetic]
A model-theoretic approach to regular string relations
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
We study algebras of definable string relations, classes of regular n-ary relations that arise as the definable sets within a model whose carrier is the set of all strings. We show that the largest such algebra-the collection of regular relations-has some quite undesirable computational and model-theoretic properties. In contrast, we exhibit several definable relation algebras that have much tamer behavior: for example, they admit quantifier elimination, and have finite VC dimension. We show that the properties of a definable relation algebra are not at all determined by the one-dimensional definable sets. We give models whose definable sets are all star-free, but whose binary relations are quite complex, as well as models whose definable sets include all regular sets, but which are much more restricted and tractable than the full algebra of regular relations.
[Virtual colonoscopy, formal languages, definable relation algebras, Computational modeling, automata theory, Formal languages, regular n-ary relations, 1D definable sets, regular string relations, finite VC dimension, Postal services, Computer science, formal logic, star-free, Algebra, Ores, one-dimensional definable sets, Automata, Logic functions, model theoretic approach, quantifier elimination, automata, definable string relations, formal language]
A symbolic labelled transition system for coinductive subtyping of F/sub /spl mu//spl les// types
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
F/sub /spl les// is a typed /spl lambda/-calculus with subtyping and bounded polymorphism. Type checking for F/sub /spl les// is known to be undecidable, because the subtyping relation on types is undecidable. F/sub /spl mu//spl les// is an extension of F/sub /spl les// with recursive types. In this paper, we show how symbolic labelled transition system techniques from concurrency theory can be used to reason about subtyping for F/sub /spl mu//spl les//. We provide a symbolic labelled transition system for F/sub /spl mu//spl les// types, together with an appropriate notion of simulation, which coincides with the existing co-inductive definition of subtyping. We then provide a 'simulation up to' technique for proving subtyping, for which there is a simple model-checking algorithm. The algorithm is more powerful than the usual one for F/sub /spl les//, e.g. it terminates on G. Ghelli's (1995) canonical example of non-termination.
[lambda calculus, nontermination, symbolic labelled transition system, program verification, Computational modeling, recursive types, simulation, typed /spl lambda/-calculus, type checking, concurrency theory, co-inductive subtyping, type theory, State-space methods, F/sub /spl mu//spl les// types, Concurrent computing, bounded polymorphism, Computer languages, Turing machines, decidability, Automata, algorithm termination, Space exploration, model-checking algorithm, Kernel]
Semistructured data: from practice to theory
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Semi-structured data is data that presents some regularity (i.e. it is not an image or plain text), but perhaps not as much as some relational data or some ODMG data (the standard for object databases). Such data is becoming increasingly important and, with XML, should become the standard for publishing data on the World Wide Web. With XML, the Web is turning into a worldwide heterogeneous distributed database. In this paper, we briefly discuss typing and languages for semi-structured data and some new issues arising from the context of data management on the Web.
[standard, electronic publishing, data management, Relational databases, Turning, World Wide Web, HTML, Database languages, storage management, Publishing, distributed databases, semi-structured data, Database systems, data structures, data publishing, hypermedia markup languages, information resources, languages, data regularity, worldwide heterogeneous distributed database, Standards publication, Computer science, Image databases, XML, typing]
A bound on attacks on payment protocols
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Electronic payment protocols are designed to work correctly in the presence of an adversary that can prompt honest principals to engage in an unbounded number of concurrent instances of the protocol. This paper establishes an upper bound on the number of protocol instances needed to attack a large class of protocols, which contains versions of some well-known electronic payment protocols, including SET and 1KP. Such bounds clarify the nature of attacks on and provide a rigorous basis for automated verification of payment protocols.
[Protocols, SET, upper bound, State-space methods, Electronic mail, History, Security, honest principals, Yarn, adversary, electronic money, attack bound, Computer science, Upper bound, electronic payment protocols, security of data, formal verification, 1KP, concurrent protocol instances, Space exploration, Secure Electronic Transactions, protocols, automated verification]
The hierarchy inside closed monadic /spl Sigma//sub 1/ collapses on the infinite binary tree
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Closed monadic /spl Sigma//sub 1/, as proposed in (Ajtai et al., 1998), is the existential monadic second order logic where alternation between existential monadic second order quantifiers and first order quantifiers is allowed. Despite some effort very little is known about the expressive power of this logic on finite structures. We construct a tree automaton which exactly characterizes closed monadic /spl Sigma//sub 1/ on the Rabin tree and give a full analysis of the expressive power of closed monadic /spl Sigma//sub 1/ in this context. In particular we prove that the hierarchy inside closed monadic /spl Sigma//sub 1/, defined by the number of alternations between blocks of first order quantifiers and blocks of existential monadic second order quantifiers collapses, on the infinite tree, to the level 2.
[Rabin tree, finite automata, finite structures, infinite binary tree, first order quantifiers, trees (mathematics), hierarchy, Computer science, formal logic, infinite tree, existential monadic second order quantifiers, Automata, closed monadic sigma collapses, Binary trees, tree automaton, Polynomials, monadic second order logic, Logic]
A second-order system for polytime reasoning using Gradel's theorem
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
We introduce a second-order system V/sub 1/-Horn of bounded arithmetic formalizing polynomial-time reasoning, based on Gradel's (1992) second-order Horn characterization of P. Our system has comprehension over P predicates (defined by Gradel's second-order Horn formulas), and only finitely, many function symbols. Other systems of polynomial-time reasoning either allow induction on NP predicates (such as Buss's (1986) S/sub 2//sup 1/ or the second-order V/sub 1//sup 1/), and hence are more powerful than our system (assuming the polynomial hierarchy does not collapse), or use Cobham's theorem to introduce function symbols for all polynomial-time functions (such as Cook's PV and Zambella's P-def). We prove that our system is equivalent to QPV and Zambella's (1996) P-def. Using our techniques, we also show that V/sub 1/-Horn is finitely, axiomatizable, and, as a corollary, that the class of /spl forall//spl Sigma//sub 1//sup b/ consequences of S/sub 2//sup 1/ is finitely axiomatizable as well, thus answering an open question.
[second-order Horn formulas, Horn clauses, second-order system, bounded arithmetic, inference mechanisms, polytime reasoning, Equations, NP predicates, P-def, polynomial-time reasoning, function symbols, Polynomials, Arithmetic, computational complexity]
A decision procedure for an extensional theory of arrays
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
A decision procedure for a theory of arrays is of interest for applications in formal verification, program analysis and automated theorem proving. This paper presents a decision procedure for an extensional theory of arrays and proves it correct.
[Design automation, program diagnostics, Laboratories, Application software, Equations, correctness proof, decidability, formal verification, decision procedure, array theory, program analysis, automated theorem proving, Libraries, data structures, arrays, theorem proving, Logic arrays, Formal verification, extensional theory]
Definitions by rewriting in the calculus of constructions
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Considers an extension of the calculus of constructions where predicates can be defined with a general form of rewrite rules. We prove the strong normalization of the reduction relation generated by the /spl beta/-rule and user-defined rules under some general syntactic conditions, including confluence. As examples, we show that two important systems satisfy these conditions: (i) a sub-system of the calculus of inductive constructions, which is the basis of the proof assistant Cog, and (ii) natural deduction modulo a large class of equational theories.
[/spl beta/-rule, Modular construction, rewriting systems, natural deduction, confluence, Data structures, Calculus, Encoding, calculus of inductive constructions, Equations, strong normalization, reduction relation, Cog proof assistant, process algebra, syntactic conditions, calculus of constructions, equational theories, rewrite rules, theorem proving, predicate definitions, Logic, user-defined rules]
Logician in the land of OS: abstract state machines in Microsoft
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Analysis of foundational problems like "What is computation" leads to a sketch of the paradigm of abstract state machines (ASMs). This is followed by a brief discussion on ASMs applications. Then we present some theoretical problems that bridge between the traditional LICS themes and abstract state machines.
[Computer science, Bridges, formal logic, Algebra, finite automata, Programming, Logic functions, Microsoft, Application software, abstract state machines, Software engineering, computation]
Typechecking XML views of relational databases
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Motivated by the need to export relational databases as XML data in the context of the World Wide Web, we investigate the type-checking problem for transformations of relational data into tree data (i.e. XML). The problem consists of statically verifying that the output of every transformation belongs to a given output tree language (specified for XML by a document type definition), for input databases satisfying given integrity constraints. The type-checking problem is parameterized by the class of formulas defining the transformation, the class of output tree languages and the class of integrity constraints. While undecidable in its most general formulation, the type-checking problem has many special cases of practical interest that turn out to be decidable. The main contribution of this paper is to trace a fairly tight boundary of decidability for type-checking in this framework. In the decidable cases, we examine the complexity and show lower and upper bounds. We also exhibit a practically appealing restriction for which type-checking is in PTIME.
[Industrial relations, tree data, Relational databases, Medical services, type checking, World Wide Web, static verification, transformation formulas, integrity constraints, decidability, upper complexity bound, output tree languages, hypermedia markup languages, information resources, XML views, formal languages, problem parameterization, trees (mathematics), data integrity, relational databases, database theory, relational data transformation, electronic data interchange, lower complexity bound, Markup languages, XML, PTIME complexity class, Web sites, document type definition, computational complexity]
Dependent types for program termination verification
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Program termination verification is a challenging research subject of significant practical importance. While there is already a rich body of literature on this subject, it is still undeniably a difficult task to design a termination checker for a realistic programming language that supports general recursion. In this paper, we present an approach to program termination verification that makes use of a form of dependent types developed in Dependent ML (DML), demonstrating a novel application of such dependent types to establishing a liveness property. We design a type system that enables the programmer to supply metrics for verifying program termination and prove that every well-typed program in this type system is terminating. We also provide realistic examples, which are all verified in a prototype implementation, to support the effectiveness of our approach to program termination verification as well as its unobtrusiveness to programming. The main contribution of the paper lies in the design of an approach to program termination verification that smoothly combines types with metrics, yielding a type system capable of guaranteeing program termination that supports a general form of recursion (including mutual recursion), higher-order functions, algebraic data types and polymorphism.
[algebraic data types, program verification, dependent types, higher-order functions, program termination verification, liveness property, type theory, polymorphism, programming languages, Programming profession, ML language, mutual recursion, general recursion, unobtrusiveness, type system, Dependent ML, Polynomials, termination checker, Error correction, well-typed programs, software metrics]
Strong normalisation in the /spl pi/-calculus
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Introduces a typed /spl pi/-calculus where strong normalisation is ensured by typability. Strong normalisation is a useful property in many computational contexts, including distributed systems. In spite of its simplicity, our type discipline captures a wide class of converging name-passing interactive behaviours. The proof of strong normalisability combines methods from typed /spl lambda/-calculi and linear logic with process-theoretic reasoning. It is adaptable to systems involving state and other extensions. Strong normalisation is shown to have significant consequences, including finite axiomatisation of weak bisimilarity, a fully abstract embedding of the simply-typed /spl lambda/-calculus with products and sums and basic liveness in interaction. Strong normalisability has been extensively studied as a fundamental property in functional calculi, term rewriting and logical systems. This work is one of the first steps to extend theories and proof methods for strong normalisability to the context of name-passing processes.
[process-theoretic reasoning, linear logic, logical systems, liveness, Calculus, Mathematics, type theory, converging name-passing interactive behaviour, Distributed computing, products, pi calculus, interactive systems, typed /spl pi/-calculus, proof methods, distributed systems, finite axiomatisation, bisimulation equivalence, Logic, Functional programming, Context, Embedded computing, abstract embedding, message passing, term rewriting, typed /spl lambda/-calculi, typability, weak bisimilarity, state extensions, Computer science, Computer languages, strong normalisation, Tin, functional calculi, sums]
Safety and liveness in branching time
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Extends B. Alpern & F.B. Schneider's linear time characterization of safety and liveness properties to branching time, where properties are sets of trees. We define two closure operators that give rise to the following four extremal types of properties: universally safe, existentially safe, universally live and existentially live. The distinction between universal and existential properties captures the difference between the CTL (computation tree logic) path quantifiers /spl forall/ (for all paths) and /spl exist/ (there is a path). We show that every branching time property is the intersection of an existentially safe property and an existentially live property, a universally safe property and a universally live property, and an existentially safe property and a universally live property. We also examine how our closure operators behave on linear-time properties. We then focus on sets of finitely branching trees and show that our closure operators agree on linear-time safety properties. Furthermore, if a set of trees is given implicitly as a Rabin tree automaton /spl Bscr/, we show that it is possible to compute the Rabin automata corresponding to the closures of the language of /spl Bscr/. This allows us to effectively compute /spl Bscr//sub safe/ and /spl Bscr//sub live/ such that the language of /spl Bscr/ is the intersection of the languages of /spl Bscr//sub safe/ and /spl Bscr//sub live/. As above, /spl Bscr//sub safe/ and /spl Bscr//sub live/ can be chosen so that their languages are existentially safe and existentially live, universally safe and universally live, or existentially safe and universally live.
[Protocols, formal languages, branching time properties, universal properties, finitely branching trees, trees (mathematics), computation tree logic, temporal logic, Rabin tree automaton, Control systems, closure operators, Boolean algebra, extremal property types, linear time properties, liveness properties, CTL path quantifiers, Automata, safety, intersection, existential properties, Logic functions, language closures, Safety, safety properties]
Semantics of name and value passing
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Provides a semantic framework for (first-order) message-passing process calculi by combining categorical theories of abstract syntax with binding and operational semantics. In particular, we obtain abstract rule formats for name and value passing with both late and early interpretations. These formats induce an initial-algebra/final-coalgebra semantics that is compositional, respects substitution and is fully abstract for late and early congruence. We exemplify the theory with the /spl pi/-calculus and value-passing CCS (calculus of communicating systems).
[1st-order message-passing process calculi, substitution, Laboratories, operational semantics, initial-algebra/final-coalgebra semantics, binding, Concurrent computing, pi calculus, abstract syntax, /spl pi/-calculus, Carbon capture and storage, Informatics, message passing, abstract rule formats, late congruence, programming language semantics, name passing, calculus of communicating systems, value passing, Message passing, early congruence, value-passing CCS, category theory, compositional semantics, Concrete, categorical theories]
Successive approximation of abstract transition relations
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Recently, we have improved the efficiency of the predicate abstraction scheme presented by Das, Dill and Park (1999). As a result, the number of validity checks needed to prove the necessary verification condition has been reduced. The key idea is to refine an approximate abstract transition relation based on the counter-example generated. The system starts with an approximate abstract transition relation on which the verification condition (in our case, this is a safety property) is model-checked. If the property holds then the proof is done; otherwise the model checker returns an abstract counter-example trace. This trace is used to refine the abstract transition relation if possible and start anew. At the end of the process, the system either proves the verification condition or comes up with an abstract counter-example trace which holds in the most accurate abstract transition relation possible (with the user-provided predicates as a basis). If the verification condition fails in the abstract system, then either the concrete system does not satisfy it or the abstraction predicates chosen are not strong enough. This algorithm has been used on a concurrent garbage collection algorithm and a secure contract-signing protocol. This method improved the performance on the first problem significantly, and allowed us to tackle the second problem, which the previous method could not handle.
[Laboratories, History, contracts, validity checks, concurrent garbage collection algorithm, user-provided abstraction predicates, storage management, Boolean functions, formal verification, Prototypes, Static VAr compensators, Libraries, Safety, theorem proving, protocols, verification condition proof, Contracts, approximation theory, efficiency, predicate abstraction scheme, Data structures, approximate abstract transition relation, secure contract signing protocol, security of data, model checking, performance, abstract counter-example trace, Concrete, safety property, successive approximation]
On the decision problem for the guarded fragment with transitivity
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
The guarded fragment with transitive guards, [GF+TG], is an extension of GF in which certain relations are required to be transitive, transitive predicate letters appear only in guards of the quantifiers and the equality symbol may appear everywhere. We prove that the decision problem for [GF+TG] is decidable. This answers the question posed in (Ganzinger et al., 1999). Moreover, we show that the problem is 2EXPTIME-complete. This result is optimal since the satisfiability problem for GF is 2EXPTIME-complete (Gradel, 1999). We also show that the satisfiability problem for two-variable [GF+TG] is NEXPTIME-hard in contrast to GF with bounded number of variables for which the satisfiability problem is EXPTIME-complete.
[decision problem, transitive predicate letters, Knowledge representation, computability, transitive guards, Mathematics, equality symbol, modal logic, NEXPTIME-hard, 2EXPTIME-complete, Computer science, Interpolation, decidability, satisfiability, Distributed databases, guarded fragment, Robustness, Logic, quantifiers, Artificial intelligence, computational complexity]
Synthesizing distributed systems
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
In system synthesis, we transform a specification into a system that is guaranteed to satisfy the specification. When the system is distributed, the goal is to construct the system's underlying processes. Results on multi-player games imply that the synthesis problem for linear specifications is undecidable for general architectures, and is nonelementary decidable for hierarchical architectures, where the processes are linearly ordered and information among them flows in one direction. In this paper, we present a significant extension of this result. We handle both linear and branching specifications, and we show that a sufficient condition for decidability of the synthesis problem is a linear or cyclic order among the processes, in which information flows in either one or both directions. We also allow the processes to have internal hidden variables, and we consider communications with and without delay. Many practical applications fall into this class.
[branching specifications, distributed processing, formal specification, Delay, information flow, Sufficient conditions, underlying processes, decidability, hierarchical architectures, general architectures, Control system synthesis, Logic, sufficient condition, cyclically ordered processes, internal hidden variables, linear specifications, game theory, distributed system synthesis, concurrency theory, linearly ordered processes, Computer science, multi-player games, Open systems, Signal processing, Supervisory control, Signal generators, Signal synthesis, communication delays]
On definability of order in logic with choice
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
We will answer questions due to Blass and Gurevich (2000) on definability of order in the first-order logic with Hilbert's epsilon operation. We show that a linear ordering is almost surely definable in models with random choice.
[formal logic, random choice, Logic programming, Automata, first-order logic, epsilon operation, linear ordering, Mathematics, definability of order, Context modeling]
The Crane Beach Conjecture
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
A language L over an alphabet A is said to have a neutral letter if there is a letter e/spl isin/A such that inserting or deleting e's from any word in A* does not change its membership (or non-membership) in L. The presence of a neutral letter affects the definability of a language in first-order logic. It was conjectured that it renders all numerical predicates apart from the order predicate useless, i.e., that if a language L with a neutral letter is not definable in first-order logic with linear order then it is not definable in first-order. Logic with any set /spl Nscr/ of numerical predicates. We investigate this conjecture in detail, showing that it fails already for /spl Nscr/={+, *}, or possibly stronger for any set /spl Nscr/ that allows counting up to the m times iterated logarithm, 1g/sup (m)/, for any constant m. On the positive side, we prove the conjecture for the case of all monadic numerical predicates, for /spl Nscr/={+}, for the fragment BC(/spl Sigma/) of first-order logic, and for binary alphabets.
[Crane Beach Conjecture, Cranes, definability, first-order logic, monadic numerical predicates, Automatic logic units, language, Complexity theory, binary alphabets, Computational complexity, Computer science, formal logic, Logic circuits, Polynomials, Arithmetic, computational complexity]
Deconstructing Shostak
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Decision procedures for equality in a combination of theories are at the core of a number of verification systems. R.E. Shostak's (J. of the ACM, vol. 31, no. 1, pp. 1-12, 1984) decision procedure for equality in the combination of solvable and canonizable theories has been around for nearly two decades. Variations of this decision procedure have been implemented in a number of specification and verification systems, including STP, EHDM, PVS, STeP and SVC. The algorithm is quite subtle and a correctness argument for it has remained elusive. Shostak's algorithm and all previously published variants of it yield incomplete decision procedures. We describe a variant of Shostak's algorithm, along with proofs of termination, soundness and completeness.
[verification systems, SVC, program verification, Laboratories, Decision feedback equalizers, STeP, completeness, EHDM, PVS, STP, decidability, Static VAr compensators, Constraint theory, Contracts, solvable canonizable theories, termination, equality decision procedures, NASA, soundness, Partitioning algorithms, Equations, Computer science, Shostak's algorithm, formal methods, quantifier-free theory, specification systems, algorithm correctness, Arithmetic]
Probabilistic polynomial-time process calculus and security protocol analysis
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
false
[Body sensor networks, Polynomials, Calculus, Logic design, Security, Cryptography, Standards development, Contracts, Cryptographic protocols, Testing]
Foundational proof-carrying code
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Proof-carrying code is a framework for the mechanical verification of safety properties of machine-language programs, but the problem arises of "quis custodiat ipsos custodes" - i.e. who verifies the verifier itself? Foundational proof-carrying code is verification from the smallest possible set of axioms, using the simplest possible verifier and the smallest possible runtime system. I describe many of the mathematical and engineering problems to be solved in the construction of a foundational proof-carrying code system.
[Java, programming theory, program verification, machine oriented languages, verifier verification, Virtual machining, Application software, engineering problems, runtime system, mechanical program verification, axioms, Program processors, safety, mathematical problems, Marketing and sales, Safety, safety properties, Logic, foundational proof-carrying code, Assembly]
A fully abstract game semantics of local exceptions
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
A fully abstract game semantics for an extension of Idealized Algol with locally declared exceptions is presented. It is based on "Hyland-Ong games" (J.M.E. Hyland & C.-H.L. Ong, 1995), but as well as relaxing the constraints which impose functional behavior (as in games models of other computational effects, such as continuations and references), new structure is added to plays in the form of additional pointers which track the flow of control. The semantics is proved to be fully abstract by a factorization of strategies into a "new-exception generator" and a strategy with local control flow. It is shown, using examples, that there is no model of exceptions which is a conservative extension of the semantics of Idealized Algol without the new pointers.
[Hyland-Ong games, references, abstract game semantics, exception handling, strategy factorization, new-exception generator, local control flow, pointers, Java, programming theory, plays, Computational modeling, abstract data types, game theory, locally declared exceptions, Idealized Algol, control flow tracking, programming language semantics, Programming profession, ALGOL, Computer languages, functional behavior, computational effects, constraint relaxation, continuations, Error correction, Context modeling]
Permutation rewriting and algorithmic verification
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Proposes a natural subclass of regular languages, called alphabetic pattern constraints (APC), which is effectively closed under permutation rewriting, i.e. under iterative application of rules of the form ab/spl rarr/ba. It is well-known that regular languages do not have this closure property in general. Our result can be applied for example to regular model checking, for verifying properties of parametrized linear networks of regular processes and for modeling and verifying properties of asynchronous distributed systems. We also consider the complexity of testing membership in APC, and show that the question is complete for PSPACE when the input is an NFA (nondeterministic finite automaton) and complete for NLOGSPACE when it is a DFA (deterministic finite automaton). Moreover, we show that both the inclusion problem and the question of closure under permutation rewriting are PSPACE-complete when we restrict ourselves to the APC class.
[System testing, parametrized linear networks, complexity, program verification, finite automata, nondeterministic finite automaton, closure property, algorithmic languages, alphabetic pattern constraints, asynchronous distributed systems, Logic testing, deterministic automata, NLOGSPACE-complete problem, permutation rewriting, rewriting systems, Transducers, regular languages, algorithmic verification, regular processes, Radio access networks, model checking, Automata, PSPACE-complete problem, Interleaved codes, deterministic finite automaton, membership testing, Context modeling, computational complexity, iterative rule application]
"An n! lower bound on formula size"
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
We introduce a new Ehrenfeucht-Fraisse game for proving lower bounds on the size of first-order formulas. Up until now such games have only been used to prove bounds on the operator depth of formulas, not their size. We use this game to prove that the CTL/sup +/ formula Occur/sub n//spl equiv/E[Fp/sub 1//spl and/Fp/sub 2//spl and//spl middot//spl middot//spl middot//spl and/F/sub n/] which says that there is a path along which the predicates p/sub 1/ through p/sub n/ occur in some order; requires size n! to express in CTL. Our lower bound is optimal. It follows that the succinctness of CTL+ with respect to CTL is exactly /spl Theta/(n). Wilke (1999) had shown that the succinctness was at least exponential. We also use our games to prove all optimal /spl Theta/(n) lower bound on the number of boolean variables needed for a weak reachability logic (/spl Rscr//spl Lscr//sup w/) to polynomially embed the language LTL. The number of booleans needed for full reachability logic RC and the transitive closure logic FO/sup 2/(TC) remain open (Immerman and Vardi, 1997; Alechina and Immerman, 2000).
[game, transitive closure logic, Circuits, game theory, Size measurement, full reachability logic, lower bound, Computer science, formal logic, succinctness, Boolean functions, first order formula size, CTL, weak reachability logic, boolean variables, computational complexity]
Intuitionistic linear logic and partial correctness
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
We formulate a Gentzen-style sequent calculus for partial correctness that subsumes propositional Hoare logic. The system is a noncommutative intuitionistic linear logic. We prove soundness and completeness over relational and trace models. As a corollary, we obtain a complete sequent calculus for the inclusion and equivalence of regular expressions.
[soundness, Gentzen-style sequent calculus, propositional Hoare logic, equivalent expressions, Calculus, Ambient intelligence, completeness, Logic testing, trace models, formal logic, Algebra, noncommutative intuitionistic linear logic, partial correctness, regular expressions, Logic functions, relational models]
A universal characterization of the closed Euclidean interval
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
We propose a notion of interval object in a category with finite products, providing a universal property for closed and bounded real line segments. The universal property gives rise to an analogue of primitive recursion for defining computable functions on the interval. We use this to define basic arithmetic operations and to verify equations between them. We test the notion in categories of interest. In the category of sets, any closed and bounded interval of real numbers is an interval object. In the category of topological spaces, the interval objects are closed and bounded intervals with the Euclidean topology. We also prove that an interval object exists in and elementary topos with natural numbers object.
[bounded real line segments, elementary topos, set theory, Convergence, topological spaces, arithmetic operations, Logic, Informatics, interval object, Testing, programming theory, primitive recursion, computable functions, Euclidean topology, Mechanical factors, Topology, Equations, closed Euclidean interval, Computer science, process algebra, universal characterization, Set theory, category theory, category, Arithmetic]
Temporal logic query checking
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
A temporal logic query checker takes as input a Kripke structure and a temporal logic formula with a hole, and returns the set of propositional formulas that, when put in the hole, are satisfied by the Kripke structure. By allowing the temporal properties of a system to be discovered, query checking is useful in the study and reverse engineering of systems. Temporal logic query checking was first proposed by W. Chan (2000). In this paper, we generalize and simplify Chan's work by showing how a new class of alternating automata can be used for query checking with a wide range of temporal logics.
[Process design, temporal logic formula, automata theory, Reverse engineering, Lattices, alternating automata, temporal logic, reverse engineering, Logic design, system temporal properties discovery, query processing, hole, Boolean functions, propositional formulas, formal verification, Automata, temporal logic query checking, Kripke structure]
Light affine lambda calculus and polytime strong normalization
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Light linear logic (LLL) and its variant, intuitionistic light affine logic (ILAL), are logics of polytime computation. All polynomial-time functions are representable by proofs of these logics (via the proofs-as-programs correspondence), and, conversely, that there is a specific reduction (cut-elimination) strategy which normalizes a given proof in polynomial time (the latter may well be called the polytime "weak" normalization theorem). In this paper, we introduce an untyped term calculus, called the light affine lambda calculus (/spl lambda//sub LA/), generalizing the essential ideas of light logics into an untyped framework. It is a simple modification of the /spl lambda/-calculus, and has ILAL as a type assignment system. Then, in this generalized setting, we prove the polytime "strong" normalization theorem: any reduction strategy normalizes a given /spl lambda//sub LA/ term (of fixed depth) in a polynomial number of reduction steps, and indeed in polynomial time.
[lambda calculus, cut-elimination strategy, Logic programming, untyped term calculus, /spl lambda//sub LA/-calculus, intuitionistic light affine logic, Calculus, type assignment system, reduction strategy, polynomial-time functions, light affine lambda calculus, polytime strong normalization, polytime computation, Polynomials, Functional programming, light linear logic, proofs-as-programs correspondence, computational complexity]
Perturbed Turing machines and hybrid systems
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Investigates the computational power of several models of dynamical systems under infinitesimal perturbations of their dynamics. We consider models for both discrete- and continuous-time dynamical systems: Turing machines, piecewise affine maps, linear hybrid automata and piecewise-constant derivative systems (a simple model of hybrid systems). We associate with each of these models a notion of perturbed dynamics by a small /spl epsi/ (w.r.t. to a suitable metric), and define the perturbed reachability relation as the intersection of all reachability relations obtained by /spl epsi/-perturbations, for all possible values of /spl epsi/. We show that, for the four kinds of models we consider, the perturbed reachability relation is co-recursively enumerable (co-r.e.), and that any co-r.e. relation can be defined as the perturbed reachability relation of such models. A corollary of this result is that systems that are robust (i.e. whose reachability relation is stable under infinitesimal perturbation) are decidable.
[Chaos, perturbation techniques, perturbed reachability relation, piecewise constant techniques, robust systems, perturbed dynamics, dynamics, Turing machines, decidability, hybrid systems, infinitesimal perturbations, discrete-time dynamical systems, piecewise-constant derivative systems, Robustness, continuous time systems, stability, reachability analysis, Robust stability, Computational modeling, discrete time systems, perturbed Turing machines, piecewise affine maps, State-space methods, Power system modeling, co-recursively enumerable relations, continuous-time dynamical systems, Automata, metrics, linear hybrid automata]
Intensionality, extensionality, and proof irrelevance in modal type theory
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
We develop a uniform type theory that integrates intensionality, extensionality and proof irrelevance as judgmental concepts. Any object may be treated intensionally (subject only to /spl alpha/-conversion), extensionally (subject also to /spl beta//spl eta/-conversion), or as irrelevant (equal to any other object at the same type), depending on where it occurs. Modal restrictions developed by R. Harper et al. (2000) for single types are generalized and employed to guarantee consistency between these views of objects. Potential applications are in logical frameworks, functional programming and the foundations of first-order modal logics. Our type theory contrasts with previous approaches that, a priori, distinguished propositions (whose proofs are all identified - only their existence is important) from specifications (whose implementations are subject to some definitional equalities).
[Heart, uniform type theory, /spl beta//spl eta/-conversion, proof irrelevance, Logic programming, object views, 1st-order modal logics, functional programming, logical frameworks, type theory, specifications, Computer science, formal logic, definitional equalities, intensionally, propositions, modal type theory, modal restrictions, judgmental concepts, consistency guarantee, extensionality, Functional programming, /spl alpha/-conversion]
From verification to control: dynamic programs for omega-regular objectives
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Dynamic programs, or fixpoint iteration schemes, are useful for solving many problems on state spaces. For Kripke structures, a rich fixpoint theory is available in the form of the /spl mu/-calculus, yet few connections have been made between different interpretations of fixpoint algorithms. We study the question of when a particular fixpoint iteration scheme /spl phi/ for verifying an /spl omega/-regular property /spl Psi/ on a Kripke structure can be used also for solving a two-player game on a game graph with winning objective /spl Psi/. We provide a sufficient and necessary criterion for the answer to be affirmative in the form of an extremal-model theorem for games: under a game interpretation, the dynamic program /spl phi/ solves the game with objective /spl Psi/ iff both (1) under an existential interpretation on Kripke structures, /spl phi/ is equivalent to /spl exist//spl Psi/, and (2) under a universal interpretation on Kripke structures, /spl phi/ is equivalent to /spl forall//spl Psi/. In other words, /spl phi/ is correct on all two-player game graphs iff it is correct on all extremal game graphs, where one or the other player has no choice of moves. The theorem generalizes to quantitative interpretations, where it connects two-player games with costs to weighted graphs. While the standard translations from /spl omega/-regular properties to the /spl mu/-calculus violate (1) or (2), we give a translation that satisfies both conditions. Our construction, therefore, yields fixpoint iteration schemes that can be uniformly applied on Kripke structures, weighted graphs, game graphs, and game graphs with costs, in order to meet or optimize a given /spl omega/-regular objective.
[Kripke structures, iterative methods, game graphs, control theory, graph theory, /spl mu/-calculus, universal interpretation, Calculus, existential interpretation, omega-regular objectives, formal verification, quantitative interpretations, weighted graphs, optimization, Cost function, fixpoint iteration schemes, sufficient condition, verification, costs, fixpoint algorithm interpretations, game theory, dynamic programming, game interpretation, control, State-space methods, state spaces, dynamic programs, Game theory, extremal-model theorem, Equations, necessary condition, winning objective, model checking, process algebra, shortest paths, 2-player game, state-space methods]
Deterministic generators and games for LTL fragments
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Deciding infinite two-player games on finite graphs with the winning condition specified by a linear temporal logic (LTL) formula is known to be 2EXPTIME-complete. In this paper, we identify LTL fragments of lower complexity. Solving LTL games typically involves a doubly-exponential translation from LTL formulas to deterministic /spl omega/-automata. First, we show that the longest distance (length of the longest simple path) of the generator is also an important parameter, by giving an O(d log n)-space procedure to solve a Buchi game on a graph with n vertices and longest distance d. Then, for the LTL fragment with only eventualities and conjunctions, we provide a translation to deterministic generators of exponential size and linear longest distance, show both of these bounds to be optimal and prove the corresponding games to be PSPACE-complete. Introducing "next" modalities in this fragment, we provide a translation to deterministic generators that is still of exponential size but also with exponential longest distance, show both bounds to be optimal and prove the corresponding games to be EXPTIME-complete. For the fragment resulting by further adding disjunctions, we provide a translation to deterministic generators of doubly-exponential size and exponential longest distance, show both bounds to be optimal and prove the corresponding games to be EXPSPACE. Finally, we show tightness of the double-exponential bound on the size as well as the longest distance for deterministic generators for LTL, even in the absence of "next" and "until" modalities.
[optimal bounds, graph theory, conjunctions, winning condition, temporal logic, eventualities, PSPACE-complete games, decidability, Buchi game, deterministic automata, EXPSPACE games, Logic, doubly-exponential translation, infinite 2-player games, linear temporal logic formulas, until modalities, Engineering profession, Computational modeling, exponential-size translation, 2EXPTIME-complete problem, deterministic /spl omega/-automata, game theory, disjunctions, Automata, Open systems, longest simple path, NIST, next modalities, LTL fragments, finite graphs, deterministic generators, computational complexity, EXPTIME-complete games]
Normalization by evaluation for typed lambda calculus with coproducts
Proceedings 16th Annual IEEE Symposium on Logic in Computer Science
None
2001
Solves the decision problem for the simply typed lambda calculus with a strong binary sum, or, equivalently, the word problem for free Cartesian closed categories with binary co-products. Our method is based on the semantic technique known as "normalization by evaluation\
[lambda calculus, decision problem, unique normal form, Terminology, free Cartesian closed categories, normalization by evaluation, strong binary sum, Calculus, type theory, Equations, program extraction, sheaf model, Computer languages, typed lambda calculus, decidability, word problem, constructive proof, category theory, theorem proving, semantic technique, Logic, Informatics, inverted syntax interpretation, binary co-products]
Little engines of proof
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
Summary form only given. The automated construction of mathematical proof is a basic activity in computing. Since the dawn of the field of automated reasoning, there have been two divergent schools of thought. One school, best represented by Alan Robinson's resolution method, is based on simple uniform proof search procedures guided by heuristics. The other school, pioneered by Hao Wang, argues for problem-specific combinations of decision and semi-decision procedures. While the former school has been dominant in the past, the latter approach has greater promise. In recent years, several high quality inference engines have been developed, including propositional satisfiability solvers, ground decision procedures for equality and arithmetic, quantifier elimination procedures for integers and reals, and abstraction methods for finitely approximating problems over infinite domains. We describe some of these "little engines of proof" and a few of the ways in which they can be combined. We focus in particular on the combination ground decision procedures and their use in automated verification. We conclude by arguing for a modem reinterpretation and reappraisal of Hao Wang's hitherto neglected ideas on inferential analysis.
[Laboratories, NASA, Europe, inference engines, computability, Educational institutions, Decision feedback equalizers, inference mechanisms, Engines, inferential analysis, Computer science, Uniform resource locators, uniform proof search, automated reasoning, mathematical proof, theorem proving, Contracts, Arithmetic]
Semantic subtyping
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
Usually subtyping relations are defined either syntactically by a formal system or semantically by an interpretation of types in an untyped denotational model. In this paper we show how to define a subtyping relation semantically, for a language whose operational semantics is driven by types; we consider a rich type algebra, with product, arrow, recursive, intersection, union and complement types. Our approach is to "bootstrap" the subtyping relation through a notion of set-theoretic model of the type algebra. The advantages of the semantic approach are manifold. Foremost we get "for free" many properties (e.g., the transitivity of subtyping) that, with axiomatized subtyping, would require tedious and error prone proofs. Equally important is that the semantic approach allows one to derive complete algorithms for the subtyping relation or the propagation of types through patterns. As the subtyping relation has a natural (inasmuch as semantic) interpretation, the type system can give informative error messages when static type-checking fails. Last but not least the approach has an immediate impact in the definition and the implementation of languages manipulating XML documents, as this was our original motivation.
[set-theoretic model, type algebra, operational semantics, XML documents, formal system, type theory, programming language semantics, subtyping relations, Programming profession, semantic subtyping, Algebra, Databases, error prone proofs, XML, untyped denotational model, axiomatized subtyping]
Dense real-time games
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
The rapid development of complex and safety-critical systems requires the use of reliable verification methods and tools for system design (synthesis). Many systems of interest are reactive, in the sense that their behavior depends on the interaction with the environment. A natural framework to model them is a two-player game: the system versus the environment. In this context, the central problem is to determine the existence of a winning strategy according to a given winning condition. We focus on real-time systems, and choose to model the related game as a nondeterministic timed automaton. We express winning conditions by formulas of the branching-time temporal logic TCTL. While timed games have been studied in the literature, timed games with dense-time winning conditions constitute a new research topic. The main result of this paper is an exponential-time algorithm to check for the existence of a winning strategy for TCTL games where equality is not allowed in the timing constraints. Our approach consists on translating to timed tree automata both the game graph and the winning condition, thus reducing the considered decision problem to the emptiness problem for this class of automata. The proposed algorithm matches the known lower bound on timed games. Moreover, if we relax the limitation we have placed on the timing constraints, the problem becomes undecidable.
[Real time systems, exponential-time algorithm, Indium tin oxide, safety-critical software, game theory, dense real-time games, temporal logic, system design, Game theory, Computer science, safety-critical systems, winning strategy, Tree graphs, decidability, reliable verification methods, Automata, systems analysis, real-time systems, two-player game, Open systems, branching-time temporal logic, Timing, Logic, Clocks]
Decidable and undecidable fragments of first-order branching temporal logics
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
In this paper we analyze the decision problem for fragments of first-order extensions of branching time temporal logics such as computational tree logics CTL and CTL* or Prior's Ockhamist logic of historical necessity. On the one hand, we show that the one-variable fragments of logics like first-order CTL*-such as the product of propositional CTL* with simple propositional modal logic S5, or even the one-variable bundled first-order temporal logic with sole temporal operator 'some time in the future'-are undecidable. On the other hand, it is proved that by restricting applications of first-order quantifiers to state (i.e., path-independent) formulas, and applications of temporal operators and path quantifiers to formulas with at most one free variable, we can obtain decidable fragments. The positive decidability results can serve as a unifying framework for devising expressive and effective time-dependent knowledge representation formalisms, e.g., temporal description or spatio-temporal logics.
[decision problem, decidable fragments, Knowledge representation, computability, temporal logic, Ockhamist logic, first-order branching temporal logics, Educational institutions, Turning, first-order quantifiers, Application software, History, inference mechanisms, computational tree logics, branching time temporal logics, undecidable fragments, Computer science, decidability, first-order extensions, Logic]
The metric analogue of weak bisimulation for probabilistic processes
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We observe that equivalence is not a robust concept in the presence of numerical information - such as probabilities-in the model. We develop a metric analogue of weak bisimulation in the spirit of our earlier work on metric analogues for strong bisimulation. We give a fixed point characterization of the metric. This makes available conductive reasoning principles and allows us to prove metric analogues of the usual algebraic laws for process combinators. We also show that quantitative properties of interest are continuous with respect to the metric, which says that if two processes are close in the metric then observable quantitative properties of interest are indeed close. As an important example of this we show that nearby processes have nearby channel capacities - a quantitative measure of their propensity to leak information.
[equivalence, Channel capacity, metric analogue, concurrency theory, Probability distribution, State-space methods, Distributed computing, concurrency, Computer science, Concurrent computing, calculus of communicating systems, Boolean functions, Stochastic systems, Robustness, bisimulation equivalence, information theory, Logic, weak bisimulation]
Unsatisfiable random formulas are hard to certify
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We prove that every property of 3CNF formulas that implies unsatisfiability and is expressible in Datalog has asymptotic probability zero when formulas are randomly generated by taking 6n non-trivial clauses of exactly three literals uniformly and independently. Our result is a consequence of designing a winning strategy for Duplicator in the existential k-pebble game on the structure that encodes the 3CNF formula and a fixed template structure encoding a satisfiable formula. The winning strategy makes use of certain extension axioms that we introduce and hold almost surely on a random 3CNF formula. An interesting feature of our result is that it brings the fields of propositional proof complexity and finite model theory together. To make this connection more explicit, we show that Duplicator wins the existential pebble game on the structure encoding the pigeonhole principle and the template structure above. Moreover, we also prove that there exists a 2k-Datalog program expressing that an input 3CNF formula has a resolution refutation of width k. As a consequence to our result and the known size-width relationship in resolution, we obtain new proofs of the exponential lower bounds for resolution refutations of random 3CNF formulas and the pigeonhole principle.
[Datalog, probability, unsatisfiable random formulas, computability, Encoding, Calculus, Computational complexity, 3CNFformula, fixed template structure, Computer science, formal logic, asymptotic probability, 3CNF formulas, winning strategy, 2k-Datalog program, Polynomials, k-pebble game, Logic, computational complexity]
The 0-1 law fails for frame satisfiability of propositional modal logic
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
The digraph property KERNEL is a very simple and wellknown property studied in various areas. We previously defined a variant of this property as a counterexample of 0-1 law for the monadic existential second order logic with at most two first-order variables, over structures with 16 binary relations. Goranko and Kapron have defined two variants in frames which expresses frame satisfiability of propositional modal logic, also expressible in a small fragment of the logic above over structures with only one relation. We propose another variant of KERNEL which provides a counterexample of the 0-1 law for frame satisfiability of propositional modal logic. This refutes a result by Halpern and Kapron which establishes that the 0-1 law holds for this logic. It also strongly refines our previous counterexample.
[Vocabulary, Computational modeling, H infinity control, computability, temporal logic, temporal logics, Computational complexity, Combinatorial mathematics, formal logic, digraph property, KERNEL, frame satisfiability, propositional modal logic, Logic, Kernel, monadic existential second order logic, Bars, computational complexity]
Monadic queries over tree-structured data
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
Monadic query languages over trees currently receive considerable interest in the database community, as the problem of selecting nodes from a tree is the most basic and widespread database query problem in the context of XML. Partly a survey of recent work done by the authors and their group on logical query languages for this problem and their expressiveness, this paper provides a number of new results related to the complexity of such languages over so-called axis relations (such as "child" or "descendant") which are motivated by their presence in the XPath standard or by their utility for data extraction (wrapping).
[complexity, formal languages, logical query languages, database query, monadic query, Natural languages, query languages, Spatial databases, Information filtering, Data mining, Database languages, Wrapping, monadic query languages, monadic logic, data extraction, XML, Information filters, tree data structures, Logic, tree-structured data, Artificial intelligence, computational complexity, hypermedia markup languages]
On the lambda Y calculus
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
In this paper we consider three problems concerning the lambda Y calculus obtained from the simply typed lambda calculus by the addition of fixed point combinators Y: (A/spl rarr/A)/spl rarr/A. The "paradoxical" combinator Y was first discussed in by Curry & Feys Vol 1 (1958). It appears first in a typed context by A. Scott (1969) and also by R. Platek's thesis (1963), and forms the basis for L. C. F. (1980) and its descendants. In this paper we shall consider (1) the question of whether higher type Y are "definable" from lower type Y. We shall show that it is not the case in this context, sharpening a result of ours from [8]. A similar result has been obtained by Warner Damm; (2) the question of the decidability of termination. More precisely, we shall show that it is decidable whether a given term has a normal form. This extends results of Plotkin and Bercovicci. [2]. By similar methods we show that we show that it is decidable whether a term has a head normal form, and whether a term has a finite Bohm tree; (3) the question of the decidability of the word problem. This question was first put to us by Albert Meyer 20 years ago. We shall show that it is in general undecidable whether two lambda Y terms convert. This is done by encoding the behavior of register machines. In addition we shall give a decision procedure for the special case of only Y's of type (0/spl rarr/0)/spl rarr/0.
[lambda calculus, Standardization, fixed point combinators, Calculus, Magnetic heads, Encoding, type theory, finite Bohm tree, Equations, Computer science, typed lambda calculus, decidability, lambda Y calculus, Logic]
Polarized games
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We generalize the intuitionistic Hyland-Ong games to a notion of polarized games allowing games with plays starting by proponent moves. The usual constructions on games are adjusted to fit this setting yielding a game model for polarized linear logic with a definability result. As a consequence this gives a complete game model for various classical systems: LC, /spl lambda//spl mu/-calculus,... for both call-by-name and call-by-value evaluations.
[Polarization, Embedded computing, polarized games, Logic programming, definability, call-by-name, game theory, Computer science, formal logic, Computer languages, Waste materials, /spl lambda//spl mu/-calculus, process algebra, LC, intuitionistic games, polarized linear logic, call-by-value]
Complete problems for dynamic complexity classes
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We present the first complete problems for dynamic complexity classes including the classes Dyn-FO and Dyn-ThC/sup 0/, the dynamic classes corresponding to relational calculus and (polynomially bounded) SQL, respectively. The first problem we show complete for Dyn-FO is a single-step version of the circuit value problem (SSCV). Of independent interest, our construction also produces a first-order formula, /spl zeta/, that is in a sense universal for all first-order formulas. Since first-order formulas are stratified by quantifier depth, the first-order formula /spl zeta/ emulates formulas of greater depth by iterated application. As a corollary we obtain a fixed quantifier block, QBC, that is complete for all first-order quantifier blocks.
[dynamic complexity classes, Heuristic algorithms, relational algebra, Circuits, dynamic classes, polynomially bounded SQL, Data structures, Calculus, Complexity theory, Application software, complete problems, Computer science, matrix multiplication, first-order formula, Databases, quantifier depth, first-order quantifier blocks, circuit value problem, Polynomials, Logic, computational complexity, relational calculus]
Tree-like counterexamples in model checking
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
Counter examples for specification violations provide engineers with important debugging information. Although counterexamples are considered one of the main advantages of model checking, state-of the art model checkers are restricted to relatively simple counterexamples, and surprisingly little research effort has been put into counterexamples. In this paper, we introduce a new general framework for counterexamples. The paper has three main contributions: (i) We determine the general form of ACTL counterexamples. To this end, we investigate the notion of counterexample and show that a large class of temporal logics beyond ACTL admits counterexamples with a simple tree-like transition relation. We show that the existence of tree-like counterexamples is related to a universal fragment of extended branching time logic based on w-regular temporal operators. (ii) We present new symbolic algorithms to generate tree-like counterexamples for ACTL specifications. (iii) Based on tree-like counterexamples we extend the abstraction refinement methodology developed recently by Clarke et al. (CAV'2000) to full ACTL. This demonstrates the conceptual simplicity and elegance of tree-like counterexamples.
[Art, temporal operator, Government, Switches, Debugging, temporal logic, counterexamples, branching time logic, universal logics, Computer science, Intelligent networks, model checking, Computer networks, symbolic algorithms, Logic, Contracts]
Calibrating computational feasibility by abstraction rank
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We characterize computationally the functions provable in second order logic with set existence restricted to natural classes of first order formulas. A classification of first-order set-existence by implicational rank yields a natural hierarchy of complexity classes within the class of Kalmar-elementary functions: The functions over {0, 1}* constructively provable using set existence for formulas of implicational rank /spl les/k are precisely the functions computable in deterministic time O(exp/sub k/(n)), where exp/sub 0/=U/sub k/(/spl lambda/n.n/sup k/), and exp/sub k+1/=2(exp/sub k/)./sup 1/ In particular, set-existence for positive formulas yields exactly PTime. We thus obtain lean and natural formalisms for codifying feasible mathematics, which are expressive both in allowing second order definitions and reasoning, and in incorporating equational programming and reasoning about program convergence in a direct and uncoded style. Through a formula-as-type morphism, we also obtain a link with lambda definability, which we exhibit in the full paper: The functions over {0, 1}* definable in the polymorphic lambda calculus F/sub 2/ over a base of type of words, using first-order type-arguments of rank /spl les/k, are precisely the functions computable in deterministic time O(exp/sub k/(n))./sup 2/ The poly-time case was proved (directly) in [15].
[reasoning, polymorphic lambda calculus, Mathematics, Calculus, implicational rank, deterministic time, natural hierarchy, formal logic, first-order type-arguments, formula-as-type morphism, equational programming, first order formulas, Kalmar-elementary functions, computational feasibility, Logic, Size control, natural classes, Mathematical programming, program convergence, second order logic, lambda calculus, lambda definability, complexity classes, Reasoning about programs, Calibration, abstraction rank, Computational complexity, Equations, Arithmetic, computational complexity]
The complexity of first-order and monadic second-order logic revisited
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
The model-checking problem for a logic L on a class C of structures asks whether a given L-sentence holds in a given structure in C. In this paper, we give super-exponential lower bounds for fixed-parameter tractable model-checking problems for first-order and monadic second-order logic. We show that unless PTIME=NP, the model-checking problem for monadic second-order logic on finite words is not solvable in time f(k)/spl middot/p(n), for any elementary function f and any polynomial p. Here k denotes the size of the input sentence and n the size of the input word. We prove the same result for first-order logic under a stronger complexity theoretic assumption from parameterized complexity theory. Furthermore, we prove that the model-checking problems for first-order logic on structures of degree 2 and of bounded degree d/spl ges/3 are not solvable in time 2(2/sup o(k)/)/spl middot/p(n) (for degree 2) and 2(2/sup 2o(k)/)/spl middot/p(n) (for degree d), for any polynomial p, again under an assumption from parameterized complexity theory. We match these lower bounds by corresponding upper bounds.
[complexity, program verification, first-order logic, PSPACE-complete, Complexity theory, State-space methods, monadic logic, Computer science, formal logic, Upper bound, Databases, model-checking problem, second-order logic, finite words, Polynomials, logic, Logic, L-sentence, Informatics, Artificial intelligence, computational complexity]
Computing reachability relations in timed automata
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We give an algorithmic calculus of the reachability relations on clock values defined by timed automata. Our approach is a modular one, by computing unions, compositions and reflexive-transitive closure (star) of "atomic" relations. The essential tool is a new representation technique for n-clock relations - the 2n-automata - and our strategy is to show the closure under union, composition and star of the class of 2n-automata that represent reachability relations in timed automata.
[Real time systems, reachability analysis, finite automata, algorithmic calculus, Calculus, Time measurement, reflexive-transitive closure, Matrix decomposition, Automata, real-time systems, reachability, timed automata, Clocks, Arithmetic]
Semantic minimization of 3-valued propositional formulae
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
This paper presents an algorithm for a non-standard logic-minimization problem that arises in 3-valued propositional logic. The problem is motivated by the potential for obtaining better answers in applications that use 3-valued logic. An answer of 0 or 1 provides precise (definite) information; an answer of 1/2 provides imprecise (indefinite) information. By replacing a formula /spl phi/ with a "better" formula /spl psi/, we may improve the precision of the answers obtained. In this paper we give an algorithm that always produces a formula that is "best" (in a certain well-defined sense).
[3-valued logic, Data analysis, Uncertainty, Minimization methods, Terminology, propositional logic, 3-valued propositional logic, Information analysis, minimisation of switching nets, logic minimization, Software systems, Hardware, ternary logic, Logic, Contracts]
A stratified semantics of general references embeddable in higher-order logic
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We demonstrate a semantic model of general references - that is, mutable memory cells that may contain values of any (statically-checked) closed type, including other references. Our model is in terms of execution sequences on a von Neumann machine; thus, it can be used in a Proof-Carrying Code system where the skeptical consumer checks even the proofs of the typing rules. The model allows us to prove a frame-axiom introduction rule that allows locality of specification and reasoning, even in the event of updates to aliased locations. Our proof is machine-checked in the Twelf metalogic.
[higher-order logic, mutable memory cells, frame-axiom introduction rule, Java, Object oriented modeling, proofcarrying code system, reasoning, Data structures, inference mechanisms, semantic model, Computer science, formal logic, Computer languages, general references, Twelf metalogic, von Neumann machine, Safety, stratified semantics, Logic, Arithmetic]
Remarks on isomorphisms in typed lambda calculi with empty and sum types
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
Tarski asked whether the arithmetic identities taught in high school are complete for showing all arithmetic equations valid for the natural numbers. The answer to this question for the language of arithmetic expressions using a constant for the number one and the operations of product and exponentiation is affirmative, and the complete equational theory also characterises isomorphism in the typed lambda calculus, where the constant for one and the operations of product and exponentiation respectively correspond to the unit type and the product and arrow type constructors. This paper studies isomorphisms in typed lambda calculi with empty and sum types from this viewpoint. We close an open problem by establishing that the theory of type isomorphisms in the presence of product, arrow, and sum types (with or without the unit type) is not finitely axiomatisable. Further, we observe that for type theories with arrow, empty and sum types the correspondence between isomorphism and arithmetic equality generally breaks down, but that it still holds in some particular cases including that of type isomorphism with the empty type and equality with zero.
[lambda calculus, sum types, Logic programming, complete equational theory, Laboratories, empty types, Educational institutions, Calculus, type theory, typed lambda calculi, Equations, arithmetic equations, Computer languages, typed lambda calculus, Algebra, isomorphisms, arithmetic identities, Digital arithmetic, Libraries, Functional programming]
Games on graphs and sequentially realizable functionals. Extended abstract
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We present a new category of games on graphs and derive from it a model for Intuitionistic Linear Logic. Our category has the computational flavour of concrete data structures but embeds fully and faithfully in an abstract games model. It differs markedly from the usual Intuitionistic Linear Logic setting for sequential algorithms. However, we show that with a natural exponential we obtain a model for PCF essentially equivalent to the sequential algorithms model. We briefly consider a more extensional setting and the prospects for a better understanding of the Longley Conjecture.
[Algorithm design and analysis, games on graphs, Embedded computing, intuitionistic linear logic, graph theory, abstract games model, game theory, equivalences, Data structures, Computer science, formal logic, PCF, Tree graphs, category of games, graph game, Concrete, Logic, Mathematical model]
The powerdomain of indexed valuations
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
This paper is about combining nondeterminism and probabilities. We study this phenomenon from a domain theoretic point of view. In domain theory, nondeterminism is modeled using the notion of powerdomain, while probability is modeled using the powerdomain of valuations. Those two functors do not combine well, as they are. We define the notion of powerdomain of indexed valuations, which can be combined nicely with the usual nondeterministic powerdomain. We show an equational characterization of our construction. Finally we discuss the computational meaning of indexed valuations, and we show how they can be used, by giving a denotational semantics of a simple imperative language.
[Computational modeling, equational characterization, Laboratories, probability, Probability distribution, programming language semantics, Cost accounting, Equations, powerdomain, Computer science, Algebra, Character generation, imperative language, Logic, indexed valuations, denotational semantics, domain theory]
Deciding confluence of certain term rewriting systems in polynomial time
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We present a polynomial time algorithm for deciding confluence of ground term rewrite systems. We generalize the decision procedure to get a polynomial time algorithm, assuming that the maximum arity of a symbol in the signature is a constant, for deciding confluence of rewrite systems where each rule contains a shallow linear term on one side and a ground term on the other. The existence of a polynomial time algorithm for deciding confluence of ground rewrite systems was open for a long time and was independently solved only recently. Our decision procedure is based on the concepts of abstract congruence closure and abstract rewrite closure.
[rewriting systems, Transducers, NASA, abstract rewrite closure, polynomial time algorithm, Equations, Computer science, rewrite systems, Automata, decision procedure, ground rewrite systems, abstract congruence closure, Polynomials, polynomial time, Logic, Testing, computational complexity]
Efficient type inference for record concatenation and subtyping
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
Record concatenation, multiple inheritance, and multiple-object cloning are closely related and part of various language designs. For example, in Cardelli's untyped Obliq language, a new object can be constructed from several existing objects by cloning followed by concatenation; an error is given in case of field name conflicts. Type systems for record concatenation have been studied by M. Wand (1991), R. Harper and B. Pierce (1991), D. Remy (1992), and others; and type inference for the combination of record concatenation and subtyping has been studied by M. Sulzmann (1997) and by F. Pottier (2000). In this paper we present the first polynomial-time type inference algorithm for record concatenation, subtyping, and recursive types. Our example language is the Abadi-Cardelli object calculus extended with a concatenation operator The type inference algorithm runs in O(n/sup 5/) time where n is the size of the program. Our algorithm enables efficient type checking of Obliq programs without changing the programs at all.
[record concatenation, multiple inheritance, recursive types, Cloning, Calculus, type theory, Concatenated codes, inference mechanisms, subtyping, Abadi-Cardelli object calculus, Computer science, Runtime, multiple-object cloning, Obliq language, Polynomials, Inference algorithms, Logic, polynomial-time type inference algorithm]
Automatic decidability
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We give a set of inference rules with constant constraints. Then we show how to extend a set of equational clauses, so that if the application of these inference rules halts on these clauses, then the theory is decidable by applying a standard set of Paramodulation inference rules. In addition, we can determine the number of clauses generated in this decision procedure. For some theories, such as the theory of lists, there are 0(n /spl times/ lg(n)) clauses. For others it is polynomial. And for others it is simply exponential such as the theory of (extensional) arrays.
[inference rules, Automation, equational clauses, Data structures, Mathematics, Application software, inference mechanisms, Equations, Computer science, constant constraints, decidability, first order logic, Polynomials, Inference algorithms, Logic, Faramodulation inference rules]
The proof complexity of linear algebra
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We introduce three formal theories of increasing strength for linear algebra in order to study the complexity of the concepts needed to prove the basic theorems of the subject. We give what is apparently the first feasible proofs of the Cayley-Hamilton theorem and other properties of the determinant, and study the propositional proof complexity of matrix identities.
[Educational institutions, matrix identities, Parallel algorithms, Galois fields, Lagrangian functions, Computer science, propositional proof complexity, Linear algebra, Matrices, Polynomials, Logic, linear algebra, Cayley-Hamilton theorem, computational complexity]
Some results on automatic structures
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We study the class of countable structures which can be presented by synchronous finite automata. We reduce the problem of existence of an automatic presentation of a structure to that for a graph. We exhibit a series of properties of automatic equivalence structures, linearly ordered sets and permutation structures. These serve as a first step in producing practical descriptions of some automatic structures or illuminating the complexity of doing so for others.
[complexity, Terminology, finite automata, Automatic logic units, countable structures, Mathematics, linear orderings, Computer science, permutation structures, automatic structures, Automata, equivalence structures, Polynomials, equivalence classes, computational complexity]
Tree extension algebras: logics, automata, and query languages
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We study relations on trees defined by first-order constraints over a vocabulary that includes the tree extension relation T<T', holding if and only if every branch of T extends to a branch of T', unary node-tests, and a binary relation checking if the domains of two trees are equal. We show that from such a formula one can generate a tree automaton that accepts the set of tuples of trees defined by the formula, and conversely that every automaton over tree-tuples is captured by such a formula. We look at the fragment with only extension inequalities and leaf tests, and show that it corresponds to a new class of automata on tree tuples, which is strictly weaker then general tree-tuple automata. We use the automata representations to show separation and expressibility results for formulae in the logic. We then turn to relational calculi over the logic defined here: that is, from constraints we extend to queries that have second-order parameters for a finite set of tree tuples. We give normal forms for queries, and use these to get bounds on the data complexity of query evaluation, showing that while general query evaluation is unbounded within the polynomial hierarchy, generic query evaluation has very low complexity giving strong bounds on the expressive power of relational calculi with tree extension constraints. We also give normal forms for safe queries in the calculus.
[Vocabulary, complexity, Transducers, logics, Logic programming, automata theory, relational algebra, polynomial hierarchy, tree tuples, query languages, Database languages, trees, Computer science, tree extension algebras, Algebra, Query processing, tree structures, Automata, XML, Logic functions, automata, relational calculi, computational complexity]
Domain theory and differential calculus (functions of one variable)
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
A data-type for differential calculus is introduced, which is based on domain theory. We define the integral and also the derivative of a Scott continuous function on the domain of intervals, and present a domain-theoretic generalization of the fundamental theorem of calculus. We then construct a domain for differentiable real valued functions of a real variable. The set of classical C/sup 1/ functions, equipped with its C/sup 1/ norm, is embedded into the set of maximal elements of this domain, which is a countably based bounded complete continuous domain. This gives a data type for differential calculus. The construction can be generalized to C/sup k/ and C/sup /spl infin// functions. As an immediate application, we present a domain-theoretic generalization of Picard's theorem, which provides a data type for solving differential equations.
[differential calculus, Uncertainty, differentiation, computability, Educational institutions, Calculus, Mathematics, Logic design, type theory, data-type, Application software, differential equations, Pathology, Differential equations, Approximation algorithms, Polynomials, Scott continuous function, domain theory]
Expressive equivalence of least and inflationary fixed-point logic
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We study the relationship between least and inflationary fixed-point logic. By results of Gurevich and Shelah (1986), it has been known that on finite structures both logics have the same expressive power. On infinite structures however the question whether there is a formula in IFP not equivalent to any LFP-formula was still open. In this paper, we settle the question by showing that both logics are equally expressive on arbitrary structures. The proof will also establish the strictness of the nesting-depth hierarchy for IFP on some infinite structures. Finally, we show that the alternation hierarchy for IFP collapses to the first level on all structures, i.e. the complement of an inflationary fixed-point is an inflationary fixed-point itself.
[expressive equivalence, least fixed-point logic, finite structures, inflationary fixed-point logic, Relational databases, nesting-depth hierarchy, Calculus, History, Database languages, Computational complexity, expressive power, Computer science, formal logic, Polynomials, Logic, Artificial intelligence, equivalence classes, Arithmetic]
Probabilistic abstraction for model checking: an approach based on property testing
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
The goal of model checking is to verify the correctness of a given program, on all its inputs. The main obstacle, in many cases, is the intractably large size of the program's transition system. Property testing is a randomized method to verify whether some fixed property holds on individual inputs, by looking at a small random part of that input. We join the strengths of both approaches by introducing a new notion of probabilistic abstraction, and by extending the framework of model checking to include the use of these abstractions. Our abstractions map transition systems associated with large graphs to small transition systems associated with small random subgraphs. This reduces the original transition system to a family of small, even constant-size, transition systems. We prove that with high probability, "sufficiently" incorrect programs will be rejected (E-robustness). We also prove that under a certain condition (exactness), correct programs will never be rejected (soundness). Our work applies to programs for graph properties such as bipartiteness, k-colorability, or any /spl exist//spl forall/ first order graph properties. Our main contribution is to show how to apply the ideas of property testing to syntactic programs for such properties. We give a concrete example of an abstraction for a program for bipartiteness. Finally, we show that the relaxation of the test alone does not yield transition systems small enough to use the standard model checking method. More specifically, we prove, using methods from communication complexity, that the OBDD size remains exponential for approximate bipartiteness.
[System testing, correctness, program verification, temporal logic, Data structures, Complexity theory, property testing, Application software, abstraction method, Combinatorial mathematics, Computer science, Computer languages, model checking, transition systems, Sampling methods, verification of programs, Concrete, Logic]
Description logics: foundations for class-based knowledge representation
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
Class-based languages express knowledge in terms of objects and classes, and have inspired a huge number of formalisms in computer science. Description logics forma family of both class-based and logic-based knowledge representation languages which allow for modeling an application domain in terms of objects, classes and relationships between classes, and for reasoning about them. This paper presents an overview of the research carried out in the last years in description logics, with the main goal of illustrating how these logics provide the foundations for class-based knowledge representation formalisms.
[application domain, Logic programming, Object oriented databases, Object oriented modeling, Knowledge representation, reasoning, class-based knowledge representation, Specification languages, Application software, Remuneration, inference mechanisms, class-based languages, Computer science, Computer languages, description logics, decidability, knowledge representation, formalisms, Software engineering, computational complexity]
Separability, expressiveness, and decidability in the ambient logic
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
The Ambient Logic (AL) has been proposed for expressing properties of process mobility in the calculus of Mobile Ambients (MA), and as a basis for query languages on semistructured data. We study some basic questions concerning the descriptive and discriminating power of AL, focusing on the equivalence on processes induced by the logic (=/sub L/). We consider MA, and two Turing complete subsets of it, MA/sub IF/ and MA/sub IF//sup syn/, respectively defined by imposing a semantic and a syntactic constraint on process prefixes. The main contributions include: coinductive and inductive operational characterisations of =/sub L/; an axiomatisation of =/sub L/ on MA/sub IF//sup syn/; the construction of characteristic formulas for the processes in MA/sub IF/ with respect to =/sub L/; the decidability of =/sub L/ on MA/sub IF/ and on MA/sub IF//sup syn/, and its undecidability on MA.
[Shape, Switches, query languages, Calculus, labelled tree, modal logic, Database languages, Computer science, formal logic, decidability, Ambient Logic, Query processing, process algebra, Chromium, tree data structures, process calculus, Logic, process mobility]
Separation logic: a logic for shared mutable data structures
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
In joint work with Peter O'Hearn and others, based on early ideas of Burstall, we have developed an extension of Hoare logic that permits reasoning about low-level imperative programs that use shared mutable data structure. The simple imperative programming language is extended with commands (not expressions) for accessing and modifying shared structures, and for explicit allocation and deallocation of storage. Assertions are extended by introducing a "separating conjunction" that asserts that its subformulas hold for disjoint parts of the heap, and a closely related "separating implication". Coupled with the inductive definition of predicates on abstract data structures, this extension permits the concise and flexible description of structures with controlled sharing. In this paper, we survey the current development of this program logic, including extensions that permit unrestricted address arithmetic, dynamically allocated arrays, and recursive procedures. We also discuss promising future directions.
[address arithmetic, Logic programming, reasoning, Data structures, Reflection, Computer science, formal logic, Computer languages, shared mutable data structures, recursive procedures, Bibliographies, imperative programming language, separation logic, Programmable logic arrays, low-level imperative programs, data structures, program logic, heap, Artificial intelligence, Logic arrays, Arithmetic, computational complexity, Hoare logic]
A syntactic approach to foundational proof-carrying code
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
Proof-carrying code (PCC) is a general framework for verifying the safety properties of machine-language programs. PCC proofs are usually written in a logic extended with language-specific typing rules. In foundational proof-carrying code (FPCC), on the other hand, proofs are constructed and verified using strictly the foundations of mathematical logic, with no type-specific axioms. FPCC is more flexible and secure because it is not tied to any particular type system and it has a smaller trusted base. Foundational proofs, however are much harder to construct. Previous efforts on FPCC all required building sophisticated semantic models for types. In this paper, we present a syntactic approach to FPCC that avoids the difficulties of previous work. Under our new scheme, the foundational proof for a typed machine program simply consists of the typing derivation plus the formalized syntactic soundness proof for the underlying type system. We give a translation from a typed assembly language into FPCC and demonstrate the advantages of our new system via an implementation in the Coq proof assistant.
[Assembly systems, machine-language programs, Buildings, Coq proof assistant, general framework, Proposals, typed assembly language, syntactic approach, Computer science, formal logic, Computer bugs, Safety, theorem proving, safety properties, language-specific typing rules, Logic, foundational proof-carrying code, mathematical logic]
Observational equivalence of 3rd-order Idealized Algol is decidable
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We prove that observational equivalence of 3rd-order finitary Idealized Algol (IA) is decidable using Game Semantics. By modelling state explicitly in our games, we show that the denotation of a term M of this fragment of IA (built up from finite base types) is a compactly innocent strategy-with-state i.e. the strategy is generated by a finite view function f/sub M/. Given any such f/sub M/, we construct a real-time deterministic pushdown automata (DPDA) that recognizes the complete plays of the knowing-strategy denotation of M. Since such plays characterize observational equivalence, and there is an algorithm for deciding whether any two DPDAs recognize the same language, we obtain a procedure for deciding observational equivalence of 3rd-order finitary IA. This algorithmic representation of program meanings, which is compositional, provides a foundation for model-checking a wide range of behavioural properties of IA and other cognate programming languages. Another result concerns 2nd-order IA with recursion: we show that observational equivalence for this fragment is undecidable.
[Algorithm design and analysis, decidable, model-checking, Laboratories, pushdown automata, decidability, deterministic automata, observational equivalence, Hardware, recursion, program control structures, formal languages, deterministic pushdown automata, equivalence, Data security, DPDAs, Character recognition, Application software, ALGOL, Computer languages, model checking, Automata, Computer applications, Concrete, equivalence classes]
Computational adequacy for recursive types in models of intuitionistic set theory
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
We present a general axiomatic construction of models of FPC, a recursively typed lambda-calculus with call-by-value operational semantics. Our method of construction is to obtain such models as full subcategories of categorical models of intuitionistic set theory. This allows us to obtain a notion of model that encompasses both domain-theoretic and realizability models. We show that the existence of solutions to recursive domain equations, needed for the interpretation of recursive types, depends on the strength of the set theory. The internal set theory of an elementary topos is not strong enough to guarantee their existence. However, solutions to recursive domain equations do exist if models of intuitionistic Zermelo-Fraenkel set theory are used instead We apply this result to interpret FPC, and we provide necessary and sufficient conditions on a model for the interpretation to be computationally adequate, i.e. for the operational and denotational notions of termination to agree.
[lambda calculus, Flexible printed circuits, typed lambda-calculus, Computational modeling, recursive types, operational semantics, recursive functions, set theory, Equations, intuitionistic set theory, Computer science, formal logic, Sufficient conditions, FPC, Set theory, Logic, Informatics, denotational models]
Modal and guarded characterisation theorems over finite transition systems
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
Characterisation theorems for modal and guarded fragments of first-order logic are explored over finite transition systems. We show that the classical characterisations in terms of semantic invariance under the appropriate forms of bisimulation equivalence can be recovered at the level of finite model theory. The new, more constructive proofs naturally extend to alternative proofs of the classical variants. The finite model theory version of van Benthem's characterisation of basic modal logic is due to E. Rosen. That proof is simplified and the result slightly strengthened in terms of quantitative bounds. The main theme, however is a uniform treatment that extends to incorporate universal and inverse modalities and guarded quantification over transition systems. Technically, the present treatment exploits first-order locality in the context of a new finitary construction of locally acyclic bisimilar covers. These serve as graded finite analogues of tree unravellings, giving local control over first-order logic infinite bisimilar companion structures.
[guarded characterisation theorems, modal characterisation theorems, finite transition systems, first-order logic, H infinity control, graded finite analogues, quantitative bounds, guarded fragments, tree unravellings, Game theory, first-order locality, Computer science, formal logic, characterisation theorems, inverse modalities, bisimulation equivalence, finite model theory, Logic]
Linearity in process languages
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
The meaning and mathematical consequences of linearity (managing without a presumed ability to copy) are studied for a path-based model of processes which is also a model of affine-linear logic. This connection yields an affine-linear language for processes, automatically respecting open-map bisimulation, in which a range of process operations can be expressed. An operational semantics is provided for the tensor fragment of the language. Different ways to make assemblies of processes lead to different choices of exponential, some of which respect bisimulation.
[bisimulation, CSP, Shape, Laboratories, operational semantics, linear maps, distributed computation, Distributed computing, Tensile stress, CCS, trace model, process algebra, Linearity, Character generation, Lead, affine-linear logic, bisimulation equivalence, Mathematical model, Logic, computation paths, tree model, process languages, Assembly, model of processes]
A fully abstract may testing semantics for concurrent objects
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
This paper provides a fully abstract semantics for a variant of the concurrent object calculus. We define may testing for concurrent object components and then characterise it using a trace semantics inspired by UML interaction diagrams. The main result of this paper is to show that the trace semantics is fully abstract for may testing. This is the first such result for a concurrent object language.
[Visualization, object-oriented programming, Unified modeling language, trace semantics, concurrent object language, Calculus, Production facilities, Yarn, concurrent object calculus, Jacobian matrices, formal logic, semantic networks, Robustness, Safety, UML interaction diagrams, Standards development, may testing, fully abstract semantics, Testing]
Semantics and logic of object calculi
Proceedings 17th Annual IEEE Symposium on Logic in Computer Science
None
2002
The main contribution of this paper is a formal characterization of recursive object specifications based on a denotational untyped semantics of the object calculus and the discussion of existence of those (recursive) specifications. The semantics is then applied to prove soundness of a programming logic for the object calculus and to suggest possible extensions. For the purposes of this discussion we use an informal logic of predomains in order to avoid any commitment to a particular syntax of specification logic.
[Logic programming, Object oriented modeling, object calculi, denotational untyped semantics, specification logic, Calculus, inference mechanisms, programming language semantics, Machinery, formal characterization, Computer science, formal logic, predomains, recursive object specifications, syntax, Object oriented programming, programming logic]
Proceedings 18th Annual IEEE Symposium on Logic in Computer Science
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
A cornerstone of the theory of proof nets for unit-free multiplicative linear logic (MLL) is the abstract representation of cut-free proofs modulo inessential commutations of rules. The only known extension to additives, based on monomial weights, fails to preserve this key feature: a host of cut-free monomial proof nets can correspond to the same cut-free proof. Thus the problem of finding a satisfactory notion of proof net for unit-free multiplicative-additive linear logic (MALL) has remained open since the inception of linear logic in 1986. We present a new definition of MALL proof net which remains faithful to the cornerstone of the MLL theory.
[formal logic, proof net, cut-free proof modulo, monomial weight, Theorem proving, MALL, theorem proving, Logic, MLL, multiplicative linear logic, unit-free logic, additive linear logic]
Types and programming languages: the next generation
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Summary form only given. This tutorial surveys the state of the art in type systems for programming languages, focusing on the achievements and changes in emphasis during the past decade. The first part of the talk considers the trajectory of work on object types, one of the major hot topics of the early and mid-'90s. Following some fundamental conceptual breakthroughs, the focus of attention in this area has shifted from foundational research to applications to the development and analysis of real-world language designs. The next part outlines recent progress on a number of "bread and butter" type systems topics and their applications in new programming languages: subtyping, polymorphism, type inference, effect systems, dependent types, and type systems for modular programming. The final section introduces some newer topics that have emerged (or gained unexpected prominence) in the past few years, including type systems for concurrent and distributed languages, high-level type systems for low-level languages such as assembly and C, substructural type systems based on linear logic and its relatives, modal type systems, the burgeoning area of language-based security, and native language support for statistically typed XML processing.
[Assembly systems, modular programming, low-level language, linear logic, type theory, polymorphism, programming languages, language design, formal logic, concurrent language, distributed language, assembly, Extensible Markup Language, programming language, type inference, Logic programming, effect system, programming language semantics, subtyping, high-level type system, Computer science, Computer languages, XML, C program, language analysis, XML processing]
Model checking for probability and time: from theory to practice
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Probability features increasingly often in software and hardware systems: it is used in distributed coordination and routing problems, to model fault-tolerances and performance, and to provide adaptive resource management strategies. Probabilistic model checking is an automatic procedure for establishing if a desired property holds in a probabilistic specifications such as "leader election is eventually resolved with probability 1\
[probabilistic model checking, fault-tolerance, probabilistic logic, Software performance, temporal logic, logic testing, transition system graph, linear programming, software system, probabilistic symbolic model checker, probabilistic automata, routing problem, formal verification, Fault tolerant systems, Hardware, reachability analysis, Logic programming, Nominations and elections, hardware system, linear equation, Probability, Routing, Probabilistic logic, PRISM, probabilistic specification, Markov processes, probabilistic protocol, Software systems, Resource management, distributed coordination, resource management strategy]
Labeled Markov processes: stronger and faster approximations
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
This paper proposes a measure-theoretic reconstruction of the approximation schemes developed for labeled Markov processes: approximants are seen as quotients with respect to sets of temporal properties expressed in a simple logic. This gives the possibility of customizing approximants with respect to properties of interest and is thus an important step towards using automated techniques intended for finite state systems, e.g. model checking, for continuous state systems. The measure-theoretic apparatus meshes well with an enriched logic, extended with a greatest fix-point, and gives means to define approximants which retain cyclic properties of their target.
[approximation theory, cyclic property, temporal logic, Extraterrestrial measurements, Approximation methods, Machinery, LMP, Computer science, measure-theoretic reconstruction, model checking, Automata, labeled Markov process, Markov processes, finite state system, approximation scheme, automated technique, continuous state system, Logic, Carbon capture and storage, Kernel]
A constraint-based presentation and generalization of rows
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We study the combination of possibly conditional nonstructural subtyping constraints with rows. We give a new presentation of rows, where row terms disappear; instead, we annotate constraints with filters. We argue that, in the presence of subtyping, this approach is simpler and more general. In the case where filters are finite or cofinite sets of row labels, we give a constraint solving algorithm whose complexity is O(n/sup 3/m log m), where n is the size of the constraint and m is the number of row labels that appear in it. We point out that this allows efficient type inference for record concatenation. Furthermore, by varying the nature of filters, we obtain several natural generalizations of rows.
[row generalization, constraint solving, record concatenation, constraint-based presentation, finite set, Merging, Data structures, Data mining, subtyping, Computer languages, Filters, Constraint theory, Inference algorithms, Polynomials, constraint handling, computational complexity]
Spectrum hierarchies and subdiagonal functions
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
The spectrum of a first-order sentence is the set of cardinalities of its finite models. Relatively little is known about the subclasses of spectra that are obtained by looking only at sentences with a specific signature. In this paper, we study natural subclasses of spectra and their closure properties under simple subdiagonal functions. We show that many natural closure properties turn out to be equivalent to the collapse of potential spectrum hierarchies. We prove all of our results using explicit transformations on first-order structures.
[first-order structure, functions, closure property, Complexity theory, spectrum hierarchy, Computer science, formal logic, cardinality set, Polynomials, finite model, spectra subclass, theorem proving, Logic, subdiagonal function]
Tractable conservative constraint satisfaction problems
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
In a constraint satisfaction problem (CSP), the aim is to find an assignment of values to a given set of variables, subject to specified constraints. The CSP is known to be NP-complete in general. However, certain restrictions on the form of the allowed constraints can lead to problems solvable in polynomial time. Such restrictions are usually imposed by specifying a constraint language. The principal research direction aims to distinguish those constraint languages, which give rise to tractable CSPs from those which do not. We achieve this goal for the widely used variant of the CSP, in which the set of values for each individual variable can be restricted arbitrarily. Restrictions of this type can be expressed by including in a constraint language all possible unary constraints. Constraint languages containing all unary constraints will be called conservative. We completely characterize conservative constraint languages that give rise to CSP classes solvable in polynomial time. In particular, this result allows us to obtain a complete description of those (directed) graphs H for which the List H-Coloring problem is polynomial time solvable.
[CSP, conservative constraint, Laboratories, unary constraint, constraint satisfaction problem, problem solving, NP-complete problem, logic programming languages, graph colouring, Computer science, variable set, Constraint theory, Polynomials, polynomial time, Logic, constraint handling, constraint language, computational complexity]
Intruder deductions, constraint solving and insecurity decision in presence of exclusive or
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We present decidability results for the verification of cryptographic protocols in the presence of equational theories corresponding to xor and Abelian groups. Since the perfect cryptography assumption is unrealistic for cryptographic primitives with visible algebraic properties such as xor, we extend the conventional Dolev-Yao model by permitting the intruder to exploit these properties. We show that the ground reachability problem in NP for the extended intruder theories in the cases of xor and Abelian groups. This result follows from a normal proof theorem. Then, we show how to lift this result in the xor case: we consider a symbolic constraint system expressing the reachability (e.g., secrecy) problem for a finite number of sessions. We prove that such a constraint system is decidable, relying in particular on an extension of combination algorithms for unification procedures. As a corollary, this enables automatic symbolic verification of cryptographic protocols employing xor for a fixed number of sessions.
[insecurity decision, constraint solving, Abelian group, combination algorithm, cryptographic protocol, normal proof theorem, equational theory, Algebra, decidability, formal verification, Constraint theory, Polynomials, exclusive or, xor, theorem proving, Cryptography, Logic, protocols, reachability analysis, algebraic property, cryptography, Equations, Cryptographic protocols, Computer science, Authentication, Dolev-Yao model, intruder deduction, Context modeling]
Will deflation lead to depletion? On non-monotone fixed point inductions
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We survey logical formalisms based on inflationary and deflationary fixed points, and compare them to the (more familiar) logics based on least and greatest fixed points.
[Wind, Dictionaries, greatest fixed point, first-order logic, nonmonotone induction, modal logic, inflationary fixed point, least fixed point, formal logic, IFP, Databases, deflationary fixed point, LFP, Page description languages, Polynomials, Logic, logical formalism, MIC, Power generation economics, modal fixed point, Computer science, iterated relativisation, fixed point induction, Soil, Artificial intelligence]
Model-checking trace event structures
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Given regular collection of Mazurkiewicz traces, which can be seen as the behaviors of a finite-state concurrent system, one can associate with it a canonical regular event structure. This event structure is a single (often infinite) structure that captures both the concurrency and conflict information present in the system. We study the problem of model-checking such structures against logics such as first-order logic (FOL), monadic second-order logic (MSOL) and a new logic that lies in between these two called monadic trace logic (MTL). MTL is a fragment of MSOL where the quantification is restricted to sets that are conflict-free. While it is known that model-checking such event structures against MSOL is undecidable, our main results are that FOL and MTL admit effective model-checking procedures. It turns out that FOL captures previously known decidable temporal logics on event structures. MTL is more powerful and can express interesting branching-time properties of event structures, and when restricted to a sequential setting, can express the standard logic CTL over trees.
[Protocols, model-checking, MTL, Petri nets, first-order logic, temporal logic, trace event structure, Concurrent computing, formal verification, Robustness, Logic, Labeling, FOL, decidable temporal logic, finite-state concurrent system, monadic trace logic, MSOL, Explosions, Formal specifications, Power system modeling, canonical regular event structure, Mazurkiewicz trace, Interleaved codes, CTL, monadic second-order logic]
Proof nets for unit-free multiplicative-additive linear logic (extended abstract)
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
false
[Logic, Joining processes]
Logical definability and query languages over unranked trees
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Unranked trees, that is, trees with no restriction on the number of children of nodes, have recently attracted much attention, primarily as an abstraction of XML (Extensible Markup Language) documents. In this paper, we study logical definability over unranked trees, as well as collections of unranked trees, that can be viewed as databases of XML documents. The traditional approach to definability is to view each tree as a structure of a fixed vocabulary, and study the expressive power of various logics on trees. A different approach, based on model theory, considers a structure whose universe is the set of all trees, and studies definable sets and relations; this approach extends smoothly to the setting of definability over collections of trees. We study the latter, model-theoretic approach. We find sets of operations on unranked trees that define regular tree languages, and show that some natural restrictions correspond to logics studied in the context of XML pattern languages. We then look at relational calculi over collections of unranked trees, and obtain quantifier-restriction results that give us bounds on the expressive power and complexity. As unrestricted relational calculi can express problems complete for each level of the polynomial hierarchy, we look at their restrictions, corresponding and find several calculi with low (NC/sup 1/) data complexity that can express important XML properties like DTD validation and XPath evaluation.
[Vocabulary, unranked tree, Relational databases, various logic, query languages, Database languages, model-theoretic approach, expressive power, definable relation, tree language, natural restriction, Extensible Markup Language, Polynomials, tree data structures, XML database, Logic, XML property, logical definability, hypermedia markup languages, XPath, definable sets, model theory, Navigation, quantifier-restriction result, polynomial hierarchy, fixed vocabulary, Spatial databases, XML pattern language, expressive complexity, DTD validation, NC/sup 1/ data complexity, XML, Automata, XML document, Web sites, query language, relational calculi, document type definition]
The planning spectrum - one, two, three, infinity
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Linear temporal logic (LTL) is widely used for defining conditions on the execution paths of dynamic systems. In the case of dynamic systems that allow for nondeterministic evolutions, one has to specify, along with an LTL formula /spl phi/, which are the paths that are required to satisfy the formula. Two extreme cases are the universal interpretation A./spl phi/, which requires to satisfy the formula for all the possible execution paths, and the existential interpretation E./spl phi/ which requires to satisfy the formula for some execution paths. When LTL is applied to the definition of goals in planning problems on nondeterministic domains, these two extreme cases are too restrictive. It is often impossible to develop plans that achieve the goal in all the nondeterministic evolutions of a system, and it is too weak to require that the goal is satisfied by some executions. In this paper we explore alternative interpretations of an LTL formula that are between these extreme cases. We define a language that permits an arbitrary combination of the A and E quantifiers, thus allowing, for instance, to require that each finite execution can be extended to an execution satisfying an LTL formulas (AE./spl phi/), or that there is some finite execution whose extensions all satisfy an LTL formula (EA./spl phi/). We show that only eight of these combinations of path quantifiers are relevant, corresponding to an alternation of the quantifiers of length one (A and E), two (AE and EA), three (AEA and EAE), and infinity ((AE)/sup /spl omega// and (EA)/sup /spl omega//). We also present a planning algorithm for the new language that is based on an automata-theoretic approach, and studies its complexity.
[planning spectrum, automata theory, nondeterministic domain, Robot control, H infinity control, planning algorithm, temporal logic, linear temporal logic, automata-theoretic approach, universal interpretation, Path planning, path planning, nondeterministic evolution, execution path, dynamic system, existential interpretation, algorithm theory, planning problem, Logic, arbitrary combination, alternative interpretation, LTL formula]
Homomorphism closed vs. existential positive
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Preservations theorems, which establish connection between syntactic and semantic properties of formulas, are a major topic of investigation in model theory. In the context of finite-model theory, most, but not all, preservation theorems are known to fail. It is not known, however, whether the Los-Tarski-Lyndon theorem, which asserts that a first-order sentence is preserved under homomorphisms if it is equivalent to an existential positive sentence, holds with respect to finite structures. Resolving this is an important open question in finite-model theory. In this paper we study the relationship between closure under homomorphism and positive syntax for several nonfirst-order existential logics that are of interest in computer science. We prove that the Los-Tarski-Lyndon theorem holds for these logics. The logics we consider are variable-confined existential infinitary logic, Datalog, and various fragments of second-order logic.
[Los-Tarski-Lyndon theorem, Terminology, finite automata, semantic property, finite-model theory, existential positive, finite structure, positive syntax, Computer science, formal logic, Databases, computer science, second-order logic, logic programming, Logic functions, homomorphism, syntactic property, preservations theorem, theorem proving, infinitary logic, Context modeling, datalog]
An NP decision procedure for protocol insecurity with XOR
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We provide a method for deciding the insecurity of cryptographic protocols in presence of the standard Dolev-Yao intruder (with a finite number of sessions) extended with so-called oracle rules, i.e., deduction rules that satisfy certain conditions. As an instance of this general framework, we ascertain that protocol insecurity is in NP for an intruder that can exploit the properties of the XOR operator. This operator is frequently used in cryptographic protocols but cannot be handled in most protocol models. An immediate consequence of our proof is that checking whether a message can be derived by an intruder (using XOR) is in P. We also apply our framework to an intruder that exploits properties of certain encryption modes such as cipher block chaining (CBC).
[Algorithm design and analysis, CBC, cryptography, cryptographic protocol, cipher block chaining, access protocols, Security, oracle rule, Equations, Cryptographic protocols, Computer science, Authentication, message authentication, Doley-Yao intruder, Abstracts, protocol security, XOR, Cryptography, Logic, Joining processes, NP decision procedure]
New directions in instantiation-based theorem proving
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We consider instantiation-based theorem proving whereby instances of clauses are generated by certain inferences, and where inconsistency is detected by proposition tests. We give a model construction proof of completeness by which restrictive inference systems as well as admissible simplification techniques can be justified. Another contribution of the paper are inference systems that allow one to also employ decision procedures for first-order fragments more complex than propositional logic. The decision provides for an approximate consistency test, and the instance generation inference system is a means of successively refining the approximation.
[System testing, approximation theory, model construction, restrictive inference system, propositional logic, approximation refinement, Data structures, first-order fragment, inference mechanisms, instantiation-based theorem proving, simplification technique, Computer science, completeness proof, redundancy elimination, decision procedure, Interleaved codes, instance generation, theorem proving, Logic, approximative consistency test, semantic selection]
Successor-invariance in the finite
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
A first-order sentence /spl theta/ of vocabulary /spl sigma/ /spl cup/ {S} is successor-invariant in the finite if for every finite /spl sigma/-structure M and successor relations S/sub 1/ and S/sub 2/ on M, (M, S/sub 1/) /spl vDash/ /spl theta/ /spl hArr/ (M, S/sub 2/) /spl vDash/ /spl theta/. In this paper I give an example of a non-first-order definable class of finite structures, which is, however, defined by a successor-invariant first-order sentence. This strengthens a corresponding result for order-invariant in the finite, due to Y. Gurevich.
[Vocabulary, successor relation, Relational databases, finite successor-invariance, Database languages, finite structure, Computer science, formal logic, nonfirst-order definable class, Interpolation, Presses, finite order-invariant, sigma-structure, Logic, successor-invariant first-order sentence]
Strong bisimilarity on basic parallel processes in PSPACE-complete
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
The paper shows an algorithm which, given a basic parallel processes (BPP) system, constructs a set of linear mappings which characterize the (strong) bisimulation equivalence on the system. Though the number of the constructed mappings can be exponential, they can be generated in polynomial space; this shows that the problem of deciding bisimulation equivalence on BPP is in PSAPCE. Combining with the PSPACE-hardness result by Srba, PSPACE-completeness is thus established.
[polynomial space algorithm, strong bisimilarity, Terminology, polynomials, Natural languages, PSPACE-completeness, LTS, linear mapping, Computer science, Concurrent computing, PSPACE-hardness, Upper bound, labelled transition system, Automata, Polynomials, bisimulation equivalence, theorem proving, Logic, BPP system, Arithmetic, computational complexity, basic parallel process]
A proof theory for generic judgments: an extended abstract
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
A powerful and declarative means of specifying computations containing abstractions involves meta-level, universally quantified generic judgments. We present a proof theory for such judgments in which signatures are associated to each sequent (used to account for eigenvariables of sequent) and to each formula in the sequent (used to account for generic variables locally scoped over the formula). A new quantifier, /spl nabla/, is introduced to explicitly manipulate the local signature. Intuitionistic logic extended with /spl nabla/ satisfies cut-elimination even when the logic is additionally strengthened with a proof theoretic notion of definitions. The resulting logic can be used to encode naturally a number of examples involving name abstractions, and we illustrate using the /spl pi/-calculus and the encoding of object-level provability.
[powerful mean, generic variable, declarative mean, meta-level quantified generic judgment, operational semantics, object-level provability, reasoning, intuitionistic logic, proof search, inference mechanisms, extended abstract, eigenvalues and eigenfunctions, proof theory, Computer science, universally quantified generic judgment, mu-calculus, cut-elimination, higher-order abstract syntax, name abstraction, generic judgement, theorem proving, Logic, sequent eigenvariable]
Model checking guarded protocols
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
The parameterized model checking problem (PMCP) is to decide whether a temporal property holds for a uniform family of systems, C||U/sup n/, comprised of a control process, C, and finitely, but arbitrarily, many copies of a user process, U, executing concurrently with interleaving semantics. We delineate the decidability/undecidability boundary of the PMCP for all possible systems that arise by letting processes coordinate using different subsets of the following communication primitives: conjunctive Boolean guards, disjunctive Boolean guards, pairwise rendezvous, asynchronous rendezvous and broadcast actions. Our focus is on the following linear time properties: (p1) LTL/spl bsol/X formulae over C; (p2) LTL formulae over C; (p3) regular properties specified as regular automata; and (p4) /spl omega/-regular automata. We also establish a hierarchy based on the relative expressive power of the primitives by showing that disjunctive guards and pairwise rendezvous are equally expressive, in that we can reduce the PMCP for regular and /spl omega/-regular properties for systems with disjunctive guards and pairwise rendezvous are equally expressive, in that we can reduce the PMCP for regular and /spl omega/-regular properties for systems with disjunctive guards to ones with pairwise rendezvous and vise versa, but that each of asynchronous rendezvous and broadcasts is strictly more expressive than pairwise rendezvous (and disjunctive guards). Moreover, for systems with conjunctive guards, we give a simple characterization of the decidability/undecidability boundary of the PMCP by showing that allowing stuttering sensitive properties bridges the gap between decidability (for p1) and undecidability (for p2). A broad framework for modeling snoopy cache protocols is also presented for which the PMCP for p3 is decidable and that can model all snoopy cache protocols given by Culler and Emerson (1988) thereby overcoming the undecidability results.
[Protocols, automata theory, Communication system control, pairwise rendezvous, linear time property, Multiprocessing systems, PMCP, conjunctive Boolean guard, omega-regular automata, formal verification, decidability, Broadcasting, protocols, Contracts, disjunctive Boolean guard, Process control, parameterized model checking problem, asynchronous rendezvous, Bridges, interleaving semantics, guarded protocol, LTL formulae, Automata, Coherence, broadcast action, snoopy cache protocol, Interleaved codes, undecidability boundary, control process, LTL/spl bsol/X formulae]
Spectra of monadic second-order formulas with one unary function
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We establish the eventual periodicity of the spectrum of any monadic second-order formula where: (i) all relation symbols, except equality, are unary, and (ii) there is only one function symbol and that symbol is unary.
[Computer science, Heart, formal logic, Vocabulary, functions, function symbol, Mathematics, monadic formula, Logic, second-order formula, unary function]
Orienting equalities with the Knuth-Bendix order
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Orientability of systems of equalities is the following problem: given a system of equalities s/sub 1/ /spl sime/ t/sub 1/, . . . , s/sub n/ /spl sime/ t/sub n/, does there exist a simplification ordering > which orients the system, that is for every i /spl isin/ {1, ..., n}, either s/sub i/ > t/sub i/ or t/sub i/ > s/sub i/. This problem can be used in rewriting for finding a canonical rewrite system for a system of equalities and in theorem proving for adjusting simplification orderings during completion. We prove that (rather surprisingly) the problem can be solved in polynomial time when we restrict ourselves to the Knuth-Bendix orderings.
[rewriting systems, equality system, rewrite rule, Knuth-Bendix order, simplification ordering, Explosions, Computer science, satisfiability check, system orientability, Kuiper belt, KBO, homogeneous linear inequality, Polynomials, canonical rewrite system, polynomial time, theorem proving, equality orientation]
On automatic partial orders
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We investigate partial orders that are computable, in a precise sense, by finite automata. Our emphasis is on trees and linear orders. We study the relationship between automatic linear orders and trees in terms of rank functions that are versions of Cantor-Bendixson rank. We prove that automatic linear orders and automatic trees have finite rank. As an application we provide a procedure for deciding the isomorphism problem for automatic ordinals. We also investigate the complexity and definability of infinite paths in automatic trees. In particular, we show that every infinite path in an automatic tree with countably many infinite paths is a regular language.
[finite automata, Lattices, trees order, Mathematics, isomorphism problem, regular language, Tree graphs, automatic tree, Cantor-Bendixson rank, theorem proving, finite rank, Logic, linear algebra, automatic ordinal, formal languages, Scattering, trees (mathematics), infinite path complexity, Computer science, rank function, Upper bound, automatic partial order, infinite path definability, Automata, automatic linear order]
Micro-macro stack systems: a new frontier of elementary decidability for sequential systems
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We define the class of micro-macro stack graphs, a new class of graphs modeling infinite-state sequential systems with a decidable model-checking problem. Micro-macro stack graphs are the configuration graphs of stack automata whose states are partitioned into micro and macro states. Nodes of the graph are configurations of the stack automaton where the state is a macro state. Edges of the graph correspond to the sequence of micro steps that the automaton makes between macro states. We prove that this class strictly contains the class of prefix-recognizable graphs. We give a direct automata-theoretic algorithm for model checking /spl mu/-calculus formulas over micro-macro stack graphs.
[Algorithm design and analysis, micro state, graph theory, micromacro stack graph, stack automata, mu-calculus formula, Aerospace industry, automata-theoretic algorithm, decidability, formal verification, graph node, macro state, Mathematical model, Logic, Contracts, prefix-recognizable graph, rewriting systems, infinite-state sequential system, decidable model-checking, elementary decidability, State-space methods, Formal specifications, Computer science, micromacro stack system, sequential machines, model checking, Automata, stack automaton, FETs]
About translations of classical logic into polarized linear logic
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We show that the decomposition of intuitionistic logic into linear logic along the equation A /spl rarr/ B = !A /spl rarr/ B may be adapted into a decomposition of classical logic into LLP, the polarized version of Linear Logic. Firstly, we build a categorical model of classical logic (a control category) from a categorical model of linear logic by a construction similar to the co-Kleisli category. Secondly, we analyze two standard continuation-passing style (CPS) translations, the Plotkin and the Krivine's translations, which are shown to correspond to two embeddings of LLP into LL.
[Polarization, Plotkin translation, CPS, intuitionistic logic, control category, Calculus, Logic design, polarized version, Equations, Computer science, formal logic, co-Kleisli category, LLP, Linearity, continuation-passing style, Krivine translation, category theory, categorical model, polarized linear logic, classical logic]
Query evaluation on compressed trees
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
This paper studies the problem of evaluating unary (or node-selecting) queries on unranked trees compressed in a natural structure-preserving way, by the sharing of common subtrees. The motivation to study unary queries on unranked trees comes from the database field, where querying XML (Extensible Markup Language) documents, which can be considered as unranked labeled trees, is an important task. We give algorithms and complexity results for the evaluation of XPath and monadic datalog queries. Furthermore, we propose a new automata-theoretic formalism for querying trees and give algorithms for evaluating queries defined by such automata.
[unranked tree, automata theory, Relational databases, Style sheet languages, monadic datalog, unranked labeled tree, Database languages, query processing, common subtree sharing, Extensible Markup Language, Database systems, Polynomials, tree data structures, structure-preserving way, XPath, query evaluation, querying XML document, natural way, compressed tree, tree querying, Computer science, automata-theoretic formalism, unary query, Query processing, database field, XML, Automata, node-selecting query, Solids]
Advice about logical AI
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Formalized nonmonotonic reasoning emerged in relation to the study of artificial intelligence. The paper discusses some uses of nonmonotonic reasoning that has become a mathematical subject, observations regarding AI, and the problems logical AI encountered before it can reach human level intelligence.
[Artificial Intelligence, AI, Birds, Mathematics, History, artificial intelligence, nonmonotonic reasoning, Computer science, Business communication, formal logic, Databases, mathematical application, Logic, Artificial intelligence, mathematical logic]
Reasoning about hierarchical storage
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
In this paper, we develop a new substructural logic that can encode invariants necessary for reasoning about hierarchical storage. We show how the logic can be used to describe the layout of bits in a memory word, the layout of memory words in a region, the layout of regions in an address space, or even the layout of address spaces in a multiprocessing environment. We provide a semantics for our formulas and then apply the semantics and logic to the task of developing a type system for Mini-KAM, a simplified version of the abstract machine used in the ML Kit with regions.
[storage allocation, hierarchical storage, Logic programming, Data structures, Virtual machining, programming language semantics, inference mechanisms, abstract machine, Computer science, multiprocessing environment, Computer languages, memory word, memory bit, Memory management, ML Kit, storage reasoning, type system, Bismuth, Mini-KAM, substructural logic, Assembly]
Logic in access control
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Access control is central to security in computer systems. Over the years, there have been many efforts to explain and improve access control, sometimes with logical ideas and tools. This paper is a partial survey and discussion of the role of logic in access control. It considers logical foundations for access control and their applications, in particular in languages for programming security policies.
[Access control, Pervasive computing, logical tool, programming security policy, Logic programming, logical foundation, logical idea, distributed system, Multivalued logic, computer system, Virtual machining, Application software, Machinery, logic role, Authorization, security of data, Operating systems, authorisation, logic programming, partial survey, programming policy, access control, Computer security, partial discussion]
Polynomial-time algorithms from ineffective proofs
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We present a constructive procedure for extracting polynomial-time realizers from ineffective proofs of /spl Pi//sub 2//sup 0/-theorems in feasible analysis. By ineffective proof we mean a proof which involves the noncomputational principle weak Konig's lemma WKL, and by feasible analysis we mean Cook and Urquhart's system CPV/sup /spl omega// plus quantifier-free choice QF-AC. We shall also discuss the relation between the system CPV/sup /spl omega// + QF-AC and Ferreira's base theory for feasible analysis BTFA, for which /spl Pi//sub 2//sup 0/-conservation of WKL has been non-constructively proven. This paper treats the case of weak Konig's lemma, we indicate how to formalize the proof of the Heine/Borel covering lemma in this system. The main techniques used in the paper are Godel's functional interpretation and a novel form of binary bar recursion.
[quantifier-free choice, Borel covering lemma, extracting polynomial-time realizer, binary bar recursion, Mathematics, weak Konigs lemma, QF-AC, Heine covering lemma, base theory for feasible analysis, algorithm theory, CPV/sup omega/, Polynomials, theorem proving, Logic, polynomial-time algorithm, noncomputational WKL, Equations, Cook and Urquharts system, Godels functional interpretation, Computer science, Pi/sub 2//sup 0/-theorem, constructive procedure, Ferreiras BTFA, ineffective proof, Arithmetic]
Convergence law for random graphs with specified degree sequence
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
The degree sequence of an n-vertex graph is d/sub 0/, ..., d/sub n - 1/, where each d/sub i/ is the number of vertices of degree i in the graph. A random graph with degree sequence d/sub 0/, ..., d/sub n - 1/ is a randomly selected member of the set of graphs on {0, ..., n - 1} with that degree sequence, all choices being equally likely. Let /spl lambda/ /sub 0/, /spl lambda/ /sub 1/, ... be a sequence of nonnegative reals summing to 1. A class of finite graphs has degree sequences approximated by /spl lambda//sub 0/, /spl lambda//sub 1/, ... if, for every i and n, the members of the class of size n have /spl lambda//sub i/ n + o(n) vertices of degree i. Our main result is a convergence law for random graphs with degree sequences approximated by some sequence /spl lambda//sub 0/, /spl lambda//sub 1/, .... With certain conditions on the sequence /spl lambda//sub 0/, /spl lambda//sub 1/, ..., the probability of any first-order sentence on random graphs of size n converges to a limit as n grows.
[random graph, Biological system modeling, graph theory, convergence, probability, first-order sentence probability, convergence law, degree sequence, Convergence, Diseases, Computer science, Sociology, Collaboration, n-vertex, Power systems, theorem proving, IP networks, Internet telephony, Power engineering and energy]
Dependent intersection: a new way of defining records in type theory
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Records and dependent records are a powerful tool for programming, representing mathematical concepts, and program verification. In this last decade several type systems with records as primitive types were proposed. The question is arisen whether it is possible to define record type in existent type theories using standard types without introducing new primitives. It was known that independent records can be defined in type theories with dependent functions or intersection. On the other hand dependent records cannot be formed using standard types. Hickey introduced a complex notion of very dependent functions to represent dependent records. In the current paper we extend Martin-Lof's type theory with a simpler type constructor dependent intersection, i.e., the intersection of two types, where the second type may depend on elements of the first one (not to be confused with the intersection of a family of types). This new type constructor allows us to define dependent records in a very simple way. It also allows us to define the set type constructor.
[program testing, program verification, set type constructor, dependent function, programming tool, type theory, mathematical concept representation, PER semantic, Research initiatives, programming language semantics, independent record, NuPRL type theory, Computer science, dependent intersection, inference rule, record defining, existent type theory, complex notion, partial equivalence relation, Martin-Lofs type theory, software tools, standard type, Mathematical programming]
System ST /spl beta/-reduction and completeness
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We prove that system ST (introduced in a previous work) enjoys subject reduction and is complete for realizability semantics. As far as the author knows, this is the only type system enjoying the second property. System ST is a very expressive type system, whose principle is to use two kinds of formulae: types (formulae with algorithmic content) and propositions (formulae without algorithmic content). The fact that subtyping is used to build propositions and that propositions can be used in types through a special implication gives its great expressive power to the system: all the operators you can imagine are definable (union, intersection, singleton, ...).
[realizability semantics, type theory, completeness, programming language semantics, subtyping, Computer science, formal logic, Computer languages, type system, Logic, system ST, /spl beta/-reduction, propositions formula, types formula]
Revisiting digitization, robustness, and decidability for timed automata
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We consider several questions related to the use of digitization techniques for timed automata. These very successful techniques reduce dense-time language inclusion problems to discrete time, but are applicable only when the implementation is closed under digitization and the specification is closed under inverse digitization. We show that, for timed automata, the former (whether the implementation is closed under digitization) is decidable, but not the latter. We also investigate digitization questions in connection with the robust semantics for timed automata. The robust modeling approach introduces a timing fuzziness through the semantic removal of equality testing. Since its introduction half a decade ago, research into the robust semantics has suggested that it yields roughly the same theory as the standard semantics. This paper shows that, surprisingly, this is not the case: the robust semantics is significantly less tractable, and differs from the standard semantics in many key respects. In particular, the robust semantics yields an undecidable (nonregular) discrete-time theory, in stark contrast with the standard semantics. This makes it virtually impossible to apply digitization techniques together with the robust semantics. On the positive side, we show that the robust languages of timed automata remain recursive.
[Real time systems, Algorithm design and analysis, automata theory, inverse digitization, Mathematics, equality testing, automata decidability, automata digitization, robust control, Robustness, timed automata, robust semantics, precise semantics, Contracts, Testing, timing fuzziness, semantic removal, Government, discrete-time theory, inclusion problem, programming language semantics, Computer science, discrete time, digitization technique, Automata, automata robustness, Timing, robust language, dense-time language, modeling approach]
A sound framework for untrusted verification-condition generators
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We propose a framework called configurable proof-carrying code, which allows the untrusted producer of mobile code to provide the bulk of the code verifier used by a code receiver to check the safety of the received code. The resulting system is both more flexible and also more trustworthy than a standard proof-carrying code system, because only a small part of the verifier needs to be trusted, while the remaining part can be configured freely to suit the safety policy on one hand, and the structure of the mobile code on the other hand. In this paper we describe formally the protocol that the untrusted verifier must follow in the interaction with the trusted infrastructure. We present a proof of the soundness of the system, and we give preliminary evidence that the architecture is expressive enough to delegate to the untrusted verifier even the handling of loop invariants, indirect jumps and calling conventions.
[Java, Protocols, Optimizing compilers, Engineering profession, program verification, Scalability, Government, indirect jump convention, untrusted generator, sound framework, calling convention, Code standards, proof-carrying code, untrusted verifier, security of data, Computer architecture, loop invariant, Software systems, Safety, verification-condition generator, distributed programming]
Formal verification at Intel
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
As designs become more complex, formal verification techniques are becoming increasingly important in the hardware industry. Many different methods are used, ranging from propositional tautology checking up to use of interactive higher-order theorem provers. Our own work is mainly concerned with the formal verification of floating-point mathematical functions. As this paper illustrates, such applications require a rather general mathematical framework and the ability to automate special-purpose proof algorithms in a reliable way. Our work uses the public-domain interactive theorem prover HOL Light, and we claim that this and similar 'LCF-style' theorem provers are a good choice for such applications.
[proof algorithm, higher-order theorem prover, tautology checking, Intel, mathematical function, formal verification, propositional checking, Bismuth, Cost function, Hardware, theorem proving, Mathematical model, Logic, hardware industry, Testing, mathematical framework, HOL Light, public-domain theorem prover, Application software, Programming profession, LCF-style theorem prover, floating-point function, special-purpose algorithm, Computer errors, interactive theorem prover, Formal verification]
The complexity of resolution refinements
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Resolution is the most widely studied approach to propositional theorem proving. In developing efficient resolution-based algorithms, dozens of variants and refinements of resolution have been studied from both the empirical and analytical sides. The most prominent of these refinements are: DP (Davis-Putnam) (ordered), DLL (tree), semantic, negative, linear and regular resolution. In this paper, we characterize and study these six refinements of resolution. We give a nearly complete characterization of the relative complexities of all six refinements. While many of the important separations and simulations were already known, many new ones are presented in this paper; in particular, we give the first separation of semantic resolution from general resolution. As a special case, we obtain the first exponential separation of negative resolution from general resolution. We also attempt to present a unifying framework for studying all of these refinements.
[relative complexity, resolution-based algorithm, first exponential separation, semantic resolution, refinement calculus, propositional theorem proving, DP resolution, empirical side, DLL resolution, unifying framework, regular resolution, negative resolution, Computer science, analytical side, resolution variant, resolution refinement, linear resolution, theorem proving, Logic, Testing, computational complexity]
Structural subtyping of non-recursive types is decidable
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
We show that the first-order theory of structural subtyping of non-recursive types is decidable, as a consequence of a more general result on the decidability of term powers of decidable theories. Let /spl Sigma/ be a language consisting of function symbol and let /spl Cscr/; (with a finite or infinite domain C) be an L-structure where L is a language consisting of relation symbols. We introduce the notion of /spl Sigma/-term-power of the structure /spl Cscr/; denoted /spl Pscr/;/sub /spl Sigma//(/spl Cscr/;). The domain of /spl Pscr/;/sub /spl Sigma//(/spl Cscr/;) is the set of /spl Sigma/-terms over the set C. /spl Pscr/;/sub /spl Sigma//(/spl Cscr/;) has one term algebra operation for each f /spl isin/ /spl Sigma/, and one relation for each r /spl isin/ L defined by lifting operations of /spl Cscr/; to terms over C. We extend quantifier for term algebras and apply the Feferman-Vaught technique for quantifier elimination in products to obtain the following result. Let K be a family of L-structures and K/sub P/ the family of their /spl Sigma/-term-powers. Then the validity of any closed formula F on K/sub P/ can be effectively reduced to the validity of some closed formula q(F) on K. Our result implies the decidability of the first-order theory of structural subtyping of non-recursive types with covariant constructors, and the construction generalizes to contravariant constructors as well.
[covariant constructor, Feferman-Vaught technique, Laboratories, Lattices, nonrecursive type, type theory, algebra operation, contravariant constructor, Algebra, decidability, Constraint theory, L-structure, quantifier elimination, Computational linguistics, theorem proving, term power, Logic programming, Sigma-term-power, first-order theory, relation symbol, structural subtyping, Application software, term algebra, P/sub Sigma/(C), Computer science, lifting operation, Power system reliability, decidable theory]
Satisfiability in alternating-time temporal logic
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Alternating-time temporal logic (ATL) is a branching-time temporal logic that naturally describes computations of multi-agent distributed systems and multi-player games. In particular, ATL explicitly allows for the expression of coalitional ability in such situations. We present an automata-based decision procedure for ATL, by translating the satisfiability problem for ATL to the nonemptiness problem for the alternating automata on infinite trees. The key result that enables this translation is a bounded-branching tree model theorem for ATL, proving that a satisfiable in a tree model of bounded branching degree. It follows that ATL is decidable in exponential time, which is also the optimal complexity: satisfiability in CTL, a fragment of ATL, is EXPTIME-complete. The paper thus answers a fundamental logical question about ATL and provides an example of how alternation in automata may elegantly express game-like transitions.
[Protocols, alternating-time temporal logic, bounded-branching tree model theorem, automata theory, game-like transition, alternating automata, temporal logic, distributed system, EXPTIME-complete, Mathematics, Distributed computing, multiagent system, infinite tree, logical question, decidability, Operating systems, nonemptiness problem, satisfiability, optimal complexity, Logic, branching-time logic, multiplayer game, computation tree logic, Africa, coalitional ability, Specification languages, bounded branching degree, Application software, exponential time, fundamental question, Automata, decision procedure, decision trees, Distributed control, ATL, CTL, automata-based procedure]
On program equivalence in languages with ground-type references
18th Annual IEEE Symposium of Logic in Computer Science, 2003. Proceedings.
None
2003
Using game semantics we prove that program equivalence is undecidable in finitary Idealized Algol with active expressions as well as in its call-by-value counterpart. It is also shown that strategies corresponding to Idealized Algol terms of respectively second, third and higher orders define exactly regular, context-free and recursively enumerable languages.
[active expression, Laboratories, game theory, call-by-value counterpart, Calculus, Idealized Algol, programming language semantics, game semantics, Game theory, ALGOL, reduced ML, Computer science, RML, Computer languages, program equivalence, ground-type reference, IA, programming language, context-free language, Logic, recursively enumerable language]
The sensible graph theories of lambda calculus
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Sensible /spl lambda/-theories are equational extensions of the untyped lambda calculus that equate all the unsolvable /spl lambda/-terms and are closed under derivation. A longstanding open problem in lambda calculus is whether there exists a non-syntactic model whose equational theory is the least sensible /spl lambda/-theory H (generated by equating all the unsolvable terms). A related question is whether, given a class of models, there exist a minimal and maximal sensible /spl lambda/-theory represented by it. In This work we give a positive answer to this question for the semantics of lambda calculus given in terms of graph models. We conjecture that the least sensible graph theory, where "graph theory" means "/spl lambda/-theory of a graph model\
[Bohm tree, graph theory, Lattices, Calculus, equational theory, Tree graphs, untyped lambda calculus, unsolvable /spl lambda/-terms, greatest sensible graph theory, Mathematical model, Logic, Kernel, graph models, least sensible /spl lambda/-theory, lambda calculus, equational extensions, nonsyntactic model, lambda calculus semantics, Graph theory, Topology, minimal lambda theory, Character generation, Differential equations, sensible /spl lambda/-theories, solvable /spl lambda/-terms]
Light types for polynomial time computation in lambda-calculus
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We propose a new type system for lambda-calculus ensuring that well-typed programs can be executed in polynomial time: dual light affine logic (DIAL). DIAL has a simple type language with a linear and an intuitionistic type arrow, and one modality. It corresponds to a fragment of light affine logic (LAL). We show that contrarily to LAL, DIAL ensures good properties on lambda-terms: subject reduction is satisfied and a well-typed term admits a polynomial bound on the reduction by any strategy. Finally we establish that as LAL, DIAL allows to represent all polytime functions.
[type language, well-typed term, linear type arrow, polynomial time computation, dual light affine logic, light types, type theory, lambda-calculus, Runtime, Polynomials, Space exploration, Informatics, polynomial bound, lambda-terms, lambda calculus, intuitionistic type arrow, Logic design, Computational complexity, Programming profession, subject reduction, Computer science, polytime functions, Set theory, well-typed programs, computational complexity]
Beyond image-finiteness: labelled transition systems as a Stone space
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
The bisimulation quotient of labelled transition systems over a finite set of events is a Stone space whose compact, zero-dimensional, and ultra-metrizable Hausdorff topology measures the degree of bisimilarity such that image-finite labelled transition systems are dense. A fully abstract domain for modal transition systems, modulo refinement, realizes this Stone space as a 'maximal-points space'. Therefore, we extend our results to those systems; unify existing denotational, operational, and metric semantics; and obtain consistency measures for modal transition systems.
[System testing, Protocols, operational semantics, compact Hausdorff topology, set theory, image finiteness, Fluid flow measurement, modal transition systems, metric semantics, bisimulation equivalence, Logic, zero-dimensional Hausdorff topology, denotational semantics, topology, Extraterrestrial measurements, Educational institutions, Topology, labelled transition systems, Computer science, Information security, Systems engineering and theory, bisimulation quotient, maximal-points space, ultra-metrizable Hausdorff topology, finite event set, Stone space]
A graph of a relational structure and constraint satisfaction problems
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
In the constraint satisfaction problem CSP(H) corresponding to a finite relational structure H, the aim is to decide, given a relational structure G, whether there exists a homomorphism from G to H. In (Bulatov, 2003), we proved that if H is a conservative structure, then it can be associated with a complete edge-3-colored graph whose vertex set is the universe of H. The complexity and a solution algorithm for CSP(H) strongly depend on certain properties of the associated graph. In this paper we show how a similar edge-3-colored graph can be defined for an arbitrary finite relational structure H. Then we study properties of the defined graph and find a solution algorithm for CSP(H), where G(H) satisfies some restrictions. The latter result substantially generalizes the results (2000,2002,1998,1997) concerning max-closed constraints and constraints with a 2-semilattice, semigroup or conservative groupoid polymorphism. Finally, we complete the study of the complexity of maximal constraint languages started in (Bulatov et al., 2001).
[Algorithm design and analysis, Heuristic algorithms, vertex, Laboratories, constraint theory, 2-semilattice, finite relational structure, graph colouring, group theory, constraint satisfaction problems, edge-3-colored graph, relational structure graph, max-closed constraints, maximal constraint languages, conservative structure, semigroup, homomorphism, Polynomials, Time factors, algorithm complexity, conservative groupoid polymorphism, computational complexity]
A second-order theory for NL
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We introduce a second-order theory V-Krom of bounded arithmetic for nondeterministic log space. This system is based on Gradel's characterization of NL by second-order Krom formulae with only universal first-order quantifiers, which in turn is motivated by the result that the decision problem for 2-CNF satisfiability is complete for coNL (and hence for NL). This theory has the style of the authors' theory Vi-Horn [APAL 124 (2003)] for polynomial time. Both theories use Zambella's elegant second-order syntax, and are axiomatized by a set 2-BASIC of simple formulae, together with a comprehension scheme for either second-order Horn formulae (in the case of V/sub 1/-Horn), or second-order Krom (2CNF) formulae (in the case of V-Krom). Our main result for V-Krom is a formalization of the Immerman-Szelepcsenyi theorem that NL is closed under complementation. This formalization is necessary to show that the NL functions are /spl Sigma//sub 1//sup B/-definable in V-Krom. The only other theory for NL in the literature relies on the Immerman-Szelepcsenyi's result rather than proving it.
[second-order theory, decision problem, universal first-order quantifiers, 2-CNF satisfiability, Immerman-Szelepcsenyi theorem, computability, second-order Krom formulae, nondeterministic log space, second-order Horn formulae, Turing machines, set 2-BASIC, elegant second-order syntax, Polynomials, polynomial time, Logic, V-Krom, Horn clauses, Gradel characterization, bounded arithmetic, Encoding, NL functions, Computer science, formalization, Vi-Horn, Artificial intelligence, Arithmetic, computational complexity]
The strength of replacement in weak arithmetic
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
The replacement (or collection or choice,) axiom scheme BB(/spl Gamma/) asserts bounded quantifier exchange as follows: /spl forall/I < |a| /spl exist/x < ao(i, x) /spl rarr/ /spl exist/w /spl forall/i < |a| o (i, [w]/sub i/) where o is in the class /spl Gamma/ of formulas. The theory S/sub 2//sup 1/ proves the scheme BB(/spl Sigma//sub 1//sup b/), and thus in S/sub 2//sup 1/ every /spl Sigma//sub 1//sup b/ formula is equivalent to a strict /spl Sigma//sub 1//sup b/ formula (in which all non-sharply-bounded quantifiers are in front). Here we prove (sometimes subject to an assumption) that certain theories weaker than S/sub 2//sup 1/ do not prove either BB(/spl Sigma//sub 1//sup b/) or BB(/spl Sigma//sub 0//sup b/). We show (unconditionally) that V/sup 0/ does not prove BB(/spl Sigma//sub 1//sup B/), where V/sup 0/ (essentially I/spl Sigma//sub 0//sup 1,b/) is the two-sorted theory associated with the complexity class AC/sup 0/. We show that PV does not prove BB(/spl Sigma//sub 0//sup b/), assuming that integer factoring is not possible in probabilistic polynomial time. Johannsen and Pollet introduced the theory C/sub 2//sup 0/ associated with the complexity class TC/sup 0/, and later introduced an apparently weaker theory /spl Delta//sub 1//sup b/ - CR for the same class. We use our methods to show that /spl Delta//sub 1//sup b/ - CR is indeed weaker than C/sub 2//sup 0/, assuming that RSA is secure against probabilistic polynomial time attack. Our main tool is the KPT witnessing theorem.
[Gold, strict /spl Sigma//sub 1//sup b/ formula, RSA, complexity class, KPT witnessing theorem, weak arithmetic, nonsharply-bounded quantifiers, integer factoring, Computer science, formal logic, replacement axiom scheme, probabilistic polynomial time, two-sorted theory, Polynomials, bounded quantifier exchange, Arithmetic, computational complexity]
On the geometry of interaction for classical logic
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
It is well-known that weakening and contraction cause naive categorical models of the classical sequent calculus to collapse to Boolean lattices. We introduce sound and complete models that avoid this collapse by interpreting cut-reduction by a partial order between morphisms. We provide concrete examples of such models by applying the geometry-of-interaction construction to quantaloids with finite biproducts, and show how these models illuminate cut reduction in the presence of weakening and contraction. Our models make no commitment to any translation of classical logic into intuitionistic logic and distinguish non-deterministic choices of cut-elimination.
[sequent calculus, Solid modeling, cut elimination, Lattices, naive categorical models, quantaloids, intuitionistic logic, Calculus, Boolean algebra, Geometry, Computer science, Boolean functions, process algebra, geometry-of-interaction construction, Chromium, Concrete, finite biproducts, Logic, Boolean lattices, classical logic]
Bisimulation: from the origins to today
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
This is a summary of topics that the author discussed at LICS'04. The author intends to expand substantially some of them, notably the part on the origins of bisimulation (and co-induction).
[Computer science, Concurrent computing, bisimulation, Automata, Lattices, coinductive proof, bisimulation equivalence, Carbon capture and storage, Logic, bisimilarity, inductive definition]
The succinctness of first-order logic on linear orders
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Succinctness is a natural measure for comparing the strength of different logics. Intuitively, a logic L/sub 1/ is more succinct than another logic L/sub 2/ if oil properties that can be expressed in L/sub 2/ can be expressed in L/sub 1/ by formulas of (approximately) the same size, but some properties can be expressed in L/sub 1/ by (significantly) smaller formulas. We study the succinctness of logics on linear orders that have the same expressive power as first-order logic. Our first theorem is concerned with the finite variable fragments of first-order logic. We prove that:(i) Up to a polynomial factor, the 2- and the 3-variable fragments of first-order logic on linear orders have the same succinctness.(ii) The 4-variable fragment is exponentially more succinct than the 3-variable fragment. Our second main result compares the succinctness of first-order logic on linear orders with that of monadic second-order logic. We prove that the fragment of monadic second-order logic that has the same expressiveness as first-order logic on linear orders is non-elementarily more succinct than first-order logic.
[finite variable fragments, Scattering, first-order logic, Encoding, Complexity theory, polynomial factor, Application software, Database languages, Computer science, formal logic, succinctness, Power measurement, Automata, Polynomials, monadic second-order logic, Logic, linear orders, logics strength]
Games with secure equilibria
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
In 2-player nonzero-sum games, Nash equilibria capture the options for rational behavior if each player attempts to maximize her payoff. In contrast to classical game theory, we consider lexicographic objectives: first, each player tries to maximize her own payoff, and then, the player tries to minimize the opponent's payoff. Such objectives arise naturally in the verification of systems with multiple components. There, instead of proving that each component satisfies its specification no matter how the other components behave, it often suffices to prove that each component satisfies its specification provided that the other components satisfy their specifications. We say that a Nash equilibrium is secure if it is an equilibrium with respect to the lexicographic objectives of both players. We prove that in graph games with Borel objectives, which include the games that arise in verification, there may be several Nash equilibria, but there is always a unique maximal payoff profile of secure equilibria. We show how this equilibrium can be computed in the case of /spl omega/-regular objectives, and we characterize the memory requirements of strategies that achieve the equilibrium.
[maximal payoff profile, graph theory, game theory, Nash equilibrium, component specification, graph games, systems verification, nonzero-sum games, Game theory, formal specification, Computer science, secure equilibria, Borel objectives, formal verification, Nash equilibria, lexicographic objectives]
A sequent calculus for nominal logic
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Nominal logic is a theory of names and binding based on the primitive concepts of freshness and swapping, with a self-dual N- (or "new")-quantifier, originally presented as a Hilbert-style axiom system extending first-order logic. We present a sequent calculus for nominal logic called fresh logic, or FL, admitting cut-elimination. We use FL to provide a proof-theoretic foundation for nominal logic programming and show how to interpret FO/spl lambda//spl nabla/, another logic with a self-dual quantifier, within FL.
[sequent calculus, Protocols, Logic programming, Data security, Neodymium, Humans, first-order logic, Hilbert spaces, Calculus, FO/spl lambda//spl nabla/, Hilbert-style axiom, fresh logic, proof theory, Computer science, cut-elimination, process algebra, nominal logic, logic programming, Concrete, self-dual N-quantifier, theorem proving]
From automata to formulas: convex integer polyhedra
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Automata-based representations have recently been investigated as a tool for representing and manipulating sets of integer vectors. In this paper, we study some structural properties of automata accepting the encodings (most significant digit first) of the natural solutions of systems of linear Diophantine inequations, i.e., convex polyhedra in /spl Nopf//sup n/. Based on those structural properties, we develop an algorithm that takes as input an automaton and generates a quantifier-free formula that represents exactly the set of integer vectors accepted by the automaton. In addition, our algorithm generates the minimal Hilbert basis of the linear system. In experiments made with a prototype implementation, we have been able to synthesize in seconds formulas and Hilbert bases from automata with more than 10,000 states.
[Linear systems, quantifier-free formula, Optimizing compilers, combinatorial mathematics, automata theory, Automata-based representation, computational geometry, Linear programming, Vectors, Encoding, integer vectors, Program processors, linear system, Difference equations, linear Diophantine inequations, Automata, Prototypes, convex integer polyhedra, Hilbert basis, Arithmetic]
Model-checking problems as a basis for parameterized intractability
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Most parameterized complexity classes are defined in terms of a parameterized version of the Boolean satisfiability problem (the so-called weighted satisfiability problem. For example, Downey and Fellow's W-hierarchy is of this form. But there are also classes, for example, the A-hierarchy, that are more naturally characterised in terms of model-checking problems for fragments of first-order logic. R. G. Downey et al. (1998) were the first to establish a connection between the two formalisms by giving a characterisation of the W-hierarchy in terms of first-order model-checking problems. We improve their result and then prove a similar correspondence between weighted satisfiability and model-checking problems for the A-hierarchy and the W-hierarchy. Thus we obtain very uniform characterisations of many of the most important parameterized complexity classes in both formalisms. Our results can be used to give new, simple proofs of some of the core results of structural parameterized complexity theory.
[Algorithm design and analysis, Terminology, weighted satisfiability problem, Boolean satisfiability problem, A-hierarchy, first-order logic, Relational databases, computability, Calculus, Complexity theory, Boolean algebra, W-hierarchy, formal verification, parameterized intractability, structural parameterized complexity, Query processing, uniform characterisations, Polynomials, Logic, first-order model-checking problems, computational complexity]
Deciding quantifier-free Presburger formulas using parameterized solution bounds
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Given a formula /spl Phi/ in quantifier-free Presburger arithmetic, it is well known that, if there is a satisfying solution to /spl Phi/, there is one whose size, measured in bits, is polynomially bounded in the size of /spl Phi/. In this paper, we consider a special class of quantifier-free Presburger formulas in which most linear constraints are separation (difference-bound) constraints, and the nonseparation constraints are sparse. This class has been observed to commonly occur in software verification problems. We derive a solution bound in terms of parameters characterizing the sparseness of linear constraints and the number of nonseparation constraints, in addition to traditional measures of formula size. In particular, the number of bits needed per integer variable is linear in the number of nonseparation constraints and logarithmic in the number and size of nonzero coefficients in them, but is otherwise independent of the total number of linear constraints in the formula. The derived bound can be used in a decision procedure based on instantiating integer variables over a finite domain and translating the input quantifier-free Presburger formula to an equisatisfiable Boolean formula, which is then checked using a Boolean satisfiability solver. We present empirical evidence indicating that this method can greatly outperform other decision procedures.
[quantifier-free Presburger formulas, program verification, software verification, separation constraints, computability, Cost accounting, Boolean functions, decidability, Bismuth, Polynomials, Hardware, parameterized solution bounds, Logic, difference-bound constraints, constraint theory, quantifier-free Presburger arithmetic, Size measurement, Encoding, Boolean satisfiability solver, equisatisfiable Boolean formula, Computer science, nonseparation constraints, linear constraints, decision procedures, Arithmetic, Electronics packaging, computational complexity]
An algebraic approach to the complexity of propositional circumscription
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Every logical formalism gives rise to two fundamental problems: model checking and inference. Circumscription is one of the most important and well studied formalisms in the realm of nonmonotonic reasoning. The model checking and inference problem for propositional circumscription has been extensively studied from the viewpoint of computational complexity. We use a new approach based on algebraic techniques to study the complexity of the model checking and inference problems for propositional variable circumscription in a unified way. We prove that there exists a dichotomy theorem for the complexity of the inference problem in propositional variable circumscription. We also study the model checking and inference problem for propositional variable circumscription in many-valued logics using the same algebraic techniques. In particular we prove dichotomy theorems for the complexity of model checking and inference for propositional variable circumscription in the case of 3-valued logic.
[model inference, 3-valued logic, dichotomy theorem, Multivalued logic, Boolean algebra, inference problem, Computational complexity, nonmonotonic reasoning, algebraic approach, Information science, Boolean functions, model checking, multivalued logic, propositional circumscription complexity, Logic functions, Polynomials, many-valued logics, logical formalism, computational complexity]
Self-adjusting computation
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
A static algorithm is one that computes the result of a query about the output for a single, fixed input. For example, a static sorting algorithm is one that takes as input a set of keys, and permits queries about the relative order of these keys according to some ordering relation. A dynamic, or incremental, algorithm is one that permits queries about the output to be interleaved with operations that incrementally modify the input. For example, a dynamic sorting algorithm is one that would permit insertion or deletion of keys to be interleaved with queries about their relative ordering. It is often easier to find a static algorithm than a dynamic algorithm for a given problem. There is a large and growing literature on dynamic algorithms for a broad range of problems. Self-adjusting computation is a method for deriving a dynamic algorithm for a problem by "dynamizing" a static algorithm for it. We have studied three main techniques for dynamization: 1. adaptivity 2. selective memoization 3. adaptive memoization.
[static sorting algorithm, Heuristic algorithms, Data structures, Adaptive control, incremental algorithm, Sorting, Computer science, fixed input, Programmable control, self-adjusting computation, ordering relation, selective memoization, algorithm theory, adaptive memoization, Kinetic theory, Logic, dynamic sorting algorithm, self-adaptive computation]
Testing, optimization, and games
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We discuss algorithmic problems arising in the testing of reactive systems, i.e. systems that interact with their environment. The goal is to design test sequences so that we can deduce desired information about the given system under test, such as whether it conforms to a given specification model, or whether it satisfies given requirement properties. Test generation can be approached from different points of view - as an optimization problem of minimizing cost and maximizing the effectiveness of the tests; as a game between tester and system under test; or as a learning problem. We touch on some of these aspects and related algorithmic questions.
[Software testing, algorithmic problems, System testing, optimization problem, program testing, program verification, game theory, conformance testing, Logic testing, formal specification, reactive system testing, test sequences, Computer science, test generation, optimisation, Automatic testing, Automata, Cost function, Software systems, Hardware]
The omega rule is /spl Pi//sub 2//sup 0/-hard in the /spl lambda//spl beta/-calculus
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We give a many-one reduction of the set of true /spl Pi//sub 2//sup 0/ sentences to the set of consequences of the lambda calculus with the omega rule. This solves in the affirmative a well known problem of H. Barendregt. The technique of proof has interest in itself and can be extended to prove that the theory which identifies all unsolvable terms together with the omega rule is H/sub 1//sup 1/-complete which solves another long-standing conjecture of H. Barendregt.
[lambda calculus, many-one set reduction, Automation, H/sub 1//sup 1/-complete, Terminology, unsolvable terms, omega rule, Calculus, proof technique, /spl lambda//spl beta/-calculus, Computer science, pi calculus, /spl Pi//sub 2//sup 0/-hard, Character generation, Logic, /spl Pi//sub 2//sup 0/ sentences, computational complexity]
Multi-clock timed networks
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We consider verification of safety properties for parameterized systems of timed processes, so called timed networks. A timed network consists of a finite state process, called a controller, and an arbitrary set of identical timed processes. In a previous work, we showed that checking safety properties is decidable in the case where each timed process is equipped with a single real-valued clock. It was left open whether the result could be extended to multi-clock timed networks. We show that the problem becomes undecidable when each timed process has two clocks. On the other hand, we show that the problem is decidable when clocks range over a discrete time domain. This decidability result holds when processes have any finite number of clocks.
[Safety devices, Protocols, discrete time domain, Process control, Control systems, Encoding, safety properties verification, finite state machines, Counting circuits, clocks, real-valued clock, parameterized systems, decidability, formal verification, timed processes, Automata, Automatic control, finite state process, Timing, Clocks, multi-clock timed networks]
Automatic structures: richness and limitations
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
This paper studies the existence of automatic presentations for various algebraic structures. The automatic Boolean algebras are characterised, and it is proven that the free Abelian group of infinite rank and many Fraisse limits do not have automatic presentations. In particular, the countably infinite random graph and the universal partial order do not have automatic presentations. Furthermore, no infinite integral domain is automatic. The second topic of the paper is the isomorphism problem. We prove that the complexity of the isomorphism problem for the class of all automatic structures is /spl Sigma//sub 1//sup 1/-complete.
[infinite rank, automata theory, Abelian group, Automatic logic units, Boolean algebra, infinite random graph, universal partial order, isomorphism problem, Computer science, group theory, isomorphism complexity, algebraic structures, automatic Boolean algebras, Fraisse limits, computational complexity]
A symmetric modal lambda calculus for distributed computing
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We present a foundational language for spatially distributed programming, called Lambda 5, that addresses both mobility of code and locality of resources. In order to construct our system, we appeal to the powerful propositions-as-types interpretation of logic. Specifically, we take the possible worlds of the intuitionistic modal logic IS5 to be nodes on a network, and the connectives /spl square/ and /spl diams/ to reflect mobility and locality, respectively. We formulate a novel system of natural deduction for IS5, decomposing the introduction and elimination rules for /spl square/ and /spl diams/, thereby allowing the corresponding programs to be more direct. We then give an operational semantics to our calculus that is type-safe, logically faithful, and computationally realistic.
[lambda calculus, foundational language, Logic programming, Scientific computing, intuitionistic modal logic, Instruments, operational semantics, propositions-as-types logic interpretation, Calculus, IS5, elimination rules, programming languages, programming language semantics, Distributed computing, distributed computing, Computer languages, Physics computing, Lambda 5, spatially distributed programming, Computer networks, symmetric modal lambda calculus, Internet, Large-scale systems, distributed programming]
First-order definable retraction problems for posets and reflexive graphs
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
A retraction from a structure P to its substructure Q is a homomorphism from P onto Q that is the identity on Q. We present an algebraic condition which completely characterises all posets and all reflexive graphs Q with the following property: the class of all posets or reflexive graphs, respectively, that admit a retraction onto Q is first-order definable.
[posets, Vocabulary, combinatorial mathematics, structure P, substructure Q, Computational complexity, reflexive graphs, Computer science, formal logic, algebraic condition, definable retraction problems, graphs, first-order retraction problems, Chromium, homomorphism, Logic, Artificial intelligence]
Equicardinality on linear orders
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Linear orders are of inherent interest infinite model theory, especially in descriptive complexity theory. Here, the class of ordered structures is approached from a novel point of view, using generalized quantifiers as a means of analysis. The main technical result is a characterization of the cardinality quantifiers which can express equicardinality on ordered structures. This result can be viewed as a dichotomy: the cardinality quantifier either shows a lot of periodicity, or is quite non-periodic, the equicardinality quantifier being definable only in the latter case. The main result shows, once more, that there is a drastic difference between definability among ordered structures and definability on unordered structures. Connections of the result to the descriptive complexity of low-level complexity classes are discussed.
[Vocabulary, cardinality quantifiers, Mathematics, Complexity theory, Statistics, Computer science, formal logic, Turing machines, infinite model theory, descriptive complexity theory, generalized quantifiers, equicardinality, ordered structures, Logic, Mathematical model, linear orders, computational complexity]
High-level methods for quantum computation and information
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Quantum information and computation is concerned with the use of quantum-mechanical systems to carry out computational and information-processing tasks (Nielsen and Chunag, 2000). In the few short years that this approach has been studied, a number of remarkable concepts and results have emerged, most notably:a couple of spectacular algorithms and a number of information protocols, exemplified by quantum teleportation, which exploit quantum entanglement in an essential fashion. The current tools available for developing quantum algorithms and protocols are deficient on two main levels: firstly, they are too low-level and at a more fundamental level, the standard mathematical framework for quantum mechanics (which is essentially due to von Neumann (1932)) is actually insufficiency comprehensive for informatic purposes. In joint work with Bob Coecke, we have recently made some striking progress in addressing both these points. They have recast the von Neumann formalism at a more abstract and conceptual level, using category theory.
[Performance evaluation, computational tasks, Protocols, Laboratories, Circuits, quantum-mechanical systems, quantum entanglement, Fault tolerance, Quantum computing, Fluid flow measurement, high-level methods, quantum mechanics, von Neumann formalism, Polynomials, quantum communication, quantum algorithms, quantum computation, quantum teleportation, Quantum entanglement, Teleportation, teleportation, information protocols, quantum information, quantum computing, category theory, information-processing tasks]
Congruence for SOS with data
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
While studying the specification of the operational semantics of different programming languages and formalisms, one can observe the following three facts. Firstly, Plotkin's style of structured operational semantics (SOS) has become a standard in defining operational semantics. Secondly, congruence with respect to some notion of bisimilarity is an interesting property for such languages and it is essential in reasoning about them. Thirdly, there are numerous languages that contain an explicit data part in the state of the operational semantics. The first two facts have resulted in a line of research exploring syntactic formats of operational rules to derive the desired congruence property for free. However, the third point (in combination with the first two) is not sufficiently addressed and there is no standard congruence format for operational semantics with an explicit data state. In this paper, we address this problem by studying the implications of the presence of a data state on the notion of bisimilarity. Furthermore, we propose a number of formats for congruence.
[operational rules, formal languages, operational semantics specifications, syntactic formats, programming formalisms, Proposals, Application software, programming language semantics, programming languages, formal specification, bisimilarity, explicit data, Computer science, congruence property, Computer languages, data state, Layout, structured operational semantics, bisimulation equivalence, Logic, Plotkin style, congruence format]
Semantics of a sequential language for exact real-number computation
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We study a programming language with a built-in ground type for real numbers. In order for the language to be sufficiently expressive but still sequential, we consider a construction proposed by Boehm and Cartwright. The non-deterministic nature of the construction suggests the use of powerdomains in order to obtain a denotational semantics for the language. We show that the construction cannot be modelled by the Plotkin or Smyth powerdomains, but that the Hoare powerdomain gives a computationally adequate semantics. As is well known, Hoare semantics can be used in order to establish partial correctness only. Since computations on the reals are infinite, one cannot decompose total correctness into the conjunction of partial correctness and termination as it is traditionally done. We instead introduce a suitable operational notion of strong convergence and show that total correctness can be proved by establishing partial correctness (using denotational methods) and strong convergence (using operational methods). We illustrate the technique with a representative example.
[operational methods, program verification, sequential language, convergence, Mathematics, Proposals, programming language semantics, programming languages, language semantics, Convergence, Hoare powerdomain, Concurrent computing, Computer science, Computer languages, real-number computation, denotational methods, Parallel processing, Plotkin powerdomains, programming language, power domains, Smyth powerdomains, denotational semantics]
Three-valued abstractions of games: uncertainty, but with precision
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We present a framework for abstracting two-player turn-based games that preserves any formula of the alternating /spl mu/-calculus (AMC). Unlike traditional conservative abstractions which can only prove the existence of winning strategies for only one of the players, our framework is based on 3-valued games, and it can be used to prove and disprove formulas of AMC including arbitrarily nested strategy quantifiers. Our main contributions are as follows. We define abstract 3-valued games and an alternating refinement relation on these that preserves winning strategies for both players. We provide a logical characterization of the alternating refinement relation. We show that our abstractions are as precise as can be via completeness results. We present AMC formulas that solve 3-valued games with /spl omega/-regular objectives, and we show that such games are determined in a 3-valued sense. We also discuss the complexity of model checking arbitrary AMC formulas on 3-valued games and of checking alternating refinement.
[Uncertainty, Computational modeling, arbitrarily nested strategy quantifiers, alternating refinement relation, game theory, refinement calculus, Control systems, conservative abstractions, State-space methods, Application software, abstract 3-valued games, three-valued abstractions, game abstraction, formal verification, model checking, process algebra, two-player turn-based games, Open systems, Concrete, Logic, alternating mu-calculus, Formal verification, Context modeling]
Nominal games and full abstraction for the nu-calculus
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We introduce nominal games for modelling programming languages with dynamically generated local names, as exemplified by Pitts and Stark's nu-calculus. Inspired by Pitts and Gabbay's recent work on nominal sets, we construct arenas and strategies in the world (or topos) of Fraenkel-Mostowski sets (or simply FM-sets). We fix an infinite set N of names to be the "atoms" of the FM-theory, and interpret the type v of names as the flat arena whose move-set is N. This approach leads to a clean and precise treatment of fresh names and standard game constructions (such as plays, views, innocent strategies, etc.) that are considered invariant under renaming. The main result is the construction of the first fully-abstract model for the nu-calculus.
[infinite set, fully-abstract model, full abstraction, game theory, Calculus, set theory, programming languages, Yarn, Computer languages, Privacy, Runtime, nu-calculus, process algebra, programming languages modeling, Fraenkel-Mostowski sets, nominal games, move set, Joining processes, Testing]
Feasible proofs and computations: partnership and fusion
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
A computation or a proof is called feasible if it obeys prescribed bounds on the resources consumed during its execution. It turns out that when restricted to this world of feasibility, proofs and computations become extremely tightly interrelated, sometimes even indistinguishable. Moreover, many of these rich relations, underlying concepts, techniques etc. look very different from their "'classical" counterparts, or simply do not have any. This paper is intended as a very informal and popular (highly biased as well) attempt to illustrate these fascinating connections by several related developments in the modern complexity theory.
[Computer science, complexity theory, feasible computation, Humans, Solids, Mathematics, Polynomials, Complexity theory, theorem proving, proof feasibility, Logic, computational complexity]
On the automata size for Presburger arithmetic
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Automata provide an effective mechanization of decision procedures for Presburger arithmetic. However, only crude lower and upper bounds are known on the sizes of the automata produced by this approach. In this paper, we prove that the number of states of the minimal deterministic automaton for a Presburger arithmetic formula is triple exponentially bounded in the length of the formula. This upper bound is established by comparing the automata for Presburger arithmetic formulas with the formulas produced by a quantifier elimination method. We also show that this triple exponential bound is tight (even for nondeterministic automata). Moreover, we provide optimal automata constructions for linear equations and inequations.
[automata size, linear inequations, Linear programming, arithmetic, Presburger arithmetic, Equations, minimal deterministic automaton, Computer science, Upper bound, Turing machines, Councils, deterministic automata, Automata, Collaborative work, quantifier elimination, Logic, optimal automata constructions, Arithmetic, linear equations]
VTC/sup O/: a second-order theory for TC/sup 0/
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We introduce a finitely axiomatizable second-order theory, which is VTC/sup 0/ associated with the class FO-uniform TC/sup 0/. It consists of the base theory V/sup 0/ for AC/sup 0/ reasoning together with the axiom NUMONES, which states the existence of a "counting array" Y for any string X: the ith row of Y contains only the number of 1 bits up to (excluding) bit i of X. We introduce the notion of "strong /spl Delta//sub 1//sup B/-definability" for relations in a theory, and use a recursive characterization of the TC/sup 0/ relations (rather than functions) to show that the TC/sup 0/ relations are strongly /spl Delta//sub 1//sup B/-definable. It follows that the TC/sup 0/ functions are /spl Sigma//sub 1//sup B/-definable in VTC/sup 0/. We prove a general witnessing theorem for second-order theories and conclude that the/spl Sigma//sub 1//sup B/ theorems of VTC/sup 0/ are witnessed by TC/sup 0/ functions. We prove that VTC/sup 0/ is RSUV isomorphic to the first order theory /spl Delta//sub 1//sup b/-CR of Johannsen and Pollett (the "minimal theory for TC/sup 0/"), /spl Delta//sub 1//sup b/-CR includes the /spl Delta//sub 1//sup b/ comprehension rule, and J and P ask whether there is an upper bound to the nesting depth required for this rule. We answer "yes\
[counting array, polynomial-size constant-depth, RSUV isomorphism, nesting depth, first order theory, constant-depth TC/sup 0/-Frege proofs, polynomial-size TC/sup 0/-Frege proofs, Logic circuits, propositional tautologies, Polynomials, formal languages, NUMONES, minimal theory, FO-uniform TC/sup 0/, recursive functions, axiomatizable second-order theory, Sorting, finitely second-order theory, Computer science, recursive characterization, Upper bound, general witnessing theorem, comprehension rule, AC/sup O/reasoning, Artificial intelligence, computational complexity]
Proving termination assertions in dynamic logics
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Total correctness assertions (TCAs) have long been considered a natural formalization of successful program termination. However, research dating back to the 1980s suggests that validity of TCAs is a notion of limited interest; we corroborate this by proving compactness and Herbrand properties for the valid TCAs, defining in passing a new sound, complete, and syntax-directed deductive system for TCAs. It follows that proving TCAs whose truth depends on underlying inductive data-types is impossible in logics of programs that are sound for all structures, such as dynamic logic based on Segerberg's PDL, even when augmented with powerful first-order theories like Peano arithmetic. Harel's convergence rule bypasses this difficulty, but is methodologically and conceptually problematic, in addition to being unsound for general validity. We propose instead to bind variables to inductive data via DL's box operator, leading to an alternative formalization of termination assertions, which we dub inductive TCA (ITCA). We observe that a TCA is provable in Harel's DL exactly when the corresponding ITCA is provable in Segerberg's DL, thereby showing that the convergence rule is not foundationally or practically necessary. We also show that validity of ITCAs is directly reducible to validity of partial correctness assertions, confirming the foundational importance of the latter.
[Peano arithmetic, inductive TCA, program verification, total correctness assertions, Herbrand properties, dynamic logics, Computer science, formal logic, program termination, syntax-directed deductive system, inductive data-types, PDL, theorem proving, Logic, program logics, termination assertions, Harel convergence rule, inductive logic programming]
A landscape with games in the background
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
An overview of applications of two player path-forming games to verification and synthesis is given. Several extensions of the standard model of finite games with regular winning conditions are discussed. One direction is that of considering non-regular winning conditions. The other concerns the ways games are played, in particular probabilistic and multi-player games.
[winning conditions, program verification, multiplayer games, game theory, Probabilistic logic, synthesis problems, Proposals, Game theory, Cost accounting, Stress, Computer science, probabilistic games, Automata, finite games, Robustness, verification problems, path-forming games]
On the language inclusion problem for timed automata: closing a decidability gap
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We consider the language inclusion problem for timed automata: given two timed automata A and B, are all the timed traces accepted by B also accepted by A? While this problem is known to be undecidable, we show here that it becomes decidable if A is restricted to having at most one clock. This is somewhat surprising, since it is well-known that there exist timed automata with a single clock that cannot be complemented. The crux of our proof consists in reducing the language inclusion problem to a reachability question on an infinite graph; we then construct a suitable well-quasi-order on the nodes of this graph, which ensures the termination of our search algorithm. We also show that the language inclusion problem is decidable if the only constant appearing among the clock constraints of A is zero. Moreover, these two cases are essentially the only decidable instances of language inclusion, in terms of restricting the various resources of timed automata.
[Real time systems, Algorithm design and analysis, reachability analysis, decidability gap, well-quasiorder, search algorithm, Computational modeling, automata theory, language inclusion, Government, computational linguistics, Mathematics, Computer science, infinite graph, clock constraints, decidability, Automata, reachability, timed automata, Artificial intelligence, Contracts, Clocks]
Parametric limits
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We develop a categorical model of polymorphic lambda calculi using the notion of parametric limits, which extend the notion of limits in categories to reflexive graphs of categories. We show that a number of parametric models of polymorphism can be captured in this way. We also axiomatize the structure of reflexive graphs needed for modelling parametric polymorphism based on ideas of fibrations, and show that it leads to proofs of representation results such as the initial algebra and final coalgebra properties one expects in polymorphic lambda calculi.
[lambda calculus, final coalgebra properties, relational parametricity, topology, reflexive graphs, Computer science, polymorphic lambda calculi, parametric polymorphism, parametric limits, parametric models, categorical model, fibrations, Logic, representation proofs, initial algebra]
Towards imperative modules: reasoning about invariants and sharing of mutable state
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Imperative and object-oriented programs make ubiquitous use of shared mutable objects. Updating a shared object can and often does transgress a boundary that was supposed to be established using static constructs such as a class with private fields. This paper shows how auxiliary fields can be used to express two state-dependent encapsulation disciplines: ownership, a kind of separation, and local co-dependence, a kind of sharing. A methodology is given for specification and modular verification of encapsulated object invariants and shown sound for a class-based language.
[Encapsulation, object-oriented programming, Object oriented modeling, Interference, encapsulated object invariants, Data structures, Reasoning about programs, mutable state, formal specification, Programming profession, static constructs, modular verification, Computer science, state-dependent encapsulation, formal verification, class-based language, object-oriented programs, shared mutable objects, imperative modules, auxiliary fields, Logic, Protection, data encapsulation, imperative programs]
Proof nets and Boolean circuits
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We study the relationship between proof nets for mutiplicative linear logic (with unbounded fan-in logical connectives) and Boolean circuits. We give simulations of each other in the style of the proofs-as-programs correspondence; proof nets correspond to Boolean circuits and cut-elimination corresponds to evaluation. The depth of a proof net is defined to be the maximum logical depth of cut formulas in it, and it is shown that every unbounded fan-in Boolean circuit of depth n, possibly with stC0NN/sub 2/ gates, is polynomially simulated by a proof net of depth O(n) and vice versa. Here, stC0NN/sub 2/ stands for st-connectivity gates for undirected graphs of degree 2. Let APN/sup i/ be the class of languages for which there is a polynomial size, log/sup i/-depth family of proof nets. We then have APN/sup i/ = AC/sup i/(stCONN/sub 2/).
[Circuit simulation, Computational modeling, mutiplicative linear logic, proof nets, circuit simulation, Computational complexity, Concurrent computing, Computer science, Boolean functions, cut-elimination, Turing machines, st-connectivity gates, Logic circuits, unbounded fan-in logical connectives, Polynomials, theorem proving, Boolean circuits, proofs-as-programs correspondence, undirected graphs, Informatics, logic circuits, computational complexity]
Vector addition tree automata
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We introduce a new class of automata, which we call vector addition tree automata. These automata are a natural generalization of vector addition systems with states, which are themselves equivalent to Petri-nets. Then, we prove that the decidability of provability in multiplicative exponential linear logic (which is an open problem) is equivalent to the decidability of the reachability relation for vector addition tree automata. This result generalizes the well-known connection existing between Petri nets and the !-horn fragment of multiplicative exponential linear logic.
[vector addition tree automata, multiplicative exponential linear logic, automata theory, Petri nets, Natural languages, Vectors, provability, reachability relation, Computer science, vector addition systems, decidability, Automata, Logic, !-horn fragment]
A computational interpretation of open induction
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We study the proof-theoretic and computational properties of open induction, a principle which is classically equivalent to Nash-Williams' minimal-bad-sequence argument and also to (countable) dependent choice (and hence contains full classical analysis). We show that, intuitionistically, open induction and dependent choice are quite different: Unlike dependent choice, open induction is closed under negative- and A-translation, and therefore proves the same /spl pi//sub 2//sup 0/-formulas (over not necessarily decidable, basic-predicates) with classical or intuitionistic arithmetic. Via modified realizability we obtain a new direct method for extracting programs from classical proofs of /spl pi//sub 2//sup 0/-formulas using open induction. We also show that the computational interpretation of classical countable choice given by S. Berardi et al. (1998) can be derived from our results.
[/spl pi//sub 2//sup 0/-formulas, computational interpretation, programs extraction, Topology, countable choice, modified realizability, intuitionistic arithmetic, Computer science, formal logic, open induction, proof-theoretic properties, Set theory, theorem proving, minimal-bad-sequence argument, Logic, dependent choice, Arithmetic]
An arithmetical hierarchy of the law of excluded middle and related principles
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
The topic of this paper is relative constructivism. We are concerned with classifying nonconstructive principles from the constructive viewpoint. We compare, up to provability in intuitionistic arithmetic, subclassical principles like Markov's principle, (a function-free version of) weak Konig's lemma, Post's theorem, excluded middle for simply existential and simply universal statements, and many others. Our motivations are rooted in the experience of one of the authors with an extended program extraction and of another author with bound extraction from classical proofs.
[bound extraction, simply universal statements, simply existential statements, Computer science, formal logic, intuitionistic arithmetic provability, weak Konig lemma, Markov processes, Markov principle, extended program extraction, theorem proving, Logic, classical proofs, Post theorem, relative constructivism, excluded middle law]
Model checking synchronized products of infinite transition systems
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Formal verification using the model-checking paradigm has to deal with two aspects. The systems models are structured, often as products of components, and the specification logic has to be expressive enough to allow the formalization of reachability properties. The present paper is a study on what can be achieved for infinite transition systems under these premises. As models, we consider products of infinite transition systems with different synchronization constraints. We introduce finitely synchronized transition systems, i.e. product systems which contain only finitely many synchronized transitions, and show that the decidability of FO(R), first-order logic extended by reachability predicates, of the product system can be reduced to the decidability of FO(R) of the components in a Feferman-Vaught like style. This result is optimal in the following sense. (1) If we allow semifinite synchronization, i.e. just in one component infinitely many transitions are synchronized, the FO(R)-theory of the product system is in general undecidable. (2) We cannot extend the expressive power of the logic under consideration. Already a weak extension of first-order logic with transitive closure, where we restrict the transitive closure operators to arity one and nesting depth two, is undecidable for an asynchronous (and hence finitely synchronized) product, namely for the infinite grid.
[first-order logic, semifinite synchronization, synchronized transition systems, Filters, decidability, formal verification, FO(R)-theory, infinite transition systems, Logic, reachability properties, Computational modeling, constraint theory, reachability predicates, infinite grid, synchronization constraints, specification logic, arity one, synchronisation, Computer science, FO(R) logic, product system, model checking, transitive closure operators, asynchronous product, nesting depth two]
The existence of finite abstractions for branching time model checking
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Abstraction is often essential to verify a program with model checking. Typically, a concrete source program with an infinite (or finite, but large) state space is reduced to a small, finite state, abstract program on which a correctness property can be checked. The fundamental question we investigate in this paper is whether such a reduction to finite state programs is always possible, for arbitrary branching time temporal properties. We begin by showing that existing abstraction frameworks are inherently incomplete for verifying purely existential or mixed universal-existential properties. We then propose a new, complete abstraction framework which is based on a class of focused transition systems (FTS's). The key new feature in FTS's is a way of "focusing" an abstract state to a set of more precise abstract states. While focus operators have been defined for specific contexts, this result shows their fundamental usefulness for proving non-universal properties. The constructive completeness proof provides linear size maximal models for properties expressed in logics such as CTL and the mu-calculus. This substantially improves upon known (worst-case) exponential size constructions for their universal fragments.
[program verification, linear size maximal models, Scalability, branching time model checking, nonuniversal properties, temporal logic, finite state machines, infinite state space, abstraction framework, Space technology, worst-case exponential size constructions, branching time temporal properties, existential properties, Safety, Logic, abstract state, constructive completeness proof, abstract program, finite abstractions, State-space methods, source program, focused transition systems, Computer science, finite state programs, arbitrary branching time, process algebra, Automata, mixed universal-existential properties, Concrete, Context modeling, focus operators]
Model checking probabilistic pushdown automata
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We consider the model checking problem for probabilistic pushdown automata (pPDA) and properties expressible in various probabilistic logics. We start with properties that can be formulated as instances of a generalized random walk problem. We prove that both qualitative and quantitative model checking for this class of properties and pPDA is decidable. Then, we show that model checking for the qualitative fragment of the logic PCTL and pPDA is also decidable. Moreover, we develop an error-tolerant model checking algorithm for general PCTL and the subclass of stateless pPDA. Finally, we consider the class of properties definable by deterministic Buchi automata, and show that both qualitative and quantitative model checking for pPDA is decidable.
[Uncertainty, Protocols, generalized random walk problem, probabilistic logic, pushdown automata, random processes, Probabilistic logic, probabilistic pushdown automata, PCTL, Computer science, Concurrent computing, Asynchronous communication, probabilistic automata, formal verification, decidability, deterministic automata, Fault tolerant systems, Automata, deterministic Buchi automata, error-tolerant model checking, Personal digital assistants, Informatics]
Spi calculus translated to /spl pi/-calculus preserving may-tests
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
We present a concise and natural encoding of the spi-calculus into the more basic /spl pi/-calculus and establish its correctness with respect to a formal notion of testing. This is particularly relevant for security protocols modelled in spi since the tests can be viewed as adversaries. The translation has been implemented in a prototype tool. As a consequence, protocols can be described in the spi calculus and analysed with the emerging flora of tools already available for /spl pi/. The translation also entails a more detailed operational understanding of spi since high level constructs like encryption are encoded in a well known lower level. The formal correctness proof is nontrivial and interesting in its own; so called context bisimulations and new techniques for compositionality make the proof simpler and more concise.
[Context-aware services, context bisimulations, program verification, spi-calculus, formal testing, Access protocols, cryptography, Calculus, Encoding, Information technology, pi calculus, security protocols, /spl pi/-calculus, encryption, Prototypes, Authentication, Information security, compositionality, bisimulation equivalence, Cryptography, protocols, formal correctness proof, Testing]
Transition invariants
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Proof rules for program verification rely on auxiliary assertions. We propose a (sound and relatively complete) proof rule whose auxiliary assertions are transition invariants. A transition invariant of a program is a binary relation over program states that contains the transitive closure of the transition relation of the program. A relation is disjunctively well-founded if it is a finite union of well-founded relations. We characterize the validity of termination or another liveness property by the existence of a disjunctively well-founded transition invariant. The main contribution of our proof rule lies in its potential for automation via abstract interpretation.
[Automation, Logic programming, program verification, abstract interpretation, transition program relation, auxiliary assertions, State-space methods, Computer science, Computer languages, transition invariants, Automatic testing, Automata, Collaborative work, Safety, theorem proving, program states, transitive closure, proof rules]
Dedicated to the memory of Harald Ganzinger
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
A brief biography of Harald Ganzinger is given highlighting his professional achievements.
[Obituaries, Harald, Ganzinger]
Preface
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Presents the welcome message from the conference proceedings.
[]
Conference organization
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Provides a listing of current committee members and society officers.
[]
Program Committee
Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004.
None
2004
Provides a listing of current committee members.
[]
Foreword
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Presents the welcome message from the conference proceedings.
[]
Conference organization
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Provides a listing of current committee members and society officers.
[]
Program Committee
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Provides a listing of current committee members.
[]
Relations in concurrency
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
The theme of this paper is profunctors, and their centrality and ubiquity in understanding concurrent computation. Profunctors (a.k.a. distributors, or bimodules) are a generalisation of relations to categories. Here they are first presented and motivated via spans of event structures, and the semantics of nondeterministic dataflow. Profunctors are shown to play a key role in relating models for concurrency and to support an interpretation as higher-order processes (where input and output may be processes). Two recent directions of research are described. One is concerned with a language and computational interpretation for profunctors. This addresses the duality between input and output in profunctors. The other is to investigate general spans of event structures (the spans can be viewed as special profunctors) to give causal semantics to higher-order processes. For this it is useful to generalise event structures to allow events, which "persist".
[higher-order processes, Computational modeling, relational algebra, Laboratories, concurrency theory, concurrent computation, History, relations generalisation, Concurrent computing, Computer science, profunctors, nondeterministic dataflow semantics, data flow computing, category theory, Concrete, Books, Logic, event structures]
Regular expressions in process algebra
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We tackle an open question of Milner (1984). We define a set of so-called well-behaved finite automata that, modulo bisimulation equivalence, corresponds exactly to the set of regular expressions.
[formal languages, finite automata, Formal languages, Mathematics, set theory, regular expression, Computer science, Algebra, process algebra, Automata, modulo bisimulation equivalence, System recovery, bisimulation equivalence, Carbon capture and storage, Logic]
Modal characterisation theorems over special classes of frames
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We investigate model theoretic characterisations of the expressive power of modal logics in terms of bisimulation invariance. The paradigmatic result of this kind is van Benthem's theorem, which says that a first-order formula is invariant under bisimulation if and only if it is equivalent to a formula of basic modal logic. The present investigation primarily concerns ramifications for specific classes of structures. We study in particular model classes defined through conditions on the underlying frames, with a focus on frame classes that play a major role in modal correspondence theory and often correspond to typical application domains of modal logics. Classical model theoretic arguments do not apply to many of the most interesting classes -for instance, rooted connected frames, well-founded frames, finite rooted connected frames, finite transitive frames, finite equivalence frames - as these are not elementary. Instead we develop and extend the game-based analysis (first-order Ehrenfeucht-Fraisse versus bisimulation games) over such classes and provide bisimulation preserving model constructions within these classes.
[Computer science, frame classes, first-order formula, Benthem theorem, Laboratories, game theory, bisimulation invariance, modal characterisation theorem, bisimulation equivalence, Logic, modal logic, game-based analysis]
Temporal logics over unranked trees
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We consider unranked trees that have become an active subject of study recently due to XML applications, and characterize commonly used fragments of first-order (FO) and monadic second-order logic (MSO) for them via various temporal logics. We look at both unordered trees and ordered trees (in which children of the same node are ordered by the next-sibling relation), and characterize Boolean and unary FO and MSO queries. For MSO Boolean queries, we use extensions of the /spl mu/-calculus: with counting for unordered trees, and with the past for ordered. For Boolean FO queries, we use similar extensions of CTL*. We then use composition techniques to transfer results to unary queries. For the ordered case, we need the same logics as for Boolean queries, but for the unordered case, we need to add both past and counting to the /spl mu/-calculus and CTL*. We also consider MSO sibling-invariant queries, that can use the sibling ordering but do not depend on the particular one used, and capture them by a variant of the /spl mu/-calculus with modulo quantifiers.
[Navigation, trees (mathematics), first-order logic, sibling-invariant queries, temporal logic, Boolean queries, Boolean algebra, Database languages, composition techniques, Computer science, query processing, Boolean functions, Query processing, process algebra, XML, Automata, unranked trees, Binary trees, CTL, monadic second-order logic, Logic]
Looping caterpillars [semistructured data querying]
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
There are two main paradigms for querying semi structured data: regular path queries and XPath. The aim of this paper is to provide a synthesis between these two. This synthesis is given by a small addition to tree walk automata and the corresponding caterpillar expressions. These are evaluated on unranked finite sibling-ordered trees. At the expression level we add an operator whose meaning is intersection with the identity relation. This language can express every first-order definable relation and its expressive power is characterized by pebble tree walk automata that cannot inspect pebbles. We also define an expansion of the caterpillar expressions whose expressive power is characterized by ordinary pebble tree walk automata. Combining results from Bloem-Engelfriet and Gottlob-Koch, we also define an XPath like query language which is complete for all MSO definable binary relations.
[XPath, caterpillar expression, formal languages, automata theory, trees (mathematics), Calculus, Proposals, Data mining, Database languages, unranked finite sibling-ordered trees, binary relations, query processing, tree walk automata, Tree graphs, Algebra, Query processing, Automata, regular path queries, Logic, query language, Informatics]
Generalizing parametricity using information-flow
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Run-time type analysis allows programmers to easily and concisely define operations based upon type structure, such as serialization, iterators, and structural equality. However, when types can be inspected at run time, nothing is secret. A module writer cannot use type abstraction to hide implementation details from clients: clients can determine the structure of these supposedly "abstract" data types. Furthermore, access control mechanisms do not help isolate the implementation of abstract datatypes from their clients. Buggy or malicious authorized modules may leak type information to unauthorized clients, so module implementors cannot reliably tell which parts of a program rely on their type definitions. Currently, module implementors rely on parametric polymorphism to provide integrity and confidentiality guarantees about their abstract datatypes. However, standard parametricity does not hold for languages with run-time type analysis; this paper shows how to generalize parametricity so that it does. The key is to augment the type system with annotations about information-flow. Implementors can then easily see which parts of a program depend on the chosen implementation by tracking the flow of dynamic type information.
[Access control, System testing, information-flow, Cloning, abstract data types, type structure, data flow analysis, type theory, module implementor, run-time type analysis, Remuneration, Programming profession, access control mechanism, Information analysis, parametric polymorphism, Information science, Runtime, User interfaces, Dynamic programming, malicious authorized modules]
Relational parametricity and control
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We study the equational theory of Parigot's second-order /spl lambda//spl mu/-calculus in connection with a call-by-name continuation-passing style (CPS) translation into a fragment of the second-order /spl lambda/-calculus. It is observed that the relational parametricity on the target calculus induces a natural notion of equivalence on the /spl lambda//spl mu/-terms. On the other hand, the unconstrained relational parametricity on the /spl lambda//spl mu/-calculus turns out to be inconsistent with this CPS semantics. Following these facts, we propose to formulate the relational parametricity on the /spl lambda//spl mu/-calculus in a constrained way, which might be called "focal parametricity".
[lambda calculus, equational theory, call-by-name continuation-passing style, Algebra, relational parametricity, Calculus, Encoding, Optical fiber theory, CPS semantics, lambda-calculus, Equations, focal parametricity]
Recursive polymorphic types and parametricity in an operational framework
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We construct a realizability model of recursive polymorphic types, starting from an untyped language of terms and contexts. An orthogonality relation e/spl perp//spl pi/ indicates when a term e and a context /spl pi/ may be safely combined in the language. Types are interpreted as sets of terms closed by biorthogonality. Our main result states that recursive types are approximated by converging sequences of interval types. Our proof is based on a "type-directed" approximation technique, which departs from the "language-directed" approximation technique developed by MacQueen, Plotkin and Sethi in the ideal model. We thus keep the language elementary (a call-by-name /spl lambda/-calculus) and unstratified (no typecase, no reduction labels). We also include a short account of parametricity, based on an orthogonality relation between quadruples of terms and contexts.
[lambda calculus, Terminology, untyped language, Lattices, H infinity control, call-by-name lambda-calculus, recursive functions, type theory, realizability model, orthogonality relation, Equations, Computer science, pi calculus, type-directed approximation, recursive polymorphic types, Layout, Logic, Context modeling]
Semantic subtyping for the /spl pi/-calculus
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Subtyping relations for the /spl pi/-calculus are usually defined in a syntactic way, by means of structural rules. We propose a semantic characterisation of channel types and use it to derive a subtyping relation. The type system we consider includes read-only and write-only channel types, as well as Boolean combinations of types. A set-theoretic interpretation of types is provided, in which Boolean combinations are interpreted as the corresponding set-theoretic operations. Subtyping is defined as inclusion of the interpretations. We prove the decidability of the subtyping relation and sketch the subtyping algorithm. In order to fully exploit the type system, we define a variant of the /spl pi/-calculus where communication is subjected to pattern matching that performs dynamic typecase.
[pattern matching, Boolean combinations, Educational institutions, type theory, Boolean algebra, set theory, Equations, semantic subtyping relations, pi calculus, decidability, /spl pi/-calculus, Communication channels, type system, set-theoretic interpretation, Pattern matching, Testing]
An insider's guide to logic in telecommunications data
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Most of the functionality of modern telecommunication systems has migrated to software, and much of that software consists of code for manipulating data: data describing either subscriber features or equipment configuration. The data is generally hierarchically structured but extremely complex - it consists of hundreds or even thousands of "classes" (roughly speaking, distinct labels on a tree), with the same information occurring in different formats across many classes in a hierarchy. The data is also required to satisfy a gigantic number of integrity constraints, vital to the correct routing of phone calls. The challenge is to create tools for populating this data, updating the data, and propagating these updates to derived data; all without violating these integrity constraints. The aim of this article is to give an overview of recent projects at Bell Labs that tackle this problem. Declarative languages play a key role. Indeed, we can think of a solution as consisting of languages for: the integrity constraints, the large-scale changes to the data, and the relationships between base data and derived data. In this article the author starts by explaining the languages used, and the key algorithmic ideas behind the tools. Generally these tools can all be seen as "implementations" of closure properties of definable tree and tree-structured data languages. The author then discusses briefly some of the pragmatic issues in getting these systems used in industrial projects.
[declarative languages, Base stations, database languages, definable tree closure properties, Routing, data integrity, tree-structured data languages, Electrical capacitance tomography, Application software, database management systems, High level languages, telecommunication computing, Computer science, formal logic, integrity constraints, Runtime, Boolean functions, XML, telecommunication systems, Large-scale systems, tree data structures, Logic]
On digraph coloring problems and treewidth duality
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
It is known that every constraint satisfaction problem (CSP) reduces, and is in fact polynomially equivalent, to a digraph coloring problem. By carefully analyzing the constructions, we observe that the reduction is quantifier-free. Using this, we illustrate the power of the logical approach to CSPs by resolving two conjectures about treewidth duality in the digraph case. The point is that the analogues of these conjectures for general CSPs were resolved long ago by proof techniques that seem to break down for digraphs. We also completely characterize those CSPs that are first-order definable and show that they coincide with those that have finitary tree duality. The combination of this result with an older result by Nesetril and Tardif shows that it is semi-decidable, given H, whether the H-coloring problem is definable in full first-order logic. Finally, we provide new width lower bounds for some tractable CSPs. The novelty is that our bounds are a tight function of the treewidth of the underlying instance.
[CSP, H-coloring problem, constraint theory, trees (mathematics), first-order logic, constraint satisfaction problem, treewidth duality, Graph theory, graph colouring, digraph coloring problem, Computer science, Tree graphs, decidability, directed graphs, Polynomials, theorem proving, Logic, computational complexity]
Quantitative analysis of probabilistic pushdown automata: expectations and variances
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Probabilistic pushdown automata (pPDA) have been identified as a natural model for probabilistic programs with recursive procedure calls. Previous works considered the decidability and complexity of the model-checking problem for pPDA and various probabilistic temporal logics. In this paper we concentrate on computing the expected values and variances of various random variables defined over runs of a given probabilistic pushdown automaton. In particular, we show how to compute the expected accumulated reward and the expected gain for certain classes of reward functions. Using these results, we show how to analyze various quantitative properties of pPDA that are not expressible in conventional probabilistic temporal logics.
[probabilistic programs, H infinity control, pushdown automata, random processes, temporal logic, Probabilistic logic, pPDA, Probability distribution, recursive functions, probabilistic pushdown automata, Computer science, recursive procedure calls, probabilistic automata, decidability, formal verification, model-checking problem, Automata, probabilistic temporal logics, Random variables, Performance analysis, Informatics, Analysis of variance]
Verifying infinite Markov chains with a finite attractor or the global coarseness property
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We consider infinite Markov chains which either have a finite attractor or satisfy the global coarseness property. Markov chains derived from probabilistic lossy channel systems (PLCS) or probabilistic vector addition systems with states (PVASS) are classic examples for these types, respectively. We consider three different variants of the reachability problem and the repeated reachability problem: the qualitative problem, i.e., deciding if the probability is one (or zero); the approximate quantitative problem, i.e., computing the probability up-to arbitrary precision; the exact quantitative problem, i.e., computing probabilities exactly. We express the qualitative problem in abstract terms for Markov chains with a finite attractor and for globally coarse Markov chains, and show an almost complete picture of its decidability of PLCS and PVASS. We also show that the path enumeration algorithm of (P. Iyer et al., 1997) terminates for our types of Markov chain and can thus be used to solve the approximate quantitative reachability problem. Furthermore, a modified variant of this algorithm can solve the approximate quantitative repeated reachability problem for Markov chains with a finite attractor. Finally, we show that the exact probability of (repeated) reachability cannot be effectively expressed in the first-order theory of the reals (R,+,*,/spl les/) for either PLCS or PVASS (unlike for other probabilistic models, e.g., probabilistic pushdown automata (J. Esparza et al., 2004, K. Etessami et al., 2005, J. Esparza et al., 2004).
[Stochastic logic, reachability analysis, probabilistic logic, probabilistic pushdown automata, Reachability analysis, path enumeration algorithm, probabilistic lossy channel systems, approximate quantitative reachability problem, decidability, formal verification, infinite Markov chains, Markov processes, global coarseness property, probabilistic vector addition systems]
Recognizing /spl omega/-regular languages with probabilistic automata
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Probabilistic finite automata as acceptors for languages over finite words have been studied by many researchers. In this paper, we show how probabilistic automata can serve as acceptors for /spl omega/-regular languages. Our main results are that our variant of probabilistic Buchi automata (PBA) is more expressive than non-deterministic /spl omega/-automata, but a certain subclass of PBA, called uniform PBA, has exactly the power of /spl omega/-regular languages. This also holds for probabilistic /spl omega/-automata with Streett or Rabin acceptance. We show that certain /spl omega/-regular languages have uniform PBA of linear size, while any nondeterministic Streett automaton is of exponential size, and vice versa. Finally, we discuss the emptiness problem for uniform PBA and the use of PBA for the verification of Markov chains against qualitative linear-time properties.
[Costs, formal languages, finite automata, Process planning, nondeterministic Streett automaton, Probabilistic logic, Markov chains, nondeterministic /spl omega/-automata, Computer science, Power measurement, probabilistic automata, probabilistic Buchi automata, formal verification, /spl omega/-regular languages, Automata, Biological processes, Speech recognition, Markov processes, Polynomials, probabilistic finite automata]
A polynomial time Presburger criterion and synthesis for number decision diagrams
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Number decision diagrams (NDD) are the automata-based symbolic representation for manipulating sets of integer vectors encoded as strings of digit vectors (least or most significant digit first). Since 1969 (A. Cobham, 1969, A. Semenov, 1977), we know that any Presburger-definable set (M. Presburger, 1929) (a set of integer vectors satisfying a formula in the first-order additive theory of the integers) can be represented by a NDD, and efficient algorithm for manipulating these sets have been recently developed (P. Wolper et al., 2000, A. Boudet et al., 1996). However, the problem of deciding if a NDD represents such a set, is a well-known hard problem first solved by Muchnik in 1991 with a quadruply-exponential time algorithm. In this paper, we show how to determine in polynomial time whether a NDD represents a Presburger-definable set, and we provide in this positive case a polynomial time algorithm that constructs from the NDD a Presburger-formula that defines the same set.
[number decision diagrams, Art, Logic programming, Optimizing compilers, automata-based symbolic representation, automata theory, decision diagrams, computability, Presburger-definable set, Linear programming, set theory, Program processors, Inverse problems, decidability, Councils, digital arithmetic, Automata, symbol manipulation, polynomial time Presburger criterion, Polynomials, Arithmetic, computational complexity, number theory]
Model checking vs. generalized model checking: semantic minimizations for temporal logics
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Three-valued models, in which properties of a system are either true, false or unknown, have recently been advocated as a better representation for reactive program abstractions generated by automatic techniques such as predicate abstraction. Indeed, for the same cost, model checking three-valued abstractions can be used to both prove and disprove any temporal-logic property, whereas traditional conservative abstractions can only prove universal properties. Also, verification results can be more precise with generalized model checking, which checks whether there exists a concretization of an abstraction satisfying a temporal-logic formula. Since generalized model checking includes satisfiability as a special case (when everything in the model is unknown), it is in general more expensive than traditional model checking. In this paper, we study how to reduce generalized model checking to model checking by a temporal-logic formula transformation, which generalizes a transformation for propositional logic known as semantic minimization in the literature. We show that many temporal-logic formulas of practical interest are self-minimizing, i.e., are their own semantic minimizations, and hence that model checking for these formulas has the same precision as generalized model checking.
[Costs, generalized model checking, temporal-logic formula transformation, propositional logic, Computational modeling, Automatic logic units, temporal logic, computability, Educational institutions, Minimization, State-space methods, predicate abstraction, three-valued abstractions, semantic minimization, Simultaneous localization and mapping, formal verification, reactive program abstractions, satisfiability, Concrete, ternary logic, minimisation, Software tools, Formal verification]
Model-checking hierarchical structures
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Hierarchical graph definitions allow a modular description of graphs using modules for the specification of repeated substructures. Beside this modularity, hierarchical graph definitions allow to specify graphs of exponential size using polynomial size descriptions. In many cases, this succinctness increases the computational complexity of decision problems when input graphs are defined hierarchically. In this paper, the model-checking problem for first-order logic (FO), monadic second-order logic (MSO), and second-order logic (SO) on hierarchically defined input graphs is investigated. Several new complete problems for the levels of the polynomial time hierarchy and the exponential time hierarchy are obtained. Two restrictions on the structure of hierarchical graph definitions that lead to more efficient model-checking algorithms are presented.
[Circuits, graph theory, first-order logic, Very large scale integration, polynomial time hierarchy, Complexity theory, Computational complexity, Computer science, Semiconductor device modeling, formal logic, Databases, formal verification, Automata, exponential time hierarchy, model-checking algorithms, Polynomials, hierarchical graph definitions, decision problems, monadic second-order logic, Logic, computational complexity]
Mean-payoff parity games
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Games played on graphs may have qualitative objectives, such as the satisfaction of an /spl omega/-regular property, or quantitative objectives, such as the optimization of a real-valued reward. When games are used to model reactive systems with both fairness assumptions and quantitative (e.g., resource) constraints, then the corresponding objective combines both a qualitative and a quantitative component. In a general case of interest, the qualitative component is a parity condition and the quantitative component is a mean-payoff reward. We study and solve such mean-payoff parity games. We also prove some interesting facts about mean-payoff parity games which distinguish them both from mean-payoff and from parity games. In particular, we show that optimal strategies exist in mean-payoff parity games, but they may require infinite memory.
[Computer science, optimisation, /spl omega/-regular property, mean-payoff parity games, graph theory, Power generation economics, game theory, graph games, Network synthesis, Game theory, Power system modeling]
On the decidability of metric temporal logic
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Metric temporal logic (MTL) is a prominent specification formalism for real-time systems. In this paper, we show that the satisfiability problem for MTL over finite timed words is decidable, with non-primitive recursive complexity. We also consider the model-checking problem for MTL: whether all words accepted by a given Alur-Dill timed automaton satisfy a given MTL formula. We show that this problem is decidable over finite words. Over infinite words, we show that model checking the safety fragment of MTL-which includes invariance and time-bounded response properties-is also decidable. These results are quite surprising in that they contradict various claims to the contrary that have appeared in the literature. The question of the decidability of MTL over infinite words remains open.
[Real time systems, finite automata, Laboratories, temporal logic, Mathematics, Alur-Dill timed automaton, Turing machines, decidability, model-checking problem, satisfiability problem, Automata, Abstracts, Constraint theory, Safety, Timing, Logic, metric temporal logic]
Closure properties of coalgebra automata
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We generalize some of the central results in automata theory to the abstraction level of coalgebras. In particular, we show that for any standard, weak pullback preserving functor F, the class of recognizable languages of F -coalgebras is closed under taking unions, intersections and projections. Our main technical result concerns a construction which transforms a given alternating F -automaton into an equivalent non-deterministic one.
[Shape, finite automata, automata theory, closure property, coalgebra automata, recognizable language, Logic design, Application software, weak pullback preserving functor, Game theory, Computer science, nondeterministic equivalent, Tree graphs, Operating systems, process algebra, Automata]
Constructing free Boolean categories
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
By Boolean category we mean something which is to a Boolean algebra what a category is to a poset. We propose an axiomatic system for Boolean categories, which is different in several respects from the ones proposed recently In particular everything is done from the start in a *-autonomous category and not in a weakly distributive one, which simplifies issues like the Mix rule. An important axiom, which is introduced later, is a "graphical" condition, which is closely related to denotational semantics and the Geometry of Interaction. Then we show that a previously constructed category of proof nets is the free "graphical" Boolean category in our sense. This validates our categorical axiomatization with respect to a real-life example. Another important aspect of this work is that we do not assume a-priori the existence of units in the *-autonomous categories we use. This has some retroactive interest for the semantics of linear logic, and is motivated by the properties of our example with respect to units.
[Geometry, Computer science, graphical condition, linear logic, autonomous category, category theory, Calculus, Polynomials, Boolean algebra, Logic]
Completions of /spl mu/-algebras
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We define the class of algebraic models of /spl mu/-calculi and study whether every such model can be embedded into a model which is a complete lattice. We show that this is false in the general case and focus then on free modal /spl mu/-algebras, i.e. Lindenbaum algebras of the propositional modal /spl mu/-calculus. We prove the following fact: the MacNeille-Dedekind completion of a free modal /spl mu/-algebra is a complete modal algebra, hence a modal /spl mu/-algebra (i.e. an algebraic model of the propositional modal /spl mu/-calculus). The canonical embedding of the free modal /spl mu/-algebra into its Dedekind-MacNeille completion preserves the interpretation of all the terms in the class Comp(/spl Sigma//sub 1//spl Pi//sub 1/) of the alternation-depth hierarchy. The proof uses algebraic techniques only and does not directly rely on previous work on the completeness of the modal /spl mu/-calculus.
[Dedekind-MacNeille completion, Lattices, Electronic mail, Boolean algebra, Lindenbaum algebra, Equations, algebraic model, Computer science, process algebra, /spl mu/-calculi, /spl mu/-algebras, Logic functions, Concrete]
Proof-theoretic approach to description-logic
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
In recent work Baader has shown that a certain description logic with conjunction, existential quantification and with circular definitions has a polynomial time subsumption problem both under an interpretation of circular definitions as greatest fixpoints and under an interpretation as arbitrary fixpoints (introduced by Nebel). This was shown by translating definitions in the description logic ("TBoxes") into a labelled transition system and by reducing subsumption to a question of the existence of certain simulations. In the case of subsumption under the descriptive semantics a new kind of simulation, called synchronised simulation, had to be introduced. In this paper, we also give polynomial-time decision procedures for these logics; this time by devising sound and complete proof systems for them and demonstrating that proof search is polynomial for these systems. We then use the proof-theoretic method to study the hitherto unknown complexity of description logic with universal quantification, conjunction, and GCI axioms. Finally, we extend the proof-theoretic method to negation and thus obtain a decision procedure for the description logic ALC with fixpoints. This last section is only sketched.
[Computer science, formal logic, description logic, polynomials, Automatic logic units, complete proof system, Polynomials, theorem proving, polynomial-time decision procedures, proof-theoretic approach, polynomial time subsumption problem, Equations]
Process algebras for quantitative analysis
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
In the 1980s process algebras became widely accepted formalisms for describing and analysing concurrency. Extensions of the formalisms, incorporating some aspects of systems which had previously been abstracted, were developed for a number of different purposes. In the area of performance analysis models must quantify both timing and probability. Addressing this domain led to the formulation of stochastic process algebras. In this paper we give a brief overview of stochastic process algebras and the problems which motivated them, before focussing on their relationship with the underlying mathematical stochastic process. This is presented in the context of the PEPA formalism.
[Context, PEPA formalism, Stochastic processes, probability, mathematical stochastic process, Sparse matrices, Power system modeling, Concurrent computing, process algebras, Algebra, process algebra, Markov processes, Performance analysis, Timing, performance analysis model, stochastic processes, quantitative analysis, Informatics]
A functional quantum programming language
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We introduce the language QML, a functional language for quantum computations on finite types. Its design is guided by its categorical semantics: QML programs are interpreted by morphisms in the category FQC of finite quantum computations, which provides a constructive semantics of irreversible quantum computations realisable as quantum gates. QML integrates reversible and irreversible quantum computations in one language, using first order strict linear logic to make weakenings explicit. Strict programs are free from decoherence and hence preserve superpositions and entanglement -which is essential for quantum parallelism.
[functional quantum programming language, Quantum entanglement, Logic programming, finite quantum computation, Circuits, quantum gates, quantum entanglement, Computer science, formal logic, Computer languages, Quantum computing, Program processors, Parallel programming, first order strict linear logic, Parallel processing, quantum parallelism, Functional programming, functional languages]
Semantics of separation-logic typing and higher-order frame rules
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We show how to give a coherent semantics to programs that are well-specified in a version of separation logic for a language with higher types: idealized algol extended with heaps (but with immutable stack variables). In particular, we provide simple sound rules for deriving higher-order frame rules, allowing for local reasoning.
[coherent semantic, Genetic mutations, type theory, inference mechanisms, higher-order frame rules, High level languages, Stress, formal logic, local reasoning, Computer languages, reasoning about programs, Logic, separation-logic type]
An observationally complete program logic for imperative higher-order functions
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We propose a simple compositional program logic for an imperative extension of call-by-value PCF, built on Hoare logic and our preceding work on program logics for pure higher-order functions. A systematic use of names and operations on them allows precise and general description of complex higher-order imperative behaviour. The logic offers a foundation for general treatment of aliasing and local state on its basis, with minimal extensions. After establishing soundness, we prove that valid assertions for programs completely characterise their behaviour up to observational congruence, which is proved using a variant of finite canonical forms. The use of the logic is illustrated through reasoning examples which are hard to assert and infer using existing program logics.
[formal logic, Computer languages, Logic programming, imperative higher-order function, logic programming, finite canonical form, Educational institutions, Data structures, Functional programming, complete program logic, Network address translation, Hoare logic]
Expressiveness of spatial logic for trees
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
In this paper we investigate the quantifier-free fragment of the TQL logic proposed by Cardelli and Ghelli. The TQL logic, inspired from the ambient logic, is the core of a query language for semistructured data represented as unranked and unordered trees. The fragment we consider here, named STL, contains as main features spatial composition and location as well as a fixed point construct. We prove that satisfiability for STL is undecidable. We show also that STL is strictly more expressive than the Presburger monadic second-order logic (PMSO) of Seidl, Schwentick and Muscholl when interpreted over unranked and unordered edge-labelled trees. We define a class of tree automata whose transitions are conditioned by arithmetical constraints; we show then how to compute from a closed STL formula a tree automaton accepting precisely the models of the formula. Finally, still using our tree automata framework, we exhibit some syntactic restrictions over STL formulae that allow us to capture precisely the logics MSO and PMSO.
[TQL logic, Pulleys, trees (mathematics), computability, spatial logic, Computer science, Presburger monadic second-order logic, Tree graphs, deterministic automata, Automata, tree automata, Logic, query language, Arithmetic, ambient logic]
Proof theory for Kleene algebra
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
The universal Horn theory of relational Kleene algebra with tests (RKAT) is of practical interest, particularly for program semantics. We develop an (infinitary) proof system, based on well-founded trees of finite automata, which is sound and complete for this theory. A small modification of this system yields a proof system which is sound and complete for the universal Horn theory of *-continuous Kleene algebras with tests (KAT*). This sheds light on the relationship between RKAT and KAT*.
[Algorithm design and analysis, System testing, Acoustic testing, finite automata, Heuristic algorithms, relational algebra, Horn clauses, universal Horn theory, trees (mathematics), Mathematics, RKAT, *-continuous Kleene algebras, relational Kleene algebra, Equations, KAT*, Computer science, infinitary proof system, Algebra, program semantics, Automata, Kleene algebra proof theory, theorem proving, Logic]
Name generation and linearity
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
A path-based domain theory for higher-order processes is extended to allow name generation. The original domain theory is built around the monoidal-closed category Lin consisting of path orders with join-preserving functions between their domains of path sets. Name generation is adjoined by forming the functor category [I, Lin], where I consists of finite sets of names and injections. The functor category [I, Lin] is no longer monoidal-closed w.r.t. the tensor inherited pointwise from Lin. However, conditions are given under which function spaces exist. The conditions are preserved by a rich discipline of linear types, including those of new-HOPLA, a recent powerful language for higher-order processes with name generation.
[functor category, higher-order processes, linear types, Computational modeling, Laboratories, path orders, Lin monoidal-closed category, tensor, Distributed computing, name generation, join-preserving functions, Concurrent computing, group theory, Sufficient conditions, Tensile stress, process algebra, new-HOPLA language, Linearity, category theory, Concrete, Logic, path-based domain theory, Power generation]
Reactive systems over cospans
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
The theory of reactive systems, introduced by Leifer and Milner and previously extended by the authors, allows the derivation of well-behaved labelled transition systems (LTS) for semantic models with an underlying reduction semantics. The derivation procedure requires the presence of certain colimits (or, more usually and generally, bicolimits) which need to be constructed separately within each model. In this paper, we offer a general construction of such bicolimits in a class of bicategones of cospans. The construction sheds light on as well as extends Ehrig and Konig's rewriting via borrowed contexts and opens the way to a unified treatment of several applications.
[rewriting systems, graph transformations, Petri nets, reactive systems, reduction semantics, labelled transition systems, semantic models, Computer science, Concurrent computing, group theory, graph grammars, groupoidal relative pushouts, Algebra, bisimulation congruence, bicolimits, cospan bicategones, Computer architecture, Bipartite graph, bisimulation equivalence, Logic, Computer security, National security, Mobile computing, rewriting system]
Uniform distributed synthesis
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We provide a uniform solution to the problem of synthesizing a finite-state distributed system. An instance of the synthesis problem consists of a system architecture and a temporal specification. The architecture is given as a directed graph, where the nodes represent processes (including the environment as a special process) that communicate synchronously through shared variables attached to the edges. The same variable may occur on multiple outgoing edges of a single node, allowing for the broadcast of data. A solution to the synthesis problem is a collection of finite-state programs for the processes in the architecture, such that the joint behavior of the programs satisfies the specification in an unrestricted environment. We define information forks, a comprehensive criterion that characterizes all architectures with an undecidable synthesis problem. The criterion is effective: for a given architecture with n processes and v variables, it can be determined in O(n/sup 2//spl middot/v) time whether the synthesis problem is decidable. We give a uniform synthesis algorithm for all decidable cases. Our algorithm works for all /spl omega/-regular tree specification languages, including the /spl mu/-calculus. The undecidability proof, on the other hand, uses only LTL or, alternatively, CTL as the specification language. Our results therefore hold for the entire range of specification languages from LTL/CTL to the /spl mu/-calculus.
[Pipelines, LTL, temporal specification, temporal logic, /spl mu/-calculus, finite state machines, /spl omega/-regular tree specification languages, decidability, Computer architecture, specification languages, directed graph, Broadcasting, Logic, algebraic specification, formal languages, undecidability proof, Specification languages, Computer science, decidable cases, uniform distributed synthesis algorithm, finite-state distributed system, distributed algorithms, directed graphs, system architecture, undecidable synthesis problem, CTL, finite-state programs]
Automated verification of selected equivalences for security protocols
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
In the analysis of security protocols, methods and tools for reasoning about protocol behaviors have been quite effective. We aim to expand the scope of those methods and tools. We focus on proving equivalences P/spl ap/Q in which P and Q are two processes that differ only in the choice of some terms. These equivalences arise often in applications. We show how to treat them as predicates on the behaviors of a process that represents P and Q at the same time. We develop our techniques in the context of the applied pi calculus and implement them in the tool ProVerif.
[Calculus, Security, Cryptographic protocols, selected equivalence automated verification, pi calculus, security protocols, security, formal verification, Broadcasting, Writing, ProVerif tool, Cryptography, protocols, equivalence classes]
Tarski's influence on computer science
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Summary form only given. The great logician Alfred Tarski played one of the leading roles in the development of mathematical logic in the twentieth century, as much for the programs he promoted and the conceptual organization of the subject as for his many important results. Except for his fixed-point theorem, Tarski's influence on computer science has been largely indirect but nevertheless substantial. The author surveys this influence through his work in the areas of decision procedures, semantics of formal languages, model theory, and algebraic logic.
[Computer science, formal logic, model theory, USA Councils, formal language semantics, Formal languages, algebraic logic, decision procedures, Logic functions, Mathematics, Alfred Tarski, mathematical logic]
Logic and Systems Biology
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
false
[Computer science, Systems biology, Logic]
Eager normal form bisimulation
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
This paper describes two new bisimulation equivalences for the pure untyped call-by-value /spl lambda/-calculus, called enf bisimilarity and enf bisimilarity up to /spl eta/. They are based on eager reduction of terms to eager normal form (enf), analogously to co-inductive bisimulation characterizations of Levy-Longo tree equivalence and Bohm tree equivalence (up to /spl eta/). We argue that enf bisimilarity is the call-by-value analogue of Levy-Longo tree equivalence. Enf bisimilarity (up to /spl eta/) is the congruence on source terms induced by the call-by-value CPS transform and Bohm tree equivalence (up to /spl eta/) on target terms. Enf bisimilarity and enf bisimilarity up to /spl eta/ enjoy powerful bisimulation proof principles which, among other things, can be used to establish a retraction theorem for the call-by-value CPS transform.
[lambda calculus, trees (mathematics), Transforms, untyped call-by-value /spl lambda/-calculus, Data structures, eager normal form bisimulation equivalences, Levy-Longo tree equivalence, call-by-value CPS transform, Computer science, Differential equations, co-inductive bisimulation characterizations, Bohm tree equivalence, enf bisimilarity, bisimulation equivalence, Logic, Testing]
Separation with streams in the /spl Lambda//spl mu/-calculus
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
The /spl lambda//spl mu/-calculus is an extension of the /spl lambda/-calculus introduced in 1992 by Parigot (M. Parigot, 1992) in order to generalize the Curry-Howard isomorphism to classical logic. Two versions of the calculus are usually considered in the literature: Parigot's original syntax and an alternative syntax introduced by de Groote. In 2001, David and Py (R. David, 2001) proved that the Separation Property (also referred to as Bohm theorem) fails for Parigot's /spl lambda//spl mu/-calculus. By analyzing David & Py's result, we exhibit an extension of Parigot's /spl lambda//spl mu/-calculus, the /spl Lambda//spl mu/-calculus, for which the Separation Property holds and which is built as an intermediate language between Parigot's and de Groote's /spl lambda//spl mu/-calculi. We prove the theorem and describe how /spl Lambda//spl mu/-calculus can be considered as a calculus of terms and streams. We then illustrate Separation in showing how in /spl Lambda//spl mu/-calculus it is possible to separate the counter-example used by David & Py.
[lambda calculus, /spl Lambda//spl mu/-calculus, B&amp;#246;hm Theorem, Untyped ??-calculus., Separation Property, Calculus, Curry-Howard isomorphism, Bohm theorem, Stress, Failure analysis, Groote /spl lambda//spl mu/-calculi, untyped /spl lambda//spl mu/-calculus, Parigot /spl lambda//spl mu/-calculus, Logic, Calculus of Streams]
The geometry of linear higher-order recursion
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Linearity and ramification constraints have been widely used to weaken higher-order (primitive) recursion in such a way that the class of representable functions equals the class of poly time functions. We show that fine-tuning these two constraints leads to different expressive strengths, some of them lying well beyond polynomial time. This is done by introducing a new semantics, called algebraic context semantics. The framework stems from Gonthier's original work and turns out to be a versatile and powerful tool for the quantitative analysis of normalization in presence of constants and higher-order recursion.
[lambda calculus, linear higher-order recursion geometry, linearity constraints, algebraic context semantics, Calculus, recursive functions, type theory, Computational complexity, Geometry, Computer science, Computer languages, typed lambda calculus, Algebra, normalization, Linearity, Logic functions, Polynomials, geometry, ramification constraints, algebraic specification, representable functions, Context modeling]
Ludics nets, a game model of concurrent interaction
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We introduce L-nets as a game model of concurrent interaction. L-nets, which correspond to strategies (in Games Semantics) or designs (in Ludics), are graphs, and the interactions (plays) result into partial orders, hence allowing for parallelism.
[Additives, Computational modeling, graph theory, concurrent interaction game model, Games Semantics, concurrency theory, Calculus, L-net abstract proof net, multiplicative additive linear logic, Concurrent computing, Bridges, formal logic, Ludics nets, Tree graphs, Parallel processing, Constraint theory, theorem proving, Logic, Testing]
Asynchronous games 4: a fully complete model of propositional linear logic
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We construct a denotational model of propositional linear logic based on asynchronous games and winning uniform innocent strategies. Every formula A is interpreted as an asynchronous game [A] and every proof /spl pi/ of A is interpreted as a winning uniform innocent strategy [/spl pi/] of the game [A]. We show that the resulting model is fully complete: every winning uniform innocent strategy /spl sigma/ of the asynchronous game [A] is the denotation [/spl pi/] of a proof /spl pi/ of the formula A.
[Computer science, formal logic, Computer languages, Polarization, asynchronous games, Tensile stress, Refining, propositional linear logic, game theory, Dynamic programming, Logic]
Herbrand constraint abduction
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
In this paper we explore abduction over the Herbrand domain - equations on the algebra of finite terms (or finite trees) - which is a central element of logic programming and first-order automated reasoning. This paper is a case study of constraint abduction in the Herbrand domain. The direct relationship between Herbrand constraint abduction and type inference outlined above should make it easy to interpret the results of this paper in the context of type inference.
[Logic programming, Herbrand domain, type theory, Equations, Databases, Algebra, Query processing, process algebra, automated reasoning, logic programming, Concrete, Australia, type inference]
Certifying compilation for a language with stack allocation
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
This paper describes an assembly-language type system capable of ensuring memory safety in the presence of both heap and stack allocation. The type system uses linear logic and a set of domain-specific predicates to specify invariants about the shape of the store. Part of the model for our logic is a tree of "stack tags" that tracks the evolution of the stack over time. To demonstrate the expressiveness of the type system, we define Micro-CLI, a simple imperative language that captures the essence of stack allocation in the common language infrastructure. We show how to compile well-typed Micro-CLI into well-typed assembly.
[assembly language, System testing, Assembly systems, Shape, linear logic, assembly-language type system, Automatic logic units, Data structures, High level languages, program compilers, MicroCLI, common language infrastructure, Computer science, formal logic, storage management, Utility programs, Memory management, stack allocation, Safety, tree data structures]
Inverse and implicit functions in domain theory
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We construct a domain-theoretic calculus for Lipschitz and differentiate functions, which includes addition, subtraction and composition. We then develop a domain-theoretic version of the inverse function theorem for a Lipschitz function, in which the inverse function is obtained as a fixed point of a Scott continuous functional and is approximated by step functions. In the case of a C/sup 1/ function, the inverse and its derivative are obtained as the least fixed point of a single Scott continuous functional on the domain of differentiable functions and are approximated by two sequences of step functions, which are effectively computed from two increasing sequences of step functions respectively converging to the original function and its derivative. In this case, we also effectively obtain an increasing sequence of polynomial step functions whose lower and upper bounds converge in the C/sup 1/ norm to the inverse function. A similar result holds for implicit functions, which combined with the domain-theoretic model for computational geometry, provides a robust technique for construction of curves and surfaces.
[Solid modeling, domain-theoretic calculus, Piecewise linear approximation, computational geometry, Calculus, implicit function, sequences, surface fitting, formal logic, inverse fuction, Lipschitz function, Robustness, Polynomials, surface construction, approximation theory, Computational modeling, polynomials, Educational institutions, convergence of numerical methods, differentiable function, Application software, curve construction, Computational geometry, Upper bound, Scott continuous functional, curve fitting]
Operational domain theory and topology of a sequential programming language
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
A number of authors have exported domain-theoretic techniques from denotational semantics to the operational study of contextual equivalence and preorder. We further develop this, and, moreover, we additionally export topological techniques. In particular, we work with an operational notion of compact set and show that total programs with values on certain types are uniformly continuous on compact sets of total elements. We apply this and other conclusions to prove the correctness of non-trivial programs that manipulate infinite data. What is interesting is that the development applies to sequential programming languages.
[programming theory, operational domain theory, Topology, Finite element methods, programming language semantics, Game theory, Computer science, Computer languages, program correctness proving, reasoning about programs, Virtual manufacturing, Logic, sequential programming language, denotational semantics, Context modeling]
Generalized majority-minority operations are tractable
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
Let A be a finite set and let /spl phi/ : A/sup k//spl rarr/A with k/spl ges/3 be a k-ary operation on A. We say that /spl phi/ is a generalized majority-minority (GMM) operation if for all a, b /spl isin/ A we have that /spl phi/(x, y,...,y) = /spl phi/(y, x,..,y) =...=/spl phi/(y, y,..,x) = y for all x, y /spl isin/ {a, b} or /spl phi/{x, y,..,y) = /spl phi/(y, y,..,x) = x for all x, y /spl isin/ {a, b}. Near-unanimity and Mal'tsev operations are particular instances of GMM operations. We prove that every CSP instance where all constraint relations are invariant under a (fixed) GMM operation is solvable in polynomial time. This constitutes one of the largest tractable cases of the CSP.
[constraint theory, computability, set theory, Combinatorial mathematics, Computer science, generalized majority-minority operation, Algebra, Logic functions, Polynomials, Concrete, near-unanimity operation, Artificial intelligence, computational complexity, Mal'tsev operation]
Small substructures and decidability issues for first-order logic with two variables
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We study first-order logic with two variables FO/sup 2/ and establish a small substructure property. Similar to the small model property for FO/sup 2/ we obtain an exponential size bound on embedded substructures, relative to a fixed surrounding structure that may be infinite. We apply this technique to analyse the satisfiability problem for FO/sup 2/ under constraints that require several binary relations to be interpreted as equivalence relations. With a single equivalence relation, FO/sup 2/ has the finite model property and is complete for non-deterministic exponential time, just as for plain FO/sup 2/. With two equivalence relations, FO/sup 2/ does not have the finite model property, but is shown to be decidable via a construction of regular models that admit finite descriptions even though they may necessarily be infinite. For three or more equivalence relations, FO/sup 2/ is undecidable.
[Vocabulary, Taxonomy, first-order logic, Knowledge representation, computability, Application software, Game theory, Computer science, decidability, satisfiability, Hardware, Robustness, equivalence relation, Logic, Artificial intelligence, equivalence classes]
Definability on a random 3-CNF formula
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We consider the question of certifying unsatisfiability of random 3-CNF formulas. At which densities can we hope for a simple sufficient condition for unsatisfiability that holds almost surely? We study this question from the point of view of definability theory. The main result is that first-order logic cannot express any sufficient condition that holds almost surely on random 3-CNF formulas with n/sup 2-/spl alpha// clauses, for any irrational positive number /spl alpha/. In contrast, it can when the number of clauses is n/sup 2+/spl alpha//, for any positive /spl alpha/. As an intermediate step, our proof exploits the planted distribution for 3-CNF formulas in a new technical way. Moreover, the proof requires us to extend the methods of Shelah and Spencer for proving the zero-one law for sparse random graphs to arbitrary relational languages.
[sparse random graph, graph theory, Optimization methods, first-order logic, Linear programming, Physics, formal logic, Sufficient conditions, random 3-CNF formula, Layout, relational language, Polynomials, Logic, Testing, computational complexity]
Existential positive types and preservation under homomorphisms
20th Annual IEEE Symposium on Logic in Computer Science
None
2005
We prove the finite homomorphism preservation theorem: a first-order formula is preserved under homomorphisms on finite structures iff it is equivalent in the finite to an existential positive formula. We also strengthen the classical homomorphism preservation theorem by showing that a formula is preserved under homomorphisms on all structures iff it is equivalent to an existential positive formula of the same quantifier rank. Our method involves analysis of existential positive types and a new notion of existential positive saturation.
[Computer science, formal logic, Databases, finite homomorphism preservation theorem, finite structures, theorem proving, Logic]
Foreward
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Presents the welcome message from the conference proceedings.
[]
Conference organization
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Provides a listing of current committee members and society officers.
[]
Organizing Committee
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Provides a listing of current committee members.
[]
Formal Verification of Infinite State Systems Using Boolean Methods
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
The UCLID project seeks to develop formal verification tools for infinite-state systems having a degree of automation comparable to that of model checking tools for finite-state systems. The UCLID modeling language describes systems where the state variables are Booleans, integers, and functions mapping integers to integers or Booleans. The verifier supports several forms of verification for proving safety properties. They rely on a decision procedure that translates a quantifier-free formula into an equi-satisfiable Boolean formula and then applies a Boolean satisfiability solver. UCLID has successfully verified a number of hardware designs and protocols
[quantifier-free formula, Automation, Protocols, automata theory, infinite state systems, hardware designs, computability, Data structures, Power system modeling, Boolean satisfiability solver, equisatisfiable Boolean formula, Computer science, Boolean functions, formal verification, decision procedure, Boolean methods, Hardware, Safety, UCLID modeling language, safety properties, Logic, Formal verification]
Two-Variable Logic on Words with Data
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
In a data word each position carries a label from a finite alphabet and a data value from some infinite domain. These models have been already considered in the realm of semistructured data, timed automata and extended temporal logics. It is shown that satisfiability for the two-variable first-order logic FO2(~,&lt;,+1) is decidable over finite and over infinite data words, where ~ is a binary predicate testing the data value equality and +1,&lt; are the usual successor and order predicates. The complexity of the problem is at least as hard as Petri net reachability. Several extensions of the logic are considered, some remain decidable while some are undecidable
[data word, semistructured data, formal languages, Navigation, Petri nets, two-variable first-order logic, temporal logic, finite alphabet, Logic testing, binary predicate testing, data models, Petri net reachability, Upper bound, Databases, decidability, satisfiability, Automata, XML, Data models, timed automata, computational complexity]
LTL with the Freeze Quantifier and Register Automata
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Temporal logics, first-order logics, and automata over data words have recently attracted considerable attention. A data word is a word over a finite alphabet, together with a datum (an element of an infinite domain) at each position. Examples include timed words and XML documents. To refer to the data, temporal logics are extended with the freeze quantifier, first-order logics with predicates over the data domain, and automata with registers or pebbles. We investigate relative expressiveness and complexity of standard decision problems for LTL with the freeze quantifier (LTLdarr), 2-variable first-order logic (FO2) over data words, and register automata. The only predicate available on data is equality. Previously undiscovered connections among those formalisms, and to counter automata with incrementing errors, enable us to answer several questions left open in recent literature. We show that the future-time fragment of LTLdarr which corresponds to FO2 over finite data words can be extended considerably while preserving decidability, but at the expense of non-primitive recursive complexity, and that most of further extensions are undecidable. We also prove that surprisingly, over infinite data words, LTLdarr without the 'until' operator, as well as nonemptiness of one-way universal register automata, are undecidable even when there is only 1 register
[data word, Art, formal languages, automata theory, LTL, first-order logic, temporal logic, Registers, finite alphabet, Logic testing, Counting circuits, until operator, Computer science, freeze quantifier, decidability, satisfiability, Automata, XML, register automata, decision problems, Clocks, computational complexity]
Fixed-Parameter Hierarchies inside PSPACE
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Treewidth measures the "tree-likeness" of structures. Many NP-complete problems, e.g., propositional satisfiability, are tractable on bounded-treewidth structures. In this work, we study the impact of treewidth bounds on QBF, a canonical PSPACE-complete problem. This problem is known to be fixed-parameter tractable if both the treewidth and alternation depth are taken as parameters. We show here that the function bounding the complexity in the parameters is provably nonelementary (assuming P is different than NP). This yields a strict hierarchy of fixed-parameter tractability inside PSPACE. As a tool for proving this result, we first prove a similar hierarchy for model checking QPTL, quantified propositional temporal logic. Finally, we show that QBF, restricted to instances with a slowly increasing (log*) treewidth, is still PSPACE-complete
[bounded-treewidth structures, fixed-parameter hierarchies, Poles and towers, trees (mathematics), computability, temporal logic, fixed-parameter tractability, NP-complete problem, Computer science, quantified propositional temporal logic, QBF canonical PSPACE-complete problem, formal verification, model checking, NP-complete problems, propositional satisfiability, Logic, computational complexity]
The Boundedness Problem for Monadic Universal First-Order Logic
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We consider the monadic boundedness problem for least fixed points over FO formulae as a decision problem: Given a formula phi(X, x), positive in X, decide whether there is a uniform finite bound on the least fixed point recursion based on phi. Few fragments of FO are known to have a decidable boundedness problem; boundedness is known to be undecidable for many fragments. We here show that monadic boundedness is decidable for purely universal FO formulae without equality in which each non-recursive predicate occurs in just one polarity (e.g., only negatively). The restrictions are shown to be essential: waving either the polarity constraint or allowing positive occurrences of equality, the monadic boundedness problem for universal formulae becomes undecidable. The main result is based on a model theoretic analysis involving ideas from modal and guarded logics and a reduction to the monadic second-order theory of trees
[decision problem, guarded logic, trees (mathematics), Binary decision diagrams, Data structures, recursive functions, decidable boundedness problem, universal FO formulae, modal logic, Database languages, Computer science, model theoretic analysis, binary decision diagrams, least fixed point recursion, Boolean functions, decidability, Query processing, monadic universal first-order logic, Logic, Artificial intelligence, monadic second-order theory, computational complexity]
On the Expressiveness of Linearity vs Persistence in the Asychronous Pi-Calculus
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We present an expressiveness study of linearity and persistence of processes. We choose the pi-calculus, one of the main representatives of process calculi, as a framework to conduct our study. We consider four fragments of the pi-calculus. Each one singles out a natural source of linearity/persistence also present in other frameworks such as concurrent constraint programming (CCP), linear CCP, and several calculi for security. The study is presented by providing (or proving the non-existence of) encodings among the fragments, a processes-as-formulae interpretation and a reduction from, Minsky machines
[security calculi, Protocols, linearity expressiveness, asychronous pi-calculus, Linear programming, concurrency theory, cryptography, Calculus, Encoding, encoding, Information technology, Computer science, pi calculus, processes-as-formulae interpretation, linear CCP, Linearity, Information security, concurrent constraint programming, persistence expressiveness, Carbon capture and storage, Logic, constraint handling, process calculi, Minsky machines]
Saturated Semantics for Reactive Systems
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
The semantics of process calculi has traditionally been specified by labelled transition systems (LTS), but with the development of name calculi it turned out that reaction rules (i.e., unlabelled transition rules) are often more natural. This leads to the question of how behavioural equivalences (bisimilarity, trace equivalence, etc.) defined for LTS can be transferred to unlabelled transition systems. Recently, in order to answer this question, several proposals have been made with the aim of automatically deriving an LTS from reaction rules in such a way that the resulting equivalences are congruences. Furthermore these equivalences should agree with the standard semantics, whenever one exists. In this paper we propose saturated semantics, based on a weaker notion of observation and orthogonal to all the previous proposals, and we demonstrate the appropriateness of our semantics by means of two examples: logic programming and a subset of the open pi-calculus. Indeed, we prove that our equivalences are congruences and that they coincide with logical equivalence and open bisimilarity respectively, while equivalences studied in previous works are strictly finer
[Chemical sensors, System testing, Petri nets, reactive systems, set theory, Proposals, pi calculus, logic programming, Bipartite graph, bisimulation equivalence, process calculi, Logic programming, behavioural equivalences, Subspace constraints, labelled transition systems, programming language semantics, logical equivalence, Computer science, open pi-calculus, saturated semantics, Interactive systems, unlabelled transition systems, Open systems, reaction rules, congruence equivalence, open bisimilarity]
On Model-Checking Trees Generated by Higher-Order Recursion Schemes
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We prove that the modal mu-calculus model-checking problem for (ranked and ordered) node-labelled trees that are generated by order-n recursion schemes (whether safe or not, and whether homogeneously typed or not) is n-EXPTIME complete, for every nges0. It follows that the monadic second-order theories of these trees are decidable. There are three major ingredients. The first is a certain transference principle from the tree generated by the scheme - the value tree - to an auxiliary computation tree, which is itself a tree generated by a related order-0 recursion scheme (equivalently, a regular tree). Using innocent game semantics in the sense of Hyland and Ong, we establish a strong correspondence between paths in the value tree and traversals in the computation tree. This allows us to prove that a given alternating parity tree automaton (APT) has an (accepting) run-tree over the value tree iff it has an (accepting) traversal-tree over the computation tree. The second ingredient is the simulation of an (accepting) traversal-tree by a certain set of annotated paths over the computation tree; we introduce traversal-simulating APT as a recognising device for the latter. Finally, for the complexity result, we prove that traversal-simulating APT enjoy a succinctness property: for deciding acceptance, it is enough to consider run-trees that have a reduced branching factor. The desired bound is then obtained by analysing the complexity of solving an associated (finite) acceptance parity game
[Algorithm design and analysis, modal mu-calculus model-checking problem, node-labelled trees, run-tree, Laboratories, transference principle, alternating parity tree automaton, Tree graphs, decidability, formal verification, Safety, Logic, order-0 recursion scheme, Embedded computing, Computational modeling, higher-order recursion schemes, game theory, acceptance parity game, traversal-tree, recursive functions, auxiliary computation tree, tree searching, Game theory, monadic second-order theories, innocent game semantics, Computer science, order-n recursion schemes, process algebra, Automata, value tree, computational complexity, traversal-simulating APT]
Monadic Chain Logic Over Iterations and Applications to Pushdown Systems
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Logical properties of iterations of relational structures are studied and these decidability results are applied to the model checking of a powerful extension of pushdown systems. It is shown that the monadic chain theory of the iteration of a structure A (in the sense of Shelah and Stupp) is decidable in case the first-order theory of the structure A is decidable. This result fails if Muchnik's clone-predicate is added. A model of pushdown automata, where the stack alphabet is given by an arbitrary (possibly infinite) relational structure, is introduced. If the stack structure has a decidable first-order theory with regular reachability predicates, then the same holds for the configuration graph of this pushdown automaton. This result follows from our decidability result for the monadic chain theory of the iteration
[Tree data structures, iterative methods, configuration graph, reachability analysis, first-order theory, pushdown systems, reachability predicates, Cloning, trees (mathematics), pushdown automata, logical properties, relational structure iteration, Power system modeling, stack structure, decidability, formal verification, monadic chain logic, model checking, Automata, Binary trees, Lab-on-a-chip, Logic, clone-predicate, Periodic structures]
An Automata-Theoretic Approach for Model Checking Threads for LTL Propert
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
In this paper, we propose a new technique for the verification of concurrent multi-threaded programs. In general, the problem is known to be undecidable even for programs with just two threads. However, we exploit the observation that, in practice, a large fraction of concurrent programs can either be modeled as pushdown systems communicating solely using locks or can be reduced to such systems by applying standard abstract interpretation techniques or by exploiting separation of data from control. Moreover, standard programming practice guidelines typically recommend that programs use locks in a nested fashion. In fact, in languages like Java and C#, locks are guaranteed to be nested. For such a framework, we show, by using the new concept of Lock Constrained Multi-Automata Pair (LMAP), that pre*-closures of regular sets of states can be computed efficiently. This is accomplished by reducing the pre*-closure computation for a regular set of states of a concurrent program with nested locks to those for its individual threads. Leveraging this new technique then allows us to formulate a fully automatic, efficient and exact (sound and complete) decision procedure for model checking threads communicating via nested locks for indexed linear-time temporal logic formulae
[program verification, Automatic logic units, pushdown automata, model checking threads, temporal logic, Yarn, Communication standards, Guidelines, Concurrent computing, File systems, Databases, decidability, abstract interpretation techniques, LMAP, Operating systems, National electric code, data structures, lock constrained multiautomata pair, concurrent multithreaded program verification, Java, program control structures, multi-threading, pushdown systems, automata-theoretic approach, concurrency theory, nested locks, indexed linear-time temporal logic formulae, undecidability, pre*-closure computation, decision procedure, LTL properties]
On Typability for Rank-2 Intersection Types with Polymorphic Recursion
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We show that typability for a natural form of polymorphic recursive typing for rank-2 intersection types is undecidable. Our proof involves characterizing typability as a context free language (CFL) graph problem, which may be of independent interest, and reduction from the boundedness problem for Turing machines. We also show a property of the type system which, in conjunction with the undecidability result, disproves a misconception about the Milner-Mycroft type system. We also show undecidability of a related program analysis problem
[program diagnostics, Government, graph theory, CFL graph problem, context free language, type theory, polymorphic recursive typing, rank-2 intersection types, undecidability, Computer science, Computer languages, Turing machines, context-free languages, decidability, program analysis problem, type system, Writing, Logic]
Adapting Logics
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
In this paper the author plans to survey some of the adaptations and variations of logic that have been introduced for various purposes. For obvious reasons, we concentrate mainly on purposes related to computer science and on adaptations that have played a role in the research. Along the way, the author discusses some open problems
[Computer science, formal logic, computer science, game theory, Set theory, Mathematics, Logic, Database languages]
Managing Digital Rights using Linear Logic
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Digital music players protect songs by enforcing licenses that convey specific rights for individual songs or groups of songs. For licenses specified in industry, we show that deciding whether a license authorizes a sequence of actions is NP-complete, with a restricted version of the problem solvable efficiently using a reduction to maximum network flow. The authorization algorithm used in industry is online, deciding which rights to exercise as actions occur, but we show that all online algorithms are necessarily non-monotonic: each allows actions under one license that it does not allow under a more flexible license. In one approach to achieving monotonicity, we exhibit the unique maximal set of licenses on which there exists a monotonic online algorithm. This set of well-behaved licenses induces an approximation algorithm by replacing each license with a well-behaved license. In a second approach, we consider allowing the player to revise its past decisions about which rights to exercise while still ensuring compliance with the license. We propose an efficient algorithm based on linear logic, with linear negation used to revise past decisions. We prove our algorithm monotonic, live, and sound with respect to the semantics of licenses
[copyright, Subscriptions, Cement industry, linear logic, digital rights management, Licenses, NP-complete problem, license semantics, Authorization, Computer science, formal logic, maximum network flow, monotonic online algorithm, music, authorisation, online authorization algorithm, approximation algorithm, Approximation algorithms, Libraries, Logic, Cryptography, Protection, digital music players, computational complexity]
Variables as Resource in Hoare Logics
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Hoare logic is bedevilled by complex but coarse side conditions on the use of variables. We define a logic, free of side conditions, which permits more precise statements of a program's use of variables. We show that it admits translations of proofs in Hoare logic, thereby showing that nothing is lost, and also that it admits proofs of some programs outside the scope of Hoare logic. We include a treatment of reference parameters and global variables in procedure call (though not of parameter aliasing). Our work draws on ideas from separation logic: program variables are treated as resource rather than as logical variables in disguise. For clarity we exclude a treatment of the heap
[programming theory, procedure call, Educational institutions, program variables, Hoare logics, Programming profession, Concurrent computing, Computer science, formal logic, Program processors, proof translation, separation logic, Permission, Writing, global variables, Logic]
Independence and Concurrent Separation Logic
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
A compositional Petri net based semantics is given to a simple pointer-manipulating language. The model is then applied to give a notion of validity to the judgements made by concurrent separation logic that emphasizes the process-environment duality inherent in such rely-guarantee reasoning. Soundness of the rules of concurrent separation logic with respect to this definition of validity is shown. The independence information retained by the Petri net model is then exploited to characterize the independence of parallel processes enforced by the logic. This is shown to permit a refinement operation capable of changing the granularity of atomic actions
[pointer-manipulating language, Parallel languages, refinement operation, Logic programming, Laboratories, Petri nets, rely-guarantee reasoning, refinement calculus, process-environment duality, concurrency theory, parallel process independence, State-space methods, programming language semantics, parallel programming, Concurrent computing, concurrent separation logic, Parallel programming, Interleaved codes, Hardware, Joining processes, Spatial resolution, compositional Petri net based semantics]
Matching Explicit and Modal Reasoning about Programs: A Proof Theoretic Delineation of Dynamic Logic
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We establish a match between two broad approaches to reasoning about programs: modal (dynamic logic) proofs on the one hand, and explicit higher-order reference to program semantics, on the other. We show that Pratt-Segerberg's first-order dynamic logic DL proves precisely program properties that are provable in second-order logic with set-existence restricted to a natural class of formulas, well-known to be related to computation theory. The set-existence principle is for computational formulas, i.e. of the form forallRexistxoarrF where R is relational, F quantifier-free. Depending on the exact nature of the programs considered, some fine tuning is needed. We establish a descriptive match, of independent interest, between programming languages L and particular classes DL of computational formulas, in the following sense: the semantics of programs alphaisinL is explicitly definable, in all relational structures, by a formula phi<sub>alpha </sub> of D<sub>L</sub>; and for every formula phi of D<sub>L</sub> there is a program in L whose termination is equivalent to phi. In particular, we match the class of regular programs with random assignments to computational formulas that are "sequential\
[Calculus, set theory, explicit reasoning, programming languages, random assignments, formal logic, computational formulas, explicit higher-order reference, program semantics, natural variable scoping condition, Pratt-Segerberg first-order dynamic logic, computation theory, Hardware, theorem proving, Logic, set-existence principle, regular programs, relational structures, Reasoning about programs, Educational institutions, Calibration, programming language semantics, Equations, Computer languages, modal reasoning, descriptive match, proof theoretic delineation, Computation theory, second-order logic, reasoning about programs, Principal component analysis]
Context Semantics, Linear Logic and Computational Complexity
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We show that context semantics can be fruitfully applied to the quantitative analysis of proof normalization in linear logic. In particular, context semantics lets us define the weight of a proof-net as a measure of its inherent complexity: it is both an upper bound to normalization time (modulo a polynomial overhead, independently on the reduction strategy) and a lower bound to the number of steps to normal form (for certain reduction strategies). Weights are then exploited in proving strong soundness theorems for various subsystems of linear logic, namely elementary linear logic, soft linear logic and light linear logic
[Solid modeling, polynomial overhead, elementary linear logic, Circuits, normalization time, Time measurement, proof normalization quantitative analysis, programming language semantics, Computational complexity, proof-net weight, Geometry, formal logic, Upper bound, reduction strategy, soft linear logic, Particle measurements, Polynomials, theorem proving, Logic, light linear logic, strong soundness theorems, Context modeling, computational complexity, context semantics]
Obsessional Cliques: A Semantic Characterization of Bounded Time Complexity
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We give a semantic characterization of bounded complexity proofs. We introduce the notion of obsessional clique in the relational model of linear logic and show that restricting the morphisms of the category RscrEscrLscr to obsessional cliques yields models of ELL and SLL. Conversely, we prove that these models are relatively complete: an LL proof whose interpretation is an obsessional clique is always an ELL/SLL proof. These results are achieved by introducing a system of ELL/SLL untyped proof-nets, which is both correct and complete with respect to elementary/polynomial time complexity
[semantic characterization, Mathematics, Lighting control, Electronic mail, Cultural differences, Computational complexity, ELL-SLL untyped proof-nets, elementary time complexity, linear logic relational model, Computer science, formal logic, bounded time complexity proofs, obsessional cliques, Polynomials, theorem proving, Logic, Mathematical model, polynomial time complexity, Arithmetic, computational complexity]
Conditional Lower Bound for a System of Constant-Depth Proofs with Modular Connectives
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
It is known that constant-depth Frege proofs of some tautologies require exponential size. No such lower bound result is known for more general proof systems. We consider sequent calculus proofs in which formulas can contain modular connectives and only the cut formulas are restricted to be of constant depth. Under a plausible hardness assumption concerning small-depth Boolean circuits, we prove an exponential lower bound for such proofs. We prove this lower bound directly from the computational hardness assumption. By using the same approach, we obtain the following additional results. We provide a much simpler proof of a known (unconditional) lower bound in the case where only conjunctions and disjunctions are allowed. We establish a conditional exponential separation between the power of constant-depth proofs that use different modular connectives. Finally, under a plausible hardness assumption concerning the polynomial-time hierarchy, we show that the hierarchy G<sub>i</sub>* of quantified propositional proof systems does not collapse
[constant-depth Frege proof system, conditional lower bound, conditional exponential separation, plausible hardness assumption, Calculus, modular connectives, exponential lower bound, Computer science, Boolean functions, Logic circuits, process algebra, sequent calculus proofs, Polynomials, quantified propositional proof systems, theorem proving, computational hardness assumption, small-depth Boolean circuits]
A Characterisation of First-Order Constraint Satisfaction Problems
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We characterise finite relational core structures admitting finitely many obstructions, in terms of special near unanimity functions, and in terms of dismantling properties of their square. As a consequence, we show that it is decidable to determine whether a constraint satisfaction problem is first-order definable: we show the general problem to be NP-complete, and give a polynomial-time algorithm in the case of cores
[relational algebra, constraint theory, Relational databases, Educational institutions, Graph theory, Character recognition, first-order constraint satisfaction problem characterisation, NP-complete problem, Statistics, Combinatorial mathematics, Computer science, decidability, Constraint theory, Polynomials, finite relational core structures, near-unanimity functions, Logic, polynomial-time algorithm, computational complexity]
First Order Formulas with Modular Ppredicates
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Two results by Schutzenberger (1965) and by McNaughton and Papert (1971) lead to a precise description of the expressive power of first order logic on words interpreted as ordered colored structures. In this paper, we study the expressive power of existential formulas and of Boolean combinations of existential formulas in a logic enriched by modular numerical predicates. We first give a combinatorial description of the corresponding regular languages, and then give an algebraic characterization in terms of their syntactic morphisms. It follows that one can effectively decide whether a given regular language is captured by one of these two fragments of first order logic. The proofs rely on nontrivial techniques of semigroup theory: stamps, derived categories and wreath products
[Vocabulary, formal languages, algebraic characterization, Indium tin oxide, regular language combinatorial description, Complexity theory, Boolean algebra, existential formula expressive power, existential formula Boolean combinations, semigroup theory, modular predicates, Computer science, group theory, decidability, Logic circuits, syntactic morphisms, Automata, first order logic, ordered colored structures]
On Tractability and Congruence Distributivity
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Constraint languages that arise from finite algebras have recently been the object of study, especially in connection with the dichotomy conjecture of Feder and Vardi. An important class of algebras are those that generate congruence distributive varieties and included among this class are lattices, and more generally, those algebras that have near-unanimity term operations. An algebra will generate a congruence distributive variety if and only if it has a sequence of ternary term operations, called Jonsson terms, that satisfy certain equations. We prove that constraint languages consisting of relations that are invariant under a short sequence of Jonsson terms are tractable by showing that such languages have bounded width. Consequently, the class of instances of the constraint satisfaction problem arising from such a constraint language that fail to have solutions is definable in Datalog
[congruence distributive variety, near-unanimity term operations, Terminology, Datalog, constraint theory, Lattices, constraint satisfaction problem, Mathematics, Jonsson terms, sequences, Equations, Computer science, dichotomy conjecture, Algebra, tractable constraint languages, process algebra, finite algebras, ternary term operations, Statistical distributions, Constraint theory, theorem proving, congruence distributivity, Logic, constraint handling]
PSPACE Bounds for Rank-1 Modal Logics
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
For lack of general algorithmic methods that apply to wide classes of logics, establishing a complexity bound for a given modal logic is often a laborious task. The present work is a step towards a general theory of the complexity of modal logics. Our main result is that all rank-1 logics enjoy a shallow model property and thus are, under mild assumptions on the format of their axiomatization, in PSPACE. This leads not only to a unified derivation of (known) tight PSPACE-bounds for a number of logics including K, coalition logic, and graded modal logic (and to a new algorithm in the latter case), but also to a previously unknown tight PSPACE-bound for probabilistic modal logic, with rational probabilities coded in binary. This generality is made possible by a coalgebraic semantics, which conveniently abstracts from the details of a given model class and thus allows covering a broad range of logics in a uniform way
[algorithmic methods, Object oriented modeling, graded modal logic, Knowledge representation, PSPACE bounds, Probabilistic logic, Encoding, Specification languages, probabilistic modal logic, Computer science, formal logic, rank-1 modal logics, shallow model property, Automata, coalition logic, Abstracts, Concrete, complexity bound, computational complexity, coalgebraic semantics]
Avoiding Determinization
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Automata on infinite objects are extensively used in system specification, verification, and synthesis. Applications that involve determinization of automata on infinite words have been doomed to belong to the second category. This has to do with the intricacy of Safra's optimal determinization construction, the fact that the state space that results from determinization is awfully complex and is not amenable to optimizations and a symbolic implementation, and the fact that determinization requires the introduction of acceptance conditions that are more complex than the Buchi acceptance condition. Examples of applications that involve determinization and belong to the unfortunate second category include model checking of omega-regular properties, decidability of branching temporal logics, and synthesis and control of open systems. We offer an alternative to the standard automata-theoretic approach. The crux of our approach is avoiding determinization. Our approach goes instead via universal co-Buchi automata. Like nondeterministic automata, universal automata may have several runs on every input. However, an input is accepted if all of the runs are accepting. We show how the use of universal automata simplifies significantly known complementation constructions for automata on infinite words, known decision procedures for branching temporal logics, known synthesis algorithms, and other applications that are now based on determinization. Our algorithms are less difficult to implement and have practical advantages like being amenable to optimizations and a symbolic implementation
[automata theory, temporal logic, Mathematics, system specification, formal specification, formal logic, formal verification, Control system synthesis, Automatic control, Logic, nondeterministic automata, automata-theoretic approach, State-space methods, infinite words, universal coBuchi automata, Construction industry, synthesis algorithms, Computer science, model checking, Safra optimal determinization construction, symbolic implementation, Automata, Open systems, decision procedures, Formal verification, computational complexity, automata determinization]
From Nondeterministic Buchi and Streett Automata to Deterministic Parity Automata
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
In this paper we revisit Safra's determinization constructions. We show how to construct deterministic automata with fewer states and, most importantly, parity acceptance conditions. Specifically, starting from a nondeterministic Buchi automaton with n states our construction yields a deterministic parity automaton with n2n+2 states and index 2n (instead of a Rabin automaton with (12)nn2n states and n pairs). Starting from a nondeterministic Streett automaton with n states and k pairs our construction yields a deterministic parity automaton with nn(k+2)+2(k+1)2n(K+1) states and index 2n(k+1) (instead of a Rabin automaton with (12)n(k+1)n n(k+2)(k+1)2n(k+1) states and n(k+1) pairs). The parity condition is much simpler than the Rabin condition. In applications such as solving games and emptiness of tree automata handling the Rabin condition involves an additional multiplier of n2n!(or(n(k+1))2(n(k+1))! in the case of Streett) which is saved using our construction
[deterministic parity automata, deterministic automata, Automata, nondeterministic Streett automata, nondeterministic Buchi automata, tree automata, Safra determinization constructions, computational complexity, parity acceptance conditions]
Memoryful Branching-Time Logic
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Traditional branching-time logics such as CTL* are memoryless: once a path in the computation tree is quantified at a given node, the computation that led to that node is forgotten. Recent work in planning suggests that CTL* cannot easily express temporal goals that refer to whole computations. Such goals require memoryful quantification of paths. With such a memoryful quantification, Epsi holds at a node s of a computation tree if there is a path pi starting at the root of the tree and going through s such that pi satisfies the linear-time formula psi. We define the memoryful branching-time logic mCTL* and study its expressive power and algorithmic properties. We show that mCTL* is as expressive, but exponentially more succinct, than CTL*, and that the ability of mCTL* to refer to the present is essential for this equivalence. From the algorithmic point of view, while the satisfiability problem for mCTL* is 2EXPTIME-complete - not harder than that of CTL*, its model-checking problem is EXPSPACE-complete - exponentially harder than that of CTL*. The upper bounds are obtained by extending the automata-theoretic approach to handle memoryful quantification, and are much more efficient than these obtained by translating mCTL* to branching logics with past. The EXPSPACE lower bound for the model-checking problem applies already to formulas of restricted form (in particular, to AGEpsi, which is useful for specifying possibility properties), and implies that reasoning about a memoryful branching-time logic is harder than reasoning about the linear-time logic of its path formulas
[Computational modeling, automata theory, computation tree, trees (mathematics), computability, temporal logic, automata-theoretic approach, temporal logics, Computer science, Upper bound, formal verification, model-checking problem, satisfiability, memoryful quantification, Computer applications, CTL branching-time logic, Logic, Mathematical model, mCTL, Artificial intelligence, linear-time formula, Formal verification, computational complexity, memoryful branching-time logic]
Faster Solutions of Rabin and Streett Games
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
In this paper we improve the complexity of solving Rabin and Streett games to approximately the square root of previous bounds. We introduce direct Rabin and Streett ranking that are a sound and complete way to characterize the winning sets in the respective games. By computing directly and explicitly the ranking we can solve such games in time O(mnk+1kk!) and space O(nk) for Rabin and O(nkk!) for Streett where n is the number of states, m the number of transitions, and k the number of pairs in the winning condition. In order to prove completeness of the ranking method we give a recursive fixpoint characterization of the winning regions in these games. We then show that by keeping intermediate values during the fixpoint evaluation, we can solve such games symbolically in time O(nk+1k!) and space O(nk+1k!). These results improve on the current bounds of O(mn2kk!) time in the case of direct (symbolic) solution or O(m(nk2k!)k) in the case of reduction to parity games
[recursive fixpoint characterization, Computerized monitoring, Rabin game, H infinity control, game theory, recursive functions, Streett ranking, Condition monitoring, winning regions, Tree graphs, Automata, computational complexity improvement, parity games, Streett game, computational complexity]
Bounds in w-Regularity
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We consider an extension of omega-regular expressions where two new variants of the Kleene star L* are added: LB and LS . These exponents act as the standard star, but restrict the number of iterations to be bounded (for LB) or to tend toward infinity (for LS). These expressions can define languages that are not omega-regular. We develop a theory for these languages. We study the decidability and closure questions. We also define an equivalent automaton model, extending Buchi automata. This culminates with a - partial -complementation result
[Computer science, formal languages, closure questions, decidability, automata theory, Automata, H infinity control, equivalent automaton model, Kleene star, omega-regular expressions, Buchi automata, Logic]
Head Normal Form Bisimulation for Pairs and the \\lambda\\mu-Calculus
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Bohm tree equivalence up to possibly infinite eta expansion for the pure lambda-calculus can be characterized as a bisimulation equivalence. We call this co-inductive syntactic theory extensional head normal form bisimilarity and in this paper we extend it to the lambdaFP-calculus (the lambda-calculus with functional and surjective pairing) and to two untyped variants of Parigot's lambdamu-calculus. We relate the extensional head normal form bisimulation theories for the different calculi via Fujita's extensional CPS transform into the lambdaFP-calculus. We prove that extensional hnf bisimilarity is fully abstract for the pure lambda-calculus by a co-inductive reformulation of Barendregt's proof for Bohm tree equivalence up to possibly infinite eta expansion. The proof uses the so-called Bohm-out technique from Bohm's proof of the separation property for the lambda-calculus. Moreover, we extend the full abstraction result to extensional hnf bisimilarity for the lambdaFP-calculus. For the "standard" lambdamu-calculus, the separation property fails, as shown by David and Py, and for the same reason extensional hnf bisimilarity is not fully abstract. However, an "extended" variant of the lambdamu-calculus satisfies the separation property, as shown by Saurin, and we show that extensional hnf bisimilarity is fully abstract for this extended lambdamu-calculus
[lambda calculus, Fujita extensional CPS transform, trees (mathematics), Calculus, lambdaFP-calculus, coinductive reformulation, head normal form bisimulation, Computer science, separation property, Bohm-out technique, Barendregt proof, lambdamu-calculus, Bohm tree equivalence, coinductive syntactic theory, bisimulation equivalence, Logic]
A Proof of Strong Normalisation using Domain Theory
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
U. Berger, (2005) significantly simplified Tait's normalisation proof for bar recursion, replacing Tait's introduction of infinite terms by the construction of a domain having the property that a term, is strongly normalizing if its semantics is neperp. The goal of this paper is to show that, using ideas from the theory of intersection types and Martin-Lof's domain interpretation of type theory, we can in turn simplify U, Berger's argument in the construction of such a domain model. We think that our domain model can be used to give modular proofs of strong normalization for various type theory. As an example, we show in some details how it can be used to prove strong normalization for Martin-Lof dependent type theory extended with bar recursion, and with some form of proof-irrelevance
[Martin-Lof domain interpretation, Lattices, normalisation proof, Calculus, recursive functions, type theory, programming language semantics, bar recursion, Computer science, Computer languages, domain model, Martin-Lof dependent type theory, intersection type theory, Logic, Arithmetic, domain theory]
Boolean Algebras for Lambda Calculus
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
In this paper we show that the Stone representation theorem for Boolean algebras can be generalized to combinatory algebras. In every combinatory algebra there is a Boolean algebra of central elements (playing the role of idempotent elements in rings), whose operations are defined by suitable combinators. Central elements are used to represent any combinatory algebra as a Boolean product of directly indecomposable combinatory algebras (i.e., algebras which cannot be decomposed as the Cartesian product of two other nontrivial algebras). Central elements are also used to provide applications of the representation theorem to lambda calculus. We show that the indecomposable semantics (i.e., the semantics of lambda calculus given in terms of models of lambda calculus, which are directly indecomposable as combinatory algebras) includes the continuous, stable and strongly stable semantics, and the term models of all semisensible lambda theories. In one of the main results of the paper we show that the indecomposable semantics is equationally incomplete, and this incompleteness is as wide as possible: for every recursively enumerable lambda theory Tscr, there is a continuum of lambda theories including Tscr which are omitted by the indecomposable semantics
[lambda calculus, combinatorial mathematics, computational linguistics, Lattices, lambda calculus semantics, Calculus, Boolean algebra, Topology, Equations, Computer science, Boolean product, Stone representation theorem, Logic functions, Mathematical model, Kernel, indecomposable combinatory algebras]
Normalisation is Insensible to \\lambda-Term Identity or Difference
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
This paper analyses the computational behaviour of lambda-term applications. The properties we are interested in are weak normalisation (i.e. there is a terminating reduction) and strong normalisation (i.e. all reductions are terminating). One can prove that the application of a lambda-term M to a fixed number n of copies of the same arbitrary strongly normalising lambda-term is strongly normalising if and only if the application of M to n different arbitrary strongly normalising lambda-terms is strongly normalising, i.e. one has that M (X ... X)/n is strongly normalising, for an arbitrary strongly normalising X, if and only if MX<sub>1</sub>...X<sub>n</sub> is strongly normalising for arbitrary strongly normalising X<sub>1</sub>, ..., X<sub>n</sub>. The analogous property holds when replacing strongly normalising by weakly normalising. As an application of the result on strong normalisation the lambda-terms whose interpretation is the top element (in the environment which associates the top element to all variables) of the Honsell-Lenisa model turn out to be exactly the lambda-terms which, applied to an arbitrary number of strongly normalising lambda-terms, always produces strongly normalising lambda-terms. This proof uses a finitary logical description of the model by means of intersection types. This answers an open question stated by Dezani, Honsell and Motohama
[Computer science, lambda calculus, Shape, Tin, finitary logical model description, lambda-term identity normalisation, Logic]
Shaken Foundations or Groundbreaking Realignment? A Centennial Assessment of Kurt G&#246;del's Impact on Logic, Mathematics, and Computer Science
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
The publication of Godel's incompleteness theorems has frequently been portrayed as a devastating event, from which mathematics has not yet recovered. Yet those same theorems have also been hailed as proving that the powers of the human mind surpass those of any computer. Both those views, however, are caricatures. Godel's impact on modern logic has been profound, but the incompleteness theorems did not cause widespread upset at the time of their publication, and subsequent mathematical work outside logic has hardly been affected by them. Nor is mathematics any less "secure" than it was before Godel's work
[centennial assessment, Mathematics, history, set theory, Computer science, formal logic, computer science, Kurt Godel incompleteness theorem, Set theory, Logic, Artificial intelligence, mathematical logic, Arithmetic]
Provable Implementations of Security Protocols
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
The author implements the relatively new enterprise of adapting formal methods for security to work on code instead of abstract models. The goal is to lower the practical cost of security protocol verification by eliminating the need to write a separate formal model. The main technical content is on extracting pi-calculus models from protocol implementation code. Our software is developed in the functional language F#, a dialect of ML
[Algorithm design and analysis, Automation, Computational modeling, Design methodology, pi-calculus, cryptography, cryptographic protocol, security protocol verification, ML language, Cryptographic protocols, pi calculus, Computer languages, formal verification, Information security, formal methods, functional language, Robustness, Cryptography, protocols, Computer security]
Stochastic games with branching-time winning objectives
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We consider stochastic turn-based games where the winning objectives are given by formulae of the branching-time logic PCTL. These games are generally not determined and winning strategies may require memory and or randomization. Our main results concern history-dependent strategies. In particular, we show that the problem whether there exists a history-dependent winning strategy in 1frac12-player games is highly undecidable, even for objectives formulated in the Lscr(F=5/8 ,F=1,F&gt;0,G=1) fragment of PCTL. On the other hand, we show that the problem becomes decidable (and in fact EXPTIME-complete) for the Lscr(F=1,F&gt;0,G=1) fragment of PCTL, where winning strategies require only finite memory. This result is tight in the sense that winning strategies for Lscr(F=1,F&gt;0,G=1,G&gt;0 ) objectives may already require infinite memory
[stochastic turn-based games, Stochastic processes, temporal logic, Probability distribution, Mathematics, finite memory, History, PCTL, branching-time winning objectives, Computer science, decidability, history-dependent winning strategies, Logic, branching-time logic, Informatics, stochastic games]
Coinductive Proof Principles for Stochastic Processes
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We give an explicit coinduction principle for recursively-defined stochastic processes. The principle applies to any closed property, not just equality, and works even when solutions are not unique. The rule encapsulates low-level analytic arguments, allowing reasoning about such processes at a higher algebraic level. We illustrate the use of the rule in deriving properties of a simple coin-flip process
[functional programming, Stochastic processes, recursive functions, Equations, low-level analytic arguments, Computer science, Analytical models, Q measurement, coin-flip process, process algebra, algebraic level, Automata, Tail, recursively-defined stochastic processes, theorem proving, Functional programming, Logic, stochastic processes, coinductive proof principles, Arithmetic]
Control in o-minimal Hybrid Systems
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
In this paper, we consider the control of general hybrid systems. In this context we show that time-abstract bisimulation is not adequate for solving such a problem. That is why we consider other equivalence, namely the suffix equivalence based on the encoding of trajectories through words. We show that this suffix equivalence is in general a correct abstraction for control problems. We apply this result to o-minimal hybrid systems, and get decidability and computability results in this framework
[control theory, suffix equivalence, computability, trajectory encoding, Control systems, Encoding, time-abstract bisimulation, finite state machines, Computer science, Mars, decidability, Automata, Automatic control, bisimulation equivalence, Logic, Formal verification, computational complexity, o-minimal hybrid systems]
An Abstraction-Refinement Framework for Multi-Agent Systems
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Abstraction is a key technique for reasoning about systems with very large or even infinite state spaces. When a system is composed of reactive components, the interaction between the components is modeled by a multi-player game and verification corresponds to finding winners in the game. We describe an abstraction-refinement framework for multi-player games, with respect to specifications in the alternating mu-calculus (AMC). Our framework is based on abstract alternating transition systems (AATSs). Each agent in an AATS has transitions that over-approximate its power and transitions that under-approximate its power. We define the framework, define a 3-valued semantics for AMC formulas in an AATS, study the model-checking problem, define an abstraction preorder between AATSs, suggest a refinement procedure (in case model checking returns an indefinite answer), and study the completeness of the framework. For the case of predicate abstraction, we show how reasoning can be automated with a theorem prover. Abstractions of multi-player games have been studied in the past. Our main contribution with respect to earlier work is that we study general (rather than only turn-based) ATSs, we add a refinement procedure on top of the model checking procedure, and our abstraction preorder is parameterized by a set of agents
[Multiagent systems, multi-agent systems, 3-valued semantics, game theory, refinement calculus, State-space methods, Security, Power system modeling, Game theory, Computer science, abstract alternating transition systems, formal verification, model-checking problem, theorem prover, Automata, Open systems, abstraction-refinement framework, Concrete, theorem proving, Logic, infinite state spaces, alternating mu-calculus, multiagent systems, multiplayer game]
Temporal Logics and Model Checking for Fairly Correct Systems
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
We motivate and study a generic relaxation of correctness of reactive and concurrent systems with respect to a temporal specification. We define a system to be fairly correct if there exists a fairness assumption under which it satisfies its specification. Equivalently, a system is fairly correct if the set of runs satisfying the specification is large from a topological point of view, i.e., it is a co-meager set. We compare topological largeness with its more popular sibling, probabilistic largeness, where a specification is probabilistically large if the set of runs satisfying the specification has probability 1. We show that topological and probabilistic largeness of omega-regular specifications coincide for bounded Borel measures on finite-state systems. As a corollary, we show that, for specifications expressed in LTL or by Buchi automata, checking that a finite-state system is fairly correct has the same complexity as checking that it is correct. Finally we study variants of the logics CTL and CTL*, where the 'for all runs' quantifier is replaced by a 'for a large set of runs' quantifier. We show that the model checking complexity for these variants is the same as for the original logics
[probabilistic largeness, reactive systems, LTL, generic correctness relaxation, temporal specification, run quantifier, computability, temporal logic, finite-state systems, temporal logics, finite state machines, model checking complexity, topological largeness, decidability, formal verification, Logic, Books, algebraic specification, co-meager set, probability, Educational institutions, Topology, omega-regular specifications, bounded Borel measures, fairness assumption, Automata, concurrent systems, Concrete, Buchi automata, CTL, fairly correct systems, computational complexity]
3-Valued Abstraction: More Precision at Less Cost
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
This paper investigates both the precision and the model checking efficiency of abstract models designed to preserve branching time logics w.r.t. a 3-valued semantics. Current abstract models use ordinary transitions to over approximate the concrete transitions, while they use hyper transitions to under approximate the concrete transitions. In this work we refer to precision measured w.r.t. the choice of abstract states, independently of the formalism used to describe abstract models. We show that current abstract models do not allow maximal precision. We suggest a new class of models and a construction of an abstract model which is most precise w.r.t. any choice of abstract states. As before, the construction of such models might involve an exponential blowup, which is inherent by the use of hyper transitions. We therefore suggest an efficient algorithm in which the abstract model is constructed during model checking, by need. Our algorithm achieves maximal precision w.r.t. the given property while remaining quadratic in the number of abstract states. To complete the picture, we incorporate it into an abstraction-refinement framework
[Costs, 3-valued semantics, abstract states, refinement calculus, branching time logics, Logic design, Explosions, abstract models, Electronic mail, finite state machines, Power system modeling, Computer science, concrete transitions, 3-valued abstraction, formal verification, model checking efficiency, maximal precision, hyper transitions, abstraction-refinement framework, Concrete, algebraic specification, computational complexity]
Approximation Schemes for First-Order Definable Optimisation Problems
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Let phi(X) be a first-order formula in the language of graphs that has a free set variable X, and assume that X only occurs positively in phi(X). Then a natural minimisation problem associated with phi(X) is to find, in a given graph G, a vertex set S of minimum size such that G satisfies phi(S). Similarly, if X only occurs negatively in phi(X), then phi(X) defines a maximisation problem. Many well-known optimisation problems are first-order definable in this sense, for example, minimum dominating set or maximum independent set. We prove that for each class Gscr of graphs with excluded minors, in particular for each class of planar graphs, the restriction of a first-order definable optimisation problem to the class Gscr has a polynomial time approximation scheme. A crucial building block of the proof of this approximability result is a version of Gaifman's locality theorem for formulas positive in a set variable. This result may be of independent interest
[formal languages, Particle separators, graph theory, planar graphs, maximisation problem, first-order logic, set theory, first-order definable optimisation problems, maximum independent set, Gaifman locality theorem, formal logic, first-order formula, minimisation problem, optimisation, minimum dominating set, polynomial time approximation scheme, Polynomials, Logic, computational complexity]
Approximate Satisfiability and Equivalence
21st Annual IEEE Symposium on Logic in Computer Science
None
2006
Inspired by property testing, we relax the classical satisfiability UvDashF between a finite structure U of a class K and a formula F, to a notion of epsiv-satisfiability UvDash<sub>epsiv </sub>F, and the classical equivalence F<sub>1</sub>equivF<sub>2</sub> between two formulas F<sub>1</sub> and F<sub>2</sub>, to epsiv-equivalence F<sub>1</sub>equiv<sub>epsiv</sub>F<sub>2</sub> for epsiv&gt;0. We consider the class of strings and trees with the edit distance with moves, and show that these approximate notions can be efficiently decided. We use a statistical embedding of words (resp. trees) into lscr<sub>1</sub>, which generalizes the original Parikh mapping, obtained by sampling O(f(epsiv)) finite samples of the words (resp. trees). We give a tester for equality and membership in any regular language, in time independent of the size of the structure. Using our geometrical embedding, we can also test the equivalence between two regular properties on words, defined by monadic second order formulas. Our equivalence tester has polynomial time complexity in the size of the automaton (or regular expression), for a fixed epsiv, whereas the exact version of the equivalence problem is PSPACE-complete. Last, we extend the geometric embedding, and hence the tester algorithms, to infinite regular languages and to context-free languages. For context-free languages, the equivalence tester has an exponential time complexity, whereas the exact version is undecidable
[classical equivalence tester, infinite regular languages, automata theory, computability, Logic testing, equality tester algorithms, context-free languages, decidability, Vegetation mapping, Polynomials, Robustness, polynomial time complexity, sampling methods, Hamming distance, exponential time complexity, trees (mathematics), PSPACE-complete equivalence problem, property testing, statistical word embedding, automaton theory, finite structure, Computer science, approximate classical satisfiability, monadic second order formulas, Automatic testing, Working environment noise, Automata, word sampling, Sampling methods, equivalence classes, Parikh mapping, computational complexity]
Foreword
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Presents the introductory welcome message from the conference proceedings.
[]
Organizing Committee
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Provides a listing of current committee members.
[]
Normalization by Evaluation for Martin-Lof Type Theory with Typed Equality Judgements
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
The decidability of equality is proved for Martin-Lof type theory with a universe a la Russell and typed beta-eta- equality judgements. A corollary of this result is that the constructor for dependent function types is injective, a property which is crucial for establishing the correctness of the type-checking algorithm. The decision procedure uses normalization by evaluation, an algorithm which first interprets terms in a domain with untyped semantic elements and then extracts normal forms. The correctness of this algorithm is established using a PER-model and a logical relation between syntax and semantics.
[beta-eta-equality judgements, Buildings, dependent function types, PER-model, Calculus, Decision feedback equalizers, type theory, Application software, logical relation, semantic elements, Computer science, semantic networks, Mathematical model, Logic, type-checking algorithm, Martin-Lof type theory]
Strong Normalization as Safe Interaction
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
When enriching the lambda-calculus with rewriting, union types may be needed to type all strongly normalizing terms. However, with rewriting, the elimination rule (orE) of union types may also allow to type non normalizing terms (in which case we say that (orE) is unsafe). This occurs in particular with non-determinism, but also with some confluent systems. It appears that studying the safety of (orE) amounts to the characterization, in a term, of safe interactions between some of its subterms. In this paper, we study the safety of (orE) for an extension of the lambda-calculus with simple rewrite rules. We prove that the union and intersection type discipline without (orE) is complete w.r.t. strong normalization. This allows to show that (orE) is safe if and only if an interpretation of types based on biorthogonals is sound for it. We also discuss two sufficient conditions for the safety of (orE), and study an alternative biorthogonality relation, based on the observation of the least reducibility candidate.
[lambda calculus, rewriting systems, elimination rule, union types, safe interactions, lambda-calculus, Convergence, strong normalization, Computer science, Sufficient conditions, Pathology, biorthogonality relation, Safety, Logic]
A Dependent Set Theory
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Set theories are traditionally based on first-order logic. We show that in a constructive setting, basing a set theory on a dependent logic yields many benefits. To this end, we introduce a dependent impredicative constructive set theory which we call IZF<sub>D</sub>. Using realizability, we prove that the underlying lambda calculus weakly normalizes, thus enabling program extraction from IZF_D proofs. We also show that IZF<sub>D</sub> can interpret IZF with Collection. By a wellknown result of Friedman, this establishes IZF<sub>D</sub> as a remarkably strong theory, with proof-theoretical power equal to that of ZFC. We further demonstrate that IZF<sub>D</sub> provides a natural framework to interpret first-order definitions, thus removing a longstanding barrier to implementing constructive set theories. Finally, we prove that IZF<sub>D</sub> extended with excluded middle is consistent, thus paving the way to using our framework in the classical setting as well.
[lambda calculus, Protocols, Buildings, Calculus, Mathematics, set theory, Application software, IZF<sub>D</sub>, Computer science, Computer languages, Set theory, Logic, dependent impredicative constructive set theory, Software engineering]
Some Methods of Problem Solving in Elementary Geometry
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Many elementary problems in geometry arise as part of the proof of the Kepler conjecture on sphere packings. In the original proof, most of these problems were solved by hand. This article investigates the methods that were used in the original proof and describes a number of other methods that might be used to automate the proofs of these problems. A companion article presents the collection of elementary problems in geometry for which automated proofs are sought. This article is a contribution to the Flyspeck project, which aims to give a complete formal proof of the Kepler conjecture.
[Visualization, Automation, problem solving, History, Logic testing, Computer science, Computational geometry, Upper bound, elementary geometry, sphere packings, Kepler conjecture, face-centered cubic packing, geometry, Flyspeck project, Problem-solving]
Principles of Superdeduction
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
In predicate logic, the proof that a theorem P holds in a theory Th is typically conducted in natural deduction or in the sequent calculus using all the information contained in the theory in a uniform way. Introduced ten years ago, deduction modulo allows us to make use of the computational part of the theory Th for true computations modulo which deductions are performed. Focusing on the sequent calculus, this paper presents and studies the dual concept where the theory is used to enrich the deduction system with new deduction rules in a systematic, correct and complete way. We call such a new deduction system "superdeduction ". We introduce a proof-term language and a cut-elimination procedure both based on Christian Urban's work on classical sequent calculus. Strong normalisation is proven under appropriate and natural hypothesis, therefore ensuring the consistency of the embedded theory and of the deduction system. The proofs obtained in such a new system are much closer to the human intuition and practice. We consequently sketch how superdeduction along with deduction modulo can be used to ground the formal foundations of new extendible proof assistants like lemuridae, our prototypal implementation of superdeduction modulo.
[sequent calculus, proof-term language, natural deduction, cut-elimination procedure, Humans, Calculus, Mathematics, Security, calculus, predicate logic, Certification, superdeduction principles, formal logic, deduction modulo, Prototypes, dual concept, Libraries, Safety, theorem proving, Logic, Informatics]
Complete Sequent Calculi for Induction and Infinite Descent
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
This paper compares two different styles of reasoning with inductively defined predicates, each style being encapsulated by a corresponding sequent calculus proof system. The first system supports traditional proof by induction, with induction rules formulated as sequent rules for introducing inductively defined predicates on the left of sequents. We show this system to be cut-free complete with respect to a natural class of Henkin models; the eliminability of cut follows as a corollary. The second system uses infinite (non-well-founded) proofs to represent arguments by infinite descent. In this system, the left rules for inductively defined predicates are simple case-split rules, and an infinitary, global condition on proof trees is required to ensure soundness. We show this system to be cut-free complete with respect to standard models, and again infer the eliminability of cut. The second infinitary system is unsuitable for formal reasoning. However, it has a natural restriction to proofs given by regular trees, i.e. to those proofs representable by finite graphs. This restricted "cyclic" system subsumes the first system for proof by induction. We conjecture that the two systems are in fact equivalent, i.e., that proof by induction is equivalent to regular proof by infinite descent.
[induction rules, Henkin models, case-split rules, Educational institutions, Calculus, Mathematics, calculus, inference mechanisms, formal reasoning, induction-infinite descent sequent calculi, cyclic system, Computer science, Tree graphs, natural restriction, Constraint theory, Libraries, sequent calculus proof system, Logic, Informatics]
Highly Efficient Secrecy-Preserving Proofs of Correctness of Computations and Applications
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
We present a highly efficient method for proving correctness of computations while preserving secrecy of the input values. This is done in an Evaluator-Prover model which can also be realized by a secure processor. We describe an application to secure auctions.
[zero knowledge proofs, Protocols, Circuits, Nominations and elections, cryptography, highly efficient secrecy-preserving proofs, secure processor, Security, Galois fields, Computer science, Voting, Computer applications, evaluator-prover model, Cryptography, Logic]
A Complete Axiomatization of Knowledge and Cryptography
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
The combination of first-order epistemic logic with formal cryptography offers a potentially powerful framework for security protocol verification. In this paper, cryptography is modelled using private constants and one-way computable operations, as in the applied Pi-calculus. To give the concept of knowledge a computational justification, we propose a generalized Kripke semantics that uses permutations on the underlying domain of cryptographic messages to reflect agents' limited resources. This interpretation links the logic tightly to static equivalence, another important concept of knowledge that has recently been examined in the security protocol literature, and for which there are strong computational soundness results. We exhibit an axiomatization which is sound and complete relative to the underlying theory of terms, and to an omega-rule for quantifiers. Besides standard axioms and rules, the axiomatization includes novel axioms for the interaction between knowledge and cryptography. As protocol examples we use mixes, a Crowds-style protocol, and electronic payments. Furthermore, we provide embedding results for BAN and SVO.
[Multiagent systems, cryptographic protocols, formal cryptography, security protocol verification, Crowds-style protocol, Equations, Cryptographic protocols, Computer science, Body sensor networks, first-order epistemic logic, applied Pi-calculus, generalized Kripke semantics, knowledge complete axiomatization, Cryptography, Logic, Computer security, Observability, Testing]
Limits of Multi-Discounted Markov Decision Processes
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Markov decision processes (MDPs) are controllable discrete event systems with stochastic transitions. The payoff received by the controller can be evaluated in different ways, depending on the payoff function the MDP is equipped with. For example a mean-payoff function evaluates average performance, whereas a discounted payoff function gives more weights to earlier performance by means of a discount factor. Another well-known example is the parity payoff function which is used to encode logical specifications. Surprisingly, parity and mean-payoff MDPs share two non-trivial properties: they both have pure stationary optimal strategies and they both are approximable by discounted MDPs with multiple discount factors (multi- discounted MDPs). In this paper we unify and generalize these results. We introduce a new class of payoff functions called the priority weighted payoff functions, which are generalization of both parity and mean-payoff functions. We prove that priority weighted MDPs admit optimal strategies that are pure and stationary, and that the priority weighted value of an MDP is the limit of the multi-discounted value when discount factors tend to 0 simultaneously at various speeds.
[Process control, Stochastic processes, stochastic transitions, Control systems, payoff function, Convergence, Computer science, discrete event systems, multidiscounted Markov decision processes, Stochastic systems, Optimal control, Markov processes, Discrete event systems, Logic, stationary optimal strategies]
Game Relations and Metrics
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
We consider two-player games played over finite state spaces for an infinite number of rounds. At each state, the players simultaneously choose moves; the moves determine a successor state. It is often advantageous for players to choose probability distributions over moves, rather than single moves. Given a goal (e.g., "reach a target state"), the question of winning is thus a probabilistic one: "what is the maximal probability of winning from a given state?". On these game structures, two fundamental notions are those of equivalences and metrics. Given a set of winning conditions, two states are equivalent if the players can win the same games with the same probability from both states. Metrics provide a bound on the difference in the probabilities of winning across states, capturing a quantitative notion of state "similarity". We introduce equivalences and metrics for two-player game structures, and we show that they characterize the difference in probability of winning games whose goals are expressed in the quantitative mu-calculus. The quantitative mu- calculus can express a large set of goals, including reachability, safety, and omega-regular properties. Thus, we claim that our relations and metrics provide the canonical extensions to games, of the classical notion of bisimulation for transition systems. We develop our results both for equivalences and metrics, which generalize bisimulation, and for asymmetrical versions, which generalize simulation.
[Heart, finite state spaces, quantitative mu-calculus, probability, game theory, equivalences, Minimax techniques, Probability distribution, State-space methods, calculus, finite state machines, Cost accounting, Computer science, Stochastic systems, two-player games, Safety, metrics, Logic, Kernel]
Two-way unary temporal logic over trees
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
We consider a temporal logic EF + F-1 for unranked, unordered finite trees. The logic has two operators: EFphi , which says "in some proper descendant phi holds\
[unordered finite trees, trees (mathematics), temporal logic, forest algebra, Character recognition, tree searching, Logic testing, Algebra, two-way unary temporal logic, Automata, XML, Logic functions, Robustness, Page description languages, characterization, algorithm]
Alternation-free modal mu-calculus for data trees
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
An alternation-free modal mu-calculus over data trees is introduced and studied. A data tree is an unranked ordered tree whose every node is labelled by a letter from a finite alphabet and an element ("datum") from an infinite set. For expressing data-sensitive properties, the calculus is equipped with freeze quantification. A freeze quantifier stores in a register the datum labelling the current tree node, which can then be accessed for equality comparisons deeper in the formula. The main results in the paper are that, for the fragment with forward modal operators and one register, satisfiability over finite data trees is decidable but not primitive recursive, and that for the subfragment consisting of safety formulae, satisfiability over countable data trees is decidable but not elementary. The proofs use alternating tree automata which have registers, and establish correspondences with nondeterministic tree automata which have faulty counters. Allowing backward modal operators or two registers causes undecidability. As consequences, decidability is obtained for two data-sensitive fragments of the XPath query language. The paper shows that, for reasoning about data trees, the forward fragment of the calculus with one register is a powerful alternative to a recently proposed first-order logic with two variables.
[first-order logic, alternation-free modal mu-calculus, XPath query language, query languages, data trees, Calculus, calculus, alternating tree automata, Database languages, Counting circuits, Computer science, freeze quantifier, Automata, XML, Safety, tree data structures, Logic, Labeling, backward modal, data-sensitive properties, Formal verification]
A Contraction Method to Decide MSO Theories of Deterministic Trees
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
In this paper we generalize the contraction method, originally proposed by Elgot and Rabin and later extended by Carton and Thomas, from labeled linear orderings to colored deterministic trees. The method we propose rests on a suitable notion of indistinguishability of trees with respect to tree automata that allows us to reduce a number of instances of the acceptance problem for tree automata to decidable instances involving regular trees. We prove that such a method works effectively for a large class of trees, which is closed under noticeable operations and includes all the deterministic trees of the Caucal hierarchy obtained via unfoldings and inverse finite mappings as well as several trees outside such a hierarchy.
[Tree data structures, finite automata, trees (mathematics), Caucal hierarchy, contraction method, Specification languages, Cost accounting, decide MSO theories, labeled linear orderings, acceptance problem, deterministic automata, Automata, Vegetation mapping, Binary trees, inverse finite mappings, colored deterministic trees, tree automata, monadic second-order logic, Logic, Periodic structures]
First-Order and Temporal Logics for Nested Words
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Nested words are a structured model of execution paths in procedural programs, reflecting their call and return nesting structure. Finite nested words also capture the structure of parse trees and other tree-structured data, such as XML. We provide new temporal logics for finite and infinite nested words, which are natural extensions of LTL, and prove that these logics are first-order expressively- complete. One of them is based on adding a "within" modality, evaluating a formula on a subword, to a logic CaRet previously studied in the context of verifying properties of recursive state machines. The other logic is based on the notion of a summary path that combines the linear and nesting structures. For that logic, both model-checking and satisfiability are shown to be EXPTIME-complete. Finally, we prove that first-order logic over nested words has the three-variable property, and we present a temporal logic for nested words which is complete for the two- variable fragment of first-order.
[recursive state machines, model-checking, Navigation, parse trees, Inspection, temporal logic, Logic design, temporal logics, Computer science, nested words, Boolean functions, satisfiability, XML, Automata, first-order expressively- complete, tree data structures, tree-structured data]
A Robust Class of Context-Sensitive Languages
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
We define a new class of languages defined by multi-stack automata that forms a robust subclass of context-sensitive languages, with decidable emptiness and closure under boolean operations. This class, called multi-stack visibly pushdown languages (MVPLs), is defined using multi-stack pushdown automata with two restrictions: (a) the pushdown automaton is visible, i.e. the input letter determines the operation on the stacks, and (b) any computation of the machine can be split into k stages, where in each stage, there is at most one stack that is popped. MVPLs are an extension of visibly pushdown languages that captures noncontext free behaviors, and has applications in analyzing abstractions of multithreaded recursive programs, signifi- cantly enlarging the search space that can be explored for them. We show that MVPLs are closed under boolean operations, and problems such as emptiness and inclusion are decidable. We characterize MVPLs using monadic second-order logic over appropriate structures, and exhibit a Parikh theorem for them.
[Tree data structures, automata theory, boolean operations, recursive functions, multistack visibly pushdown languages, Application software, Computer science, Boolean functions, multithreaded recursive programs, SGML, Automata, XML, multistack pushdown automata, Robustness, monadic second-order logic, Logic, context-sensitive languages]
A New Efficient Simulation Equivalence Algorithm
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
It is well known that simulation equivalence is an appropriate abstraction to be used in model checking because it strongly preserves ACTL* and provides a better space reduction than bisimulation equivalence. However, computing simulation equivalence is harder than computing bisimulation equivalence. A number of algorithms for computing simulation equivalence exist. Let Sigma denote the state space, rarr the transition relation and P<sub>sim</sub> the partition of Sigma induced by simulation equivalence. The algorithms by Henzinger, Henzinger, Kopke and by Bloom and Paige run in O(|Sigma||rarr|)-time and, as far as time-complexity is concerned, they are the best available algorithms. However, these algorithms have the drawback of a quadratic space complexity that is bounded from below by Omega(|Sigma|2). The algorithm by Gentilini, Piazza, Policriti appears to be the best algorithm when both time and space complexities are taken into account. Gentilini et al.'s algorithm runs in O(|P<sub>sim</sub>|2|rarr|)-time while the space complexity is in O(|P<sub>sim</sub>|2 + |Sigma| log(|P<sub>sim</sub>|)). We present here a new efficient simulation equivalence algorithm that is obtained as a modification of Henzinger et al.'s algorithm and whose correctness is based on some techniques used in recent applications of abstract interpretation to model checking. Our algorithm runs in O(|P<sub>sim</sub>||rarr|)-time and O(|P<sub>sim</sub>||Sigma|)-space. Thus, while retaining a space complexity which is lower than quadratic, our algorithm improves the best known time bound.
[Algorithm design and analysis, Computational modeling, ACTL, state space, abstract interpretation, time-complexity, simulation equivalence algorithm, Partitioning algorithms, State-space methods, Specification languages, formal specification, Computer science, space reduction, formal verification, model checking, Concrete, bisimulation equivalence, Logic, Labeling, quadratic space complexity, Context modeling, computational complexity, state-space methods]
Infinite State AMC-Model Checking for Cryptographic Protocols
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Only very little is known about the automatic analysis of cryptographic protocols for game-theoretic security properties. In this paper, we therefore study decidability and complexity of the model checking problem for AMC-formulas over infinite state concurrent game structures induced by cryptographic protocols and the Dolev-Yao intruder. We show that the problem is NEXPTIME-complete when making reasonable assumptions about protocols and for an expressive fragment of AMC, which contains, for example, all properties formulated by Kremer and Raskin in fair ATL for contract-signing and non-repudiation protocols. We also prove that our assumptions on protocols are necessary to obtain decidability, unless other restrictions are imposed on protocols.
[cryptographic protocols, Communication system control, game theory, State-space methods, Security, Cryptographic protocols, infinite state AMC-model checking, contract-signing protocols, game-theoretic security properties, Authentication, Collaboration, Communication channels, Automatic control, Error correction, Communication networks, Dolev-Yao intruder]
Symmetric Datalog and Constraint Satisfaction Problems in Logspace
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
We introduce symmetric Datalog, a syntactic restriction of linear Datalog and show that its expressive power is exactly that of restricted symmetric Krom monotone SNP. The deep result of Reingold [17] on the complexity of undirected connectivity suffices to show that symmetric Datalog queries can be evaluated in logarithmic space. We show that for a number of constraint languages Gamma, the complement of the constraint satisfaction problem CSP(Gamma) can be expressed in symmetric Datalog. In particular, we show that if CSP(Gamma) is first-order definable and Lambda is a finite subset of the relational clone generated by Gamma then notCSP(Lambda) is definable in symmetric Datalog. Over the two-element domain and under standard complexity-theoretic assumptions, expressibility of notCSP(Gamma) in symmetric Datalog corresponds exactly to the class of CSPs computable in logarithmic space. Finally, we describe a fairly general subclass of implicational (or 0/1/all) constraints for which the complement of the corresponding CSP is also definable in symmetric Datalog. Our results provide preliminary evidence that symmetric Datalog may be a unifying explanation for families of CSPs lying in L.
[complexity-theoretic assumptions, constraint theory, Cloning, Graph theory, DATALOG, symmetric Datalog queries, two-element domain, Computer science, Constraint optimization, query processing, constraint satisfaction problems, Databases, Algebra, constraint languages, operations research, logarithmic space, Constraint theory, Polynomials, Logic, Artificial intelligence, computational complexity]
Quantified Equality Constraints
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
An equality template (also equality constraint language) is a relational structure with infinite universe whose relations can be defined by boolean combinations of equalities. We prove a complete complexity classification for quantified constraint satisfaction problems (QCSPs) over equality templates: these problems are in L (decidable in logarithmic space), NP-complete, or PSPACE-complete. To establish our classification theorem we combine methods from universal algebra with concepts from model theory.
[constraint theory, quantified equality constraints, PSPACE-complete, NP-complete, relational structure, Computer science, optimisation, constraint satisfaction problems, Algebra, logarithmic space, Constraint theory, complexity classification, Performance analysis, Logic, constraint handling]
Tractability and learnability arising from algebras with few subpowers
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
A k-edge operation phi on a finite set A is a k + 1-ary operation that satisfies the identities phi (x,x,y,...,y) ap phi(x,y,x,y,...,y) ap y, phi(y,y,y,x,y,...,y) ap phi(y,y,y,y,x,y,...,y) ap ... ap ... phi(y,y,y,...,y,x) ap y. We prove that any constraint language .. that, for some k &gt; 1, has a k-edge operation as a polymorphism is globally tractable. We also show that the set of relations definable over Gamma using quantified generalized formulas is polynomially exactly learnable using improper equivalence queries. Special instances of k-edge operations are Mal'cev and near-unanimity operations and so this class of constraint languages includes many well known examples.
[polynomials, finite set, Mathematics, Vectors, set theory, Statistics, Equations, Computer science, Algebra, k-edge operations, Gaussian processes, algebras, Polynomials, Logic, Informatics]
Examining The Fragments of G
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
When restricted to proving Sigma<sub>i</sub> q formulas, the quantified prepositional proof system G<sub>i</sub>* is closely related to the Sigma<sub>i</sub> b theorems of Buss's theory S<sub>2</sub> i. Namely, G<sub>i</sub>* has polynomial- size proofs of the translations of theorems of S<sub>2</sub> i, and S<sub>2</sub> i proves that G<sub>i</sub>* is sound. However, little is known about G* when proving more complex formulas. In this paper, we prove a witnessing theorem for G<sub>i</sub>* similar in style to the KPT witnessing theorem for T<sub>2</sub> i. This witnessing theorem is then used to show that S<sub>2</sub> i proves G* is sound with respect to prenex Sigma<sub>i+1</sub> q formulas. Note that unless the polynomial hierarchy collapses S<sub>2</sub> i is the weakest theory in the S<sub>2</sub> i hierarchy for which this is true. The witnessing theorem is also used to show that G<sub>1</sub>* is p-equivalent to a quantified version of extended-Frege. This is followed by a proof that Gi p-simulates G*<sub>i+1</sub>. We finish by proving that S<sub>2</sub> can be axiomatized by S<sub>2</sub> 1 plus axioms stating that the cut-free version of G* is sound. All together this shows that the connection between G<sub>i</sub>* and S<sub>2</sub> i does not extend to more complex formulas.
[Computer science, complex formulas, weakest theory, prepositional proof system, Polynomials, theorem proving, witnessing theorem, Logic, Buss theory, Computational complexity, extended-Frege, Arithmetic]
Separating DAG-Like and Tree-Like Proof Systems
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
We show that tree-like (Gentzen's calculus) PK where all cut formulas have depth at most a constant d does not simulate cut-free PK. Generally, we exhibit a family of sequents that have polynomial size cut-free proofs but requires superpolynomial tree-like proofs even when the cut rule is allowed on a class of cut-formulas that satisfies some plausible hardness assumption. This gives (in some cases, conditional) negative answers to several questions from a recent work of Maciel and Pitassi (LICS 2006). Our technique is inspired by the technique from Maciel and Pitassi. While the sequents used in earlier work are derived from the Pigeonhole principle, here we generalize Statman's sequents. This gives the desired separation, and at the same time provides stronger results in some cases.
[separating DAG-like systems, polynomial size cut-free proofs, Computational modeling, Computer simulation, polynomials, trees (mathematics), Pigeonhole principle, Search problems, Calculus, Topology, Computer science, tree-like PK, superpolynomial tree-like proofs, Polynomials, theorem proving, Decision trees, tree-like proof systems]
The Complexity of Proving the Discrete Jordan Curve Theorem
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
The Jordan Curve Theorem (JCT) states that a simple closed curve divides the plane into exactly two connected regions. We formalize and prove the theorem in the context of grid graphs, under different input settings, in theories of bounded arithmetic that correspond to small complexity classes. The theory V0 (corresponding to AC0(2)) proves that any set of edges that form disjoint cycles divides the grid into at least two regions. The theory V0 (corresponding to AC0) proves that any sequence of edges that form a simple closed curve divides the grid into exactly two regions. As a consequence, the Hex tautologies and the st-Connectivity tautologies have polynomial size AC0(2)-Frege-proofs, which improves results of Buss which only apply to the stronger proof system TC0-Frege.
[Vocabulary, grid graphs, proof systems, polynomials, st-connectivity tautologies, Circuits, graph theory, bounded arithmetic, Mathematics, polynomial size, Computer science, discrete Jordan curve theorem, Polynomials, theorem proving, Books, Arithmetic]
Reflections on Finite Model Theory
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Advances in finite model theory have appeared in LICS proceedings since the very beginning of the LICS Symposium. The goal of this paper is to reflect on finite model theory by highlighting some of its successes, examining obstacles that were encountered, and discussing some open problems that have stubbornly resisted solution.
[Vocabulary, Reflection, Computational complexity, Conference proceedings, database theory, Computer science, formal logic, Databases, computer science, finite model theory, Logic, Mathematical model, Books, computational complexity]
Locally Excluding a Minor
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
We introduce the concept of locally excluded minors. Graph classes locally excluding a minor are a common generalisation of the concept of excluded minor classes and of graph classes with bounded local tree-width. We show that first-order model-checking is fixed-parameter tractable on any class of graphs locally excluding a minor. This strictly generalises analogous results by Flum and Grohe on excluded minor classes and Frick and Grohe on classes with bounded local tree-width. As an important consequence of the proof we obtain fixed-parameter algorithms for problems such as dominating or independent set on graph classes excluding a minor, where now the parameter is the size of the dominating set and the excluded minor. We also study graph classes with excluded minors, where the minor may grow slowly with the size of the graphs and show that again, first-order model-checking is fixed-parameter tractable on any such class of graphs.
[bounded local tree-width, graph classes, Laboratories, trees (mathematics), locally excluded minors, fixed-parameter tractability, NP-complete problem, Computer science, Tree graphs, fixed-parameter algorithm, Polynomials, first order model checking, Logic, Testing, computational complexity]
Lindstrom theorems for fragments of first-order logic
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Lindstrom theorems characterize logics in terms of model-theoretic conditions such as Compactness and the Lowenheim-Skolem property. Most existing Lindstrom theorems concern extensions of first-order logic. On the other hand, many logics relevant to computer science are fragments or extensions of fragments of first-order logic, e.g., k-variable logics and various modal logics. Finding Lindstrom theorems for these languages can be challenging, as most known techniques rely on coding arguments that seem to require the full expressive power of first-order logic. In this paper, we provide Lindstrom characterizations for a number of fragments of first-order logic. These include the k-variable fragments for k &gt; 2, Tarski's relation algebra, graded modal logic, and the binary guarded fragment. We use two different proof techniques. One is a modification of the original Lindstrom proof. The other involves the modal concepts of bisimulation, tree unraveling, and finite depth. Our results also imply semantic preservation theorems. Characterizing the 2-variable fragment or the full guarded fragment remain open problems.
[Tarski relation algebra, first-order logic, tree unraveling, modal logic, finite depth concept, Lowenheim-Skolem property, Computer science, formal logic, k-variable logic, Algebra, bisimulation concept, computer science, Lindstrom theorem, Logic functions]
Environmental Bisimulations for Higher-Order Languages
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Developing a theory of bisimulation in higher-order languages can be hard. Particularly challenging can be: (1) the proof of congruence, as well as enhancements of the bisimulation proof method with "up-to context" techniques, and (2) obtaining definitions and results that scale to languages with different features. To meet these challenges, we present environmental bisimulations, a form of bisimulation for higher-order languages, and its basic theory. We consider four representative calculi: pure lambda-calculi (call-by-name and call-by-value), call-by-value lambda-calculus with higher-order store, and then higher-order pi-calculus. In each case: we present the basic properties of environmental bisimilarity, including congruence; we show that it coincides with contextual equivalence; we develop some up-to techniques, including up-to context, as examples of possible enhancements of the associated bisimulation method. Unlike previous approaches (such as applicative bisimulations, logical relations, Sumii-Pierce-Koutavas-Wand), our method does not require induction/indices on evaluation derivation/steps (which may complicate the proofs of congruence, transitivity, and the combination with up-to techniques), or sophisticated methods such as Howe's for proving congruence. It also scales from the pure lambda-calculi to the richer calculi with simple congruence proofs.
[pure lambda-calculi, high level languages, higher-order languages, higher-order pi-calculus, Proposals, Code standards, Computer science, pi calculus, environmental bisimulations, Impedance matching, up-to context techniques, contextual equivalence, bisimulation proof method, call-by-value lambda-calculus, Robustness, Concrete, Logic]
Pi-Calculus in Logical Form
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Abramsky's logical formulation of domain theory is extended to encompass the domain theoretic model for pi-calculus processes of Stark and of Fiore, Moggi and Sangiorgi. This is done by defining a logical counterpart of categorical constructions including dynamic name allocation and name exponentiation, and showing that they are dual to standard constructs in functor categories. We show that initial algebras of functors defined in terms of these constructs give rise to a logic that is sound, complete, and characterises bisimilarity. The approach is modular, and we apply it to derive a logical formulation of pi-calculus. The resulting logic is a modal calculus with primitives for input, free output and bound output.
[Art, functor algebras, pi-calculus, modal calculus, Calculus, Equations, Communication standards, Computer science, pi calculus, Algebra, Councils, Writing, Logic functions, Carbon capture and storage, domain theory]
Characterising Testing Preorders for Finite Probabilistic Processes
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
In 1992 Wang &amp; Larsen extended the may- and must preorders of De Nicola and Hennessy to processes featuring probabilistic as well as nondeterministic choice. They concluded with two problems that have remained open throughout the years, namely to find complete axiomatisations and alternative characterisations for these preorders. This paper solves both problems for finite processes with silent moves. It characterises the may preorder in terms of simulation, and the must preorder in terms of failure simulation. It also gives a characterisation of both preorders using a modal logic. Finally it axiomatises both preorders over a probabilistic version of CSP.
[Computer science, Australia Council, complete axiomatisations, failure simulation, Calculus, Logic, Informatics, statistical testing, testing preorders, finite probabilistic processes, silent moves, Testing]
Higher-Order Matching, Games and Automata
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Higher-order matching is the problem given t = u where t, u are terms of simply typed lambda-calculus and u is closed, is there a substitution thetas such that tthetas and u have the same normal form with respect to betaeta-equality: can t be pattern matched to u? This paper considers the question: can we characterize the set of all solution terms to a matching problem? We provide an automata-theoretic account that is relative to resource: given a matching problem and a finite set of variables and constants, the (possibly infinite) set of terms that are built from those components and that solve the problem is regular. The characterization uses standard bottom-up tree automata.
[lambda calculus, automata theory, Encoding, lambda-calculus, Interpolation, standard bottom-up tree automata, higher-order matching, Automata, games, Logic, automata, Informatics, Pattern matching]
Bialgebraic Operational Semantics and Modal Logic
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
A novel, general approach is proposed to proving the compositionality of process equivalences on languages defined by structural operational semantics (SOS). The approach, based on modal logic, is inspired by the simple observation that if the set of formulas satisfied by a process can be derived from the corresponding sets for its subprocesses, then the logical equivalence is a congruence. Striving for generality, SOS rules are modeled categorically as bialgebraic distributive laws for some notions of process syntax and behaviour, and modal logics are modeled via coalgebraic polyadic modal logic. Compositionality is proved by providing a suitable notion of behaviour for the logic together with a dual distributive law, reflecting the one modeling the SOS specification. Concretely, the dual laws may appear as SOS-like rules where logical formulas play the role of processes, and their behaviour models logical decomposition over process syntax. The approach can be used either to proving compositionality for specific languages or for defining SOS congruence formats.
[programming language semantics, Power system modeling, logical equivalence, Computer science, Computer languages, Algebra, bialgebraic operational semantics, process algebra, structural operational semantics, Logic functions, process equivalences compositionality, coalgebraic polyadic modal logic, Joining processes, Testing, Context modeling]
Relational Parametricity for Computational Effects
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
According to Strachey, a polymorphic program is parametric if it applies a uniform algorithm independently of the type instantiations at which it is applied. The notion of relational parametricity, introduced by Reynolds, is one possible mathematical formulation of this idea. Relational parametricity provides a powerful tool for establishing data abstraction properties, proving equivalences of datatypes, and establishing equalities of programs. Such properties have been well studied in a pure functional setting. Many programs, however, exhibit computational effects. In this paper, we develop a framework for extending the notion of relational parametricity to languages with effects.
[Computer science, Technological innovation, relational algebra, relational parametricity, Reynolds, polymorphic program, data abstraction properties, Calculus, Encoding, data structures, Logic, Informatics]
Static Name Control for FreshML
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
FreshML extends ML with constructs for declaring and manipulating abstract syntax trees that involve names and statically scoped binders. It is impure: name generation is an observable side effect. In practice, this means that FreshML allows writing programs that create fresh names and unintentionally fail to bind them. Following in the steps of early work by Pitts and Gabbay, this paper defines Pure FreshML, a subset of FreshML equipped with a static proof system that guarantees purity. Pure FreshML relies on a rich binding specification language, on user-provided assertions, expressed in a logic that allows reasoning about values and about the names that they contain, and on a conservative, automatic decision procedure for this logic. It is argued that pure FreshML can express non-trivial syntax-manipulating algorithms.
[page description languages, Pure FreshML, Costs, Logic programming, computational linguistics, Automatic logic units, Specification languages, name generation, abstract syntax trees, specification languages, Writing, Pattern matching, specification language]
Local Action and Abstract Separation Logic
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Separation logic is an extension of Hoare's logic which supports a local way of reasoning about programs that mutate memory. We present a study of the semantic structures lying behind the logic. The core idea is of a local action, a state transformer that mutates the state in a local way. We formulate local actions for a class of models called separation algebras, abstracting from the RAM and other specific concrete models used in work on separation logic. Local actions provide a semantics for a generalized form of (sequential) separation logic. We also show that our conditions on local actions allow a general soundness proof for a separation logic for concurrency, interpreted over arbitrary separation algebras.
[abstract separation logic, Logic programming, Random access memory, separation algebras, Read-write memory, Transformer cores, Educational institutions, Reasoning about programs, state transformer, programming language semantics, Concurrent computing, Algebra, process algebra, Logic functions, Concrete, semantic structures]
Categorical Combinatorics for Innocent Strategies
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
We show how to construct the category of games and innocent strategies from a more primitive category of games. On that category we define a comonad and monad with the former distributing over the latter. Innocent strategies are the maps in the induced two-sided Kleisli category. Thus the problematic composition of innocent strategies reflects the use of the distributive law. The composition of simple strategies, and the combinatorics of pointers used to give the comonad and monad are themselves described in categorical terms. The notions of view and of legal play arise naturally in the explanation of the distributivity. The category-theoretic perspective provides a clear discipline for the necessary combinatorics.
[Law, combinatorial mathematics, game primitive category, game theory, Collision mitigation, two-sided Kleisli category, Combinatorial mathematics, Game theory, Stress, Computer science, categorical combinatorics, Logic, innocent strategies, Legal factors]
Resource modalities in game semantics
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
The description of resources in game semantics has never achieved the simplicity and precision of linear logic, because of a misleading conception: the belief that linear logic is more primitive than game semantics. We advocate the contrary here: that game semantics is conceptually more primitive than linear logic. Starting from this revised point of view, we design a categorical model of resources in game semantics, and construct an arena game model where the usual notion of bracketing is extended to multi-bracketing in order to capture various resource policies: linear, affine and exponential.
[Logic programming, Switches, game theory, Logic design, game semantics, formal logic, Computer languages, Tensile stress, resource allocation, Propulsion, linear logic precision, arena game model, resource modalities, multi-bracketing]
Full abstraction for nominal general references
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Game semantics has been used with considerable success in formulating fully abstract semantics for languages with higher-order procedures and a wide range of computational effects. Recently, nominal games have been proposed for modeling functional languages with names. These are ordinary games cast in the theory of nominal sets developed by Pitts and Gabbay. Here we take nominal games one step further, by developing a fully abstract semantics for a language with nominal general references.
[nominal general references, Object oriented modeling, Laboratories, higher-order languages, Interference, game theory, Calculus, programming language semantics, game semantics, functional language modelling, Game theory, Computer languages, Differential equations, Logic, nominal games, Object oriented programming, abstract semantics, Testing, functional languages]
Stratified Bounded Affine Logic for Logarithmic Space
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
A number of complexity classes, most notably PTIME, have been characterised by sub-systems of linear logic. In this paper we show that the functions computable in logarithmic space can also be characterised by a restricted version of linear logic. We introduce stratified bounded affine logic (SBAL), a restricted version of bounded linear logic, in which not only the modality, but also the universal quantifier is bounded by a resource polynomial. We show that the proofs of certain sequents in SBAL represent exactly the functions computable logarithmic space. The proof that SBAL-proofs can be compiled to LOGSPACE functions rests on modelling computation by interaction dialogues in the style of game semantics. We formulate the compilation of SBAL-proofs to space-efficient programs as an interpretation in a realisability model, in which realisers are taken from a geometry of interaction situation.
[Solid modeling, interaction dialogues, complexity classes, Computational modeling, polynomials, resource polynomial, LOGSPACE functions, Encoding, Geometry, universal quantifier, bounded linear logic, stratified bounded affine logic, logarithmic space, logic programming, geometry of interaction situation, Polynomials, Logic, Functional programming, computational complexity]
Light Logics and Optimal Reduction: Completeness and Complexity
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Typing of lambda-terms in elementary and light affine logic (EAL , LAL resp.) has been studied for two different reasons: on the one hand the evaluation of typed terms using LAL (EAL resp.) proof-nets admits a guaranteed polynomial (elementary, resp.) bound; on the other hand these terms can also be evaluated by optimal reduction using the abstract version of Lamping's algorithm. The first reduction is global while the second one is local and asynchronous. We prove that for LAL (EAL resp.) typed terms, Lamping's abstract algorithm also admits a polynomial (elementary, resp.) bound. We also show its soundness and completeness (for EAL and LAL with type fixpoints), by using a simple geometry of interaction model (context semantics).
[Lamping abstract algorithm, Solid modeling, lambda calculus, complexity, light affine logic, Switches, interaction model, Machinery, Geometry, Computer science, elementary affine logic, Polynomials, Concrete, geometry, optimal reduction, Logic, polynomial bound, Fellows, lambda-terms, Context modeling, computational complexity, context semantics]
Modified Realizability Interpretation of Classical Linear Logic
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
This paper presents a modified realizability interpretation of classical linear logic. The interpretation is based on work of de Paiva (1989), Blass (1995), and Shirahata (2006) on categorical models of classical linear logic using Godel's Dialectica interpretation. Whereas the Dialectica categories provide models of linear logic, our interpretation is presented as an endo-interpretation of proofs, which does not leave the realm of classical linear logic. The advantage is that we obtain stronger versions of the disjunction and existence properties, and new conservation results for certain choice principles. Of particular interest is the simple branching quantifier used in order to obtain a completeness result for the modified realizability interpretation.
[Computer science, formal logic, classical linear logic, branching quantifier, modified realizability interpretation, Logic]
Infinite sets that admit fast exhaustive search
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
Perhaps surprisingly, there are infinite sets that admit mechanical exhaustive search in finite time. We investigate three related questions: What kinds of infinite sets admit mechanical exhaustive search in finite time? How do we systematically build such sets? How fast can exhaustive search over infinite sets be performed?
[Computer science, topology., PCF, fast exhaustive search, infinite sets, Kleene-Kreisel functionals, Higher-type computability and complexity, Haskell, Topology, set theory, search problems, Accidents]
On Noetherian Spaces
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
A topological space is Noetherian iff every open is compact. Our starting point is that this notion generalizes that of well-quasi order, in the sense that an Alexandroff-discrete space is Noetherian iff its specialization quasi-ordering is well. For more general spaces, this opens the way to verifying infinite transition systems based on non-well quasi ordered sets, but where the preimage operator satisfies an additional continuity assumption. The technical development rests heavily on techniques arising from topology and domain theory, including sobriety and the de Groot dual of a stably compact space. We show that the category Nthr of Noetherian spaces is finitely complete and finitely cocomplete. Finally, we note that if X is a Noetherian space, then the set of all (even infinite) subsets of X is again Noetherian, a result that fails for well-quasi orders.
[preimage operator, Instruments, infinite transition systems, Noetherian topological spaces, quasiordered sets, Alexandroff-discrete space, Topology, set theory]
A computable approach to measure and integration theory
22nd Annual IEEE Symposium on Logic in Computer Science
None
2007
We introduce a computable framework for Lebesgue's measure and integration theory in the spirit of domain theory. For an effectively given locally compact second countable Hausdorff space and an effectively given locally finite Borel measure on the space, we define the notion of a computable measurable set with respect to the given measure, which is stronger than Sanin's recursive measurable set. The set of computable measurable subsets is closed under complementation, finite unions and finite intersections. We then introduce interval-valued measurable functions and develop the notion of computable measurable functions using interval-valued simple functions. This leads us to the interval versions of the main results of the theory of Lebesgue integration which provide a computable framework for measure and integration theory. The Lebesgue integral of a computable integrable function with respect to an effectively given (sigma-)finite Borel measure on an effectively given (locally) compact second countable Hausdorff space can be computed up to any required accuracy. We show that, with respect to the metric induced from the L1 norm, the set of Scott continuous interval-valued functions is dense in the set of interval-valued integrable functions.
[locally finite Borel measure, computable measurable set, interval-valued, computability, Extraterrestrial measurements, Educational institutions, set theory, Application software, Lebesgue integration theory, data type, Computer science, Measurement units, Upper bound, locally compact second countable Hausdorff space, Scott continuous interval-valued function, Stochastic systems, measurable function, interval-valued Lebesgue integral., Markov processes, integration, Particle measurements, Logic, Domain theory, domain theory]
Foreword
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Presents the introductory welcome message from the conference proceedings.
[Computer science, Meetings, Conference management, Logic, Computer security, Testing]
Committee Lists
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Provides a listing of current committee members.
[]
Cryptographically-Sound Protocol-Model Abstractions
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We present a formal theory for cryptographically-sound theorem proving. Our starting point is the Backes-Pfitzmann-Waidner (BPW) model, which is a symbolic protocol model that is cryptographically sound in the sense of blackbox reactive simulatability. To achieve cryptographic soundness, this model is substantially more complex than standard symbolic models and the main challenge in formalizing and using this model is overcoming this complexity. We present a series of cryptographically-sound abstractions of the original BPW model that bring it much closer to standard Dolev-Yao style models. We present a case study showing that our abstractions enable proofs of complexity comparable to those based on more standard models. Our entire development has been formalized in Isabelle/HOL.
[cryptographic protocols, HOL, cryptographically-sound protocol-model, simulatability, symbolic protocol model, State-space methods, cryptographically-sound theorem proving, Equations, Dolev-Yao style models, Cryptographic protocols, Computer science, formal logic, cryptographic soundness, formal theory, Information security, Isabelle, formal methods, Concrete, Libraries, theorem proving, Cryptography, Logic, Pattern matching, Backes-Pfitzmann-Waidner model]
On the Expressiveness and Complexity of Randomization in Finite State Monitors
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
The continuous run-time monitoring of the behavior of a system is a technique that is used both as a complementary approach to formal verification and testing to ensure reliability, as well as a means to discover emergent properties in a distributed system, like intrusion and event correlation. The monitors in all these scenarios can be abstractly viewed as automata that process a (unbounded) stream of events to and from the component being observed, and raise an ``alarm'' when an error or intrusion is discovered. These monitors indicate the absence of error or intrusion in a behavior implicitly by the absence of an alarm.In this paper we study the power of randomization in run-time monitoring. Specifically, we examine finite memory monitoring algorithms that toss coins to make decisions on the behavior they are observing. We give a number of results that characterize, topologically as well as with respect to their computational power, the sets of sequences the monitors permit. We also present results on the complexity of deciding non-emptiness of the set of sequences permitted by a monitor.
[program testing, software reliability, distributed system, intrusion detection, finite state machines, Logic testing, Condition monitoring, Runtime, decidability, formal verification, event correlation, run-time monitoring, randomization, Robustness, Safety, formal languages, Computerized monitoring, finite memory monitoring algorithm, probability, finite state automata, Computer science, Computer displays, Automata, Hidden Markov models, system monitoring, computational complexity, formal language]
Combining Generic Judgments with Recursive Definitions
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Many semantical aspects of programming languages, such as their operational semantics and their type assignment calculi, are specified by describing appropriate proof systems. Recent research has identified two proof-theoretic features that allow direct, logic-based reasoning about such descriptions: the treatment of atomic judgments as fixed points (recursive definitions) and an encoding of binding constructs via generic judgments. However, the logics encompassing these two features have thus far treated them orthogonally: that is, they do not provide the ability to define object-logic properties that themselves depend on an intrinsic treatment of binding. We propose a new and simple integration of these features within an intuitionistic logic enhanced with induction over natural numbers and we show that the resulting logic is consistent. The pivotal benefit of the integration is that it allows recursive definitions to not just encode simple, traditional forms of atomic judgments but also to capture generic properties pertaining to such judgments. The usefulness of this logic is illustrated by showing how it can provide elegant treatments of object-logic contexts that appear in proofs involving typing calculi and of arbitrarily cascading substitutions that play a role in reducibility arguments.
[generic judgment, natural numbers, logic-based reasoning, proof systems, operational semantics, Switches, intuitionistic logic, proof search, type theory, atomic judgments, higher-order abstract syntax, cascading substitution, programming language, theorem proving, Carbon capture and storage, type assignment calculus, generic judgments, Logic programming, Encoding, recursive functions, programming language semantics, reasoning about operational semantics, Equations, recursive definition, Computer science, Computer languages, Animation, object-logic properties, reducibility argument, number theory]
Mechanizing the Metatheory of LF
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
LF is a dependent type theory in which many other formal systems can be conveniently embedded. However, correct use of LF relies on nontrivial metatheoretic developments such as proofs of correctness of decision procedures for LF's judgments. Although detailed informal proofs of these properties have been published, they have not been formally verified in a theorem prover. We have formalized these properties within Isabelle/HOL using the nominal datatype package, closely following a recent article by Harper and Pfenning. In the process, we identified and resolved a gap in one of the proofs and a small number of minor lacunae in others. Besides its intrinsic interest, our formalization provides a foundation for studying the adequacy of LF encodings, the correctness of Twelf-style metatheoretic reasoning, and the metatheory of extensions to LF.
[Inspection, logical frameworks, Encoding, nominal datatype package, Computer science, formal logic, theorem prover, nominal logic, Packaging, Writing, theorem proving, Logic, learning (artificial intelligence), logical framework, metatheoretic reasoning, mechanized metatheory]
Second-Order and Dependently-Sorted Abstract Syntax
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
The paper develops a mathematical theory in the spirit of categorical algebra that provides a model theory for second-order and dependently-sorted syntax. The theory embodies notions such as alpha-equivalence, variable binding, capture-avoiding simultaneous substitution, term metavariable, meta-substitution, mono and multi sorting, and sort dependency. As a matter of illustration, a model is used to extract a second-order syntactic theory, which is thus guaranteed to be correct by construction.
[substitution, Laboratories, computational linguistics, second-order abstract syntax, variable binding, abstract syntax, alpha-equivalence, Algebra, sorting, Logic functions, metavariable, Mathematical model, second-order syntax, meta-substitution, model theory, dependently-sorted abstract syntax, mathematical theory, second-order syntactic theory, categorical algebra, MONOS devices, Sorting, Computer science, dependently-sorted syntax, process algebra, category theory]
Structural Logical Relations
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Tait's method (a.k.a. proof by logical relations) is a powerful proof technique frequently used for showing foundational properties of languages based on typed lambda-calculi. Historically, these proofs have been extremely difficult to formalize in proof assistants with weak meta-logics, such as Twelf, and yet they are often straightforward in proof assistants with stronger meta-logics. In this paper, we propose structural logical relations as a technique for conducting these proofs in systems with limited meta-logical strength by explicitly representing and reasoning about an auxiliary logic. In support of our claims, we give a Twelf-checked proof of the completeness of an algorithm for checking equality of simply typed lambda-terms.
[lambda calculus, proof assistants, meta-logics, typed lambda-calculi, Turning, Encoding, Twelf, inference mechanisms, structural logical relations, auxiliary logic, Logical Relations, Computer science, USA Councils, Logical Frameworks, Twelf-checked proof, Normalization, Logic, Cut-Elimination]
Types for Hereditary Permutators
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
This paper answers the open problem of finding a type system that characterizes hereditary permutators. First this paper shows that there does not exist such a type system by showing that the set of hereditary permutators is not recursively enumerable. The set of positive primitive recursive functions is used to prove it. Secondly this paper gives a best-possible solution by providing a countably infinite set of types such that a term has every type in the set if and only if the term is a hereditary permutator. By the same technique for the first claim, this paper also shows that a set of normalizing terms in infinite lambda-calculus is not recursively enumerable if it contains some term having a computable infinite path,and shows the set of streams is not recursively enumerable.
[lambda calculus, hereditary permutator, Calculus, recursive functions, type theory, set theory, Computer science, positive primitive recursive function, stream type, type system, infinite lambda-calculus, Logic, intersection type, Informatics]
Context Matching for Compressed Terms
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
This paper is an investigation of the matching problem for term equations s = t where s contains context variables and first-order variables, and both terms s and t are given using some kind of compressed representation. The main result is a polynomial time algorithm for context matching with dags, when the number of different context variables is fixed for the problem. NP-completeness is obtained when the terms are represented using the more general formalism of singleton tree grammars. As an ingredient of this proof, we also show that the special case of first-order matching with singleton tree grammars is decidable in polynomial time.
[Logic programming, context matching, Information retrieval, Large scale integration, tree compression, singleton tree grammars, unification, polynomial time algorithm, Equations, matching, Computer science, Program processors, context variables, first-order variables, matching problem, NP-completeness, context-free grammars, Polynomials, Computational linguistics, compressed representation, Deductive databases, Artificial intelligence, computational complexity]
Nonlocal Flow of Control and Kleene Algebra with Tests
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Kleene algebra with tests (KAT) is an equational system for program verification that combines Kleene algebra (KA), or the algebra of regular expressions, with Boolean algebra. It can model basic programming and verification constructs such as conditional tests, while loops, and Hoare triples, thus providing a relatively simple equational approach to program equivalence and partial correctness. In this paper we show how KAT can be used to give a rigorous equational treatment of control constructs involving nonlocal transfer of control such as unconditional jumps, loop statements with multi-level breaks, and exception handlers. We develop a compositional semantics and a complete equational axiomatization. The approach has some novel technical features, including a treatment of multi-level break statements that is reminiscent of de Bruijn indices in the variable-free lambda calculus. We illustrate the use of the system by giving a purely calculational proof that every deterministic flowchart is equivalent to a loop program with multi-level breaks.
[program loop statement, System testing, program testing, program verification, equational system, Kleene algebra, Calculus, deterministic flowchart, Kleene algebra with tests, regular expression, Logic testing, Flowcharts, program restructuring, control flow, equational axiomatization, lambda calculus, program control structures, formal languages, nonlocal control flow, Logic programming, Boolean algebra, programming language semantics, Equations, Computer science, Automatic testing, program equivalence, Automata, flowcharting, compositional semantics, Hoare triples]
An Algebraic Process Calculus
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We present an extension of the piI-calculus with formal sums of terms. A study of the properties of this sum reveals that its neutral element can be used to make assumptions about the behaviour of the environment of a process. Furthermore, the formal sum appears as a fundamental construct that can be used to decompose both internal and external choice. From these observations, we derive an enriched calculus that enjoys a confluent reduction which preserves the testing semantics of processes. This system is shown to be strongly normalising for terms without replication, and the study of its normal forms provides fully abstract trace semantics for testing of piI processes.
[System testing, Acoustic testing, pi-I-calculus, Computational modeling, pi-calculus, trace semantics, full abstraction, Calculus, fully abstract trace semantics, algebraic process calculus, Equations, Computer science, Concurrent computing, pi calculus, normalisation, process algebra, Linearity, Logic functions, testing semantics of processes, testing semantics, formal sum, Context modeling]
On the Expressiveness and Decidability of Higher-Order Process Calculi
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
In higher-order process calculi the values exchanged in communications may contain processes. A core calculus of higher-order concurrency is studied; it has only the operators necessary to express higher-order communications: input prefix, process output, and parallel composition. By exhibiting a nearly deterministic encoding of Minsky machines, the calculus is shown to be Turing complete and therefore its termination problem is undecidable. Strong bisimilarity, however, is shown to be decidable. Further, the main forms of strong bisimilarity for higher-order processes (higher-order bisimilarity, context bisimilarity, normal bisimilarity, barbed congruence) coincide. They also coincide with their asynchronous versions. A sound and complete axiomatization of bisimilarity is given. Finally, bisimilarity is shown to become undecidable if at least four static (i.e., top-level) restrictions are added to the calculus.
[Calculus, Proposals, calculus, Turing calculus, Counting circuits, behavioral equivalences, Concurrent computing, Turing machines, context bisimilarity, normal bisimilarity, decidability, parallel composition, expressiveness, Carbon capture and storage, Logic, process calculi, higher-order process calculi, Testing, Commutation, higher-order concurrency, higher-order languages, concurrency theory, Encoding, Computer science, barbed congruence, higher-order bisimilarity, Minsky machines]
On the Axiomatizability of Impossible Futures: Preorder versus Equivalence
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We investigate the (in)equational theory of impossible futures semantics over the process algebra BCCSP. We prove that no finite, sound axiomatization for BCCSP modulo impossible futures equivalence is ground-complete. By contrast, we present a finite, sound, ground-complete axiomatization for BCCSP modulo impossible futures preorder. If the alphabet of actions is infinite, then this axiomatization is shown to be omega-complete. If the alphabet is finite, we prove that the in equational theory of BCCSP modulo impossible futures preorder lacks such a finite basis. We also derive non-finite axiomatizability results for nested impossible futures semantics.
[Computational modeling, inequational theory, Equations, Computer science, Concurrent computing, Algebra, process algebra, process algebra BCCSP, System recovery, Logic functions, Concrete, Carbon capture and storage, Testing]
General Structural Operational Semantics through Categorical Logic
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Certain principles are fundamental to operational semantics, regardless of the languages or idioms involved. Such principles include rule-based definitions and proof techniques for congruence results. We formulate these principles in the general context of categorical logic. From this general formulation we recover precise results for particular language idioms by interpreting the logic in particular categories. For instance, results for first-order calculi, such as CCS, arise from considering the general results in the category of sets. Results for languages involving substitution and name generation, such as the pi-calculus, arise from considering the general results in categories of sheaves and group actions. As an extended example, we develop a tyft/tyxt-like rule format for open bisimulation in the pi-calculus.
[open bisimulation, Pulleys, Laboratories, Natural languages, pi-calculus, proof techniques, programming language semantics, Machinery, language idioms, Computer science, pi calculus, Computer languages, CCS, Algebra, rule-based definitions, structural operational semantics, first-order calculi, Concrete, bisimulation equivalence, Logic, Carbon capture and storage, categorical logic, tyft/tyxt-like rule format]
Parameterization as Abstraction: A Tractable Approach to the Dataflow Analysis of Concurrent Programs
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Dataflow analysis for concurrent programs is a problem of critical importance but, unfortunately, also an undecidable one. A key obstacle is to determine precisely how dataflow facts at a location in a given thread could be affected by operations of other threads.This problem, in turn, boils down to pairwise reachability, i.e., given program locations c<sub>1</sub> and c<sub>2</sub> in two threads T<sub>1</sub> and T<sub>2</sub>, respectively, determining whether c1 and c2 are simultaneously reachable in the presence of constraints imposed by synchronization primitives. Unfortunately, pairwise reachability is undecidable for most synchronization primitives. However, we leverage the surprising result that the closely related problem of parameterized pairwise reachability of c<sub>1</sub> and c<sub>2</sub>, i.e., whether for some n<sub>1</sub> and n<sub>2</sub>, c<sub>1</sub> and c<sub>2</sub> are simultaneously reachable in the program T<sub>1</sub> n<sub>1||</sub>T<sub>2</sub> n<sub>2</sub> comprised of n<sub>1</sub> copies of T<sub>1</sub> and n<sub>2</sub> copies of T<sub>2</sub>,is not only decidable for many primitives, but efficiently so. Although parameterization makes pairwise reachability tractable it may over-approximate the set of pairwise reachable locations and can, therefore, be looked upon as an abstraction technique.Where as abstract interpretation is used for control and data abstractions, we propose the use of parameterization as an abstraction for concurrency. Leveraging abstract interpretation in conjunction with parameterization allows us to lift two desirable properties of sequential dataflow analysis to the concurrent domain, i.e., precision and scalability.
[Dataflow Analysis, Scalability, Switches, concurrent programs, Yarn, Concurrent computing, Model Checking, decidability, USA Councils, National electric code, data abstractions, Logic, synchronization primitives, Data analysis, reachability analysis, dataflow analysis, Pushdown Systems, multi-threading, abstract interpretation, pairwise reachability, data flow analysis, concurrency theory, synchronisation, Computer science, Parameterized Systems, concurrency control, Interleaved codes, Concurrent Programs]
Winning Regions of Higher-Order Pushdown Games
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
In this paper we consider parity games defined by higher-order pushdown automata. These automata generalise pushdown automata by the use of higher-order stacks, which are nested "stack of stacks" structures. Representing higher-order stacks as well-bracketed words in the usual way, we show that the winning regions of these games are regular sets of words. Moreover a finite automaton recognising this region can be effectively computed. A novelty of our work are abstract pushdown processes which can be seen as (ordinary) pushdown automata but with an infinite stack alphabet. We use the device to give a uniform presentation of our results.From our main result on winning regions of parity games we derive a solution to the Modal Mu-Calculus Global Model-Checking Problem for higher-order pushdown graphs as well as for ranked trees generated by higher-order safe recursion schemes.
[Laboratories, higher-order pushdown game, pushdown automata, infinite stack alphabet, higher-order stack structure, Tree graphs, formal verification, higher-order pushdown automata, Polynomials, winning region, Logic, higher-order pushdown graph, modal mu-calculus global model-checking problem, formal languages, higher-order recursion schemes, trees (mathematics), game theory, recursive functions, finite automaton, Computer science, parity game, process algebra, Automata, ranked tree, abstract pushdown process, safe recursion scheme, mu-calculus model-checking, parity games]
The Ordinal Recursive Complexity of Lossy Channel Systems
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We show that reachability and termination for lossy channel systems is exactly at level F<sub>omega</sub>omega in the fast-growing hierarchy of recursive functions, the first level that dominates all multiply-recursive functions.
[complexity, telecommunication channels, Computational modeling, Size measurement, recursive functions, ordinal recursive complexity, Computer science, Upper bound, lossy channel systems, Automata, Robustness, Fast-Growing Hierarchy, Logic, Size control]
Almost-Sure Model Checking of Infinite Paths in One-Clock Timed Automata
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
In this paper, we define two relaxed semantics (one based on probabilities and the other one based on the topological notion of largeness) for LTL over infinite runs of timed automata which rule out unlikely sequences of events. We prove that these two semantics match in the framework of single-clock timed automata (and only in that framework), and prove that the corresponding relaxed model-checking problems are PSPACE-Complete. Moreover, we prove that the probabilistic non-Zenoness can be decided for single-clocktimed automata in NLOGSPACE.
[Real time systems, automata theory, one-clock timed automata, single-clock timed automata, infinite paths, Topology, almost-sure model checking, Delay, NLOGSPACE, Computer science, clocks, Automata, Robustness, Polynomials, Mathematical model, Logic, Clocks]
From Axioms to Analytic Rules in Nonclassical Logics
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We introduce a systematic procedure to transform large classes of (Hilbert) axioms into equivalent inference rules in sequent and hypersequent calculi. This allows for the automated generation of analytic calculi for a wide range of prepositional nonclassical logics including intermediate, fuzzy and substructural logics. Our work encompasses many existing results, allows for the definition of new calculi and contains a uniform semantic proof of cut-elimination for hypersequent calculi.
[Availability, prepositional nonclassical logic, axiom scheme, nonclassical logics, fuzzy logic, Calculus, Explosions, hypersequent calculi, sequent calculi, inference mechanisms, uniform semantic proof, Fuzzy logic, Computer science, semantic cut-elimination, process algebra, intermediate logic, equivalent inference rule, substructural logic, Informatics]
Focusing on Binding and Computation
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Variable binding is a prevalent feature of the syntax and proof theory of many logical systems. In this paper, we define a programming language that provides intrinsic support for both representing and computing with binding. This language is extracted as the Curry-Howard interpretation of a focused sequent calculus with two kinds of implication, of opposite polarity. The representational arrow extends systems of definitional reflection with a notion of scoped inference rules, which are used to represent binding. On the other hand, the usual computational arrow classifies recursive functions defined by pattern-matching. Unlike many previous approaches, both kinds of implication are connectives in a single logic, which serves as a rich logical framework capable of representing inference rules that mix binding and computation.
[sequent calculus, pattern matching, computational linguistics, logical systems, binding, Calculus, variable binding, programming languages, Databases, Curry-Howard interpretation, programming language, theorem proving, Functional programming, Pattern analysis, polarity, Embedded computing, inference rules, Logic programming, focused sequent calculus, logical frameworks, Reflection, recursive functions, proof theory, computation, Computer science, Computer languages, process algebra, syntax, Pattern matching]
A First-Order Representation of Pure Type Systems Using Superdeduction
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Superdeduction is a formalism closely related to deduction modulo which permits to enrich a deduction system - especially a first-order one such as natural deduction or sequent calculus - with new inference rules automatically computed from the presentation of a theory. We give a natural encoding from every functional pure type system (PTS) into superdeduction by defining an appropriate first-order theory. We prove that this translation is correct and conservative, showing a correspondence between valid typing judgments in the PTS and provable sequents in the corresponding superdeductive system. As a byproduct, we also introduce the superdeductive sequent calculus for intuitionistic logic, which was until now only defined for classical logic. We show its equivalence with the superdeductive natural deduction. This implies that superdeduction can be easily used as a logical framework. These results lead to a better understanding of the implementation and the automation of proof search for PTS, as well as to more cooperation between proof assistants.
[superdeductive system, first-order logic, Automatic logic units, intuitionistic logic, Calculus, type theory, superdeductive sequent calculus, deduction modulo, natural deduction vs. sequent calculus, theorem proving, superdeductive natural deduction, proof assistant, classical logic, lambda-calculus with explicit substitutions, lambda calculus, Automation, Computational modeling, first-order representation theory, logical frameworks, Encoding, inference mechanisms, superdeduction formalism, functional pure type system, Computer science, inference rule]
The Quest for a Logic Capturing PTIME
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
The question of whether there is a logic that captures polynomial time is the central open problem in descriptive complexity theory. In my talk, I will review the question and the early, mostly negative results that were obtained until the mid 1990s, and then move on to positive results about capturing polynomial time on specific classes of graphs. This will include recent results on definability in fixed-point logic and graph structure theory. Finally, I will dicuss stronger logics and propose directions for further research.The purpose of this accompanying note is to give the basic definitions in detail, state the main results, mention some open problems, and give a list of references.
[Vocabulary, Terminology, graph theory, Relational databases, fixed-point logic, descriptive complexity, query languages, Complexity theory, Database languages, Computer science, formal logic, PTIME, descriptive complexity theory, Polynomials, Robustness, polynomial time, finite model theory, Logic, Mathematical model, graph structure theory, computational complexity]
On the Asymptotic Nullstellensatz and Polynomial Calculus Proof Complexity
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We show that the asymptotic complexity of uniformly generated (expressible in first-order (FO) logic) prepositional tautologies for the nullstellensatz proof system (NS) as well as for polynomial calculus, (PC) has four distinct types of asymptotic behavior over fields of finite characteristic. More precisely, based on some highly non-trivial work by Krajicek, we show that for each prime p there exists a function l(n) G isin Omega(log(n)) for NS and l(n) G Omega (log(log(n)) for PC, such that the prepositional translation of any FO formula (that fails in all finite models), has degree proof complexity over fields of characteristic p, that behave in 4 mutually distinct ways: (i) The degree complexity is bound by a constant. (ii) The degree complexity is at least l(n) for all values of n. (iii) The degree complexity is at least l(n) except in a finite number of regular subsequences of infinite size, where the degree is constant. (iv) The degree complexity fluctuates in a very particular way with the degree complexity taking different constant values on an infinite number of regular subsequences each of infinite size. We leave it as an open question whether the classification remains valid for l[n) isin nOmega(1) or even for I (n) isin Omega(n). Finally, we show that for any non-empty proper subset A sube {(i), (ii), (iii), (iv)} the decision problem of whether a given input FO formula Psi has type belonging to A - is undecidable.
[uniformly generated prepositional tautologies, finite characteristics, Propositional proof complexity, prepositional translation, degree complexity, polynomial calculus proof complexity, nullstellensatz proof system, first-order logic, Knowledge representation, Calculus, predicate logic, asymptotic nullstellensatz proof complexity, Computer science, formal logic, Algebraic proof complexity, asymptotic complexity, Character generation, Polynomials, finite model, theorem proving, Logic, Testing, computational complexity]
On the Computational Complexity of Cut-Reduction
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Using appropriate notation systems for proofs, cut-reduction can often be rendered feasible on these notations. Explicit bounds can be given. Developing a suitable notation system for Bounded Arithmetic, and applying these bounds, all the known results on definable functions of certain such theories can be reobtained in a uniform way.
[propositional logic, proof notations, Search problems, bounded arithmetic, Computational complexity, Machinery, Computer science, Bounded Arithmetic, Writing, Polynomials, theorem proving, Logic, cut-reduction, Arithmetic, computational complexity]
Maltsev + Datalog --&#x226B; Symmetric Datalog
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Let B be a finite, core relational structure and let A be the algebra associated to B, i.e. whose terms are the operations on the universe of B that preserve the relations of B. We show that if A generates a so-called arithmetical variety then CSP(B), the constraint satisfaction problem associated to B, is solvable in Logspace; in fact notCSP(B) is expressible in symmetric Datalog. In particular, we obtain that notCSP(B) is expressible in Datalog and the relations of B are invariant under a Maltsev operation then notCSP(B) is in symmetric Datalog.
[Maltsev term, constraint theory, Maltsev, constraint satisfaction problem, Graph theory, algebra, Equations, Computer science, Constraint optimization, Typesetting, Algebra, Databases, Symmetric Datalog, symmetric datalog, operations research, Constraint theory, Logic functions, Polynomials, Dstalog]
Caterpillar Duality for Constraint Satisfaction Problems
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
The study of constraint satisfaction problems definable in various fragments of Datalog has recently gained considerable importance. We consider constraint satisfaction problems that are definable in the smallest natural recursive fragment of Datalog - monadic linear Datalog with at most one EDB per rule. We give combinatorial and algebraic characterisations of such problems, in terms of caterpillar dualities and lattice operations, respectively. We then apply our results to study graph H-colouring problems.
[Datalog, caterpillar structures, constraint theory, Lattices, constraint satisfaction problem, DATALOG, Combinatorial mathematics, duality, Equations, graph colouring, Computer science, Computer languages, graph H-colouring, Tree graphs, Algebra, caterpillar duality, constraint satisfaction, Logic functions, homomorphism, Artificial intelligence]
Quantified Constraints and Containment Problems
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We study two containment problems related to the quantified constraint satisfaction problem (QCSP). Firstly, we give a combinatorial condition on finite structures A and B that is necessary and sufficient to render QCSP(A) a subset of QCSP(B). The required condition is the existence of a positive integer r such that there is a surjective homomorphism from the power structure A^r to B. We note that this condition is already necessary to guarantee containment of the Pi_2 restriction of QCSP, that is Pi_2-CSP(A) a subset of Pi_2-CSP(B). Since we are able to give an effective bound on such an r, we provide a decision procedure for the model containment problem with non-deterministic double-exponential time complexity. Secondly, we prove that the entailment problem for quantified conjunctive-positive first-order logic is decidable. That is, given two sentences phi and psi of first-order logic with no instances of negation or disjunction, we give an algorithm that determines whether "phi implies psi" is true in all structures (models). Our result is in some sense tight, since we show that the entailment problem for positive first-order logic (i.e. quantified conjunctive-positive logic plus disjunction) is undecidable.
[combinatorial mathematics, positive integer, nondeterministic double-exponential time complexity, constraint theory, quantified constraint satisfaction problem, set theory, finite structure, Computer science, entailment problem, containment problem, power structure, decidability, Polynomials, quantified conjunctive-positive first-order logic, Logic, Argon, Artificial intelligence, computational complexity, combinatorial condition, surjective homomorphism]
Hiding Local State in Direct Style: A Higher-Order Anti-Frame Rule
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Separation logic involves two dual forms of modularity: local reasoning makes part of the store invisible within a static scope, whereas hiding local state makes part of the store invisible outside a static scope. In the recent literature, both idioms are explained in terms of a higher-order frame rule. I point out that this approach to hiding local state imposes continuation-passing style, which is impractical. Instead, I introduce a higher-order anti-frame rule, which permits hiding local state in direct style. I formalize this rule in the setting of a type system, equipped with linear capabilities, for an ML-like programming language, and prove type soundness via a syntactic argument. Several applications illustrate the expressive power of the new rule.
[local state hiding, Shape, hidden local state, higher-order frame rule, dynamic memory allocation, Knowledge management, maximum likelihood estimation, Computer science, formal logic, local reasoning, ML-like programming language, Computer languages, Pollution, Runtime, Memory management, separation logic, continuation-passing style, Concrete, Logic, syntactic argument, Proofs of programs, higher-order anti-frame rule]
Typed Normal Form Bisimulation for Parametric Polymorphism
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
This paper presents a new bisimulation theory for parametric polymorphism which enables straight forward co-inductive proofs of program equivalences involving existential types. The theory is an instance of typed normal form bisimulation and demonstrates the power of this recent framework for modeling typed lambda calculi as labelled transition systems.We develop our theory for a continuation-passing style calculus, Jump-With-Argument, where normal form bisimulation takes a simple form. We equip the calculus with both existential and recursive types. An "ultimate pattern matching theorem" enables us to define bisimilarity and we show it to be a congruence. We apply our theory to proving program equivalences, type isomorphisms and genericity.
[bisimulation, pattern matching, recursive types, type isomorphisms, Calculus, type theory, LTS, program equivalences, typed normal form bisimulation, Counting circuits, parametric polymorphism, typed lambda calculus, bisimulation theory, Filling, Robustness, bisimulation equivalence, theorem proving, Logic, continuation-passing style calculus, lambda calculus, coinductive proofs, Reasoning about programs, recursive functions, Power system modeling, Computer science, Computer languages, ultimate pattern matching theorem, equivalence classes, lambda calculi, Pattern matching]
Reachability Games and Game Semantics: Comparing Nondeterministic Programs
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We investigate the notions of may- and must-approximation in Erratic Idealized Algol (a nondeterministic extension of Idealized Algol), and give explicit characterizations of both using its game model. Notably, must-approximation is captured by a novel preorder on nondeterministic strategies, whose definition is formulated in terms of winning regions in a reachability game. The game is played on traces of one of the strategies and its objective is reaching a complete position without encountering any divergences. The concrete accounts of may- and must-approximation make it possible to derive tight complexity bounds for the corresponding decision problems in the finitary (finite datatypes) variant EIA<sub>f</sub> of Erratic Idealized Algol. In fact we give a complete classification of the complexity of may- and must-approximation for fragments of EIA<sub>f</sub> of bounded type order (for terms in beta-normal form). The complexity of the decidable cases ranges from PSPACE to 2-EXPTIME for may-approximation and from EXPSPACE to 3-EXPTIME for must-approximation. Our decidability results rely on a representation theorem for nondeterministic strategies which, for a given term, yields a single (finite or visibly pushdown) automaton capturing both traces and divergences of the corresponding strategy with two distinct sets of final states. The decision procedures producing optimal bounds incorporate numerous automata-theoretic techniques: complementation, determinization, computation of winning regions in reachability games over finite and pushdown graphs as well as product constructions. We see our work as a starting point of research that relates game semantics with other game-based theories.
[game model, Laboratories, nondeterministic program, complexity bounds, may-approximation, reachability game, decidability, Erratic Idealized Algol, Logic, nondeterminism, approximation theory, reachability analysis, Software algorithms, game theory, pushdown graphs, Idealized Algol, Application software, game semantics, Game theory, Computer science, Computer languages, Automata, must-approximation, Concrete, reachability games, Context modeling, computational complexity]
Weak Topology and a Differentiable Operator for Lipschitz Maps
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We show that the Scott topology induces a topology for real-valued Lipschitz maps on Banach spaces which we call the L-topology. It is the weakest topology with respect to which the L-derivative operator, as a second order functional which maps the space of Lipschitz functions into the function space of non-empty weak* compact and convex valued maps equipped with the Scott topology, is continuous. For finite dimensional Euclidean spaces, where the L-derivative and the Clarke gradient coincide, we provide a simple characterisation of the basic open subsets of the L-topology in terms of ties or primitive maps of functions. We use this to verify that the L-topology is strictly coarser than the well-known Lipschitz norm topology. We then develop a fundamental theorem of calculus of second order in finite dimensions showing that the continuous integral operator from the continuous Scott domain of non-empty convex and compact valued functions to the continuous Scott domain of ties is inverse to the continuous operator induced by the L-derivative.
[Weakest topology, Solid modeling, second order functional, Clarke gradient, Calculus, Mathematics, Banach spaces, calculus, L-topology, Hausdorff metric, differential equations, continuous integral operator, Integral equations, Clarke gradient coincide, Polynomials, Logic, Domain theory, gradient methods, finite dimensional Euclidean spaces, differentiable operator, topology, Educational institutions, convex programming, L-derivative operator, nonempty convex, Scott topology, Topology, mathematical operators, Computer science, integral equations, convex valued maps, Differential equations, weak topology, Fundamental Theorem of Calculus, Second order functionals, Lipschitz maps]
A Logical Characterization of Individual-Based Models
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Individual-based models are a relatively new approach to modelling dynamical systems of interacting entities, for example molecules in a biological cell. Although they are computationally expensive, they have the capability of modelling systems more realistically than traditional state-variable models. We give a formal definition of individual-based models, which includes state-variable models as a special case. We examine the questions of when state-variable models are sufficient for accurate modelling of a system, and when individual-based models are necessary. We define notions of abstraction and approximation, and give sufficient conditions that imply that an individual-based model can be approximated by a deterministic state-variable model. We also give negative results: examples of individual-based models that cannot be approximated by any state-variable model.
[systems biology, dynamical systems modelling, Object oriented modeling, Biological system modeling, probability, temporal logic, interacting entity, Biochemistry, deterministic state-variable model, Biological cells, Physics, Computer science, Sufficient conditions, Chemistry, formal verification, model checking, biology computing, individual-based models, Differential equations, biochemistry, finite model theory, Logic, biochemical network]
The Satisfiability Problem for Probabilistic CTL
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We study the satisfiability problem for qualitative PCTL (probabilistic computation tree logic), which is obtained from "ordinary" CTL by replacing the EX, AX, EU, and AU operators with their qualitative counterparts X &gt; 0, X = 1, U &gt; 0, and U = 1, respectively. As opposed to CTL, qualitative PCTL does not have a small model property, and there are even qualitative PCTL formulae which have only infinite- state models. Nevertheless, we show that the satisfiability problem for qualitative PCTL is EXPTIME-complete and we give an exponential-time algorithm which for a given formula phi computes a finite description of a model (if it exists), or answers "not satisfiable" (otherwise). We also consider the finite satisfiability problem and provide analogous results. That is, we show that the finite satisfiability problem for qualitative PCTL is EXPTIME-complete, and every finite satisfiable formula has a model of an exponential size which can effectively be constructed in exponential time. Finally, we give some results about the quantitative PCTL, where the numerical bounds in probability constraints can be arbitrary rationals between 0 and 1. We prove that the problem whether a given quantitative PCTL formula phi has a model of the branching degree at most k, where k &gt; 2 is an arbitrary but fixed constant, is highly undecidable. We also show that every satisfiable formula phi has a model with branching degree at most \\phi\\ + 2. However, this does not yet imply the undecidability of the satisfiability problem for quantitative PCTL, and we in fact conjecture the opposite.
[Gold, probabilistic logic, finite satisfiability problem, computability, EXPTIME-complete, Probabilistic logic, Markov chains, temporal logics, probabilistic computation tree logic, Computer science, exponential time algorithm, Informatics, probabilistic CTL, computational complexity]
The Axiomatic Derivation of Absolute Lower Bounds
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
The ancient Euclidean algorithm computes the greatest common divisor gcd(m, n) of two natural numbers from (or relative to) the remainder operation rem, which is assumed as primitive; it requires no more than 2 log(min(m, n)) applications of the remainder operation to compute gcd(m, n) (for m, n ges 2), and it is not known to be optimal: Conjecture: for every algorithm a which computes on Nopf from rem the greatest common divisor function, there is a constant r &gt; 0 such that for infinitely many pairs a ges b ges 1, c<sub>alpha</sub>(a, b) ges rlog<sub>2</sub>(a), where c<sub>alpha</sub>(m,n) counts the number of calls to "the remainder oracle" required by a for the computation of gcd(m, n). The conjecture claims a logarithmic lower bound for all algorithms which compute gcd(m, n) from the remainder operation, not just those expressed by a specific class of computation models. In this lecture the author develops an approach to the theory of algorithms in the style of abstract model theory which makes it possible to make precise and (on occasion) prove the existence of non-trivial, absolute lower bounds for a wide variety of problems and specified primitives, including many of the results in the bibliography.
[Computational modeling, axiomatic derivation, Mathematics, abstract model theory, remainder oracle, Computer science, formal logic, logarithmic lower bound, absolute lower bounds, Bibliographies, Euclidean algorithm, algorithm theory, common divisor function, natural number, Logic, greatest common divisor, Arithmetic]
Definable Tree Decompositions
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We introduce a notion of definable tree decompositions of graphs. Actually, a definable tree decomposition of a graph is not just a tree decomposition, but a more complicated structure that represents many different tree decompositions of the graph. It is definable in the graph by a tuple of formulas of some logic. In this paper, only study tree decomposition definable in fixed-point logic. We say that a definable tree decomposition is over a class of graphs if the pieces of the decomposition are in this class. We prove two general theorems lifting definability results from the pieces of a tree decomposition of a graph to the whole graph. Besides unifying earlier work on fixed-point definability and descriptive complexity theory on planar graphs and graphs of bounded tree width, these general results can be used to prove that the class of all graphs without a K<sub>5</sub>-minor is definable infixed-point logic and that fixed-point logic with counting captures polynomial time on this class.
[definable tree decompositions, bounded tree width, polynomials, fixed point arithmetic, graph decomposition, trees (mathematics), planar graphs, fixed-point logic, descriptive complexity, Complexity theory, fixed point logic, fixed-point definability, Computer science, Tree graphs, Databases, infixed-point logic, descriptive complexity theory, Polynomials, polynomial time, Logic, tree decomposition, Context modeling]
Hypergraph Acyclicity and Extension Preservation Theorems
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
A class of structures satisfies the extension preservation theorem if, on this class, every first order sentence is preserved under extension iff it is equivalent to an existential sentence. We consider different acyclicity notions for hypergraphs (\\gamma, \\beta and \\alpha-acyclicity and also acyclicity on hypergraph quotients) and estimate their influence on the validity of the extension preservation theorem on classes of finite structures. More precisely, we prove that \\gamma-acyclic classes satisfy the extension preservation theorem, whereas \\beta-acyclic classes do not. We also extend the validity of the extension preservation theorem for a generalization of \\gamma-acyclicity that we call \\gamma-acyclic k-quotient. To achieve this, we make a reduction from finite structures to their k-quotients and we use combinatorial arguments on \\gamma-acyclic hypergraphs.
[Computer science, gamma-acyclic class, Databases, hypergraph acyclicity, graph theory, beta-acyclic class, extension preservation theorem, logic, finite model theory, preservation theorems, Logic]
From Automatic Structures to Borel Structures
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We study the classes of Buchi and Rabin automatic structures. For Buchi (Rabin) automatic structures their domains consist of infinite strings (trees), and the basic relations, including the equality relation, and graphs of operations are recognized by Buchi (Rabin) automata. A Buchi (Rabin) automatic structure is injective if different infinite strings (trees) represent different elements of the structure. The first part of the paper is devoted to understanding the automata- theoretic content of the well-known Lowenheim-Skolem theorem in model theory. We provide automata-theoretic versions of Lowenheim-Skolem theorem for Rabin and Buchi automatic structures. In the second part, we address the following two well-known open problems in the theory of automatic structures: Does every Buchi automatic structure have an injective Buchi presentation? Does every Rabin automatic structure have an injective Rabin presentation? We provide examples of Buchi structures without injective Buchi and Rabin presentations. To answer these questions we introduce Borel structures and use some of the basic properties of Borel sets and isomorphisms. Finally, in the last part of the paper we study the isomorphism problem for Buchi automatic structures.
[Shape, automata theory, Automatic logic units, Mathematics, trees, isomorphism, formal logic, automata-theoretic content, Buechi, Tree graphs, USA Councils, equality relation, Borel, model theory, trees (mathematics), Lowenheim-Skolem theorem, Boolean algebra, infinite strings, Statistics, basic relations, Computer science, Borel structures, automatic structures, Automata, Buchi automata, automata]
Piecewise Testable Tree Languages
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
This paper presents a decidable characterization of tree languages that can be defined by a boolean combination of Sigma<sub>1</sub> formulas. This is a tree extension of the Simon theorem, which says that a string language can be defined by a boolean combination of Sigma<sub>1</sub> formulas if and only if its syntactic monoid is J-trivial.
[formal languages, computational linguistics, trees (mathematics), Educational institutions, algebra, Logic testing, Computer science, Boolean functions, syntactic monoid, Algebra, decidability, Veins, Automatic testing, Automata, decidable characterization, Logic functions, Simon theorem, Page description languages, logic, tree automata, piecewise testable tree languages, Boolean combination]
Collapsible Pushdown Automata and Recursion Schemes
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Collapsible pushdown automata (CPDA) are a new kind of higher-order pushdown automata in which every symbol in the stack has a link to a stack situated somewhere below it. In addition to the higher-order push and pop operations, CPDA have an important operation called collapse, whose effect is to "collapse" a stack s to the prefix as indicated by the link from the topmost symbol of s. Our first result is that CPDA are equi-expressive with recursion schemes as generators of (possibly infinite) ranked trees. In one direction, we give a simple algorithm that transforms an order-n CPDA to an order-n recursion scheme that generates the same tree, uniformly for all n Gt= 0. In the other direction, using ideas from game semantics, we give an effective transformation of order-n recursion schemes (not assumed to be homogeneously typed, and hence not necessarily safe) to order-n CPDA that compute traversals over an abstract syntax graph of the scheme, and hence paths in the tree generated by the scheme. Our equi-expressivity result is the first automata-theoretic characterization of higher-order recursion schemes. Thus CPDA are also a characterization of the simply-typed lambda calculus with recursion (generated from uninterpreted 1st-order symbols) and of (pure) innocent strategies. An important consequence of the equi-expressivity result is that it allows us to reduce decision problems on trees generated by recursion schemes to equivalent problems on CPDA and vice versa. Thus we show, as a consequence of a recent result by Ong (modal mu-calculus model-checking of trees generated by recursion schemes is n-EXPTIME complete), that the problem of solving parity games over the configuration graphs of order-n CPDA is n-EXPTIME complete, subsuming several well-known results about the solvability of games over higher-order pushdown graphs by (respectively) Walukiewicz, Cachat, and Knapik et al. Another contribution of our work is a self-contained proof of the same solvability result by generalizing standard techniques in the field. By appealing to our equi-expressivity result, we obtain a new proof of Ong's result. In contrast to higher-order pushdown graphs, we show that the monadic second-order theories of the configuration graphs of CPDA are undecidable. It follows that -- as generators of graphs -- CPDA are strictly more expressive than higher-order pushdown automata.
[lambda calculus, higher-order recursion schemes, Laboratories, trees (mathematics), pushdown automata, n-EXPTIME complete, higher-order pushdown graphs, Calculus, game semantics, simply-typed lambda calculus, abstract syntax graph, Computer science, Tree graphs, Automata, Character generation, recursion schemes, Safety, Logic, Personal digital assistants, collapsible pushdown automata, higher-order stack operations, Higher-order pushdown automata]
The Geometry of Interaction of Differential Interaction Nets
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
The geometry of interaction purpose is to give a semantic of proofs or programs accounting for their dynamics. The initial presentation, translated as an algebraic weighting of paths in proofnets, led to a better characterization of the lambda-lambda-calculus optimal reduction. Recently Ehrhard and Regnier have introduced an extension of the multiplicative exponential fragment of linear logic (MELL) that is able to express non-deterministic behaviour of programs and a proofnet-like calculus: differential interaction nets. This paper constructs a proper geometry of interaction (GoI) for this extension. We consider it both as an algebraic theory and as a concrete reversible computation. We draw links between this GoI and the one of MELL. As a by-product we give for the first time an equational theory suitable for the GoI of the multiplicative additive fragment of linear logic.
[nondeterministic behaviour, Costs, Logic programming, linear logic, computational geometry, interaction purpose geometry, lambda-calculus optimal reduction, Encoding, Calculus, Electronic mail, sharing graphs, Data mining, calculus, Equations, differential linear logic, Computer science, concrete reversible computation, multiplicative additive fragment, geometry of interaction, Computational geometry, multiplicative exponential fragment of linear logic, Concrete, algebraic theory, differential interaction nets]
Correctness of Multiplicative Additive Proof Structures is NL-Complete
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
The authors revisit the correctness criterion for the multiplicative additive fragment of linear logic. We prove that deciding the correctness of corresponding proof structures is NL-complete.
[multiplicative additive proof structures, NL-complete, NL-completness, Additives, linear logic, Calculus, Complexity theory, Correctness Criterion, Parallel algorithms, Multiplicative Additive Linear Logic, Computer science, Jacobian matrices, formal logic, proof-nets, theorem proving, Logic, Computational Complexity]
Cut Elimination for Monomial MALL Proof Nets
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We present a syntax for MALL (multiplicative additive linear logic without units) proof nets which refines Girard's one. It is also based on the use of monomial weights for identifying additive components (slices). Our generalization gives the possibility of representing a kind of sharing of nodes which does not exist in Girard's nets. This sharing leads to the definition of a strong cut elimination procedure for MALL. We give a correctness criterion which is proved to be stable by reduction and to give a sequentialization theorem with respect to the sequent calculus. Sequentialization is proved by showing that an expansion procedure allows us to unfold any of our proof nets into a Girard proof net.
[monomial MALL proof nets, sequent calculus, Additives, Stability, cut elimination, computational linguistics, Calculus, Boolean algebra, Proposals, multiplicative additive linear logic, Linear Logic, Computer science, formal logic, Tensile stress, Proof Net, Cut Elimination, syntax, Girard proof net, theorem proving, Logic, Joining processes, sequentialization theorem]
A Neutral Approach to Proof and Refutation in MALL
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
We propose a setting in which the search for a proof of B or a refutation of B (a proof of not B) can be carried out simultaneously. In contrast with the usual approach in automated deduction, we do not need to first commit to either proving B or to proving not B: instead we devise a neutral setting for attempting both a proof and a refutation. This setting is described as a two player game in which each player follows the same rules. A winning strategy translates to a proof of the formula and a winning counter-strategy translates to a refutation of the formula. The game is described for multiplicative and additive linear logic without atomic formulas. A game theoretic treatment of the multiplicative connectives is intricate and our approach to it involves two important ingredients. First, labeled graph structures are used to represent positions in a game and, second, the game playing must deal with the failure of a given player and with an appropriate resumption of play. This latter ingredient accounts for the fact that neither players might win (that is, neither B nor not B might be provable).
[Additives, proof approach, graph theory, linear logic, game theory, Calculus, game semantics, Game theory, neutral approach, Computer science, formal logic, multiplicative logic, automated deduction approach, labeled graph structure, Propulsion, two-player game winning counter-strategy, theorem proving, atomic formula, Logic, additive linear logic]
[Roster]
2008 23rd Annual IEEE Symposium on Logic in Computer Science
None
2008
Provides a listing of current committee members and society officers.
[]
Foreword
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
Presents the welcome message from the conference proceedings.
[Computer science, Fault tolerance, Computer languages, Awards committees, Logic, Synthetic aperture sonar, Computer security, Computational complexity, Certification, Testing]
Conference organization
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
Provides a listing of current committee members and society officers.
[]
My 27-year Quest to Overcome the State Explosion Problem
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
Model checking is an automatic verification technique for state-transition systems that are finite-state or that have finite-state abstractions. In the early 1980's in a series of joint papers with my graduate students E.A. Emerson and A.P. Sistla, we proposed that model checking could be used for verifying concurrent systems and gave algorithms for this purpose. At roughly the same time, Joseph Sifakis and his student J.P. Queille at the University of Grenoble independently developed a similar technique. Model checking has been used successfully to reason about computer hardware and communication protocols and is beginning to be used for verifying computer software. Specifications are written in temporal logic, which is particularly valuable for expressing concurrency properties. An intelligent, exhaustive search is used to determine if the specification is true or not. If the specification is not true, the model checker will produce a counterexample execution trace that shows why the specification does not hold. This feature is extremely useful for finding obscure errors in complex systems. The main disadvantage of model checking is the state-explosion problem, which can occur if the system under verification has many processes or complex data structures. Although the state-explosion problem is inevitable in worst case, over the past 27 years considerable progress has been made on the problem for certain classes of state-transition systems that occur often in practice. In this talk, I will describe what model checking is, how it works, and the main techniques that have been developed for combating the state explosion problem.
[Protocols, Automatic logic units, finite-state abstractions, temporal logic, Data structures, Explosions, Computer science, Concurrent computing, formal verification, model checking, USA Councils, automatic verification technique, state explosion problem, state-transition systems, Hardware, Software, data structures]
The General Vector Addition System Reachability Problem by Presburger Inductive Invariants
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
The reachability problem for Vector Addition Systems (VASs) is a central problem of net theory. The general problem is known decidable by algorithms exclusively based on the classical Kosaraju-Lambert-Mayr-Sacerdote-Tenney decomposition. This decomposition is used in this paper to prove that the Parikh images of languages accepted by VASs are semi-pseudo-linear; a class that extends the semi-linear sets, a.k.a. the sets definable in the Presburger arithmetic. We provide an application of this result; we prove that a final configuration is not reachable from an initial one if and only if there exists a Presburger formula denoting a forward inductive invariant that contains the initial configuration but not the final one. Since we can decide if a Preburger formula denotes an inductive invariant, we deduce that there exist checkable certificates of non-reachability. In particular, there exists a simple algorithm for deciding the general VAS reachability problem based on two semi-algorithms. A first one that tries to prove the reachability by enumerating finite sequences of actions and a second one that tries to prove the non-reachability by enumerating Presburger formulas.
[general vector addition system reachability problem, Invariant, Petri nets, Lattices, arithmetic, VAS, set theory, Presburger inductive invariant, Concurrent computing, decidability, Presburger, Logic, formal languages, reachability analysis, Kosaraju-Lambert-Mayr-Sacerdote-Tenney decomposition, Presburger arithmetic, Zinc, Linear, Reachability, Computer science, net theory, Upper bound, vectors, finite sequence, Parikh images, Arithmetic, Petri Net]
Boundedness vs. Unboundedness of Lock Chains: Characterizing Decidability of Pairwise CFL-Reachability for Threads Communicating via Locks
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
The problem of pairwise CFL-reachability is to decide whether two given program locations in different threads are simultaneously reachable in the presence of recursion in threads and scheduling constraints imposed by synchronization primitives. Pairwise CFL-reachability is the core problem underlying concurrent program analysis especially dataflow analysis. Unfortunately, it is undecidable even for the most commonly used synchronization primitive, i.e., mutex locks. Lock usage in concurrent programs can be characterized in terms of lock chains, where a sequence of mutex locks is said to be chained if the scopes of adjacent (non-nested) mutexes overlap. Although pairwise reachability is known to decidable for threads interacting via nested locks, i.e., chains of length one, these techniques donpsilat extend to programs with non-nested locks used in crucial applications like databases and device drivers. In this paper, we exploit the fact that lock usage patterns in real life programs do not produce unbounded lock chains. For such programs, we show that pairwise CFL-reachability becomes decidable. Our new results narrow the decidability gap for pairwise CFL-reachability by providing a more refined characterization for it in terms of boundedness of lock chains rather than the current state-of-the-art, i.e., nestedness of locks (chains of length one).
[Data analysis, reachability analysis, dataflow analysis, Switches, data flow analysis, Locks, Yarn, Power system modeling, Reachability, Dataflow analysis, Computer science, Databases, decidability, USA Councils, National electric code, logic programming, pairwise CFL-reachability, Interleaved codes, Concurrent Programs, concurrent program analysis, Logic, lock chain boundednesss]
Psi-calculi: Mobile Processes, Nominal Data, and Logic
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
A psi-calculus is an extension of the pi-calculus with nominal data types for data structures and for logical assertions representing facts about data. These can be transmitted between processes and their names can be statically scoped using the standard pi-calculus mechanism to allow for scope migrations. Other proposed extensions of the pi-calculus can be formulated as psi-calculi; examples include the applied pi-calculus, the spi-calculus, the fusion calculus, the concurrent constraint pi-calculus, and calculi with polyadic communication channels or pattern matching. Psi-calculi can be even more general, for example by allowing structured channels, higher-order formalisms such as the lambda calculus for data structures, and a predicate logic for assertions. Our labelled operational semantics and definition of bisimulation is straightforward, without a structural congruence. We establish minimal requirements on the nominal data and logic in order to prove general algebraic properties of psi-calculi. The proofs have been checked in the interactive proof checker Isabelle. We are the first to formulate a truly compositional labelled operational semantics for calculi of this calibre. Expressiveness and therefore modelling convenience significantly exceeds that of other formalisms, while the purity of the semantics is on par with the original pi-calculus.
[pattern matching, nominal data types, spi-calculus, operational semantics, Calculus, pi calculus, psi-calculi, Logic functions, data structures, Cryptography, lambda calculus, mobile processes, pi-calculus, polyadic communication channels, fusion calculus, Data structures, interactive proof checker, predicate logic, Information technology, Equations, Computer science, Isabelle, Communication channels, Mobile computing, Pattern matching]
An Algebra for Kripke Polynomial Coalgebras
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
Several dynamical systems, such as deterministic automata and labelled transition systems, can be described as coalgebras of so-called Kripke polynomial functors, built up from constants and identities, using product, coproduct and powerset. Locally finite Kripke polynomial coalgebras can be characterized up to bisimulation by a specification language that generalizes Kleenepsilas regular expressions for finite automata. In this paper, we equip this specification language with an axiomatization and prove it sound and complete with respect to bisimulation, using a purely coalgebraic argument. We demonstrate the usefulness of our framework by providing a finite equational system for (non-)deterministic finite automata, labelled transition systems with explicit termination, and automata on guarded strings.
[finite automata, Instruments, polynomials, Specification languages, Application software, Equations, Computer science, Algebra, deterministic automata, labelled transition system, Automata, finite equational system, Logic functions, Polynomials, specification language, Kripke polynomial coalgebra]
Trace Semantics is Fully Abstract
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
The discussion in the computer-science literature of the relative merits of linear- versus branching-time frameworks goes back to the early 1980s. One of the beliefs dominating this discussion has been that the linear-time framework is not expressive enough semantically, making linear-time logics lacking in expressiveness. In this work we examine the branching-linear issue from the perspective of process equivalence, which is one of the most fundamental concepts in concurrency theory, as defining a notion of equivalence essentially amounts to defining semantics for processes. We accept three principles that have been recently proposed for concurrent-process equivalence. The first principle takes contextual equivalence as the primary notion of equivalence. The second principle requires the description of a process to specify all relevant behavioral aspects of the process. The third principle requires observable process behavior to be reflected in its input/output behavior. It has been recently shown that under these principles trace semantics for nondeterministic transducers is fully abstract. Here we consider two extensions of the earlier model: probabilistic transducers and asynchronous transducers. We show that in both cases trace semantics is fully abstract.
[Transducers, concurrent process equivalence, linear-time frameworks, trace semantics, computer-science literature, concurrency theory, linear-time logics, Concurrent computing, Computer science, formal logic, USA Councils, branching-time frameworks, System recovery, Logic, Carbon capture and storage, Testing, Formal verification]
Logical Step-Indexed Logical Relations
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We show how to reason about "step-indexed" logical relations in an abstract way, avoiding the tedious, error-prone, and proof-obscuring step-index arithmetic that seems superficially to be an essential element of the method. Specifically, we define a logic LSLR, which is inspired by Plotkin and Abadi's logic for parametricity, but also supports recursively defined relations by means of the modal "later" operator from Appel et al.'s "very modal model" paper. We encode in LSLR a logical relation for reasoning (in-)equationally about programs in call-by-value system F extended with recursive types. Using this logical relation, we derive a useful set of rules with which we can prove contextual (in-)equivalences without mentioning step indices.
[logical step-indexed logical relation reasoning, call-by-value system F, recursive types, recursive type, parametricity, modal operator, type theory, Machinery, Step-indexed logical relations, Plotkin-Abadi logic, Safety, Logic, Mathematical model, logic LSLR encoding, Plotkin parametricity logic, contextual inequivalence, Abadi parametricity logic, Reasoning about programs, tedious error-prone proof-obscuring step-index arithmetic, recursive functions, reasoning about program, Computer science, contextual equivalence, recursively-defined relation, Computer errors, Digital arithmetic, reasoning about programs, Context modeling, Clocks]
Fully Abstract Logical Bisimilarity for a Polymorphic Object Calculus
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We characterise type structurally the termination observational congruence of Abadi and Cardellipsilas S<sub>forall</sub> calculus. Pittspsila operational reasoning approach for polymorphic lambda calculi is enhanced with subtyping and primitive covariant object types. Labelling each object with a bound ordinal of terminating method invocations and regarding omega-bounded as unlabelled reduction we achieve a crucial object unwinding lemma. Value and term bisimilarities are suitably defined with novel type structural operators and (type-, relation- and value-environment) bindings. We prove term bisimilarity complete and sound with respect to observational congruence, postulated as the largest, substitutive, compatible, (termination) adequate and (type) subsumptive, well typed term relation.
[lambda calculus, structural operator, Logic programming, fully abstract logical bisimilarity, Bounded reduction, Behavioural congruence, Calculus, primitive covariant object type, Computer science, polymorphic lambda calculi, Computer languages, Abadi-Cardelli S<sub>forall</sub> calculus, Mathematical analysis, Pitt operational reasoning approach, Concrete, reasoning about programs, Labeling, Books, unlabelled reduction, polymorphic object calculus, Testing, termination observational congruence]
Reflexive Scott Domains are Not Complete for the Extensional Lambda Calculus
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
A longstanding open problem is whether there exists a model of the untyped lambda calculus in the category CPO of complete partial orderings and Scott continuous functions, whose theory is exactly the least lambda-theory lambda-beta or the least extensional lambda-theory lambda-beta-eta. In this paper we analyze the class of reflexive Scott domains, the models of lambda-calculus living in the category of Scott domains (a full subcategory of CPO). The following are the main results of the paper: (i) Extensional reflexive Scott domains are not complete for the beta-eta-calculus, i.e., there are equations not in lambda-beta-eta which hold in all extensional reflexive Scott domains.(ii) The order theory of an extensional reflexive Scott domain is never recursively enumerable. These results have been obtained by isolating among the reflexive Scott domains a class of webbed models arising from Scott's information systems, called iweb-models. The class of iweb-models includes all extensional reflexive Scott domains, all preordered coherent models and all filter models living in CPO. Based on a fine-grained study of an ``effective'' version of Scott's information systems, we have shown that there are equations not in lambda-beta (resp. lambda-beta-eta) which hold in all (extensional) iweb-models.
[lambda calculus, Reflexive Scott domains, lambda-theory lambda-beta, lambda theories, Lattices, extensional lambda calculus, Scott continuous functions, Calculus, iweb-models, Equations, Information systems, Computer science, reflexive Scott domains, longstanding open problem, Filters, Lambda calculus, Filter models, Filtering theory, lambda-theory lambda-beta-eta, Mathematical model, Logic, Scott information systems, Kernel, computational complexity]
Substructural Operational Semantics as Ordered Logic Programming
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We describe a substructural logic with ordered, linear, and persistent propositions and then endow a fragment with a committed choice forward-chaining operational interpretation. Exploiting higher-order terms in this metalanguage, we specify the operational semantics of a number of object language features, such as call-by-value, call-by-name, call-by-need, mutable store, parallelism, communication, exceptions and continuations. The specifications exhibit a high degree of uniformity and modularity that allows us to analyze the structural properties required for each feature in isolation. Our substructural framework thereby provides a new methodology for language specification that synthesizes structural operational semantics, abstract machines, and logical approaches.
[Greedy algorithms, Logic programming, Calculus, formal specification, Computer science, forward-chaining operational interpretation, Computer languages, ordered logic programming, Parallel processing, logic programming, substructural operational semantics, metalanguage, language specification]
Logics with Rank Operators
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We introduce extensions of first-order logic (FO) and fixed-point logic (FP) with operators that compute the rank of a definable matrix. These operators are generalizations of the counting operations in FP+C (i.e. fixed-point logic with counting) that allow us to count the dimension of a definable vector space, rather than just count the cardinality of a definable set. The logics we define have data complexity contained in polynomial time and all known examples of polynomial time queries that are not definable in FP+C are definable in FP+rk, the extension of FP with rank operators. For each prime number p and each positive integer n, we have rank operators rk<sub>p</sub> for determining the rank of a matrix over the finite field GF<sub>p</sub> defined by a formula over n-tuples. We compare the expressive power of the logics obtained by varying the values p and n can take. In particular, we show that increasing the arity of the operators yields an infinite hierarchy of expressive power. The rank operators are surprisingly expressive, even in the absence of fixed-point operators. We show that FO+rk<sub>p</sub> can define deterministic and symmetric transitive closure. This allows us to show that, on ordered structures, FO+rk<sub>p</sub> captures the complexity class MOD<sub>p</sub> L, for all prime values of p.
[Transmission line matrix methods, matrix rank determination, rank operators, fixed-point operators, first-order logic, fixed-point logic, counting operations, Galois fields, Equations, Computer science, formal logic, Pathology, polynomial matrices, definable matrix, Databases, Tree graphs, polynomial time queries, Linear algebra, data complexity, Polynomials, Logic, definable vector space]
On Finite Satisfiability of Two-Variable First-Order Logic with Equivalence Relations
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We show that every finitely satisfiable two-variable first-order formula with two equivalence relations has a model of size at most triply exponential with respect to its length. Thus the finite satisfiability problem for two-variable logic over the class of structures with two equivalence relations is decidable in nondeterministic triply exponential time. We also show that replacing one of the equivalence relations in the considered class of structures by a relation which is only required to be transitive leads to undecidability. This sharpens the earlier result that two-variable logic is undecidable over the class of structures with two transitive relations.
[Tree data structures, first-order logic, computability, Mathematics, Distributed computing, Computer science, equivalence relations, exponential time, satisfiability, Distributed databases, Robustness, finite models, finite satisfiability, Logic, Mathematical model, Informatics, Artificial intelligence, two-variable logic, computational complexity]
Pointer Programs and Undirected Reachability
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
Pointer programs are a model of structured computation within LOGSPACE. They capture the common description of LOGSPACE algorithms as programs that take as input some structured data (e.g. a graph) and that store in memory only a constant number of pointers to the input (e.g. to the graph nodes). In this paper we study undirected s-t-reachability for a class of pure pointer programs in which one can work with a constant number of abstract pointers, but not with arbitrary data, such as memory registers of logarithmic size. In earlier work we have formalised this class as a programming language PURPLE that features a for all-loop for iterating over the input structure and thus subsumes other formalisations of pure pointer programs, such as Jumping Automata on Graphs JAGs and Deterministic Transitive Closure logic (DTC-logic) for locally ordered graphs. In this paper we show that PURPLE cannot decide undirected s-t-reachability, even though there does exist a LOGSPACE-algorithm for this problem by Reingold's theorem. As a corollary we obtain that DTC-logic for locally ordered graphs cannot express undirected s-t-reachability.
[locally ordered graphs, reachability analysis, Logic programming, Computational modeling, pointer program, cayley graph, LOGSPACE algorithms, Registers, undirected s-t-reachability, undirected reachability, abstract pointers, Computer science, Computer languages, logarithmic size memory registers, Turing machines, structured data, Automata, data structures, pointer programs, finite model theory, Size control, Testing]
An Exponential Lower Bound for the Parity Game Strategy Improvement Algorithm as We Know it
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
This paper presents a new lower bound for the discrete strategy improvement algorithm for solving parity games due to Voege and Jurdzinski. First, we informally show which structures are difficult to solve for the algorithm. Second, we outline a family of games on which the algorithm requires exponentially many strategy iterations, answering in the negative the long-standing question whether this algorithm runs in polynomial time. Additionally we note that the same family of games can be used to prove a similar result w.r.t. the strategy improvement variant by Schewe as well as the strategy iteration for solving discounted payoff games due to Puri.
[discounted payoff game, Stochastic processes, game theory, lower bound, Game theory, exponential lower bound, Computer science, Runtime, Upper bound, parity game, directed graphs, Automata, Ear, strategy improvement, Polynomials, parity game strategy improvement algorithm, polynomial time, Logic, strategy iteration]
Graph Reachability and Pebble Automata over Infinite Alphabets
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We study the graph reachability problem as a language over an infinite alphabet. Namely, we view a word of even length a<sub>0</sub>b<sub>0</sub> ... an b_n over an infinite alphabet as a directed graph with the symbols that appear in a<sub>0</sub>b<sub>0</sub> ... a<sub>n</sub>b<sub>n</sub> as the vertices and (a<sub>0</sub>, b<sub>0</sub>),...,(a<sub>n</sub>, b<sub>n</sub>) as the edges. We prove that for any positive integer k, k pebbles are sufficient for recognizing the existence of a path of length 2k - 1 from the vertex a<sub>0</sub> to the vertex bn, but are not sufficient for recognizing the existence of a path of length 2k+1 - 2 from the vertex a<sub>0</sub> to the vertex b<sub>n</sub>. Based on this result, we establish a number of relations among some classes of languages over infinite alphabets.
[reachability analysis, positive integer, automata theory, Natural languages, Petri nets, first-order logic, directed graph reachability problem, Graph reachability, Computer science, formal logic, infinite alphabets, Automatic testing, directed graphs, Automata, XML, infinite alphabet, pebble automata, Logic, Informatics, path recognition, Formal verification, number theory]
An Improved Lower Bound for the Complementation of Rabin Automata
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
Automata on infinite words (omega-automata) have wide applications in formal language theory as well as in modeling and verifying reactive systems. Complementation of omega-automata is a crucial instrument in many these applications, and hence there have been great interests in determining the state complexity of the complementation problem. However, obtaining nontrivial lower bounds has been difficult. For the complementation of Rabin automata, a significant gap exists between the state-of-the-art lower bound 2Omega(NlgN) and upper bound 2O(kNlgN), where k, the number of Rabin pairs, can be as large as 2N. In this paper we introduce multidimensional rankings to the full automata technique. Using the improved technique we establish an almost tight lower bound for the complementation of Rabin automata. We also show that the same lower bound holds for the determinization of Rabin automata.
[Multidimensional systems, formal languages, Instruments, automata theory, Formal languages, upper bound, Encoding, omega-automata, state complexity, infinite word, complementation, Computer science, Upper bound, USA Councils, improved lower bound, Automata, determinization, full automata, Logic, formal language theory, Rabin automata technique, Arithmetic, computational complexity, Rabin automata]
A Type System Equivalent to the Modal Mu-Calculus Model Checking of Higher-Order Recursion Schemes
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
The model checking of higher-order recursion schemes has important applications in the verification of higher-order programs. Ong has previously shown that the modal mu-calculus model checking of trees generated by order-n recursion scheme is n-EXPTIME complete, but his algorithm and its correctness proof were rather complex. We give an alternative, type-based verification method: Given a modal mu-calculus formula, we can construct a type system in which a recursion scheme is typable if, and only if, the (possibly infinite, ranked) tree generated by the scheme satisfies the formula. The model checking problem is thus reduced to a type checking problem. Our type-based approach yields a simple verification algorithm, and its correctness proof (constructed without recourse to game semantics) is comparatively easy to understand. Furthermore, the algorithm is polynomial-time in the size of the recursion scheme, assuming that the formula and the largest order and arity of non-terminals of the recursion scheme are fixed.
[Optimization methods, type theory, calculus, type checking problem, formal verification, modal mu-calculus model checking, Logic functions, Polynomials, type system equivalent, verification algorithm, Safety, polynomial-time, Gold, Embedded computing, type-based verification method, higher-order recursion schemes, higher-order programs, n-EXPTIME complete, Application software, correctness proof, type systems, Computer science, Automata, order-n recursion scheme, recursion schemes, model checking problem, Inference algorithms, computational complexity]
Clipping: A Semantics-Directed Syntactic Approximation
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
In this paper we introduce "clipping,'' a new method of syntactic approximation which is motivated by and works in conjunction with a sound and decidable denotational model for a given programming language. Like slicing, clipping reduces the size of the source code in preparation for automatic verification; but unlike slicing it is an imprecise but computationally inexpensive algorithm which does not require a whole-program analysis. The technique of clipping can be framed into an iterated refinement cycle to arbitrarily improve its precision. We first present this rather simple idea intuitively with some examples, then work out the technical details in the case of an Algol-like programming language and a decidable approximation of its game-semantic model inspired by Hankin and Malacaria's "lax functor'' approach. We conclude by presenting an experimental model checking tool based on these ideas and some toy programs.
[Algorithm design and analysis, source code size reduction, program verification, toy program, Game semantics, Programming, semantics-directed syntactic approximation, automatic software verification, sound decidable denotational approximation model, decidability, Algol-like programming language, lax functor approach, program analysis, Libraries, Logic, program slicing, program clipping method, game-semantic model, game theory, iterated refinement cycle, State-space methods, programming language semantics, Sliding mode control, ALGOL, Construction industry, Computer science, Computer languages, model checking tool, model checking, program slicing method, Computer industry]
Expressiveness and Closure Properties for Quantitative Languages
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
Weighted automata are nondeterministic automata with numerical weights on transitions. They can define quantitative languages L that assign to each word w a real number L(w). In the case of infinite words, the value of a run is naturally computed as the maximum, limsup, liminf, limit average, or discounted sum of the transition weights. We study expressiveness and closure questions about these quantitative languages. We first show that the set of words with value greater than a threshold can be non-omega-regular for deterministic limit-average and discounted-sum automata, while this set is always omega-regular when the threshold is isolated (i.e., some neighborhood around the threshold contains no word). In the latter case, we prove that the omega-regular language is robust against small perturbations of the transition weights. We next consider automata with transition weights 0 or 1 and show that they are as expressive as general weighted automata in the limit-average case, but not in the discounted-sum case. Third, for quantitative languages L<sub>1</sub> and L<sub>2</sub>, we consider the operations max(L<sub>1</sub>, L<sub>2</sub>), min(L<sub>1</sub>, L<sub>2</sub>), and 1-L<sub>1</sub>, which generalize the Boolean operations on languages, as well as the sum L<sub>1</sub> + L<sub>2</sub>. We establish the closure properties of all classes of quantitative languages with respect to these four operations.
[Energy consumption, Boolean operation, general weighted automata, closure property, set theory, Delay, Boolean functions, deterministic automata, Embedded system, real number, Cost function, Robustness, Closure operations, Logic, formal languages, nondeterministic automata, nonomega-regular language, Computational modeling, discounted-sum automata, expressiveness property, Computer science, omega-regular language, infinite word set, Expressiveness, deterministic limit-average automata, Automata, US Government, Quantitative languages, Weighted automata, quantitative language, number theory, transition weight]
Computation and the Periodic Table
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
In physics, Feynman diagrams are used to reason about quantum processes. Similar diagrams can also be used to reason about logic, where they represent proofs, and computation, where they represent programs. With the rise of topological quantum field theory and quantum computation, it became clear that diagrammatic reasoning takes advantage of an extensive network of interlocking analogies between physics, topology, logic and computation. These analogies can be made precise using the formalism of symmetric monoidal closed categories. But symmetric monoidal categories are just the n=l,fc=3 entry of a hypothesized "periodic table" of fc-tuply monoidal n- categories. This raises the question of how these analogies extend. An important clue comes from the way symmetric monoidal closed 2-categories describe rewrite rules in the lambda calculus and multiplicative intuitionistic linear logic. This talk is based on work in progress with Paul-Andre Mellies and Mike Stay.
[multiplicative intuitionistic linear logic, Mathematics, Calculus, periodic table, Quantum computing, Network topology, quantum process, Physics computing, USA Councils, Computer networks, Logic, quantum computation, lambda calculus, periodic system of elements, topological quantum field theory, Computer science, group theory, symmetric monoidal closed category, interlocking analogy, Quantum mechanics, quantum computing, diagrammatic reasoning, quantum field theory, Feynman diagrams, Feynman diagram]
The Structure of First-Order Causality
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
Game semantics describe the interactive behavior of proofs by interpreting formulas as games on which proofs induce strategies. Such a semantics is introduced here for capturing dependencies induced by quantifications in first-order prepositional logic. One of the main difficulties that has to be faced during the elaboration of this kind of semantics is to characterize definable strategies, that is strategies which actually behave like a proof. This is usually done by restricting the model to strategies satisfying subtle combinatorial conditions, whose preservation under composition is often difficult to show. Here, we present an original methodology to achieve this task, which requires to combine advanced tools from game semantics, rewriting theory and categorical algebra. We introduce a diagrammatic presentation of the monoidal category of definable strategies of our model, by the means of generators and relations: those strategies can be generated from a finite set of atomic strategies and the equality between strategies admits a finite axiomatization, this equational structure corresponding to a polarized variation of the notion of bialgebra. This work thus bridges algebra and denotational semantics in order to reveal the structure of dependencies induced by first-order quantifiers, and lays the foundations for a mechanized analysis of causality in programming languages.
[finite axiomatization, Polarization, first-order causality structure, diagrammatic presentation, polygraph, monoidal category, Algebra, proof interactive behavior, theorem proving, Logic, combinatorial condition, rewriting systems, program diagnostics, rewriting theory, programming language analysis, first-order quantifier, categorical algebra, programming language semantics, game semantics, Game theory, Equations, Computer science, Bridges, group theory, Computer languages, bialgebra, process algebra, first-order prepositional logic, presentation of a category, category theory]
The Inverse Taylor Expansion Problem in Linear Logic
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
Linear Logic is based on the analogy between algebraic linearity (i.e. commutation with sums and with products with scalars) and the computer science linearity (i.e. calling inputs only once). Keeping on this analogy, Ehrhard and Regnier introduced Differential Linear Logic(DiLL) - an extension of Multiplicative Exponential Linear Logic with differential constructions. In this setting, promotion (the logical exponentiation) can be approximated by a sum of promotion-free proofs f DiLL via Taylor expansion. We present a constructive way to revert Taylor expansion. Precisely, we define merging reduction - a rewriting system which merges a finite sum of DiLL proofs into a proof with promotion whenever the sum is an approximation of the Taylor expansion of this proof. We prove that this algorithm is sound, complete and can be run in non-deterministic polynomial time.
[computer science linearity, multiplicative exponential linear logic, Merging, Linear Logic, differential linear logic, formal logic, Runtime, Differential interaction nets, Logic functions, Polynomials, inverse Taylor expansion problem, Rewriting systems, rewriting system, rewriting systems, polynomials, Taylor series, Vectors, Functional analysis, merging reduction, Computer science, Algorithms, Denotational semantics, Linearity, nondeterministic polynomial time, algebraic linearity]
On the Computational Complexity of Verifying One-Counter Processes
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
One-counter processes are pushdown systems over a singleton stack alphabet (plus a stack-bottom symbol). We study the complexity of two closely related verification problems over one-counter processes: model checking with the temporal logic EF, where formulas are given as directed acyclic graphs, and weak bisimilarity checking against finite systems. We show that both problems are PNP-complete. This is achieved by establishing a close correspondence with the membership problem for a natural fragment of Presburger arithmetic, which we show to be PNP-complete. This fragment is also a suitable representation for the global versions of the problems. We also show that there already exists a fixed EF formula(resp. a fixed finite system) such that model checking (resp. weak bisimulation) over one-counter processes is hard for PNP[log]. However, the complexity drops to P if the one-counter process is fixed.
[temporal logic, weak bisimilarity checking, Counting circuits, Model Checking, formal verification, Automatic control, Polynomials, directed acyclic graphs, Logic, Personal digital assistants, Computational Complexity, singleton stack alphabet, PNP-complete, Computational complexity, Presburger arithmetic, finite systems, Computer science, Upper bound, model checking, one-counter process verification, directed graphs, Bisimulation, Automata, Arithmetic, computational complexity]
Co-ing B&#x0FC;chi Made Tight and Useful
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We solve the longstanding open problems of the blowup involved in the translations (when possible) of a nondeterministic Buchi word automaton (NBW) to a nondeterministic co-Buchi word automaton (NCW) and to a deterministic co-Buchi word automaton (DCW). For the NBW to NCW translation, the currently known upper bound is 2O(n log n) and the lower bound is 1.5n. We improve the upper bound to n2n and describe a matching lower bound of 2Omega(n). For the NBW to DCW translation, the currently known upper bound is 2O(m log n). We improve it to 2O(n), which is asymptotically tight. Both of our upper-bound constructions are based on a simple subset construction, do not involve intermediate automata with richer acceptance conditions, and can be implemented symbolically. We point to numerous applications of the new constructions. In particular, they imply a simple subset-construction based translation (when possible) of LTL to deterministic Buchi word automata.
[finite automata, LTL, temporal logic, linear temporal logic, Buchi, Sugar industry, Mathematics, Application software, subset construction based translation, Computer science, Upper bound, deterministic co-Buchi word automaton, deterministic automata, Automata, translations, upper-bound construction, nondeterministic co-Buchi word automaton, co-Buchi, Logic, computational complexity]
Wreath Products of Forest Algebras, with Applications to Tree Logics
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We use the recently developed theory of forest algebras to find algebraic characterizations of the languages of unranked trees and forests definable in various logics. These include the temporal logics CTL and EF, and first-order logic over the ancestor relation. While the characterizations are in general non-effective, we are able to use them to formulate necessary conditions for definability and provide new proofs that a number of languages are not definable in these logics.
[forest algebras, trees (mathematics), first-order logic, temporal logic, Educational institutions, temporal logics, Application software, wreath products, Computer science, Sufficient conditions, Algebra, Automata, Logic functions, Page description languages, tree logics]
Dinatural Terms in System F
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We provide in this article two characterisation results, describing exactly which terms verify the dinaturality diagram, in Church-style system F and in Curry-style system F. The proof techniques we use here are purely syntactic, giving in particular a direct construction of the two terms generated by the dinaturality diagram. But the origin of these techniques lies in fact directly on the analysis of system F through game semantics. Thus, this article provides an example of backward engineering, where powerful syntactic results can be extracted from a semantic analysis.
[lambda calculus, Game semantics, Parametricity, game theory, Dinaturality, Calculus, dinaturality diagram, game semantics, Church-style system F, Computer science, Character generation, Curry-style system F, Second-order logic, Logic, Power engineering and energy]
Indexed Containers
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We show that the syntactically rich notion of inductive families can be reduced to a core type theory with a fixed number of type constructors exploiting the novel notion of indexed containers. Indexed containers generalize simple containers, capturing strictly positive families instead of just strictly positive types, without having to extend the core type theory. Other applications of indexed containers include data type-generic programming and reasoning about polymorphic functions. The construction presented here has been formalized using the Agda system.
[Shape, data type-generic reasoning, polymorphic functions, Agda system, functional programming, inductive families, data type-generic programming, Containers, Programming, genetic algorithms, indexed containers, Data mining, Reactive power, Algebra, Probability density function, Type Theory, core type theory]
Functional Reachability
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
What is reachability in higher-order functional programs? We formulate reachability as a decision problem in the setting of the prototypical functional language PCF, and show that even in the recursion-free fragment generated from a finite base type, several versions of the reachability problem are undecidable from order 4 onwards, and several other versions are reducible to each other. We characterise a version of the reachability problem in terms of a new class of tree automata introduced by Stirling at FoSSaCS 2009, called Alternating Dependency Tree Automata (ADTA). As a corollary, we prove that the ADTA non-emptiness problem is undecidable, thus resolving an open problem raised by Stirling. However, by restricting to contexts constructible from a finite set of variable names, we show that the corresponding solution set of a given instance of the reachability problem is regular. Hence the relativised reachability problem is decidable.
[Software testing, decision problem, automata theory, functional programming, alternating dependency tree automata, Software safety, prototypical functional language, Simultaneous localization and mapping, decidability, higher-order functional program, Prototypes, Polynomials, Software standards, recursion-free fragment, Logic, formal languages, reachability analysis, functional reachability, trees (mathematics), higher-order computation, game semantics, Reachability, Computer science, PCF, undecidable, Automata, Computer industry, functional languages]
Statistic Analysis for Probabilistic Processes
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We associate a statistical vector to a trace and a geometrical embedding to a Markov decision process, based on a distance on words, and study basic membership and equivalence problems. The membership problem for a trace w and a Markov decision process S decides if there exists a strategy on S which generates with high probability traces close to w. We prove that membership of a trace is testable and equivalence of MDPs is polynomial time approximable. For probabilistic automata, membership is not testable, and approximate equivalence is undecidable. We give a class of properties, based on results concerning the structure of the tail sigma-field of a finite Markov chain, which characterizes equivalent Markov decision processes in this context.
[System testing, decision theory, State Action frequency, tail sigma-field, probabilistic trace, statistical vector, equivalence problem, probabilistic automata, decidability, Tail, membership problem, Polynomials, bisimulation equivalence, statistic analysis, polynomial time approximable, Higher order statistics, Markov Decision Processes, Statistical analysis, Approximation, Probabilistic logic, property testing, undecidability, Property Testing, Computer science, Automatic testing, Automata, tail sigma field, Markov processes, Frequency, Markov decision process, finite Markov chain, statistical analysis, geometrical embedding, computational complexity, Probabilistic Automata]
Quantitative Model Checking of Continuous-Time Markov Chains Against Timed Automata Specifications
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We study the following problem: given a continuous-time Markov chain (CTMC) C, and a linear real-time property provided as a deterministic timed automaton (DTA) A, what is the probability of the set of paths of C that are accepted by A (C satisfies A)? It is shown that this set of paths is measurable and computing its probability can be reduced to computing the reachability probability in a piecewise deterministic Markov process (PDP). The reachability probability is characterized as the least solution of a system of integral equations and is shown to be approximated by solving a system of partial differential equations. For the special case of single-clock DTA, the system of integral equations can be transformed into a system of linear equations where the coefficients are solutions of ordinary differential equations.
[piecewise deterministic Markov process, quantitative model checking, Partial differential equations, Stochastic processes, temporal logic, continuous stochastic logic, reachability probability, set theory, formal specification, single-clock DTA, formal verification, deterministic automata, temporal logic CSL, Integral equations, CTMC, path set, continuous time systems, linear real-time property, polynomial-time algorithm, PDP, timed CTL, linear differential equations, continuous-time Markov chain, reachability analysis, Biological system modeling, probability, ordinary differential equation, linear equation, Probabilistic logic, partial differential equation, integral equations, Stochastic systems, deterministic timed automaton specification, integral equation, Automata, Differential equations, Markov processes, partial differential equations, Clocks, computational complexity]
Qualitative Determinacy and Decidability of Stochastic Games with Signals
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We consider the standard model of finite two person zero sum stochastic games with signals. We are interested in the existence of almost surely winning or positively winning strategies, under reachability, safety, Buchi or co-Buchi winning objectives. We prove two qualitative determinacy results. First, in a reachability game either player 1 can achieve almost-surely the reachability objective, or player 2 can ensure surely the complementary safety objective, or both players have positively winning strategies. Second, in a Buchi game if player 1 cannot achieve almost-surely the Buchi objective, then player 2 can ensure positively the complementary co-Buchi objective. We prove that players only need strategies with finite memory, whose sizes range from no memory at all to doubly-exponential number of states, with matching lower bounds. Together with the qualitative determinacy results, we also provide fix point algorithms for deciding which player has an almost surely winning or a positively winning strategy and for computing the finite memory strategy. Complexity ranges from EXPTIME to 2-EXPTIME with matching lower bounds, and better complexity can be achieved for some special cases where one of the players is better informed than her opponent.
[reachability analysis, Stochastic processes, common-sense reasoning, Control systems, qualitative determinacy, finite memory, matching lower bound, Game theory, reachability objective, Computer science, fix point algorithms, winning strategy, Stochastic games, signals, Stochastic systems, imperfect information, Open systems, Control system synthesis, Safety, Logic, Monitoring, stochastic games]
Combining Ehrenfeucht-Fra&#x0EF;ss&#x0E9; Games
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
Ehrenfeucht-Fraisse games are a useful technique for proving inexpressibility results in first-order logic. Strategies for a few basic games (on long paths, set-powerset structures and random graphs, to name a few) can be used as building blocks for strategies in more complicated games. In this talk, the author discusses a few general methods for combining strategies. Applications include results on the expressive power of successor-invariant logic and k-variable logic.
[Computer science, formal logic, k-variable logic, USA Councils, Ehrenfeucht-Fraisse game, Laboratories, first-order logic, game theory, Logic, Artificial intelligence, successor-invariant logic]
Winning Concurrent Reachability Games Requires Doubly-Exponential Patience
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We exhibit a deterministic concurrent reachability game PURGATORY<sub>n</sub> with n non-terminal positions and a binary choice for both players in every position so that any positional strategy for Player 1 achieving the value of the game within given isin &lt; 1/2 must use non-zero behavior probabilities that are less than (isin2/(1 - isin))2n-2 . Also, even to achieve the value within say 1 - 2-n/2, doubly exponentially small behavior probabilities in the number of positions must be used. This behavior is close to worst case: We show that for any such game and 0 &lt; isin &lt; 1/2, there is an isin-optimal strategy with all non-zero behavior probabilities being 20(n) at least isin2O(n). As a corollary to our results, we conclude that any (deterministic or nondeterministic) algorithm that given a concurrent reachability game explicitly manipulates isin-optimal strategies for Player 1 represented in several standard ways (e.g., with binary representation of probabilities or as the uniform distribution over a multiset) must use at least exponential space in the worst case.
[reachability analysis, concurrent reachability games, game theory, Mathematics, Probability distribution, PURGATORY<sub>n</sub>, History, Computer science, isin-optimal strategy, Tail, nonzero behavior probabilities, Logic, doubly-exponential patience, computational complexity]
Graded Computation Tree Logic
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
In modal logics, graded (world) modalities have been deeply investigated as a useful framework for generalizing standard existential and universal modalities in such a way that they can express statements about a given number of immediately accessible worlds. These modalities have been recently investigated with respect to the mu-calculus, which have provided succinctness, without affecting the satisfiability of the extended logic, i.e., it remains solvable in ExpTime. A natural question that arises is how logics that allow reasoning about paths could be affected by considering graded path modalities. In this paper, we investigate this question in the case of the branching-time temporal logic CTL (GCTL, for short). We prove that, although GCTL is more expressive than CTL, the satisfiability problem for GCTL remains solvable in ExpTime. This result is obtained by exploiting an automata-theoretic approach. In particular, we introduce the class of partitioning alternating Buumlchi tree automata and show that the emptiness problem for them is ExpTime-Complete. The satisfiability result turns even more interesting as we show that GCTL is exponentially more succinct than graded mu-calculus.
[automata theory, Automatic logic units, computability, temporal logic, graded computation tree logic, satisfiability, branching-time temporal logic, Temporal logics, modal logics, trees (mathematics), automata-theoretic approach, Multitasking, graded path modality, Computational complexity, Computer science, mu-calculus, ExpTime solvability, Buumlchi tree automata, Processor scheduling, process algebra, Automata, conservativeness, minimality, graded modalities, computational complexity]
A Unified Sequent Calculus for Focused Proofs
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We present a compact sequent calculus LKU for classical logic organized around the concept of polarization. Focused sequent calculi for classical logic, intuitionistic logic, and multiplicative-additive linear logic are derived as fragments of LKU by increasing the sensitivity of specialized structural rules to polarity information. We develop a unified, streamlined framework for proving cut-elimination in the various fragments. Furthermore, each sublogic can interact with other fragments through cut. We also consider the possibility of introducing classical-linear hybrid logics.
[Polarization, focused proofs, Logic programming, linear logic, intuitionistic logic, Aerodynamics, Control systems, Calculus, focused sequent calculi, multiplicative-additive linear logic, Application software, calculus, Computer science, formal logic, Computer languages, USA Councils, LKU, Pulse inverters, theorem proving, unified sequent calculus, Proof theory, focused proof systems, classical logic]
Non-linear Rewrite Closure and Weak Normalization
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
A rewrite closure is an extension of a term rewrite system with new rules, usually deduced by transitivity. Rewrite closures have the nice property that all rewrite derivations can be transformed into derivations of a simple form. This property has been useful for proving decidability results in term rewriting. Unfortunately, when the term rewrite system is not linear, the construction of a rewrite closure is quite challenging. In this paper, we construct a rewrite closure for term rewrite systems that satisfy two properties: the right-hand side term in each rewrite rule contains no repeated variable (right-linear) and contains no variable at depth greater than one (right-shallow). The left-hand side term is unrestricted, and in particular, it may be non-linear. As a consequence of the rewrite closure construction, we are able to prove decidability of the weak normalization problem for right-linear right-shallow term rewrite systems. Proving this result also requires tree automata theory. We use the fact that right-shallow right-linear term rewrite systems are regularity preserving. Moreover, their set of normal forms can be represented with a tree automaton with disequality constraints, and emptiness of this kind of automata, as well as its generalization to reduction automata, is decidable.
[rewriting systems, term rewriting, Computational modeling, automata theory, weak normalization, trees (mathematics), tree automata theory, Large scale integration, rewrite closure construction, Equations, Computer science, nonlinear rewrite closure, decidability, right-linear right-shallow term rewrite system, Automata, Linearity, tree automata, Logic, Informatics, rewrite closure]
Ludics with Repetitions (Exponentials, Interactive Types and Completeness)
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We prove that is possible to extend Girard's Ludics so as to have repetitions (hence exponentials), and still have the results on semantical types which characterize Ludics in the panorama of Game Semantics. The results are obtained by using less structure than in the original paper; this has an interest on its own, and we hope that it will open the way to applying the approach of Ludics to a larger domain.
[Additives, Logic programming, linear logic, game theory, Interactive types, Calculus, game semantics, Linear Logic, Ludics, Computer science, formal logic, Game Semantics, Automata, Linearity, System recovery, interactive type, Testing]
Trichotomy in the Complexity of Minimal Inference
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We study the complexity of the propositional minimal inference problem. Its complexity has been extensively studied before because of its fundamental importance in artificial intelligence and nonmonotonic logics. We prove that the complexity of the minimal inference problem with unbounded queries has a trichotomy (between P, coNP-complete, and Pi<sub>2</sub>P-complete). This result finally settles with a positive answer the trichotomy conjecture of Kirousis and Kolaitis[A dichotomy in the complexity of propositional circumscription, LICS'01] in the unbounded case. We also present simple and efficiently computable criteria separating the different cases.
[propositional minimal inference problem, Logic programming, Laboratories, Cloning, Lattices, inference mechanisms, Pi<sub>2</sub>P-complete, artificial intelligence, Computer science, minimal inference complexity, optimisation, Complete classification of complexity, nonmonotonic logics, between P, Councils, Minimal inference, Virtual reality, coNP-complete, Inference algorithms, Polynomials, trichotomy conjecture, Artificial intelligence, computational complexity]
A Logic for PTIME and a Parameterized Halting Problem
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
In the work of Nash et al. (2005) have raised the question whether a logic L<sub>les</sub>, already introduced by Gurevich in 1988, captures polynomial time, and they give a reformulation of this question in terms of a parameterized halting problem p-Acc<sub>les</sub> for nondeterministic Turing machines. We analyze the precise relationship between L<sub>les</sub> and p-Acc<sub>les</sub>. We show that p-Acc<sub>les</sub> is not fixed-parameter tractable if "P ne NP holds for all time constructible and increasing functions.'' Moreover, a slightly stronger complexity theoretic hypothesis implies that L<sub>les</sub> does not capture polynomial time. Furthermore, we analyze the complexity of various variants of p-Acc<sub>les</sub> and address its construction problem.
[Algorithm design and analysis, Terminology, computability, Complexity theory, Computer science, complexity theoretic hypothesis, Turing machines, PTIME, Polynomials, Concrete, polynomial time, logic, parameterized halting problem, Logic, Context modeling, computational complexity, nondeterministic Turing machine]
A Note on the Complexity of the Satisfiability Problem for Graded Modal Logics
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
Graded modal logic is the formal language obtained from ordinary modal logic by endowing its modal operators with cardinality constraints. Under the familiar possible-worlds semantics, these augmented modal operators receive interpretations such as "It is true at no fewer than 15 accessible worlds that ...\
[formal languages, transitive frames, Laboratories, modal operators, Formal languages, cardinality constraints, Turning, Euclidean property, modal logic, Computational complexity, complexity bounds, Computer science, formal logic, graded modal logic formula, tree-model property, Polynomials, Logic, graded modalities, computational complexity, formal language]
The Complexity of Global Cardinality Constraints
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
In a constraint satisfaction problem (CSP) the goal is to find an assignment of a given set of variables subject to specified constraints. A global cardinality constraint is an additional requirement that prescribes how many variables must be assigned a certain value. We study the complexity of the problem CCSP(Gamma), the constraint satisfaction problem with global cardinality constraints that allows only relations from the set Gamma. The main result of this paper characterizes sets Gamma that give rise to problems solvable in polynomial time, and states that the remaining such problems are NP-complete.
[complexity, cardinality constraints, constraint satisfaction problem, global cardinality constraints complexity, Equations, Computer science, NP-complete problems, Constraint theory, Polynomials, polynomial time, Logic, constraint handling, computational complexity]
The Complexity of Positive First-order Logic without Equality
2009 24th Annual IEEE Symposium on Logic In Computer Science
None
2009
We study the complexity of evaluating positive equality-free sentences of first-order (FO) logic over a fixed, finite structure B. This may be seen as a natural generalisation of the non-uniform quantified constraint satisfaction problem QCSP(B). We introduce subjective hyper-endomorphisms and use them in proving a Galois connection that characterises definability in positive equality-free FO. Through an algebraic method, we derive a complete complexity classification for our problems as B ranges over structures of size at most three. Specifically, each problem is either in Logspace, is NP-complete, is coNP-complete or is Pspace-complete.
[Terminology, constraint theory, Displays, Galois fields, Computer science, formal logic, nonuniform quantified constraint satisfaction problem, Galois connection, Resists, coNP-complete, subjective hyper-endomorphism, complexity classification, positive equality-free first-order logic, Logic, algebraic method, logspace, Pspace-complete, computational complexity, Computational Complexity]
Foreword
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.
[]
Conference organization
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Provides a listing of current committee members and society officers.
[]
Querying the Guarded Fragment
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Evaluating a boolean conjunctive query q over a guarded first-order theory T is equivalent to checking whether (T &amp; not q) is unsatisfiable. This problem is relevant to the areas of database theory and description logic. Since q may not be guarded, well known results about the decidability, complexity, and finite-model property of the guarded fragment do not obviously carry over to conjunctive query answering over guarded theories, and had been left open in general. By investigating finite guarded bisimilar covers of hypergraphs and relational structures, and by substantially generalising Rosati's finite chase, we prove for guarded theories T and (unions of) conjunctive queries q that (i) T implies q iff T implies q over finite models, that is, iff q is true in each finite model of T and (ii) determining whether T implies q is 2EXPTIME-complete. We further show the following results: (iii) the existence of polynomial-size conformal covers of arbitrary hypergraphs; (iv) a new proof of the finite model property of the clique-guarded fragment; (v) the small model property of the guarded fragment with optimal bounds; (vi) a polynomial-time solution to the canonisation problem modulo guarded bisimulation, which yields (vii) a capturing result for guarded-bisimulation-invariant PTIME.
[Context, descriptive complexity, relational structures, boolean conjunctive query q, Complexity theory, Construction industry, database theory, query processing, description logic, Databases, decidability, guarded first-order theory T, conjunctive queries, hypergraphs, guarded fragment, Games, Controllability, Polynomials, finite model theory, hypergraph covers, computational complexity]
Highly Acyclic Groups, Hypergraph Covers and the Guarded Fragment
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We construct finite groups whose Cayley graphs have large girth even w.r.t. a discounted distance measure that contracts arbitrarily long sequences of edges from the same colour class, and only counts transitions between colour classes. These groups are shown to be useful in the construction of finite bisimilar hypergraph covers that avoid any small cyclic configurations. We present two applications to the finite model theory of the guarded fragment: a strengthening of the known finite model property for GF and the characterisation of GF as the guarded bisimulation invariant fragment of FO in the sense of finite model theory.
[Merging, graph theory, Color, Length measurement, Generators, Zinc, Construction industry, group theory, hypergraphs, guarded fragment, acyclicity, Book reviews, Cayley graphs, finite model theory, guarded bisimulation invariant fragment, acyclic groups, finite bisimilar hypergraph covers]
Equality Is Typable in Semi-full Pure Type Systems
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
There are two usual ways to describe equality in a dependent typing system, one that uses an external notion of computation like beta-reduction, and one that introduces a typed judgement of beta-equality directly in the typing system. After being an open problem for some time, the general equivalence between both approaches has been solved by Adams for a class of pure type systems (PTSs) called functional. In this paper, we relax the functionality constraint and prove the equivalence for all semi-full PTSs by combining the ideas of Adams with a study of the general shape of types in PTSs. As one application, an extension of this result to systems with sub-typing would be a first step toward bringing closer the theory behind a proof assistant such as Coq to its implementation.
[Context, Judgmental Equality, Shape, semifull pure type systems, Switches, Diamond-like carbon, Calculus, Pure Type Systems, dependent typing system, Construction industry, functionality constraint, formal logic, theorem proving, proof assistant, Manganese]
Strong Normalization for System F by HOAS on Top of FOAS
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We present a point of view concerning HOAS(Higher-Order Abstract Syntax) and an extensive exercise in HOAS along this point of view. The point of view is that HOAS can be soundly and fruitfully regarded as a definitional extension on top of FOAS (First-Order Abstract Syntax). As such, HOAS is not only an encoding technique, but also a higher-order view of a first-order reality. A rich collection of concepts and proof principles is developed inside the standard mathematical universe to give technical life to this point of view. The exercise consists of a new proof of Strong Normalization for System F. The concepts and results presented here have been formalized in the theorem prover Isabelle/HOL.
[Context, first-order abstract syntax, computational linguistics, Isabelle-HOL theorem prover, Encoding, Cognition, Higher-Order Abstract Syntax, Equations, Construction industry, Isabelle/HOL, higher-order abstract syntax, System F, Syntactics, HOAS, FOAS, theorem proving]
Game Semantics for a Polymorphic Programming Language
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
A fully abstract game semantics for an idealized programming language with local state and higher rank polymorphism - System F extended with general references - is described. It quite concrete, and extends existing games models by a simple development of the existing question/answer labelling to represent "copycat links" between positive and negative occurrences of type variables, using a notion of scoping for question moves. It is effectively presentable, opening the possibility of extending existing model checking techniques to polymorphic types, for example. It is also a novel example of a model of System F with the genericity property. We prove definability of finite elements, and thus a full abstraction result, using a decomposition argument. This also establishes that terms may be approximated up to observational equivalence when instantiation is restricted to tuples of type variables.
[Context, polymorphic programming language, Law, question-answer labelling, Object oriented modeling, model checking techniques, game theory, polymorphism, programming language semantics, game semantics, Computer languages, general references, formal verification, Semantics, System F, genericity, Games]
Amir Pnueli: A Gentle Giant, Lord of the Phi's and the Psi's
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
The following topics are dealt with: finite model theory; logic and automata; semantics; process calculi; and coalgebras.
[Computer science, semantic, coalgebras, Engineering profession, automata theory, process algebra, Semantics, finite model theory, logic, programming language semantics, automata, process calculi]
Robin Milner, a Craftsman of Tools for the Mind
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
The paper discusses about the programming language ML (or MetaLanguage) as a language for manipulating formal systems. It has also had much influence on the further development of functional programming languages.
[Concurrent computing, Computer languages, formal system manipulation, Semantics, meta language, functional programming language, Syntactics, Calculus, programming languages, ML language, Business]
Alternating Timed Automata over Bounded Time
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Alternating timed automata are a powerful extension of classical Alur-Dill timed automata that are closed under all Boolean operations. They have played a key role, among others, in providing verification algorithms for prominent specification formalisms such as Metric Temporal Logic. Unfortunately, when interpreted over an infinite dense time domain (such as the reals), alternating time automata have an undecidable language emptiness problem. The main result of this paper is that, over bounded time domains, language emptiness for alternating timed automata is decidable (but nonelementary). The proof involves showing decidability of a class of parametric McNaughton games that are played over timed words and that have winning conditions expressed in the monadic logic of order augmented with the distance-one relation. As a corollary, we establish the decidability of the time-bounded model-checking problem for Alur-Dill timed automata against specifications expressed as alternating timed automata.
[Algorithm design and analysis, parametric McNaughton games, automata theory, Laboratories, undecidable language emptiness problem, temporal logic, prominent specification formalisms, Cost accounting, monadic logic, Alternation, verification algorithms, metric temporal logic, alternating timed automata, Boolean operations, Time domain analysis, Church's Problem, classical Alur-Dill timed automata, infinite dense time domain, time-bounded model-checking problem, bounded time domains, Automata, Games, distance-one relation, Clocks, Timed Automata]
Regular Cost Functions over Finite Trees
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We develop the theory of regular cost functions over finite trees: aquantitative extension to the notion of regular languages of trees: Cost functions map each input (tree) to a value in &#x03C9; + 1, and are considered modulo an equivalence relation which forgets about specific values, but preserves boundedness of functions on all subsets of the domain. We introduce nondeterministic and alternating finite tree cost automata for describing cost functions. We show that all these forms of automata are effectively equivalent. We also provide decision procedures for them. Finally, following Bu&#x0308;chi's seminal idea, we use cost automata for providing decision procedures for cost monadic logic, a quantitative extension of monadic second order logic.
[Context, formal languages, finite automata, Radiation detectors, trees (mathematics), limitedness problem, costing, regular language, Integrated circuits, cost monadic logic, finite tree cost automata, Semantics, Automata, Games, monadic-second order logic, cost function, decision procedures, games, Cost function, monadic second order logic, tree automata]
Parikh Images of Grammars: Complexity and Applications
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Parikh's Theorem states that semilinear sets are effectively equivalent with the Parikh images of regular languages and those of context-free languages. In this paper, we study the complexity of Parikh's Theorem over any fixed alphabet size d. We prove various normal form the oremsin the case of NFAs and CFGs. In particular, the normalform theorems ensure that a union of linear sets with dgenerators suffice to express such Parikh images, which in the case of NFAs can further be computed in polynomial time. We then apply apply our results to derive: (1) optimal complexity for decision problems concerning Parikh images(e.g. membership, universality, equivalence, and disjointness), a new polynomial fragment of integer programming, an answer to an open question about PAC-learnability of semilinear sets, and an optimal algorithm for verifying LTL over discrete-timed reversal-bounded counter systems.
[Neodymium, regular languages, Parikh Images, PAC-learnability, Grammar, Complexity theory, set theory, semilinear sets, discrete-timed reversal-bounded counter systems, Parikh theorem, Normal Form, context-free languages, Algorithms, grammars, Automata, Production, optimal complexity, Polynomials, Skeleton, Parikh images, Grammars, computational complexity]
On the Scope of the Universal-Algebraic Approach to Constraint Satisfaction
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
The universal-algebraic approach has proved a powerful tool in the study of the computational complexity of constraint satisfaction problems (CSPs). This approach has previously been applied to the study of CSPs with finite or (infinite) &#x03C9;-categorical templates. Our first result is an exact characterization of those CSPs that can be formulated with (a finite or) an &#x03C9;-categorical template. The universal-algebraic approach relies on the fact that in finite or &#x03C9;-categorical structures A, a relation is primitive positive definable if and only if it is preserved by the polymorphisms of A. In this paper, we present results that can be used to study the computational complexity of CSPs with arbitrary infinite templates. Specifically, we prove that every CSP can be formulated with a template A such that a relation is primitive positive definable in A if and only if it is first-order definable on A and preserved by the infinitary polymorphisms of A. We present applications of our general results to the description and analysis of the computational complexity of CSPs. In particular, we present a polymorphism-based description of those CSPs that are first-order definable (and therefore can be solved in polynomial-time), and give general hardness criteria based on the absence of polymorphisms that depend on more than one argument.
[Galois Connection, constraint theory, Cloning, universal-algebraic approach, Orbits, Indexes, Computational complexity, Construction industry, &#x03C9;-categorical template, constraint satisfaction problems, Model Theory, process algebra, arbitrary infinite templates, Bismuth, polynomial-time, Constraint Satisfaction, computational complexity]
New Conditions for Taylor Varieties and CSP
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We provide two new characterizations for finitely generated varieties with Taylor terms. The first characterization is using "absorbing sets" and the second one "cyclic operations". These new conditions allow us to reprove the conjecture of Bang-Jensen and Hell (proved by the authors, comp. STOC'08, SICOMP'09) and the characterization of locally finite Taylor varieties using weak near-unanimity operations (proved by McKenzie and Maroti, Alg.Univ. 2009) in an elementary and self-contained way. The research is closely connected to the algebraic approach to CSP and previous results obtained by authors using similar tools [comp. STOC'08, SICOMP'09, FOCS'09 etc.].
[Context, cyclic operation, CSP, Taylor term, Constraint Satisfaction Problem, constraint theory, constraint satisfaction problem, algebra, Complexity theory, Indexes, algebraic approach, Algebra, Absorption, Polynomials, Taylor conditions]
The Fine Print of Security
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Summary form only given. Simple views of systems are often convenient in their design and analysis. However, attackers may attempt to exploit any oversimplification. For security, it is therefore useful to understand the value and the limitations of simplistic models. Computational-soundness theorems, which are the main subject of this lecture, can sometimes shed light on this question. We discuss them first in the context of security protocols. There, two distinct, rigorous views of cryptography have developed over the years. One of the views relies on a simple but powerful symbolic approach; the other, on a detailed computational model that considers issues of probability and complexity. In the last decade, however, we have made substantial progress in bridging the gap between these views. This progress, of which a paper with Phil Rogaway was one of the early steps, is due to many researchers. By now, this line of work provides computational justifications for formal treatments of cryptographic operations and security protocols, and also explores hybrid approaches. Similar ideas can apply in the domain of software protection, although they are less mature in this domain. Specifically, we can relate high-level security guarantees, of the kind offered by programming-language semantics, with lower-level properties of implementations. Layout randomization, one popular and effective implementation technique, again brings up issues of probability and complexity. The lecture introduces some recent work with Gordon Plotkin on this topic.
[software protection, Protocols, cryptographic protocols, Computational modeling, cryptographic operations, probability, computational-soundness theorems, Complexity theory, programming language semantics, security protocols, Semantics, Silicon, Cryptography, programming-language semantics, layout randomization]
Modular Construction of Fixed Point Combinators and Clocked B&#x0F6;hm Trees
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Fixed point combinators (and their generalization: looping combinators) are classic notions belonging to the heart of &#x03BB;-calculus and logic. We start with an exploration of the structure of fixed point combinators (fpc's), vastly generalizing the wellknown fact that if Yis an fpc, Y(SI) is again an fpc, generating the Bo&#x0308;hm sequence of fpc's. Using the infinitary &#x03BB;-calculus we devise infinitely many other generation schemes for fpc's. In this way we find schemes and building blocks to construct new fpc's in a modular way. Having created a plethora of new fixed point combinators, the task is to prove that they are indeed new. That is, we have to prove their &#x03B2;-inconvertibility. Known techniques via Bo&#x0308;hm Trees do not apply, because all fpc's have the same Bo&#x0308;hm Tree (BT). Therefore, we employ 'clocked BT's', with annotations that convey information of the tempo in which the data in the BT are produced. BT's are thus enriched with an intrinsic clock behaviour, leading to a refined discrimination method for &#x03BB;-terms. The corresponding equality is strictly intermediate between =<sub>&#x03B2;</sub> and =<sub>BT</sub>, the equality in the classical models of &#x03BB;-calculus. An analogous approach pertains to Le&#x0301;vy-Longo and Berarducci trees. Finally, we increase the discrimination power by a precision of the clock notion that we call 'atomic clock'.
[lambda calculus, clocked Bo&#x0308;hm trees, trees (mathematics), fixed point combinators, atomic clock, Birds, Calculus, atomic clocks, Equations, Atomic clocks, &#x03BB;-calculus, looping combinators, Tin, Silicon]
Recursion Schemes and Logical Reflection
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Let R be a class of generators of node-labelled infinite trees, and Lbe a logical language for describing correctness properties of the setrees. Given r in R and phi in L, we say that r_phi is aphi-reflection of r just if (i) r and r_phi generate the same underlying tree, and (ii) suppose a node u of the tree t(r) generated by r has label f, then the label of the node u of t(r_phi) is f* if uin t(r) satisfies phi; it is f otherwise. Thus if t(r) is the computation tree of a program r, we may regard r_phi as a transform of R that can internally observe its behaviour against a specification phi. We say that R is (constructively) reflective w.r.t. L just if there is an algorithm that transforms a given pair (r,phi) to r_phi. In this paper, we prove that higher-order recursion schemes are reflective w.r.t. both modal mu-calculus and monadic second order(MSO) logic. To obtain this result, we give the first characterisation of the winning regions of parity games over the transition graphs of collapsible pushdown automata (CPDA): they are regular sets defined by a new class of automata. (Order-n recursion schemes are equi-expressive with order-n CPDA for generating trees.) As a corollary, we show that these schemes are closed under the operation of MSO-interpretation followed by tree unfolding a la Caucal.
[program control structures, trees (mathematics), Transforms, pushdown automata, higher order recursion scheme, transforms, tree, Generators, Calculus, μ-calculus, Monadic Second Order Logic and Mu-Calculus Global model checking, logical language, transform, Parity Games, Recursion Schemes, Semantics, Automata, Games, Syntactics, monadic second order logic, Collapsible Pushdown Automata, automata, collapsible pushdown automata]
Undecidability of Propositional Separation Logic and Its Neighbours
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Separation logic has proven an effective formalism for the analysis of memory-manipulating programs. We show that the purely propositional fragment of separation logic is undecidable. In fact, for any choice of concrete heap-like model of separation logic, validity in that model remains undecidable. Besides its intrinsic technical interest, this result also provides new insights into the nature of decidable fragments of separation logic. In addition, we show that a number of propositional systems which approximate separation logic are undecidable as well. In particular, these include both Boolean BI and Classical BI. All of our undecidability results are obtained by means of a single direct encoding of Minsky machines.
[propositional separation logic, Computational modeling, Object oriented modeling, Radiation detectors, bunched logic, Encoding, encoding, Cost accounting, undecidability, Minsky machine, Boolean functions, Classical BI, separation logic, Bismuth, heap models, memory manipulating program, Concrete, Boolean BI]
The Undecidability of Boolean BI through Phase Semantics
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We solve the open problem of the decidability of Boolean BI logic (BBI), which can be considered as the core of separation and spatial logics. For this, we define a complete phase semantics for BBI and characterize it as trivial phase semantics. We deduce an embedding between trivial phase semantics for intuitionistic linear logic (ILL) and Kripke semantics for BBI. We single out a fragment of ILL which is both undecidable and complete for trivial phase semantics. Therefore, we obtain the undecidability of BBI.
[Context, Additives, Boolean BI logic, Neodymium, intuitionistic linear logic, bunched logic, linear logic, Calculus, spatial logic, Boolean functions, phase semantics, decidability, Semantics, Bismuth, Syntactics, Boolean BI, Kripke semantics]
Segal Condition Meets Computational Effects
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Every finitary monad T on the category of sets is described by an algebraic theory whose n-ary operations are the elements of the free algebra Tn generated by n letters. This canonical presentation of the monad (called its Lawvere theory) offers a precious guideline in the search for an intuitive presentation of the monad by generators and relations. Hence, much work has been devoted to extend this correspondence between monads and theories to situations of semantic interest, like enriched categories and countable monads. In this paper, we clarify the conceptual nature of these extended Lawvere theories by investigating the change-of-base mechanisms which underlie them. Our starting point is the Segal condition recently established by Weber for a general notion of monad with arities. Our first step is to establish the Segal condition a second time, by reducing it to the Linton condition which characterizes the algebras of a monad as particular presheavesover the category of free algebras. This reduction is achieved by a relevant change-of-base from the category of interest to its subcategory of arities. This conceptual approach leads us to an abstract notion of Lawvere theory with arities, which extends to every class of arity the traditional correspondence in Set between Lawvere theories and finitary monads. Finally, we illustrate the benefits of Lawvere's ideas by describing how the concrete presentation of the state monad recently formulated by Plotkin and Power is ultimately validated by a rewriting property on sequences of updates and lookups.
[Lawvere theories, higher dimensional algebra, nerve functor, Segal condition, arities subcategory, Generators, Equations, Guidelines, Algebra, finitary monads, process algebra, Semantics, computational effects, Computational effects, monads with arities, category theory, Concrete, algebraic theory, free algebra Tn, finitary monad, state monad, algebraic theories]
The Isomorphism Problem on Classes of Automatic Structures
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Several new undecidability results on isomorphism problems for automatic structures are shown: (i) The isomorphism problem for automatic equivalence relations is &#x03A0;<sub>1</sub>0 -complete, (ii) The isomorphism problem for automatic trees of height n &#x2265; 2 is &#x03A0;<sub>2n-3</sub>0 -complete, (iii) The isomorphism problem for automatic linear orders is not arithmetical.
[Pediatrics, Terminology, automata theory, trees (mathematics), Boolean algebra, isomorphism problem, Construction industry, Human computer interaction, automatic trees, automatic structures, Automata, arithmetical hierarchy, Silicon, isomorphism problems, equivalence classes, automatic equivalence relations]
On the Strictness of the First-Order Quantifier Structure Hierarchy over Finite Structures
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
One of the major interests of finite model theory is to separate the expressive power of different logics or fragments of logics. In this paper, we define a variant of Ehrenfeucht-Frai&#x0308;sse&#x0301; games that characterizes quantifier classes over finite structures and prove that the fragments of first-order logic based on quantifier structures form a strict hierarchy in terms of their expressiveness over finite structures.
[first order quantifier structure, Color, game theory, Ehrenfeucht-Fra&#x0EF;ss&#x0E9; games, DATALOG, History, Ehrenfeucht-Fraisse games, finite structure, Prototypes, Games, quantifier structure, Silicon, finite model theory, Argon, Junctions]
Fixed-Point Definability and Polynomial Time on Graphs with Excluded Minors
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We prove that fixed-point logic with counting captures polynomial time on all classes of graphs with excluded minors. That is, for every class C of graphs such that some graph H is not a minor of any graph in C, a property P of graphs in C is decidable in polynomial time if and only if it is definable in fixed-point logic with counting. Furthermore, we prove that for every class C of graphs with excluded minors there is a k such that the k-dimensional Weisfeiler-Leman algorithm decides isomorphism of graphs in C in polynomial time. The Weisfeiler-Leman algorithm is a combinatorial algorithm for testing isomorphism. It generalises the basic colour refinement algorithm and is much simpler than the known group-theoretic algorithms for deciding isomorphism of graphs with excluded minors. The main technical theorem behind these two results is a "definables tructure theorem" for classes of graphs with excluded minors. It states that graphs with excluded minors can be decomposed into pieces arranged in a treelike structure, together with a linear order of each of the pieces. Furthermore, the decomposition and the linear orders on the pieces are definable in fixed-point logic (without counting).
[Torso, Context, Pediatrics, linear order, fixed point arithmetic, graph theory, Color, descriptive complexity, fixed-point logic, decomposition, graph canonisation, Complexity theory, graph minor theory, fixed point logic, isomorphism, graphs, Weisfeiler-Lehman algorithm, treelike structure, Polynomials, polynomial time, tree data structures, Testing]
Lower Bounds for the Complexity of Monadic Second-Order Logic
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Courcelle's famous theorem from 1990 states that any property of graphs definable in monadic second-order logic (MSO<sub>2</sub>) can be decided in linear time on any class of graphs of bounded tree-width, or in other words, MSO<sub>2</sub> is fixed-parameter tractable in linear time on any such class of graphs. From a logical perspective, Courcelle's theorem establishes a sufficient condition, or an upper bound, for tractability of MSO<sub>2</sub>-model checking. Whereas such upper bounds on the complexity of logics have received significant attention in the literature, almost nothing is known about corresponding lower bounds. In this paper we establish a strong lower bound for the complexity of monadic second-order logic. In particular, we show that if C is any class of graphs which is closed under taking sub-graphs and whose tree-width is not bounded by a poly-logarithmic function (in fact, logc n for some small c suffices) then MSO<sub>2</sub>-model checking is intractable on C (under a suitable assumption from complexity theory).
[complexity theory, Heuristic algorithms, Nails, Adaptation model, trees (mathematics), Parameterized Complexity, Encoding, Complexity theory, bounded tree-width, Graph Structure Theory, Treewidth, formal logic, poly-logarithmic function, Upper bound, formal verification, Parameterized Intractability, MSO<sub>2</sub>-model checking, Finite Model Theory, Polynomials, Courcelle theorem, monadic second-order logic, Monadic Second-Order Logic, computational complexity, linear time]
Capturing Polynomial Time on Interval Graphs
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We prove a characterization of all polynomial-time computable queries on the class of interval graphs by sentences of fixed-point logic with counting. More precisely, it is shown that on the class of unordered interval graphs, any query is polynomial-time computable if and only if it is definable in fixed-point logic with counting. This result is one of the first establishing the capturing of polynomial time on a graph class which is defined by forbidden induced subgraphs. For this, we define a canonical form of interval graphs using a type of modular decomposition, which is different from the method of tree decomposition that is used in most known capturing results for other graph classes, specifically those defined by forbidden minors. The method might also be of independent interest for its conceptual simplicity. Furthermore, it is shown that fixed-point logic with counting is not expressive enough to capture polynomial time on the classes of chordal graphs or incomparability graphs.
[Context, fixed-point logic with counting, graph theory, fixed-point logic, chordal graphs, Data structures, incomparability graphs, Complexity theory, Construction industry, formal logic, capturing of polynomial time, canonical forms, Lead, polynomial-time computable queries, Polynomials, Bipartite graph, modular decomposition, interval graphs, computational complexity]
A Generic Operational Metatheory for Algebraic Effects
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We provide a syntactic analysis of contextual preorder and equivalence for a polymorphic programming language with effects. Our approach applies uniformly across a range of {algebraic effects}, and incorporates, as instances: errors, input/output, global state, nondeterminism, probabilistic choice, and combinations thereof. Our approach is to extend Plotkin and Power's structural operational semantics for algebraic effects (FoSSaCS 2001) with a primitive "basic preorder" on ground type computation trees. The basic preorder is used to derive notions of contextual preorder and equivalence on program terms. Under mild assumptions on this relation, we prove fundamental properties of contextual preorder (hence equivalence) including extensionality properties and a characterisation via applicative contexts, and we provide machinery for reasoning about polymorphism using relational parametricity.
[Context, Pediatrics, contextual preorder, polymorphic programming language, algebraic effects, generic operational metatheory, relational parametricity, algebra, programming language semantics, Machinery, syntactic analysis, Equations, Semantics, structural operational semantics, Syntactics, Manganese]
Polarity and the Logic of Delimited Continuations
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Polarized logic is the logic of values and continuations, and their interaction through continuation-passing style. The main limitations of this logic are the limitations of CPS: that continuations cannot be composed, and that programs are fully sequentialized. Delimited control operators were invented in response to the limitations of classical continuation-passing. That suggests the question: what is the logic of delimited continuations? We offer a simple account of delimited control, through a natural generalization of the classical notion of polarity. This amounts to breaking the perfect symmetry between positive and negative polarity in the following way: answer types are positive. Despite this asymmetry, we retain all of the classical polarized connectives, and can explain "intuitionistic polarity'' (e.g., in systems like CBPV) as a restriction on the use of connectives, i.e., as a logical fragment. Our analysis complements and generalizes existing accounts of delimited control operators, while giving us a rich logical language through which to understand the interaction of control with monadic effects.
[Context, Dictionaries, Shape, Buildings, intuitionistic polarity', Cognition, Calculus, proof theory, formal logic, logical language, Focusing, polarized logic, continuation-passing style, delimited control operators, continuations, logic, programming, polarity]
Datalog+/-: A Family of Logical Knowledge Representation and Query Languages for New Applications
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
This paper summarizes results on a recently introduced family of Datalog-based languages, called Datalog+/-, which is a new framework for tractable ontology querying, and for a variety of other applications. Datalog+/- extends plain Datalog by features such as existentially quantified rule heads and, at the same time, restricts the rule syntax so as to achieve decidability and tractability. In particular, we discuss three paradigms ensuring decidability: chase termination, guarded-ness, and stickiness.
[Context, logical knowledge representation, Computational modeling, Datalog+/-, Ontologies, query languages, Complexity theory, DATALOG, Database languages, Query Answering, Databases, decidability, tractable ontology querying, Syntactics, ontologies (artificial intelligence), Polynomials, Knowledge Representation and Reasoning]
An Extension of Data Automata that Captures XPath
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We define a new kind of automata recognizing properties of data words or data trees and prove that the automata capture all queries definable in Regular XPath. We show that the automata-theoretic approach may be applied to answer decidability and expressibility questions for XPath. Finally, we use the newly introduced automata as a common framework to classify existing automata on data words and trees, including data automata, register automata and alternating register automata.
[XPath, data word, Transducers, automata theory, automata-theoretic approach, Encoding, Regular XPath, Registers, Complexity theory, data automata, data tree, Image color analysis, Automata, register automata, Data models, tree data structures]
Deciding Definability in FO_2(&lt;_h, &lt;_v) on Trees
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We prove that it is decidable whether a regular unranked tree language is definable in FO<sub>2</sub>(&lt;;<sub>h</sub>,&lt;;<sub>v</sub>). By FO<sub>2</sub>(&lt;;<sub>h</sub>,&lt;;<sub>v</sub>) we refer to the two variable fragment of first order logic built from the descendant and following sibling predicates. In terms of expressive power it corresponds to a fragment of the navigational core of XPath that contains modalities for going up to some ancestor, down to some descendant, left to some preceding sibling, and right to some following sibling. We also investigate definability in some other fragments of XPath.
[Context, XPath, Trees, Navigation, computational linguistics, trees (mathematics), navigational core, Indexes, Equations, Xpath, Algebra, Semantics, tree language, Automata, Syntactics, first order logic, Logic]
The Emptiness Problem for Tree Automata with Global Constraints
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We define tree automata with global constraints (TAGC), generalizing the class of tree automata with global equality and disequality constraints (TAGED). TAGC can test for equality and disequality between subterms whose positions are defined by the states reached during a computation. In particular, TAGC can check that all the subterms reaching a given state are distinct. This constraint is related to monadic key constraints for XML documents, meaning that every two distinct positions of a given type have different values. We prove decidability of the emptiness problem for TAGC. This solves, in particular, the open question of decidability of emptiness for TAGED. We further extend our result by allowing global arithmetic constraints for counting the number of occurrences of some state or the number of different subterms reaching some state during a computation. We also allow local equality and disequality tests between sibling positions and the extension to unranked ordered trees. As a consequence of our results for TAGC, we prove the decidability of a fragment of the monadic second order logic on trees extended with predicates for equality and disequality between subtrees, and cardinality.
[global constraints, automata theory, trees (mathematics), global arithmetic constraint, XML Processing, Symbolic Constraint Solving, Indexes, Character recognition, Tree Automata, Semantics, global equality, Automata, XML, XML document, disequality constraint, Robustness, disequality test, tree automata, Monadic Second Order Logic, Labeling]
Addition-Invariant FO and Regularity
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We consider formulas which, in addition to the symbols in the vocabulary, may use two designated symbols -&lt;; and + that must be interpreted as a linear order and its associated addition. Such a formula is called addition-invariant if, for each fixed interpretation of the initial vocabulary, its result is independent of the particular interpretation of -&lt;; and +. This paper studies the expressive power of addition invariant first-order logic, +-inv-FO, on the class of finite strings. Our first main result gives a characterization of the regular languages definable in +-inv-FO: we show that these are exactly the languages definable in FO with extra predicates, denoted by &#x201C;lm&#x201D; for short, for testing the length of the string modulo some fixed number. Our second main result shows that every language definable in +-inv-FO, that is bounded or commutative or deterministic context-free, is regular. As an immediate consequence of these two main results, we obtain that +-inv-FO is equivalent to FO(lm) on the class of finite colored sets. Our proof methods involve Ehrenfeucht-Frai&#x0308;sse&#x0301; games, tools from algebraic automata theory, and reasoning about semi-linear sets.
[reasoning about semi-linear sets, formal languages, Radiation detectors, Computational modeling, regular languages, addition-invariant FO, Ehrenfeucht-Frai&#x0308;sse&#x0301; games, Indexes, Equations, formal logic, Games, Syntactics, addition invariant first-order logic, algebraic automata theory, bounded languages, +-inv-FO, Logic, automata, Testing]
Theorem Proving for Verification: The Early Days
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Summary form only given. Since Turing, computer scientists have understood that the question "does this program satisfy its specifications?" could be reduced to the question "are these formulas theorems?" But the theorem proving technology of the 50s and 60s was inadequate for the task. In 1971, here in Edinburgh, Boyer and I started building the first general-purpose theorem prover designed for a computational logic. This project continues today, with Matt Kaufmann as a partner; the current version of the theorem prover is ACL2 (A Computational Logic for Applicative Common Lisp). In this talk I'll give a highly personal view of the four decade long "Boyer-Moore Project," including our mechanization of inductive proof, support for recursive definitions, rewriting with previously proved lemmas, integration of decision procedures, efficient representation of logical constants, fast execution, and other proof techniques. Along the way we'll see several interesting side roads: the founding of the Edinburgh school of logic programming, a structureshared text editor that played a role in the creation of Word, and perhaps most surprisingly, the use of our "Lisp theorem prover" to formalize and prove theorems about commercial microprocessors and virtual machines via deep embeddings, including parts of processors by AMD, Centaur, IBM, Motorola, Rockwell-Collins, Sun, and others. The entire project helps shed light on the dichotomy between general-purpose theorem pro vers and special-purpose analysis tools.
[Computers, Logic programming, Roads, Buildings, computational logic, Lisp theorem prover, Educational institutions, recursive functions, Sun, Microprocessors, logic programming, logical constants, inductive proof, theorem proving, recursive definitions, theorem proving technology]
Breaking Paths in Atomic Flows for Classical Logic
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
This work belongs to a wider effort aimed at eliminating syntactic bureaucracy from proof systems. In this paper, we present a novel cut elimination procedure for classical propositional logic. It is based on the recently introduced `atomic flows': they are purely graphical devices that abstract away from much of the typical bureaucracy of proofs. We make crucial use of the `path breaker', an atomic flow construction that avoids some nasty termination problems, and that can be used in any proof system with sufficient symmetry. This paper contains an original 2-dimensional-diagram exposition of atomic flows, which helps us to connect atomic flows with other known formalisms.
[Shape, proof systems, cut elimination procedure, classical propositional logic, Generators, Complexity theory, atomic flows, Construction industry, formal logic, path breaker, proof normalization, Coherence, Syntactics, Skeleton, theorem proving, classical logic]
Infinitary Completeness in Ludics
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Traditional Go&#x0308;del completeness holds between finite proofs and infinite models over formulas of finite depth, where proofs and models are heterogeneous. Our purpose is to provide an interactive form of completeness between infinite proofs and infinite models over formulas of infinite depth (that include recursive types), where proofs and models are homogenous. We work on a nonlinear extension of ludics, a monistic variant of game semantics which has the same expressive power as the propositional fragment of polarized linear logic. In order to extend the completeness theorem of the original ludics to the infinitary setting, we modify the notion of orthogonality by defining it via safety rather than termination of the interaction. Then the new completeness ensures that the universe of behaviours (interpretations of formulas) is Cauchy-complete, so that every recursive equation has a unique solution. Our work arises from studies on recursive types in denotational and operational semantics, but is conceptually simpler, due to the purely logical setting of ludics, the completeness theorem, and use of coinductive techniques.
[recursive types, linear logic, infinitary completeness, completeness, finite depth, coinductive techniques, Ludics, coinduction, formal logic, Go&#x0308;del completeness, Semantics, ludics, infinite models, Safety, Cauchy-complete, Artificial neural networks, game theory, game semantics, Equations, finite proofs, Automata, Games, Syntactics, polarized linear logic, computational complexity]
On Strong Maximality of Paraconsistent Finite-Valued Logics
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Maximality is a desirable property of paraconsistent logics, motivated by the aspiration to tolerate inconsistencies, but at the same time retain as much as possible from classical logic. In this paper we introduce a new, strong notion of maximal paraconsistency, which is based on possible extensions of the consequence relation of a logic. We investigate this notion in the framework of finite-valued paraconsistent logics, and show that for every n &gt; 2 there exists an extensive family of n-valued logics, each of which is maximally paraconsistent in our sense, is partial to classical logic, and is not equivalent to any k-valued logic with k &lt;; n. On the other hand, we specify a natural condition that guarantees that a paraconsistent logic is contained in a logic in the class of three-valued paraconsistent logics, and show that all reasonably expressive logics in this class are maximal.
[Context, Uncertainty, paraconsistent finite-valued logics, consequence relation, Semantics, multivalued logic, strong maximality, Educational institutions, Cognition, Electronic mail, k-valued logic, Cost accounting]
Probabilistic Information Flow
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
In recent years, there has been a growing interest in considering the probabilistic aspects of Information Flow. In this abstract we review some of the main approaches that have been considered to quantify the notion of information leakage, and we focus on some recent developments.
[Uncertainty, security of data, information leakage, probability, information theoretic approach, probabilistic information flow, Probabilistic logic, Entropy, Probability distribution, Random variables, Security, Mutual information]
Weak Equivalences in Psi-Calculi
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Psi-calculi extend the pi-calculus with nominal datatypes to represent data, communication channels, and logics for facts and conditions. This general framework admits highly expressive formalisms such as concurrent higher-order constraints and advanced cryptographic primitives. We here establish the theory of weak bisimulation, where the &#x03C4; actions are unobservable. In comparison to other calculi the presence of assertions poses a significant challenge in the definition of weak bisimulation, and although there appears to be a spectrum of possibilities we show that only a few are reasonable. We demonstrate that the complications mainly stem from psi-calculi where the associated logic does not satisfy weakening. We prove that weak bisimulation equivalence has the expected algebraic properties and that the corresponding observation congruence is preserved by all operators. These proofs have been machine checked in Isabelle. The notion of weak barb is defined as the output label of a communication action, and weak barbed equivalence is bisimilarity for &#x03C4; actions and preservation of barbs in all static contexts. We prove that weak barbed equivalence coincides with weak bisimulation equivalence.
[Context, barbed bisimulation, pi-calculus, advanced cryptographic primitives, Mobile communication, Data structures, Calculus, &#x03C4; actions, Complexity theory, concurrent higher-order constraints, Jamming, pi calculus, weak bisimulation equivalence, psi-calculi, Semantics, bisimulation equivalence, pi-calculus extension, weak bisimulation]
A Calculus of Contracting Processes
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We propose a formal theory of contract-based computing. We model contracts as formulae in an intuitionistic logic extended with a "contractual'' form of implication. Decidability holds for our logic: this allows us to mechanically infer the rights and the duties deriving from any set of contracts. We embed our logic in a core calculus of contracting processes, which combines features from concurrent constraints and calculi for multiparty sessions, while subsuming several idioms for concurrency.
[Context, Airplanes, contract-based computing, cut elimination, contracting processes, concurrent constraints, intuitionistic logic, concurrency theory, Calculus, Encoding, calculus, contracts, formal theory, decidability, Syntactics, circular assume-guarantee, core calculus, Marine vehicles, Contracts]
On Probabilistic Automata in Continuous Time
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We develop a compositional behavioural model that integrates a variation of probabilistic automata into a conservative extension of interactive Markov chains. The model is rich enough to embody the semantics of generalised stochastic Petri nets. We define strong and weak bisimulations and discuss their compositionality properties. Weak bisimulation is partly oblivious to the probabilistic branching structure, in order to reflect some natural equalities in this spectrum of models. As a result, the standard way to associate a stochastic process to a generalised stochastic Petri net can be proven sound with respect to weak bisimulation.
[generalised stochastic Petri net semantics, bisimulation, weak bisimulation semantics, Petri nets, Probabilistic logic, Delay, interactive Markov chains, Concurrent computing, discrete time, probabilistic automata, process algebra, Automata, semantic networks, Markov processes, bisimulation equivalence, continuous time, compositional behavioural model, nondeterminism]
omega-QRB-Domains and the Probabilistic Powerdomain
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Is there any cartesian-closed category of continuous domains that would be closed under Jones and Plotkin's probabilistic powerdomain construction? This is a major open problem in the area of denotational semantics of probabilistic higher-order languages. We relax the question, and look for quasi-continuous dcpos instead. These retain many nice properties from continuous dcpos. We introduce a natural class of such quasi-continuous dcpos, the omega-QRB-domains. We show that they form a category omega-QRB with pleasing properties: omega-QRB is closed under the probabilistic powerdomain functor, has all finite products, all bilimits, and is stable under retracts, and even under so-called quasi-retracts. But... omega-QRB is not cartesian closed.
[probability, higher order language, Probabilistic logic, Topology, set theory, Cost accounting, probabilistic powerdomain, Construction industry, Convergence, Upper bound, &#x03C9;QRB domain, omega QRB domain, Mathematical model, Quasi-continuous domains]
Abstracting the Differential Semantics of Rule-Based Models: Exact and Automated Model Reduction
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Rule-based approaches (as in our own Kappa, or the BNG language, or many other propositions allowing the consideration of "reaction classes'') offer new and more powerful ways to capture the combinatorial interactions that are typical of molecular biological systems. They afford relatively compact and faithful descriptions of cellular interaction networks despite the combination of two broad types of interaction: the formation of complexes (a biological term for the ubiquitous non-covalent binding of bio-molecules), and the chemical modifications of macromolecules (aka post-translational modifications). However, all is not perfect. This same combinatorial explosion that pervades biological systems also seems to prevent the simulation of molecular networks using systems of differential equations. In all but the simplest cases the generation (and even more the integration) of the explicit system of differential equations which is canonically associated to a rule set is unfeasible. So there seems to be a price to pay for this increase in clarity and precision of the description, namely that one can only execute such rule-based systems using their stochastic semantics as continuous time Markov chains, which means a slower if more accurate simulation. In this paper, we take a fresh look at this question, and, using techniques from the abstract interpretation framework, we construct a reduction method which generates (typically) far smaller systems of differential equations than the concrete/canonical one. We show that the abstract/reduced differential system has solutions which are linear combinations of the canonical ones. Importantly, our method: 1) does not require the concrete system to be explicitly computed, so it is intensional, 2) nor does it rely on the choice of a specific set of rate constants for the system to be reduced, so it is symbolic, and 3) achieves good compression when tested on rule-based models of significant size, so it is also realistic.
[molecular biological systems, abstracting, Correlation, abstract interpretation framework, Biological system modeling, Equations, differential equations, Proteins, differential semantics, biology computing, Semantics, automated model reduction, knowledge based systems, rule-based systems, Markov processes, cellular interaction networks, Concrete, Mathematical model, molecular networks, rule-based models, continuous time Markov chains]
The Expressive Power of Synchronizations
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
A synchronization is a mechanism allowing two or more processes to perform actions at the same time. We study the expressive power of synchronizations gathering more and more processes simultaneously. We demonstrate the non-existence of a uniform, fully distributed translation of Milner's CCS with synchronizations of n + 1 processes into CCS with synchronizations of n processes that retains a "reasonable'' semantics. We then extend our study to CCS with symmetric synchronizations allowing a process to perform both inputs and outputs at the same time. We demonstrate that synchronizations containing more than three input/output items are encodable in those with three items, while there is an expressivity gap between three and two.
[Protocols, hypercube, concurrency theory, Calculus, Encoding, Expressive power, expressive power, synchronisation, dining philosophers problem, symmetric synchronizations, calculus of communicating systems, distributed translation, CCS, synchronizations, System recovery, Hypercubes, process calculi, Joints]
On the Expressivity of Symmetry in Event Structures
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
This paper establishes a bridge between presheaf models for concurrency and the more operationally-informative world of event structures. It concentrates on a particular presheaf category, consisting of presheaves over finite partial orders of events; such presheaves form a model of nondeterministic processes in which the computation paths have the shape of partial orders. It is shown how with the introduction of symmetry event structures represent all presheaves over finite partial orders. This is in contrast with plain event structures which only represent certain separated presheaves. Specifically a coreflection from the category of presheaves to the category of event structures with symmetry is exhibited. It is shown how the coreflection can be cut down to an equivalence between the presheaf category and the subcategory of graded event structures with symmetry. Event structures with strong symmetries are shown to represent precisely all the separated presheaves. The broader context and specific applications to the unfolding of higher-dimensional automata and Petri nets, and weak bisimulation on event structures are sketched.
[graded event structures, Shape, Computational modeling, Biological system modeling, automata theory, presheaf models, Petri nets, higher-dimensional automata, History, Construction industry, Semantics, nondeterministic processes, Mathematical model, symmetry event structures, weak bisimulation]
A Finiteness Structure on Resource Terms
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We study the Taylor expansion of lambda-terms in a on-deterministic or algebraic setting, where terms can be added. The target language is a resource lambda calculus based on a differential lambda-calculus that we introduced recently. This operation is not possible in the general untyped case where reduction can produce unbounded coefficients. We endow resource terms with a finiteness structure (in the sense of our earlier work on finiteness spaces) and show that the Taylor expansions of terms typeable in Girard's system F are finitary by a reducibility method.
[lambda calculus, differentiation, linear logic, Taylor series, Calculus, Vectors, Topology, finiteness structure, differential lambda calculus, lambda-calculus, target language, Construction industry, finiteness spaces, Semantics, reducibility, Tin, algebraic system F, Taylor expansion, unbounded coefficient, Girard system, denotational semantics]
Coalgebras, Chu Spaces, and Representations of Physical Systems
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
We investigate the use of coalgebra to represent quantum systems, thus providing a basis for the use of coalgebraic methods in quantum information and computation. Coalgebras allow the dynamics of repeated measurement to be captured, and provide mathematical tools such as final coalgebras, bisimulation and coalgebraic logic. However, this application raises new challenges for coalgebra: how to accommodate the contravariance which arises naturally as we represent both the states and the properties of physical systems; and how to represent the symmetries of these systems, which account e.g. for their unitary dynamics. This motivates us to introduce a novel fibrational structure for coalgebra, and also to make new connections betwen coalgebras and Chu spaces.
[coalgebra, fibrational structure, representation of physical systems, Stochastic processes, quantum theory, coalgebraic methods, Cognition, quantum information, Construction industry, coalgebraic logic, quantum mechanics, process algebra, Semantics, Quantum mechanics, Chu spaces, category theory, Hilbert space, categories, quantum computation, Indexing]
A Sound and Complete Calculus for Finite Stream Circuits
2010 25th Annual IEEE Symposium on Logic in Computer Science
None
2010
Stream circuits are a convenient graphical way to represent streams (or stream functions) computed by finite dimensional linear systems. We present a sound and complete expression calculus that allows us to reason about the semantic equivalence of finite closed stream circuits. For our proof of the soundness and completeness we build on recent ideas of Bonsangue, Rutten and Silva. They have provided a "Kleene theorem'' and a sound and complete expression calculus for coalgebras for endofunctors of the category of sets. The key ingredient of the soundness and completeness proof is a syntactic characterization of the final locally finite coalgebra. In the present paper we extend this approach to the category of real vector spaces. We also prove that a final locally finite (dimensional) coalgebra is, equivalently, an initial iterative algebra. This makes the connection to existing work on the semantics of recursive specifications.
[Linear systems, coalgebra, finite coalgebra, finite automata, Kleene theorem, streams, Kleene algebra, Calculus, Vectors, algebra, linear systems, finite dimensional linear system, Registers, syntactic characterization, calculus, recursive specification, semantic equivalence, Semantics, finite stream circuit, Automata, iterative algebra, regular expressions]
Foreword
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Presents the introductory welcome message from the conference proceedings.
[]
Conference organization
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Provides a listing of current committee members and society officers.
[]
A Why-on-Earth Tutorial on Finite Model Theory
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
This note advertises the topics that will be covered in the tutorial on finite model theory.
[Computer science, Computational modeling, Tutorials, Approximation algorithms, Mathematical model, Convergence]
The Meaning of Semantics
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
I will present three main themes in current research in semantics: (a) models of programming languages, (b) concurrency and (c) approximation. The first theme covers denotational semantics and operational semantics and the search for tight connections between them. This led to the full abstraction problem and ultimately to game semantics. The second theme began with the attempt to understand processes and the realization that there were brand new issues to deal with. In particular it was hard to even find compositional models at first. Finally, domain theory originally invented to provide set-theoretic models of the lambda calculus, turned into a general theory of approximation and has had an impact on the theory of probabilistic processes.
[operational semantics, compositional model, set theory, semantics, Approximation methods, programming languages, abstraction problem, Algebra, Semantics, denotational semantics, domain theory, approximation theory, lambda calculus, programming language model, Computational modeling, Tutorials, Probabilistic logic, concurrency theory, programming language semantics, game semantics, concurrency, Computer languages, dataflow, concurrency model, process algebra, probabilistic processes, set theoretic model, probabilistic systems]
Logic in Software, Dynamical and Biological Systems
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Formal methods is a key area within the Computer Science discipline. Formal methods is concerned with analyzing systems formally. Here, we focus on three different systems: software systems, dynamical control systems, and biological systems. Software systems are discrete-time systems, whereas control systems are continuous-time dynamical systems. Systems consisting of interaction between the two are called cyber-physical systems and their dynamics are given using a hybrid-time model. Biological systems are complex systems that have been modeled and analyzed as discrete, continuous, and hybrid dynamical systems. The analysis questions can be broadly classified into verification and synthesis questions. We focus on both these aspects here. Logic and logical methods play a key role in the tools and techniques across this whole range of systems and analyses.
[Biological system modeling, discrete time systems, software systems, Stochastic processes, Control systems, Cognition, biological systems, hybrid-time model, cyber-physical systems, Analytical models, formal verification, dynamical control systems, logical methods, formal methods, logic, Mathematical model]
Qualitative Tree Languages
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We study finite automata running over infinite binary trees and we relax the notion of accepting run by allowing a negligible set (in the sense of measure theory) of non-accepting branches. In this qualitative setting, a tree is accepted by the automaton if there exists a run over this tree in which almost every branch is accepting. This leads to a new class of tree languages, called the qualitative tree languages that enjoys many properties. Then, we replace the existential quantification - a tree is accepted if there exists some accepting run over the input tree - by a probabilistic quantification - a tree is accepted if almost every run over the input tree is accepting. Together with the qualitative acceptance and the Bu&#x0308;chi condition, we obtain a class of probabilistic tree automata with a decidable emptiness problem. To our knowledge, this is the first positive result for a class of probabilistic automaton over infinite trees.
[finite automata, qualitative acceptance, existential quantification, probability, trees (mathematics), probabilistic tree automata, qualitative tree languages, Probabilistic logic, probabilistic quantification, Probability distribution, Bu&#x0308;chi condition, qualitative setting, Atmospheric measurements, Automata, infinite binary trees, Games, Markov processes, Polynomials, probabilistic automaton]
Languages of Dot-Depth One over Infinite Words
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Over finite words, languages of dot-depth one are expressively complete for alternation-free first-order logic. This fragment is also known as the Boolean closure of existential first-order logic. Here, the atomic formulas comprise order, successor, minimum, and maximum predicates. Knast (1983) has shown that it is decidable whether a language has dot-depth one. We extend Knast's result to infinite words. In particular, we describe the class of languages definable in alternation-free first-order logic over infinite words, and we give an effective characterization of this fragment. This characterization has two components. The first component is identical to Knast's algebraic property for finite words and the second component is a topological property, namely being a Boolean combination of Cantor sets. As an intermediate step we consider finite and infinite words simultaneously. We then obtain the results for infinite words as well as for finite words as special cases. In particular, we give a new proof of Knast's Theorem on languages of dot-depth one over finite words.
[formal languages, Knast theorem, Mechanical factors, Topology, set theory, Finite element methods, Knast algebraic property, Equations, infinite words, topological property, dot-depth languages, Boolean functions, alternation-free first-order logic, Automata, Syntactics, Cantor sets, Mathematical model, Boolean combination]
Two Views on Multiple Mean-Payoff Objectives in Markov Decision Processes
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We study Markov decision processes (MDPs) with multiple limit-average (or mean-payoff) functions. We consider two different objectives, namely, expectation and satisfaction objectives. Given an MDP with k reward functions, in the expectation objective the goal is to maximize the expected limit-average value, and in the satisfaction objective the goal is to maximize the probability of runs such that the limit-average value stays above a given vector. We show that under the expectation objective, in contrast to the single-objective case, both randomization and memory are necessary for strategies, and that finite-memory randomized strategies are sufficient. Under the satisfaction objective, in contrast to the single-objective case, infinite memory is necessary for strategies, and that randomized memoryless strategies are sufficient for epsilon-approximation, for all epsilon&gt;;0. We further prove that the decision problems for both expectation and satisfaction objectives can be solved in polynomial time and the trade-off curve (Pareto curve) can be epsilon-approximated in time polynomial in the size of the MDP and 1/epsilon, and exponential in the number of reward functions, for all epsilon&gt;;0. Our results also reveal flaws in previous work for MDPs with multiple mean-payoff functions under the expectation objective, correct the flaws and obtain improved results.
[multiple mean payoff objectives, multiple limit average functions, Probability distribution, long-run average, finite memory randomized strategy, Approximation methods, History, Markov decision processes, Automata, multi-objective verification, Markov processes, Polynomials, Informatics, markov decision processe]
First Steps in Synthetic Guarded Domain Theory: Step-Indexing in the Topos of Trees
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We present the topos S of trees as a model of guarded recursion. We study the internal dependently-typed higher-order logic of S and show that S models two modal operators, on predicates and types, which serve as guards in recursive definitions of terms, predicates, and types. In particular, we show how to solve recursive type equations involving dependent types. We propose that the internal logic of S provides the right setting for the synthetic construction of abstract versions of step-indexed models of programming languages and program logics. As an example, we show how to construct a model of a programming language with higher-order store and recursive types entirely inside the internal logic of S.
[step-indexing, Computational modeling, synthetic guarded domain theory, modal operators, trees (mathematics), guarded recursion, Cognition, semantics, programming languages, internal dependently-typed higher-order logic, Equations, formal logic, Computer languages, Algebra, Semantics, logic, Mathematical model, program logics, topos of trees, domain theory]
Imperative Programs as Proofs via Game Semantics
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Game semantics extends the Curry-Howard isomorphism to a three-way correspondence: proofs, programs, strategies. But the universe of strategies goes beyond intuitionistic logics and lambda calculus, to capture stateful programs. In this paper we describe a logical counterpart to this extension, in which proofs denote such strategies. We can embed intuitionistic first-order linear logic into this system, as well as an imperative total programming language. The logic makes explicit use of the fact that in the game semantics the exponential can be expressed as a final co algebra. We establish a full completeness theorem for our logic, showing that every bounded strategy is the denotation of a proof.
[lambda calculus, imperative total programming language, first-order logic, game theory, history sensitive strategies, History, programming language semantics, game semantics, Curry-Howard isomorphism, Grippers, Computer science, formal logic, Reactive power, Semantics, intuitionistic first-order linear logic, full completeness, Games, Bismuth, imperative programs]
Game Semantics for Good General References
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We present a new fully abstract and effectively presentable denotational model for RefML, a paradigmatic higher-order programming language combining call-by-value evaluation and general references in the style of ML. Our model is built using game semantics. In contrast to the previous model by Abramsky, Honda and McCusker, it provides a faithful account of reference types, and the full abstraction result does not rely on the availability of spurious constructs of reference type (bad variables). This is the first denotational model of this kind, preceded only by the trace model recently proposed by Laird.
[Context, Availability, RefML, Computational modeling, game semantics, ML language, Semantics, Games, Writing, paradigmatic higher-order programming language, good general references, Mathematical model, ML]
The Computational Meaning of Probabilistic Coherence Spaces
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We study the probabilistic coherent spaces - a denotational semantics interpreting programs by power series with non negative real coefficients. We prove that this semantics is adequate for a probabilistic extension of the untyped &#x03BB;-calculus: the probability that a term reduces to ahead normal form is equal to its denotation computed on a suitable set of values. The result gives, in a probabilistic setting, a quantitative refinement to the adequacy of Scott's model for untyped &#x03BB;-calculus.
[Computational modeling, denotational semantic interpreting programs, probability, power series, untyped &#x03BB;-calculus, Probabilistic logic, Indexes, programming language semantics, Linear Logic, Probabilistic Lambda Calculus, Equations, pi calculus, Adequacy Theorem, Semantics, probabilistic coherent spaces, Coherence Spaces, Coherence, nonnegative real coefficients, Denotational Semantics, Mathematical model, Scott's model]
Continuous Random Variables
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We introduce the domain of continuous random variables (CRV) over a domain, as an alternative to Jones and Plotkin's probabilistic power domain. While no known Cartesian-closed category is stable under the latter, we show that the so-called thin (uniform) CRVs define a strong monad on the Cartesian-closed category of bc-domains. We also characterize their inequational theory, as (fair-)coin algebras. We apply this to solve a recent problem posed by M. Escardo: testing is semi-decidable for EPCF terms. CRVs arose from the study of the second author's (layered) Hoare indexed valuations, and we also make the connection apparent.
[fair-coin algebras, continuous random variables, CRV, random variable, Cartesian-closed category, algebra, EPCF terms, Cost accounting, probabilistic powerdomain, Algebra, decidability, indexed valuation, monad, domain theory, semidecidable, bc-domain, inequational theory, probability, random processes, Hoare indexed valuations, Probabilistic logic, Topology, Upper bound, probabilistic power domain, System recovery, category theory, Random variables]
Noncomputable Conditional Distributions
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We study the computability of conditional probability, a fundamental notion in probability theory and Bayesian statistics. In the elementary discrete setting, a ratio of probabilities defines conditional probability. In more general settings, conditional probability is defined axiomatically, and the search for more constructive definitions is the subject of a rich literature in probability theory and statistics. However, we show that in general one cannot compute conditional probabilities. Specifically, we construct a pair of computable random variables (X, Y) in the unit interval whose conditional distribution P[Y|X] encodes the halting problem. Nevertheless, probabilistic inference has proven remarkably successful in practice, even in infinite-dimensional continuous settings. We prove several results giving general conditions under which conditional distributions are computable. In the discrete or dominated setting, under suitable computability hypotheses, conditional distributions are computable. Likewise, conditioning is a computable operation in the presence of certain additional structure, such as independent absolutely continuous noise.
[probabilistic logic, probability, random processes, computability, Extraterrestrial measurements, Probabilistic logic, inference mechanisms, computable probability theory, Computer languages, Bayesian statistics, real computation, conditional probability, probabilistic inference, computable random variable pair, Random variables, Bayes methods, noncomputable conditional distribution, infinite dimensional continuous setting, Kernel, probabilistic programming languages]
Propositional Proof Complexity: A Survey on the State of the Art, Including Some Recent Results
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
false
[Computer science, Complexity theory]
A Type System for Complexity Flow Analysis
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We propose a type system for an imperative programming language, which certifies program time bounds. This type system is based on secure flow information analysis. Each program variable has a level and we prevent information from flowing from low level to higher level variables. We also introduce a downgrading mechanism in order to delineate a broader class of programs. Thus, we propose a relation between security-typed language and implicit computational complexity. We establish a characterization of the class of polynomial time functions.
[downgrading mechanism, polynomials, Lattices, polynomial time functions, security typed language, Security, Computational complexity, information flow, Computer languages, complexity flow analysis, flow information analysis security, PTIME, imperative programming language, Semantics, type system, Implicit computational complexity, Polynomials, security types, imperative, computational complexity]
Linear Dependent Types and Relative Completeness
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
A system of linear dependent types for the lambda calculus with full higher-order recursion, called d&#x2113;PCF, is introduced and proved sound and relatively complete. Completeness holds in a strong sense: d&#x2113;PCF is not only able to precisely capture the functional behaviour of PCF programs (i.e. how the output relates to the input) but also some of their intensional properties, namely the complexity of evaluating them with Krivine's Machine. d&#x2113;PCF is designed around dependent types and linear logic and is parametrized on the underlying language of index terms, which can be tuned so as to sacrifice completeness for tractability.
[Context, lambda calculus, program control structures, linear logic, PCF programs, Complexity theory, Indexes, type systems, relative completeness, implicit computational complexity, linear dependent types, Semantics, Vegetation, higher-order recursion, d&#x2113;PCF, Polynomials, Krivine's machine, computational complexity, functional languages]
CoQMTU: A Higher-Order Type Theory with a Predicative Hierarchy of Universes Parametrized by a Decidable First-Order Theory
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We study a complex type theory, a Calculus of Inductive Constructions with a predicative hierarchy of universes and a first-order theory T built in its conversion relation. The theory T is specified abstractly, by a set of constructors, a set of defined symbols, axioms expressing that constructors are free and defined symbols completely defined, and a generic elimination principle relying on crucial properties of first-order structures satisfying the axioms. We first show that CoqMTU enjoys all basic meta-theoretical properties of such calculi, confluence, subject reduction and strong normalization when restricted to weak-elimination, implying the decidability of type-checking in this case as well as consistency. The case of strong elimination is left open.
[Context, complex type theory, lambda calculus, first-order theory, predicative hierarchy of universes, Calculus, Encoding, calculus of inductive constructions, type theory, decidable first-order theory, meta-theoretical properties, type-checking decidability, strong normalization, Reactive power, higher-order type theory, Algebra, decidability, generic elimination principle, Semantics, Kernel, Calculus of Inductive Constructions, CoQMTU]
Isomorphisms of Types in the Presence of Higher-Order References
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We investigate the problem of type isomorphisms in a programming language with higher-order references. We first recall the game-theoretic model of higher-order references by Abramsky, Honda and McCusker. Solving an open problem by Laurent, we show that two finitely branching arenas are isomorphic if and only if they are geometrically the same, up to renaming of moves (Laurent's forest isomorphism). We deduce from this an equational theory characterizing isomorphisms of types in a finitary language L2 with higher order references. We show however that Laurent's conjecture does not hold on infinitely branching arenas, yielding a non-trivial type isomorphism in the extension of L2 with natural numbers.
[Law, Computational modeling, higher-order references, game theory, nontrivial type isomorphism, higher order statistics, programming languages, Computer languages, equational theory, unitary language, Semantics, Games, game theoretic model, programming language, Laurent conjecture, Mathematical model]
Listings and Logics
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
There are standard logics DTC, TC, and LFP capturing the complexity classes L, NL, and P on ordered structures, respectively. In we have shown that LFP<sub>inv</sub>, the "order-invariant least fixed-point logic LFP," captures P (on all finite structures) if and only if there is a listing of the P subsets of the set TAUT of propositional tautologies. We are able to extend the result to listings of the L-subsets (NL-subsets) of TAUT and the logic DTC<sub>inv</sub> (TC<sub>inv</sub>). As a byproduct we get that LFP<sub>inv</sub> captures P if DTC<sub>inv</sub> captures L. Furthermore, we show that the existence of a listing of the L-subsets of TAUT is equivalent to the existence of an almost space optimal algorithm for TAUT. To obtain this result we have to derive a space version of a theorem of Levin on optimal inverters.
[Vocabulary, complexity classes, L-subsets, Aerospace electronics, Encoding, Complexity theory, Electronic mail, TAUT, TC, formal logic, DTC, Turing machines, ordered structures, Polynomials, order-invariant least fixed-point logic LFP, computational complexity]
Computational Complexity of Quantum Satisfiability
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Quantum logic generalizes, and in dimension one coincides with, Boolean propositional logic. We introduce the weak and strong satisfiability problem for quantum logic formulas, and show both NP-complete in dimension two as well. For higher-dimensional spaces Rd and Cd with d&#x2265;3 fixed, on the other hand, we show the problem to be complete for the nondeterministic Blum-Shub-Smale model of real computation. This provides a unified view on both Turing and real BSS complexity theory, and adds (a perhaps more natural and combinatorially flavoured) one to the still sparse list of NP<sub>R</sub>-complete problems, mostly pertaining to real algebraic geometry. Our proofs rely on (a careful examination of) works by John von Neumannas well as contributions by Hagge et. al (2005,2007,2009). We finally investigate the problem over Indefinite finite dimensions and relate it to NON-commutative semi algebraic geometry.
[quantum satisfiability, Computational modeling, computability, quantum logic, Complexity theory, Boolean algebra, NP-complete problem, Quantum computing, Turing machines, Quantum mechanics, quantum computing, Boolean prepositional logic, Polynomials, Hilbert space, geometry, nondeterministic Blum-Shub-Smale model, algebraic geometry, noncommutative semialgebraic geometry, Turing theory, real BSS complexity theory, computational complexity]
Formalizing Randomized Matching Algorithms
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Using Jera&#x0301;bek's framework for probabilistic reasoning, we formalize the correctness of two fundamental RNC2 algorithms for bipartite perfect matching within the theory VPV for polytime reasoning. The first algorithm is for testing if a bipartite graph has a perfect matching, and is based on the Schwartz-Zippel Lemma for polynomial identity testing applied to the Edmonds polynomial of the graph. The second algorithm, due to Mulmuley, Vazirani and Vazirani, is for finding a perfect matching, where the key ingredient of this algorithm is the Isolating Lemma.
[Vocabulary, pattern matching, graph theory, Cognition, Complexity theory, polytime reasoning, bipartite perfect matching, probabilistic reasoning, Edmonds polynomial, Polynomials, Bipartite graph, VPV, Testing, polynomials, Schwartz-Zippel Lemma, polynomial identity testing, Probabilistic logic, bounded arithmetic, inference mechanisms, bipartite graph, isolating Lemma, Jefabek's framework, weak pigeonhole principle, randomized algorithms, computational complexity]
Forcing as a Program Transformation
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
This paper is a study of the forcing translation through the proofs as programs correspondence in classical logic, following the methodology introduced by Krivine in . For that, we introduce an extension of (classical) higher-order arithmetic suited to express the forcing translation, called PA &#x03C9;+. We present the proof system of PA &#x03C9;+- based on Curry-style proof terms with call/cc - as well as the corresponding classical realizability semantics. Then, given a poset of conditions (represented in PA &#x03C9;+ as an upwards closed subset of a fixed meet semi-lattice), we define the forcing translation A &#x21D2; (p &#x22A2; A) (where A ranges over propositions) and show that the corresponding transformation of proofs is induced by a simple program transformation t &#x21D2; t* defined on raw proof-terms (i.e. independently from the derivation). From an analysis of the computational behavior of transformed programs, we show how to avoid the cost of the transformation by introducing an extension of Krivine's abstract machine devoted to the execution of proofs constructed by forcing. We show that this machine induces new classical realizability models and present the corresponding adequacy results.
[Context, Curry-Howard, Computational modeling, Cognition, Encoding, forcing translation, Classical Realizability, set theory, Program Transformation, Cost accounting, Equations, abstract machine, formal logic, Analytical models, programs correspondence, Curry-style proof terms, Forcing, program transformation, Lambda-calculus]
Proof Nets for Additive Linear Logic with Units
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Additive linear logic, the fragment of linear logic concerning linear implication between strictly additive formulae, coincides with sum-product logic, the internal language of categories with free finite products and co products. Deciding equality of its proof terms, as imposed by the categorical laws, is complicated by the presence of the units (the initial and terminal objects of the category) and the fact that in a free setting products and co products do not distribute. The best known desicion algorithm, due to Cockett and Santocanale (CSL 2009), is highly involved, requiring an intricate case analysis on the syntax of terms. This paper provides canonical, graphical representations of the categorical morphisms, yielding a novel solution to this decision problem. Starting with (a modification of) existing proof nets, due to Hughes and Van Glabbeek, for additive linear logic without units, canonical forms are obtained by graph rewriting. The rewriting algorithm is remarkably simple. As a decision procedure for term equality it matches the known complexity of the problem. A main technical contribution of the paper is the substantial correctness proof of the algorithm.
[Context, rewriting systems, canonical representation, Additives, graph theory, linear logic, Switches, proof nets, Calculus, graph rewriting, Equations, categorical morphism graphical representations, formal logic, sum-product logic, Semantics, Syntactics, desicion algorithm, theorem proving, graph rewriting algorithm]
Higher-Order Model Checking: From Theory to Practice
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
The model checking of higher-order recursion schemes (higher-order model checking for short) has been actively studied in the last decade, and has seen significant progress in both theory and practice. From a practical perspective, higher-order model checking provides a foundation for software model checkers for functional programming languages such as ML and Haskell. This short article aims to provide an overview of the recent progress in higher-order model checking and discuss future directions.
[Computational modeling, functional programming, higher-order recursion schemes, software model checkers, Complexity theory, functional programming languages, ML language, Computer science, Analytical models, formal verification, higher-order model checking, Automata, Haskell, Software, Safety, ML]
Powermonads and Tensors of Unranked Effects
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
In semantics and in programming practice, algebraic concepts such as monads or, essentially equivalently, (large) Lawvere theories are a well-established tool for modelling generic side-effects. An important issue in this context are combination mechanisms for such algebraic effects, which allow for the modular design of programming languages and verification logics. The most basic combination operators are sum and tensor: while the sum of effects is just their non-interacting union, the tensor imposes commutation of effects. However, for effects with unbounded arities, these combinations need not in general exist. Here, we introduce the class of uniform effects, which includes unbounded nondeterminism and continuations, and prove that the tensor does always exist if one of the component effects is uniform, thus in particular improving on previous results on tensoring with continuations. We then treat the case of nondeterminism in more detail, and give an order-theoretic characterization of effects for which tensoring with nondeterminism is conservative, thus enabling nondeterministic arguments such as a generic version of the Fischer-Ladner encoding of control operators.
[Context, Lawvere theories, Additives, functional programming, verification logics, conservativity, Programming, Encoding, tensors, algebraic concepts, powermonads, monads, programming languages, tensor, Equations, formal logic, uniform, Tensile stress, effects, unranked effects, Semantics, continuations, order-theoretic characterization]
Semantics of Higher-Order Quantum Computation via Geometry of Interaction
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
While much of the current study on quantum computation employs low-level formalisms such as quantum circuits, several high-level languages/calculi have been recently proposed aiming at structured quantum programming. The current work contributes to the semantical study of such languages, by providing interaction-based semantics of a functional quantum programming language, the latter is based on linear lambda calculus and is equipped with features like the! modality and recursion. The proposed denotational model is the first one that supports the full features of a quantum functional programming language, we also prove adequacy of our semantics. The construction of our model is by a series of existing techniques taken from the semantics of classical computation as well as from process theory. The most notable among them is Girard's Geometry of Interaction (GoI), categorically formulated by Abramsky, Haghverdi and Scott. The mathematical genericity of these techniques - largely dueto their categorical formulation - is exploited for our move from classical to quantum.
[lambda calculus, higher-order quantum computation semantics, functional quantum programming language, quantum circuits, Computational modeling, functional programming, categorical semantics, Programming, Calculus, structured programming, programming languages, interaction-based semantics, Geometry, geometry of interaction, Quantum computing, Algebra, low-level formalisms, Girards geometry of interaction, Semantics, quantum computing, structured quantum programming, linear lambda calculus, quantum computation, realizability]
Separation Logic in the Presence of Garbage Collection
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Separation logic has proven to be a highly effective tool for the verification of heap-manipulating programs. However, it has been applied almost exclusively in language settings where either memory is managed manually or the issue of memory management is ignored altogether. In this paper, we present a variant of separation logic, GCSL, for reasoning about low-level programs that interface to a garbage collector. In contrast to prior work by Calcagno et al., our model of GCSL (1) permits reasoning about programs that use internal pointers and address arithmetic, (2) supports logical variables that range over pointers, and (3) validates the "frame" rule, as well as a standard interpretation of separation-logic assertions, without requiring any restrictions on existentially-quantified formulae. Essential to our approach is the technique (due originally to McCreight et al.) of distinguishing between "logical" and "physical" states, which enables us to insulate the logic from the physical reality that pointer "values" may be moved and/or deallocated by the garbage collector.
[address arithmetic, logical variables, garbage collector, reasoning, frame rule, Cognition, heap manipulating program verification, formal logic, Computer languages, storage management, memory management, GCSL, low-level programs, internal pointers, Semantics, Memory management, separation logic, Hafnium, Concrete, reasoning about programs, Resource management]
Ultrametric Semantics of Reactive Programs
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We describe a denotational model of higher-order functional reactive programming using ultra metric spaces and non expansive maps, which provide a natural Cartesian closed generalization of causal stream functions and guarded recursive definitions. We define a type theory corresponding to this semantics and show that it satisfies normalization. Finally, we show how to efficiently implement reactive programs written in this language using an imperatively updated data flow graph, and give a separation logic proof that this low-level implementation is correct with respect to the high-level semantics.
[functional programming, data flow graphs, reactive program, Calculus, type theory, Delay, nonexpansive map, dataflow graph, separation logic proof, ultrametric semantics, natural cartesian closed generalization, Semantics, higher order functional reactive programming, Bismuth, Syntactics, low level implementation, Mathematical model, causal stream function, high level semantics]
Ackermannian and Primitive-Recursive Bounds with Dickson's Lemma
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Dickson's Lemma is a simple yet powerful tool widely used in decidability proofs, especially when dealing with counters or related data structures in algorithmics, verification and model-checking, constraint solving, logic, etc. While Dickson's Lemma is well-known, most computer scientists are not aware of the complexity upper bounds that are entailed by its use. This is mainly because, on this issue, the existing literature is not very accessible. We propose a new analysis of the length of bad sequences over (Nk,&#x2264;), improving on earlier results and providing upper bounds that are essentially tight. This analysis is complemented by a ``user guide'' explaining through practical examples how to easily derive complexity upper bounds from Dickson's Lemma.
[Algorithm design and analysis, model-checking, Dickson's Lemma, Radiation detectors, Complexity theory, Electronic mail, Indexes, complexity upper bounds, Computer science, Upper bound, decidability, formal verification, decidability proofs, related data structures, primitive-recursive bounds]
The Complexity of Verifying Ground Tree Rewrite Systems
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Ground tree rewrite systems (GTRS) are an extension of pushdown systems with the ability to spawn new sub threads that are hierarchically structured. In this paper, we study the following problems over GTRS:(1) model checking EF-logic, (2)weak bi similarity checking against finite systems, and (3) strong similarity against finite systems. Although they are all known to be decidable, we show that problems (1) and (2) have nonelementbisimilarityy, whereasproblem (3) is shown to be in coNEXP by finding a syntactic fragment of EFwhose model checking complexity is complete for PNEXP.The same problems are studied over a more general but decidable extension of GTRS called regular GTRS (RGTRS), where regular rewriting is allowed. Over RGTRS we show that all three problems have non elementary complexity. We also apply our techniques to problems over PA-processes, a well-known class of infinite systems in Mayr's PRS (Process Rewrite Systems) hierarchy. For example, strong bi similarity checking of PA-processes against finite systems is shown to be in coNEXP, yielding a first elementary upper bound for this problem.
[Adaptation models, pushdown automata, Ground Tree Rewrite Systems, Complexity theory, model checking complexity, Complexity, Model Checking, decidability, formal verification, bisimilarity checking, Polynomials, nonelementary complexity, infinite systems, rewriting systems, regular GTRS, Computational modeling, pushdown systems, trees (mathematics), process rewrite system, Mayr's PRS hierarchy, coNEXP, Upper bound, finite system, syntactic fragment, PNEXP, Bisimulation equivalence, Automata, Games, EF logic, ground tree rewrite system verification]
Complexity of Two-Variable Dependence Logic and IF-Logic
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We study the two-variable fragments D2 and IF2 of dependence logic and independence-friendly logic. We consider the satisfiability and finite satisfiability problems of these logics and show that for D2, both problems are NEXPTIME-complete, whereas for IF2, the problems are undecidable. We also show that D2 is strictly less expressive than IF2 and that already in D2, equicardinality of two unary predicates and infinity can be expressed (the latter in the presence of a constant symbol).An extended version of this publication can be found at arxiv.org.
[Vocabulary, complexity, Color, finite satisfiability problems, dependence logic, Complexity theory, two variable dependence logic, independence friendly logic, formal logic, decidability, Tiles, IF-logic, Semantics, satisfiability, expressivity, Games, Syntactics, two-variable logic, independence-friendly logic]
The Dichotomy for Conservative Constraint Satisfaction Problems Revisited
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
A central open question in the study of non-uniform constraint satisfaction problems (CSPs) is the dichotomy conjecture of Feder and Vardi stating that the CSP over a fixed constraint language is either NP-complete, or tractable. One of the main achievements in this direction is a result of Bulatov (LICS'03) confirming the dichotomy conjecture for conservative CSPs, that is, CSPs over constraint languages containing all unary relations. Unfortunately, the proof is very long and complicated, and therefore hard to understand even for a specialist. This paper provides a short and transparent proof.
[Computers, CSP, dichotomy theorem, constraint theory, fixed constraint language, constraint satisfaction problem, Complexity theory, conservative constraint satisfaction problems revisited dichotomy, list homomorphism problem, dichotomy conjecture, conservative algebra, Algebra, Absorption, constraint languages, operations research, NP-complete problems, Polynomials, Argon, computational complexity]
A Tetrachotomy for Positive First-Order Logic without Equality
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We classify completely the complexity of evaluating positive equality-free sentences of first-order logic over a fixed, finite structure D. This problem may be seen as a natural generalisation of the quantified constraint satisfaction problem QCSP(D). We obtain a tetrachotomy for arbitrary finite structures: each problem is either in L, is NP-complete, is co-NP-complete or is P space-complete. Moreover, its complexity is characterised algebraically in terms of the presence or absence of specific surjective hyper-endomorphisms, and, logically, in terms of relativisation properties with respect to positive equality-free sentences. We prove that the meta-problem, to establish for a specific D into which of the four classes the related problem lies, is NP-hard.
[Context, complexity, constraint theory, arbitrary finite structures, quantified constraint satisfaction problem, NP-complete, Complexity theory, Electronic mail, P space-complete, Computer science, formal logic, Logic in Computer Science, Upper bound, positive first-order logic, Galois connection, Games, Quantified Constraint Satisfaction, Universal Algebra, Robustness, co-NP-complete, computational complexity, positive equality-free sentences, Computational Complexity]
Decidability of Definability
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
For a fixed infinite structure &#x0393; with finite signature &#x03C4;, we study the following computational problem: input are quantifier-free first-order &#x03C4;-formulas &#x03C6;<sub>0</sub>, &#x03C6;<sub>1</sub>,..., &#x03C6;<sub>n</sub> that define relations R<sub>0</sub>, R<sub>1</sub>,..., R<sub>n</sub> over &#x0393;. The question is whether the relation R<sub>0</sub> is primitive positive definable from R<sub>1</sub>,..., R<sub>n</sub>, i.e., definable by a first-order formula that uses only relation symbols for R<sub>1</sub>,..., R<sub>n</sub>, equality, conjunctions, and existential quantification (disjunction, negation, and universal quantification are forbidden). We show decidability of this problem for all structures &#x0393; that have a first-order definition in an ordered homogeneous structure &#x0394; with a finite language whose age is a Ramsey class and determined by finitely many forbidden substructures. Examples for structures &#x0393; with this property are the order of the rationals, the random graph, the homogeneous universal poset, the random tournament, all homogeneous universal C-relations, and many more. We also obtain decidability of the problem when we replace primitive positive definability by existential positive, or existential definability. Our proof makes use of universal algebraic and model theoretic concepts, Ramsey theory, and a recent characterization of Ramsey classes in topological dynamics.
[Context, finite language, Heuristic algorithms, Decidability, Lattices, definability, ordered homogeneous structure, Color, Ramsey Theory, Homogeneous Structures, Orbits, Primitive Positive Definitions, Vehicle dynamics, quantifier-free first-order &#x03C4;-formulas, Constraint Satisfaction Problems, Model Theory, Algebra, decidability, Universal Algebra, Ramsey class, computational complexity]
The Complexity of Evaluating First-Order Sentences over a Fixed Structure
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Summary form only given. Both the constraint satisfaction problem and the homomorphism problem are known to be equivalent to the problem of evaluating first-order (&#x2203;&#x039B;)-sentences over a relational structure. Many computational problems can be represented in this framework with a suitable fixed relational structure. How exactly does the complexity of the evaluation problem depend on the fixed structure? Much progress has recently been made in answering this question, with an exciting interplay of finite model theory and universal algebra at the heart of this direction. We will explain this interplay and discuss the most important results arising from it. Most of the talk will be devoted to finite structures, but we will touch on the infinite case and also on generalisations to other fragments of first-order logic.
[Heart, fixed structure, fixed relational structure, Computational modeling, constraint theory, homomorphism problem, first-order logic, first order sentence evaluation, Educational institutions, constraint satisfaction problem, Complexity theory, Electronic mail, Computer science, formal logic, Algebra, operations research, finite model theory, universal algebra, computational complexity]
Regular Repair of Specifications
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
What do you do if a computational object (e.g. program trace) fails a specification? An obvious approach is to perform repair: modify the object minimally to get something that satisfies the constraints. In this paper we study repair of temporal constraints, given as automata or temporal logic formulas. We focus on determining the number of repairs that must be applied to a word satisfying a given input constraint in order to ensure that it satisfies a given target constraint. This number may well be unbounded; one of our main contributions is to isolate the complexity of the "bounded repair problem\
[computational object, edit distance, Transducers, regular languages, distance automata, regular repair, Doped fiber amplifiers, Maintenance engineering, temporal logic, temporal constraints, finite memory, Complexity theory, formal specification, regular language, temporal logic formulas, Aggregates, bounded repair problem, Automata, automata logic formulas, Games, computational complexity]
Rigorous Approximated Determinization of Weighted Automata
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
A nondeterministic weighted finite automaton (WFA) maps an input word to a numerical value. Applications of weighted automata include formal verification of quantitative properties, as well as text, speech, and image processing. Many of these applications require the WFAs to be deterministic, or work substantially better when the WFAs are deterministic. Unlike NFAs, which can always be determinized, not all WFAs have an equivalent deterministic weighted automaton (DWFA). In, Mohri describes a determinization construction for a subclass of WFA. He also describes a property of WFAs (the twins property), such that all WFAs that satisfy the twins property are determinizable and the algorithm terminates on them. Unfortunately, many natural WFAs cannot be determinized. In this paper we study approximated determinization of WFAs. We describe an algorithm that, given a WFA A and an approximation factor t &#x2265; 1, constructs a DWFA A' that t-determinizes A. Formally, for all words w &#x03F5; &#x03A3;*, the value of w in A' is at least its value in A and at most t times its value in A. Our construction involves two new ideas:attributing states in the subset construction by both upper and lower residues, and collapsing attributed subsets whose residues can be tightened. The larger the approximation factor is, the more attributed subsets we can collapse. Thus, t-determinization is helpful not only for WFAs that cannot be determinized, but also in cases determinization is possible but results in automata that are too big to handle. In addition, t-determinization is useful for reasoning about the competitive ratio of on line algorithms. We also describe a property (the t-twins property) and use it in order to characterize t-determinizable WFAs. Finally, we describe a polynomial algorithm for deciding whether a given WFA has the t-twins property.
[Context, image processing, finite automata, rigorous approximated weighted automata determination, nondeterministic weighted finite automaton maps, polynomial algorithm, Cognition, Determinization, Approximation methods, text processing, formal verification, deterministic automata, Automata, Speech recognition, Approximation algorithms, speech processing, Weighted automata, i-determinization, Speech processing]
Automata with Group Actions
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Our motivating question is a My hill-Nerode theorem for infinite alphabets. We consider several kinds of those: alphabets whose letters can be compared only for equality, but also ones with more structure, such as a total order or a partial order. We develop a framework for studying such alphabets, where the key role is played by the automorphism group of the alphabet. This framework builds on the idea of nominal sets of Gabbay and Pitts, nominal sets are the special case of our framework where letters can be only compared for equality. We use the framework to uniformly generalize to infinite alphabets parts of automata theory, including decidability results. In the case of letters compared for equality, we obtain automata equivalent in expressive power to finite memory automata, as defined by Francez and Kaminski.
[Image recognition, formal languages, nominal sets, finite automata, automata theory, regisrer automatat, Orbits, Registers, Cost accounting, finite memory automata, group theory, Myhill-Nerode theorem, infinite alphabets, decidability, Automata, automorphism group, Syntactics, data languages, Concrete]
A Decidable Two-Way Logic on Data Words
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We study the satisfiability problem for a logic on data words. A data word is a finite word where every position carries a label from a finite alphabet and a data value from an infinite domain. The logic we consider is two-way, contains future and past modalities, which are considered as reflexive and transitive relations, and data equality and inequality tests. This logic corresponds to the fragment of XPath with the 'following-sibling-or-self' and 'preceding-sibling-or-self' axes over data words. We show that this problem is decidable, EXPSPACE-complete. This is surprising considering that with the strict (non-reflexive) navigation relations the satisfiability problem is undecidable. To prove this, we first reduce the problem to a derivation problem for an infinite transition system, and then we show how to abstract this problem into a reachability problem of a finite transition system.
[XPath, data word, Navigation, Biological system modeling, derivation problem, decidable two way logic, Complexity theory, finite alphabet, data words, transitive relations, formal logic, data value, infinite transition system, finite word, satisfiability, XML, Automata, Syntactics, data equality, data handling, EXPSPACE-complete, two-way, reflexive-transitive, Testing]
The Ultimate Undecidability Result for the Halpern-Shoham Logic
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
The Halpern-Shoham logic is a modal logic of time intervals. Some effort has been put in last ten years to classify fragments of this beautiful logic with respect to decidability of its satisfiability problem. We complete this classification by showing - what we believe is quite an unexpected result - that the logic of subintervals, the fragment of the Halpern - Shoham logic where only the operator "during'', or D, is allowed, is undecidable over discrete structures. This is surprising as this, apparently very simple, logic is decidable over dense orders and its reflexive variant is known to be decidable over discrete structures. Our result subsumes a lot of previous negative results for the discrete case, like the undecidability for ABE, BD, AA&#x0305;D, and so on.
[undecidable logic, Radiation detectors, Halpern-Shoham logic, computability, Time measurement, interval temporal logic, modal logic, Computer science, Pathology, Reactive power, decidability, satisfiability problem, Automata, Labeling]
What's Decidable about Halpern and Shoham's Interval Logic? The Maximal Fragment ABBL
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
The introduction of Halpern and Shoham's modal logic of intervals (later on called HS) dates back to 1986. Despite its natural semantics, this logic is undecidable over all interesting classes of temporal structures. This discouraged research in this area until recently, when a number of non trivial decidable fragments have been found. This paper is a contribution toward the complete classification of HS fragments. Different combinations of Allen's interval relations begins (B), meets (A), and later (L), and their inverses A&#x0305;, B&#x0305;, and L&#x0305;, have been considered in the literature. We know from previous work that the combination ABB&#x0305;A&#x0305; is decidable over finite linear orders and undecidable everywhere else. We extend these results by showing that ABB&#x0305;L&#x0305; is decidable over the class of all (resp., dense, discrete) linear orders, and that it is maximal with respect to decidability over these classes: adding any other interval modality immediately leads to undecidability.
[Decidability, Allen interval relations, temporal logic, HS fragments, Complexity theory, Compass, Vehicles, maximal fragment ABB&#x0305;L&#x0305;, Complexity, Semantics, Measurement uncertainty, Syntactics, temporal structures, Interval Temporal Logic, Trajectory, Shoham interval logic, linear orders, Halpern interval logic]
Computing Optimal Coverability Costs in Priced Timed Petri Nets
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
We consider timed Petri nets, i.e., unbounded Petri nets where each token carries a real-valued clock. Transition arcs are labeled with time intervals, which specify constraints on the ages of tokens. Our cost model assigns token storage costs per time unit to places, and firing costs to transitions. We study the cost to reach a given control-state. In general, a cost-optimal run may not exist. However, we show that the infimum of the costs is computable.
[token storage costs, Computational modeling, automata theory, Petri nets, computational geometry, formal specification, Delay, unbounded Petri nets, real-valued clock, transition arcs, formal verification, optimal coverability costs, priced timed Petri nets, Automata, concurrent systems, Cost function, timed automata, Clocks, Manganese, Formal verification, Timed Automata]
Concurrent Strategies
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
A bi category of very general nondeterministic concurrent games and strategies is presented. The intention is to formalize distributed games in which both Player (or a team of players) and Opponent (or a team of opponents) can interact in highly distributed fashion, without, for instance, enforcing that their moves alternate.
[formalize distributed games, nondeterministic concurrent games, Computational modeling, game theory, distributed fashion, Synchronization, concurrent strategies, concurrency, Tensile stress, event structure, Semantics, Games, strategy, Positron emission tomography, Distributed algorithms]
[Roster page]
2011 IEEE 26th Annual Symposium on Logic in Computer Science
None
2011
Provides a listing of current committee members and society officers.
[]
Foreword
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
This volume contains the proceedings of the Twenty-Seventh Annual ACM/IEEE Symposium on Logic in Computer Science. LICS is an annual international forum on the broad range of topics that lie at the intersection of computer science and mathematical logic. LICS 2012 was sponsored by the IEEE Technical Committee on Mathematical Foundations of Computing and by the ACM Special Interest Group on Algorithms and Computation Theory (SIGACT), in cooperation with the Association for Symbolic Logic and the European Association for Theoretical Computer Science. The meeting was held at the Electrical Engineering and Computing Department of the University of Dubrovnik, in Dubrovnik, Croatia, from June 25th to 28th, 2012. The 60 contributed papers in this volume were selected from 171 submissions. Submissions were initially reviewed by at least three members of the program committee. In some cases, the committee chose to consult additional reviewers, whose names are listed below. The program committee carried out extensive electronic discussions, which included communication with many authors to obtain clarifications regarding specific aspects of their submissions. I would like to thank my fellow program committee members for all their very hard work selecting a high quality, stimulating program of contributed papers. The symposium program also included short-paper sessions, co-chaired by Andrei Bulatov and Olivier Laurent, with 13 presentations.
[]
Backward induction in games of perfect information
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Summary form only given. One of the areas of Game Theory that are of most interest to Computer Scientists, and in which Formal Logic is most heavily used, is that of Games of Perfect Information (like Chess or Checkers). Of central interest in this connectioOne of the areas of Game Theory that are of most interest to Computer Scientists, and in which Formal Logic is most heavily used, is that of Games of Perfect Information (like Chess or Checkers). Of central interest in this connection is the Backward Induction algorithm, which has generated a good deal of controversy, and with it, a large literature. We will review some of this literature, culminating with an as yet unpublished result of Itai Arieli and the speaker.n is the Backward Induction algorithm, which has generated a good deal of controversy, and with it, a large literature. We will review some of this literature, culminating with an as yet unpublished result of Itai Arieli and the speaker.
[formal logic, backward induction, computer scientists, perfect information, game theory]
On Building Constructive Formal Theories of Computation Noting the Roles of Turing, Church, and Brouwer
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
In this article I will examine a few key concepts and design decisions that account for the high value of implemented constructive type theories in computer science. I'll stress the historical fact that these theories, and the proof assistants that animate them, were born from a strong partnership linking computer science, logic, and mathematics. I will recall how modern type theory researchers built on deep insights from the earliest pioneers: Turing - the first computer scientist, Church - the patriarch of logic in computer science, and Brouwer - a singular pioneer of intuitionism and constructive mathematics. They created solid intellectual ground on which to build a formal implemented constructive theory of computation whose influence will be felt well beyond computing and information science alone. All generations of constructive type theory researchers since this beginning have had leaders from all three disciplines. Much of the seminal modern work creating these type theories and their proof assistants was presented in LICS proceedings, and LICS could be a natural home for future work in this flourishing area which is the epitome of logic in computer science.
[Computers, propositions-as-types, Protocols, constructive formal theories, intuitionistic logic, Calculus, type theory, completeness, FLP theorem, formal logic, protocol synthesis, computer science, attack-tolerance, Semantics, automated reasoning, constructive type theories, Nuprl, proof assistants, logic of events, Computational modeling, Coq, Computer science, constructive mathematics, logic, computation theories, information science]
Privacy, Anonymity, and Accountability in Ad-Supported Services
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
In this talk, I will address three aspects of user privacy in advertiser-supported, online services. First, I present the design of a novel browser plug-in that enables anonymous search. Next, I consider economic aspects of user privacy from the point of view of the operator of an advertiser-supported website. Finally, I present recent work on "accountability" in online activity, where the goal is to hold website operators responsible for appropriate handling of users' sensitive information rather than to prevent users from ever providing information that might be misused.
[Barium, advertising data processing, economic aspect, privacy, browser plug-in, advertiser-supported Web site, Computer science, ad-supported services, user privacy, advertiser-supported online services, Accountability, data privacy, anonymity, Web sites, accountability]
Turing's Password: What Internet Cannot Leak
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Summary form only given. I use a revised, more robust, notion of computability to answer bothersome questions that are not even easy to ask with any clarity.
[Computer science, Turing password, computability, Educational institutions, Robustness, Internet]
Term rewriting and lambda calculus
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
false
[Computer science, Vocabulary, Algebra, Tutorials, Games, Calculus, Convergence]
Logics of Dynamical Systems
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We study the logic of dynamical systems, that is, logics and proof principles for properties of dynamical systems. Dynamical systems are mathematical models describing how the state of a system evolves over time. They are important in modeling and understanding many applications, including embedded systems and cyber-physical systems. In discrete dynamical systems, the state evolves in discrete steps, one step at a time, as described by a difference equation or discrete state transition relation. In continuous dynamical systems, the state evolves continuously along a function, typically described by a differential equation. Hybrid dynamical systems or hybrid systems combine both discrete and continuous dynamics. This is a brief survey of differential dynamic logic for specifying and verifying properties of hybrid systems. We explain hybrid system models, differential dynamic logic, its semantics, and its axiomatization for proving logical formulas about hybrid systems. We study differential invariants, i.e., induction principles for differential equations. We briefly survey theoretical results, including soundness and completeness and deductive power. Differential dynamic logic has been implemented in automatic and interactive theorem provers and has been used successfully to verify safety-critical applications in automotive, aviation, railway, robotics, and analogue electrical circuits.
[axiomatization, differential equation, discrete dynamical systems, safety-critical software, mathematical models, Complexity theory, Vehicle dynamics, difference equations, hybrid systems, Semantics, interactive theorem provers, interactive systems, theorem proving, Mathematical model, discrete state transition relation, logic of dynamical systems, difference equation, safety-critical applications, deduction, Automata, Differential equations, differential dynamic logic, dynamic logic, Acceleration, proof principles]
Dense-Timed Pushdown Automata
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We propose a model that captures the behavior of real-time recursive systems. To that end, we introduce dense-timed pushdown automata that extend the classical models of pushdown automata and timed automata, in the sense that the automaton operates on a finite set of real-valued clocks, and each symbol in the stack is equipped with a real-valued clock representing its "age". The model induces a transition system that is infinite in two dimensions, namely it gives rise to a stack with an unbounded number of symbols each of which with a real-valued clock. The main contribution of the paper is an EXPTIME-complete algorithm for solving the reachability problem for dense-timed pushdown automata.
[reachability analysis, Computational modeling, finite set, Petri nets, EXPTIME-complete algorithm, pushdown automata, reachability problem, real-time recursive system, Cost accounting, Standards, clocks, Analytical models, real-valued clock, automaton, Automata, transition system, Clocks, computational complexity, dense-timed pushdown automata, Formal verification]
Coproducts of Monads on Set
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Coproducts of monads on Set have arisen in both the study of computational effects and universal algebra. We describe coproducts of consistent monads on Set by an initial algebra formula, and prove also the converse: if the coproduct exists, so do the required initial algebras. That formula was, in the case of ideal monads, also used by Ghani and Uustalu. We deduce that coproduct embeddings of consistent monads are injective; and that a coproduct of injective monad morphisms is injective. Two consistent monads have a coproduct iff either they have arbitrarily large common fixpoints, or one is an exception monad, possibly modified to preserve the empty set. Hence a consistent monad has a coproduct with every monad iff it is an exception monad, possibly modified to preserve the empty set. We also show other fixpoint results, including that a functor (not constant on nonempty sets) is finitary iff every sufficiently large cardinal is a fixpoint.
[coproduct embeddings, Educational institutions, empty set, set theory, monads, Indexes, Equations, coproducts, fixpoints, Computer science, bialgebras, Algebra, process algebra, consistent monads, Semantics, computational effects, initial algebra formula, Writing, universal algebra, injective monad morphisms]
Approximate Verification of the Symbolic Dynamics of Markov Chains
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
A finite state Markov chain M is often viewed as a probabilistic transition system. An alternative view - which we follow here - is to regard M as a linear transform operating on the space of probability distributions over its set of nodes. The novel idea here is to discretize the probability value space [0,1] into a finite set of intervals. A concrete probability distribution over the nodes is then symbolically represented as a tuple D of such intervals. The i-th component of the discretized distribution D will be the interval in which the probability of node i falls. The set of discretized distributions is a finite set and each trajectory, generated by repeated applications of M to an initial distribution, will induce a unique infinite string over this finite set of letters. Hence, given a set of initial distributions, the symbolic dynamics of M will consist of an infinite language L over the finite alphabet of discretized distributions. We investigate whether L meets a specification given as a linear time temporal logic formula whose atomic propositions will assert that the current probability of a node falls in an interval. Unfortunately, even for restricted Markov chains (for instance, irreducible and aperiodic chains), we do not know at present if and when L is an (omega)-regular language. To get around this we develop the notion of an epsilon-approximation, based on the transient and long term behaviors of M. Our main results are that, one can effectively check whether (i) for each infinite word in L, at least one of its epsilon-approximations satisfies the specification; (ii) for each infinite word in L all its epsilon approximations satisfy the specification. These verification results are strong in that they apply to all finite state Markov chains. Further, the study of the symbolic dynamics of Markov chains initiated here is of independent interest and can lead to other applications.
[Transforms, temporal logic, aperiodic Markov chains, Probability distribution, set theory, linear-time temporal logic formula, atomic propositions, Approximation methods, probabilistic transition system, Probabilistic Computation, tuple, infinite-word, Model Checking, formal verification, probability value space discretization, restricted Markov chains, irreducible Markov chains, Trajectory, epsilon-approximation, approximation theory, formal languages, finite-state Markov chain, Approximation, symbolic dynamics approximate verification, probability, Probabilistic logic, infinite-language, Markov Processes, linear transform, node probability distribution space, finite-interval set, omega-regular language, Markov processes, finite-alphabet, Concrete]
Regular Transformations of Infinite Strings
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
The theory of regular transformations of finite strings is quite mature with appealing properties. This class can be equivalently defined using both logic (Monadic second-order logic) and finite-state machines (two-way transducers, and more recently, streaming string transducers); is closed under operations such as sequential composition and regular choice; and problems such as functional equivalence and type checking, are decidable for this class. In this paper, we initiate a study of transformations of infinite strings. The MSO-based definition for regular string transformations generalizes naturally to infinite strings. We define an equivalent generalization of the machine model of streaming string transducers to infinite strings. A streaming string transducer is a deterministic machine that makes a single pass over the input string, and computes the output fragments using a finite set of string variables that are updated in a copyless manner at each step. We show how Muller acceptance condition for automata over infinite strings can be generalized to associate an infinite output string with an infinite execution. The proof that our model captures all MSO-definable transformations uses two-way transducers. Unlike the case of finite strings, MSO-equivalent definition of two-way transducers over infinite strings needs to make decisions based on omega-regular look-ahead. Simulating this look-ahead using multiple variables with copyless updates, is the main technical challenge in our constructions. Finally, we show that type checking and functional equivalence are decidable for MSO-definable transformations of infinite strings.
[Computers, streaming string transducers, Streaming string transducers, two-way transducers, type checking, machine model, input string, type theory, finite state machines, Cost accounting, decidability, omega-regular look-ahead, output fragments, infinite execution, MSO-based definition, omega-regular transformations, equivalent generalization, Transducers, formal languages, Computational modeling, Muller acceptance condition, Educational institutions, sequential composition, copyless update, Indexes, regular choice, Monadic second-order logic, functional equivalence, Automata, infinite string regular transformations, deterministic machine, monadic second-order logic, finite-state machines, automata, equivalence classes]
The Semantics of Parsing with Semantic Actions
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
The recovery of structure from flat sequences of input data is a problem that almost all programs need to solve. Computer Science has developed a wide array of declarative languages for describing the structure of languages, usually based on the context-free grammar formalism, and there exist parser generators that produce efficient parsers for these descriptions. However, when faced with a problem involving parsing, most programmers opt for ad-hoc hand-coded solutions, or use parser combinator libraries to construct parsing functions. This paper develops a hybrid approach, treating grammars as collections of active right-hand sides, indexed by a set of non-terminals. Active right-hand sides are built using the standard monadic parser combinators and allow the consumed input to affect the language being parsed, thus allowing for the precise description of the realistic languages that arise in programming. We carefully investigate the semantics of grammars with active right-hand sides, not just from the point of view of language acceptance but also in terms of the generation of parse results. Ambiguous grammars may generate exponentially, or even infinitely, many parse results and these must be efficiently represented using Shared Packed Parse Forests (SPPFs). A particular feature of our approach is the use of Reynolds-style parametricity to ensure that the language that grammars describe cannot be affected by the representation of parse results.
[declarative languages, active right-hand sides, parametricity, flat sequences, context-free grammar formalism, realistic languages, ambiguity, computer science, Semantics, context sensitivity, context-free grammars, ad-hoc hand-coded solutions, Libraries, precise description, parser combinator library, parser combinators, standard monadic parser combinators, Parsing, parsing semantics, shared packed parse forests, parser generators, Generators, Grammar, monads, programming language semantics, structure recovery, Computer science, language acceptance, Reynolds-style parametricity, SPPF, Vegetation, Syntactics, parsing functions, semantic actions, ambiguous grammars]
Modular Construction of Cut-free Sequent Calculi for Paraconsistent Logics
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
This paper makes a substantial step towards automatization of Para consistent reasoning by providing a general method for a systematic and modular generation of cut-free calculi for thousands of Para consistent logics known as Logics of Formal (In)consistency. The method relies on the use of non-deterministic semantics for these logics.
[paraconsistent reasoning automatization, Knowledge based systems, Nondeterministic semantics, modular construction, systematic generation, nondeterministic logic semantics, Educational institutions, modular generation, Multivalued logic, cut-free sequent calculi, inference mechanisms, Standards, Cost accounting, logics of formal consistency, Paraconsistent logic, Computer science, paraconsistent logics, Systematics, Semantics, multivalued logic, Proof theory]
Inductive Types in Homotopy Type Theory
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Homotopy type theory is an interpretation of Martin-Lof's constructive type theory into abstract homotopy theory. There results a link between constructive mathematics and algebraic topology, providing topological semantics for intensional systems of type theory as well as a computational approach to algebraic topology via type theory-based proof assistants such as Coq. The present work investigates inductive types in this setting. Modified rules for inductive types, including types of well-founded trees, or W-types, are presented, and the basic homotopical semantics of such types are determined. Proofs of all results have been formally verified by the Coq proof assistant, and the proof scripts for this verification form an essential component of this research.
[Type theory, algebraic topology, algebra, type theory, homotopical semantics, inductive type, Martin-Lof constructive type theory, Algebra, computational approach, initial algebras, homotopy type theory, Semantics, Polynomials, intensional system, proof script, W-types, homotopy theory, topology, trees (mathematics), topological semantics, Educational institutions, Coq proof assistant, Topology, programming language semantics, Standards, constructive mathematics, abstract homotopy theory, type theory-based proof assistant, well-founded trees]
Combining Deduction Modulo and Logics of Fixed-Point Definitions
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Inductive and coinductive specifications are widely used in formalizing computational systems. Such specifications have a natural rendition in logics that support fixed-point definitions. Another useful formalization device is that of recursive specifications. These specifications are not directly complemented by fixed-point reasoning techniques and, correspondingly, do not have to satisfy strong monotonicity restrictions. We show how to incorporate a rewriting capability into logics of fixed-point definitions towards additionally supporting recursive specifications. Specifically, we describe a natural deduction calculus that adds a form of "closed-world'' equality - a key ingredient to supporting fixed-point definitions - to deduction modulo, a framework for extending a logic with a rewriting layer operating on formulas. We show that our calculus enjoys strong normalizability when the rewrite system satisfies general properties and we demonstrate its usefulness in specifying and reasoning about syntax-based descriptions. Our integration of closed-world equality into deduction modulo is based on an elimination principle for this form of equality that, for the first time, allows us to require finiteness of proofs without sacrificing stability under reduction.
[Context, fixed-point and recursive definitions, fixed-point definition logics, computational system formalization, closed-world equality, syntax-based descriptions, monotonicity restrictions, rewriting layer, Educational institutions, recursive specifications, Cognition, Calculus, formal specification, Standards, natural deduction calculus, coinductive specifications, strong normalizability, process algebra, Semantics, deduction modulo, formalization device, Syntactics, fixed-point reasoning techniques]
Graph Logics with Rational Relations and the Generalized Intersection Problem
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We investigate some basic questions about the interaction of regular and rational relations on words. The primary motivation comes from the study of logics for querying graph topology, which have recently found numerous applications. Such logics use conditions on paths expressed by regular languages and relations, but they often need to be extended by rational relations such as subword (factor) or subsequence. Evaluating formulae in such extended graph logics boils down to checking nonemptiness of the intersection of rational relations with regular or recognizable relations (or, more generally, to the generalized intersection problem, asking whether some projections of a regular relation have a nonempty intersection with a given rational relation). We prove that for several basic and commonly used rational relations, the intersection problem with regular relations is either undecidable (e.g., for subword or suffix, and some generalizations), or decidable with non-multiply-recursive complexity (e.g., for subsequence and its generalizations). These results are used to rule out many classes of graph logics that freely combine regular and rational relations, as well as to provide the simplest problem related to verifying lossy channel systems that has non-multiply-recursive complexity. We then prove a dichotomy result for logics combining regular conditions on individual paths and rational relations on paths, by showing that the syntactic form of formulae classifies them into either efficiently checkable or undecidable cases. We also give examples of rational relations for which such logics are decidable even without syntactic restrictions.
[regular-rational relation interaction, graph theory, graph logics, Resource description framework, Complexity theory, regular relations, expressive power, decidability, Semantics, formal languages, generalized intersection problem, rational relations, regular languages, Educational institutions, decidability and complexity, logics for graphs, subsequence, undecidability, recognizable relations, lossy channel systems, Query processing, nonmultiply-recursive complexity, Automata, subword, regular path queries, graph topology querying, computational complexity]
Near Unanimity Constraints Have Bounded Pathwidth Duality
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We show that if a finite relational structure has a near unanimity polymorphism, then the constraint satisfaction problem with that structure as its fixed template has bounded pathwidth duality, putting the problem in nondeterministic logspace. This generalizes the analogous result of Dalmau and Krokhin for majority polymorphisms and lends further support to a conjecture suggested by Larose and Tesson.
[Vocabulary, pathwidth duality, absorption, nondeterministic logspace, Educational institutions, constraint satisfaction problem, linear datalog, polymorphism, near unanimity, finite relational structure, Standards, artificial intelligence, unanimity constraints, unanimity polymorphism, Computer science, bounded pathwidth duality, constraint satisfaction problems, Algebra, Absorption, constraint satisfaction, Games, duality (mathematics), computational complexity]
A Computational Interpretation of Parametricity
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Reynolds' abstraction theorem has recently been extended to lambda-calculi with dependent types. In this paper, we show how this theorem can be internalized. More precisely, we describe an extension of the Pure Type Systems with a special parametricity rule (with computational content), and prove fundamental properties such as Church-Rosser's and strong normalization. All instances of the abstraction theorem can be both expressed and proved in the calculus itself. Moreover, one can apply parametricity to the parametricity rule: parametricity is itself parametric.
[Context, lambda calculus, computational interpretation, dependent types, pure type system, parametricity rule, Church-Rosser, Calculus, type theory, Indexes, computational content, strong normalization, Lambda Calculus, Syntactics, Bismuth, Concrete, Facsimile, lambda-calculi, Reynolds abstraction theorem, Type structure]
Von Neumann's Biased Coin Revisited
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Suppose you want to generate a random sequence of zeros and ones and all you have at your disposal is a coin which you suspect to be biased (but do not know the bias). Can "perfect" randomness be produced with this coin? The answer is positive, thanks to a little trick discovered by von Neumann. In this paper, we investigate a generalization of this question: if we have access to a source of bits produced according to some probability measure in some class of measures, and suppose we know the class but not the measure (in the above example, the class would be the class of all Bernoulli measures), can perfect randomness be produced? We will look at this question from the viewpoint of effective mathematics and in particular the theory of effective randomness.
[Atomic measurements, Algorithmic Randomness, probability, random processes, perfect randomness, Extraterrestrial measurements, probability measure, Topology, Frequency measurement, Von Neumann biased coin, Computability, Markov measure, Measure theory, random sequences, Randomness extraction, random sequence generation, Bernoulli measures, effective randomness, Effective mathematics, Random sequences]
On the Magnitude of Completeness Thresholds in Bounded Model Checking
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Bounded model checking (BMC) is a highly successful bug-finding method that examines paths of bounded length for violations of a given regular or w-regular specification. A completeness threshold for a given model M and specification &#x03C6; is a bound k such that, if no counterexample to &#x03C6; of length k or less can be found in M, then M in fact satisfies &#x03C6;. The quest for `small' completeness thresholds in BMC goes back to the very inception of the technique, over a decade ago, and remains a topic of active research. For a fixed specification, completeness thresholds are typically expressed in terms of key attributes of the models under consideration, such as their diameter (length of the longest shortest path) and especially their recurrence diameter (length of the longest loop-free path). A recent research paper identified a large class of LTL specifications having completeness thresholds linear in the models' recurrence diameter [7]. However, the authors left open the question of whether linearity is in general even decidable. In the present paper, we settle the problem in the affirmative, by showing that the linearity problem for both regular and &#x03C9;-regular specifications (provided as automata and Buchi automata respectively) is PSPACE-complete. Moreover, we establish the following dichotomies: for regular specifications, completeness thresholds are either linear or exponential, whereas for &#x03C9;-regular specifications, completeness thresholds are either linear or at least quadratic.
[longest loop-free path, automata theory, exponential completeness threshold, bounded length path, bounded model checking, formal specification, linearity problem, computer-aided verification, Bounded model checking, decidability, formal verification, Context, bug-finding method, quadratic completeness threshold, completeness threshold magnitude, Educational institutions, fixed specification, PSPACE-complete, Indexes, &#x03C9;-regular specifications, model key attributes, Computer science, linear completeness threshold, Automata, Linearity, LTL specification, Buchi automata, model recurrence diameter]
Collapsible Pushdown Automata and Labeled Recursion Schemes: Equivalence, Safety and Effective Selection
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Higher-order recursion schemes are rewriting systems for simply typed terms and they are known to be equi-expressive with collapsible pushdown automata (CPDA) for generating trees. We argue that CPDA are an essential model when working with recursion schemes. First, we give a new proof of the translation of schemes into CPDA that does not appeal to game semantics. Second, we show that this translation permits to revisit the safety constraint and allows CPDA to be seen as Krivine machines. Finally, we show that CPDA permit one to prove the effective MSO selection property for schemes, subsuming all known decidability results for MSO on schemes.
[Safety Constraint, pushdown automata, labeled recursion schemes, MSO selection property, decidability, Semantics, MSO Effective Selection, Production, Safety, theorem proving, Collapsible Pushdown Automata, tree generation, collapsible pushdown automata, rewriting systems, higher-order recursion schemes, trees (mathematics), typed terms, Standards, Krivine machines, Recursion Schemes, CPDA, Automata, Games, Syntactics, scheme translation proof, monadic second-order theory, safety constraint]
Partial-Observation Stochastic Games: How to Win When Belief Fails
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We consider two-player stochastic games played on finite graphs with reachability objectives where the first player tries to ensure a target state to be visited almost-surely (i.e., with probability 1), or positively (i.e., with positive probability), no matter the strategy of the second player. We classify such games according to the information and the power of randomization available to the players. On the basis of information, the game can be one-sided with either (a) player 1, or (b) player 2 having partial observation (and the other player has perfect observation), or two-sided with (c) both players having partial observation. On the basis of randomization, the players (a) may not be allowed to use randomization (pure strategies), or (b) may choose a probability distribution over actions but the actual random choice is external and not visible to the player (actions invisible), or (c) may use full randomization. Our main results for pure strategies are as follows. (1) For one-sided games with player 1 having partial observation we show that (in contrast to full randomized strategies) belief-based (subset-construction based) strategies are not sufficient, and we present an exponential upper bound on memory both for almost-sure and positive winning strategies; we show that the problem of deciding the existence of almost-sure and positive winning strategies for player 1 is EXPTIME-complete. (2) For one-sided games with player 2 having partial observation we show that non-elementary memory is both necessary and sufficient for both almost-sure and positive winning strategies. (3) We show that for the general (two-sided) case finite-memory strategies are sufficient for both positive and almost-sure winning, and at least non-elementary memory is required. We establish the equivalence of the almost-sure winning problems for pure strategies and for randomized strategies with actions invisible. Our equivalence result exhibits serious flaws in previous results of the literature: we show a non-elementary memory lower bound for almost-sure winning whereas an exponential upper bound was previously claimed.
[Stochastic processes, Positive and Almost-sure winning, EXPTIME-complete, Probability distribution, Complexity theory, statistical distributions, Complexity, random choice, nonelementary memory lower bound, Stochastic games, finite graph, randomization, probability distribution, almost-sure winning strategy, belief-based strategy, partial-observation stochastic game, almost-sure winning problem, two-player stochastic game, positive probability, Memory bounds, reachability analysis, equivalence, Partial-observation games, random processes, Probabilistic logic, reachability objective, randomised algorithms, positive winning strategy, Reachability and Buechi objectives, Upper bound, Memory management, Games, two-sided case finite-memory strategy, exponential upper bound, stochastic games, one-sided game, randomized strategy, computational complexity]
Decidable Problems for Probabilistic Automata on Infinite Words
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We consider probabilistic automata on infinite words with acceptance defined by parity conditions. We consider three qualitative decision problems: (i) the positive decision problem asks whether there is a word that is accepted with positive probability; (ii) the almost decision problem asks whether there is a word that is accepted with probability 1; and (iii) the limit decision problem asks whether words are accepted with probability arbitrarily close to 1. We unify and generalize several decidability results for probabilistic automata over infinite words, and identify a robust (closed under union and intersection) subclass of probabilistic automata for which all the qualitative decision problems are decidable for parity conditions. We also show that if the input words are restricted to lasso shape (regular) words, then the positive and almost problems are decidable for all probabilistic automata with parity conditions. For most decidable problems we show an optimal PSPACE-complete complexity bound.
[limit decision problem, Shape, decision theory, Probabilistic automata, decidable problem, almost and limit decision problems, parity condition, optimal PSPACE-complete complexity bound, probabilistic automata, decidability, Parity conditions, Robustness, Safety, Automata and formal languages, Context, qualitative decision problem, positive probability, formal languages, Probabilistic logic, positive decision problem, infinite word, Positive, Automata, Markov processes, lasso shape word, computational complexity]
Mean-Payoff Pushdown Games
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Two-player games on graphs are central in many problems in formal verification and program analysis such as synthesis and verification of open systems. In this work we consider solving recursive game graphs (or pushdown game graphs) that can model the control flow of sequential programs with recursion. While pushdown games have been studied before with qualitative objectives, such as reachability and parity objectives, in this work we study for the first time such games with the most well-studied quantitative objective, namely, mean payoff objectives. In pushdown games two types of strategies are relevant: (1) global strategies, that depend on the entire global history; and (2) modular strategies, that have only local memory and thus do not depend on the context of invocation, but only on the history of the current invocation of the module. Our main results are as follows: (1) One-player pushdown games with mean-payoff objectives under global strategies are decidable in polynomial time. (2) Two-player pushdown games with mean-payoff objectives under global strategies are undecidable. (3) One-player pushdown games with mean-payoff objectives under modular strategies are NP-hard. (4) Two-player pushdown games with mean-payoff objectives under modular strategies can be solved in NP (i.e., both one-player and two-player pushdown games with mean-payoff objectives under modular strategies are NP-complete). We also establish the optimal strategy complexity showing that global strategies for mean-payoff objectives require infinite memory even in one-player pushdown games; and memoryless modular strategies are sufficient in two-player pushdown games. Finally we also show that all the problems have the same computational complexity if the stack boundedness condition is added, where along with the mean-payoff objective the player must also ensure that the stack height is bounded.
[one-player pushdown games, Heuristic algorithms, mean-payoff pushdown games, graph theory, pushdown automata, recursive game graphs, sequential program control flow, Complexity theory, History, Meanpayoff objectives, mean payoff objectives, reachability objectives, decidability, formal verification, stack boundedness condition, program analysis, Polynomials, polynomial time, Games on graphs, open system synthesis, global strategies, optimal strategy complexity, Pushdown automata, game theory, stack height, Pushdown games, local memory, memoryless modular strategies, Computer science, NP-hard problem, open system verification, Automata, Games, global history, parity objectives, computational complexity, two-player pushdown games]
Decomposing Quantified Conjunctive (or Disjunctive) Formulas
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Model checking-deciding if a logical sentence holds on a structure-is a basic computational task that is well-known to be intractable in general. For first-order logic on finite structures, it is PSPACE-complete, and the natural evaluation algorithm exhibits exponential dependence on the formula. We study model checking on the quantified conjunctive fragment of first-order logic, namely, prenex sentences having a purely conjunctive quantifier-free part. Following a number of works, we associate a graph to the quantifier-free part; each sentence then induces a prefixed graph, a quantifier prefix paired with a graph on its variables. We give a comprehensive classification of the sets of prefixed graphs on which model checking is tractable, based on a novel generalization of treewidth, that generalizes and places into a unified framework a number of existing results.
[Atomic measurements, finite structures, graph theory, first-order logic, PSPACE-complete, Complexity theory, quantified conjunctive formula decomposition, prenex sentences, exponential formula dependence, Computer science, formal logic, quantified conjunctive fragment, Databases, formal verification, model checking, Veins, prefixed graph, Polynomials, conjunctive quantifier-free part, treewidth, computational complexity]
An Algebraic Preservation Theorem for Aleph-Zero Categorical Quantified Constraint Satisfaction
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We prove a preservation theorem for positive Horn definability in aleph-zero categorical structures. In particular, we define and study a construction which we call the periodic power of a structure, and define a periomorphism of a structure to be a homomorphism from the periodic power of the structure to the structure itself. Our preservation theorem states that, over an aleph-zero categorical structure, a relation is positive Horn definable if and only if it is preserved by all periomorphisms of the structure. We give applications of this theorem, including a new proof of the known complexity classification of quantified constraint satisfaction on equality templates.
[Context, Cloning, algebra, algebraic preservation theorem, Electronic mail, Computational complexity, aleph-zero categorical structures, aleph-zero categoricity, constraint satisfaction problems, aleph-zero categorical quantified constraint satisfaction, positive Horn definability, periodic power, preservation theorem, quantified constraint satisfaction, homomorphism, complexity classification, periomorphism, Periodic structures, computational complexity]
On the Ordered Conjecture
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
It is well-known that least fixed-point logic LFP captures the complexity class PTIME on ordered structures. The ordered conjecture claims that LFP is more expressive than first-order logic FO on every infinite class O of finite ordered structures. We present two methods which yield that LFP is more expressive than FO on various types of classes of ordered structures. The first method, the model-checking method, among others, can be applied for all such classes O of bounded cliquewidth. By the second method, the padding method, we show that for classes O of ``bounded treewidth,'' more precisely, for classes O such that there is a bound for the treewidth of the successor structures associated with the members of O, even DTC is more expressive than FO on O, where DTC denotes the deterministic transitive closure logic, a logic that captures the complexity class L on ordered structures. Furthermore, with the padding method we get that for every infinite class of ordered structures O we have that DTC is more expressive than FO on the class of all ordered sums of pairs of structures in O. Under some complexity theoretic assumption, we prove the existence of a class O of ordered structures such that on O not only LFP is more expressive than FO, but also LFP has the expressive power of existential second-order logic. Furthermore, we characterize those classes of structures whose corresponding class of all ordered versions has bounded treewidth.
[ordered conjecture, Vocabulary, complexity class, padding method, Complexity theory, Electronic mail, formal logic, model-checking method, complexity theoretic assumption, Turing machines, formal verification, bounded cliquewidth, treewidth and cliquewidth, finite ordered structure, Polynomials, least fixed-point logic, trees (mathematics), Color, deterministic algorithms, Computer science, infinite class, second-order logic, bounded treewidth, deterministic transitive closure logic, computational complexity]
The Winning Ways of Concurrent Games
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
A bicategory of concurrent games, where nondeterministic strategies are formalized as certain maps of event structures, was introduced recently. This paper studies an extension of concurrent games by winning conditions, specifying players' objectives. The introduction of winning conditions raises the question of whether such games are determined, that is, if one of the players has a winning strategy. This paper gives a positive answer to this question when the games are well-founded and satisfy a structural property, race-freedom, which prevents one player from interfering with the moves available to the other. Uncovering the conditions under which concurrent games with winning conditions are determined opens up the possibility of further applications of concurrent games in areas such as logic and verification, where both winning conditions and determinacy are most needed. A concurrent-game semantics for predicate calculus is provided as an illustration.
[Computers, Context, Winning conditions, game theory, predicate calculus, Calculus, Synchronization, calculus, Concurrent computing, concurrent games, structural property, concurrent-game semantics, Nondeterministic strategies, nondeterministic strategies, bicategory, Semantics, Concurrent games, Determinacy, Games, Event structures, race-freedom, logic, verification]
Strong Complementarity and Non-locality in Categorical Quantum Mechanics
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Categorical quantum mechanics studies quantum theory in the framework of dagger-compact closed categories. Using this framework, we establish a tight relationship between two key quantum theoretical notions: non-locality and complementarity. In particular, we establish a direct connection between Mermin-type non-locality scenarios, which we generalise to an arbitrary number of parties, using systems of arbitrary dimension, and performing arbitrary measurements, and a new stronger notion of complementarity which we introduce here. Our derivation of the fact that strong complementarity is a necessary condition for a Mermin scenario provides a crisp operational interpretation for strong complementarity. We also provide a complete classification of strongly complementary observables for quantum theory, something which has not yet been achieved for ordinary complementarity. Since our main results are expressed in the (diagrammatic) language of dagger-compact categories, they can be applied outside of quantum theory, in any setting which supports the purely algebraic notion of strongly complementary observables. We have therefore introduced a method for discussing non-locality in a wide variety of models in addition to quantum theory. The diagrammatic calculus substantially simplifies (and sometimes even trivialises) many of the derivations, and provides new insights. In particular, the diagrammatic computation of correlations clearly shows how local measurements interact to yield a global overall effect. In other words, we depict non-locality.
[nonlocality, Computational modeling, categorical quantum mechanics, dagger-compact closed categories, quantum theoretical notions, quantum entanglement, Vectors, Mermin-type nonlocality scenarios, Computer science, diagrammatic calculus, Quantum computing, abstract algebra, Wires, crisp operational interpretation, Quantum mechanics, quantum computing, strong complementarity, Abstracts]
The HOM Problem is EXPTIME-Complete
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
The HOM problem questions whether the image of a given regular tree language through a given tree homomorphism is also regular. Decidability of HOM is an important theoretical question which was open for a long time. Recently, HOM has been proved decidable with a triple exponential time algorithm. In this paper we obtain an exponential time algorithm for this problem, and conclude that it is EXPTIME-complete. The proof builds upon previous results and techniques on tree automata with constraints.
[Context, Transducers, Image recognition, formal languages, automata theory, Tree Homomorphisms, trees (mathematics), HOM problem, EXPTIME-complete, regular tree language, triple exponential time algorithm, Computer science, Tree Automata, decidability, Automata, Vegetation, Decision Problems, Polynomials, tree homomorphism, tree automata, computational complexity]
Where First-Order and Monadic Second-Order Logic Coincide
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We study on which classes of graphs first-order logic (FO) and monadic second-order logic (MSO) have the same expressive power. We show that for each class of graphs that is closed under taking subgraphs, FO and MSO have the same expressive power on the class if, and only if, it has bounded tree depth. Tree depth is a graph invariant that measures the similarity of a graph to a star in a similar way that tree width measures the similarity of a graph to a tree. For classes just closed under taking induced subgraphs, we show an analogous result for guarded second-order logic (GSO), the variant of MSO that not only allows quantification over vertex sets but also over edge sets. A key tool in our proof is a Feferman-Vaught-type theorem that is constructive and still works for unbounded partitions.
[Vocabulary, graph invariant, GSO, graph classes, trees (mathematics), first-order logic, MSO, FO, Indexes, Feferman-Vaught-type theorem, formal logic, Semantics, Automata, Vegetation, Syntactics, tree depth, Silicon, monadic second-order logic, bounded tree depth, guarded second-order logic]
First-Order and Monadic Second-Order Model-Checking on Ordered Structures
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Model-checking for first- and monadic second-order logic in the context of graphs has received considerable attention in the literature. It is well-known that the problem of verifying whether a formula of these logics is true in a graph is computationally intractable but it does become tractable on interesting classes of graphs such as classes of bounded tree-width. In this paper we continue this line of research but study model checking for first- and monadic second-order logic in the presence of an ordering on the input structure. We do so in two settings: the general ordered case, where the input structures are equipped with a fixed order or successor relation, and the order invariant case, where the formulas may resort to an ordering but their truth must be independent of the particular choice of order. In the first setting we show very strong intractability results for most interesting classes of graphs. In contrast, in order invariant case we obtain tractability results for order invariant monadic second-order logic on the same classes of graphs as in the unordered case. For first-order logic, we obtain tractability of successor-invariant FO on planar graphs.
[Vocabulary, successor relation, graph theory, planar graphs, first-order logic, algorithmic meta-theorems, Complexity theory, first-order model checking, computationally intractable formula, formal logic, monadic second-order model checking, successor-invariant FO tractability, formal verification, input structures, ordered structures, Polynomials, Context, Computational modeling, graph classes, Color, Model theory, Vegetation, finite model theory, order-invariant first-order logic, fixed order relation, order invariant monadic second-order logic, computational complexity]
A Perfect Model for Bounded Verification
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
A class of languages C is perfect if it is closed under Boolean operations and the emptiness problem is decidable. Perfect language classes are the basis for the automata-theoretic approach to model checking: a system is correct if the language generated by the system is disjoint from the language of bad traces. Regular languages are perfect, but because the disjointness problem for context-free languages is undecidable, no class containing them can be perfect. In practice, verification problems for language classes that are not perfect are often under-approximated by checking if the property holds for all behaviors of the system belonging to a fixed subset. A general way to specify a subset of behaviors is by using bounded languages. A class of languages C is perfect modulo bounded languages if it is closed under Boolean operations relative to every bounded language, and if the emptiness problem is decidable relative to every bounded language. We consider finding perfect classes of languages modulo bounded languages. We show that the class of languages accepted by multi-head pushdown automata are perfect modulo bounded languages, and characterize the complexities of decision problems. We also show that bounded languages form a maximal class for which perfection is obtained. We show that computations of several known models of systems, such as recursive multi-threaded programs, recursive counter machines, and communicating finite-state machines can be encoded as multi-head pushdown automata, giving uniform and optimal underapproximation algorithms modulo bounded languages.
[complexity, algorithms, communicating finite-state machines, pushdown automata, emptiness problem, Complexity theory, C language, disjointness problem, underapproximation, context-free languages, decidability, formal verification, decision problem complexity, Personal digital assistants, languages modulo bounded languages, recursive multithreaded programs, verification, Boolean operations, approximation theory, formal languages, Radiation detectors, Computational modeling, recursive counter machines, regular languages, automata-theoretic approach, Encoding, Magnetic heads, Boolean algebra, multihead pushdown automata, bounded verification, perfect model, model checking, underapproximation algorithms modulo bounded languages, Automata, perfect modulo bounded languages, perfect language classes, computational complexity]
Deciding the Value 1 Problem for Probabilistic Leaktight Automata
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
The value 1 problem is a decision problem for probabilistic automata over finite words: given a probabilistic automaton, are there words accepted with probability arbitrarily close to 1? This problem was proved undecidable recently. We sharpen this result, showing that the undecidability holds even if the probabilistic automata have only one probabilistic transition. Our main contribution is to introduce a new class of probabilistic automata, called leaktight automata, for which the value 1 problem is shown decidable (and PSPACE-complete). We construct an algorithm based on the computation of a monoid abstracting the behaviors of the automaton, and rely on algebraic techniques developed by Simon for the correctness proof. The class of leaktight automata is decidable in PSPACE, subsumes all subclasses of probabilistic automata whose value 1 problem is known to be decidable (in particular deterministic automata), and is closed under two natural composition operators.
[decision problem, natural composition operators, Algebraic Techniques in Automata Theory, Probabilistic automata, Process control, Probabilistic logic, PSPACE-complete, Electronic mail, Value 1 problem, probabilistic leaktight automata, undecidability, monoid, correctness proof, group theory, probabilistic automata, decidability, deterministic automata, Automata, value 1 problem, finite words, Markov processes, algebraic techniques, Transient analysis, computational complexity]
Delta-Decidability over the Reals
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Given any collection F of computable functions over the reals, we show that there exists an algorithm that, given any sentence A containing only bounded quantifiers and functions in F, and any positive rational number delta, decides either &#x201C;A is true&#x201D;, or &#x201C;a delta-strengthening of A is false&#x201D;. Moreover, if F can be computed in complexity class C, then under mild assumptions, this &#x201C;delta-decision problem&#x201D; for bounded Sigma k-sentences resides in Sigma k(C). The results stand in sharp contrast to the well-known undecidability of the general first-order theories with these functions, and serve as a theoretical basis for the use of numerical methods in decision procedures for formulas over the reals.
[formal languages, delta-decidability, bounded quantifier, complexity class, First-order Theories over the Reals, Decision Procedures, bounded sigma k-sentence, Complexity theory, Approximation methods, Computable Analysis, Standards, positive rational number delta, Turing machines, decidability, numerical method, decision procedure, Differential equations, computable function, Robustness, Polynomials, delta-strengthening, computational complexity]
Countermodels from Sequent Calculi in Multi-Modal Logics
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
A novel countermodel-producing decision procedure that applies to several multi-modal logics, both intuitionistic and classical, is presented. Based on backwards search in labeled sequent calculi, the procedure employs a novel termination condition and countermodel construction. Using the procedure, it is argued that multi-modal variants of several classical and intuitionistic logics including K, T, K4, S4 and their combinations with D are decidable and have the finite model property. At least in the intuitionistic multi-modal case, the decidability results are new. It is further shown that the countermodels produced by the procedure, starting from a set of hypotheses and no goals, characterize the atomic formulas provable from the hypotheses.
[atomic formulas, Thyristors, sequent calculi countermodels, Multi-modal logic, labeled sequent calculus, Educational institutions, Calculus, Electronic mail, History, Standards, intuitionistic logics, countermodel-producing decision procedure, decidability, process algebra, multimodal logics, Semantics, countermodels, labeled sequent calculi, finite model property]
The Complexity of Decomposing Modal and First-Order Theories
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We show that the satisfiability problem for the two-dimensional extension KxK of unimodal K is nonelementary, hereby confirming a conjecture of Marx and Mikulas from 2001. Our lower bound technique allows us to derive further lower bounds for many-dimensional modal logics for which only elementary lower bounds were previously known. We also derive nonelementary lower bounds on the sizes of Feferman-Vaught decompositions w.r.t. product for any decomposable logic that is at least as expressive as unimodal K. Finally, we study the sizes of Feferman-Vaught decompositions and formulas in Gaifman normal form for fixed-variable fragments of first-order logic.
[complexity, Poles and towers, fixed-variable fragments, first-order logic, Switches, computability, FO2, Complexity theory, Semantics, satisfiability problem, satisfiability, Gaifman's theorem, many-dimensional modal logics, Silicon, Gaifman normal form, unimodal K, nonelementary lower bounds, Feferman-Vaught decompositions, two-dimensional extension KxK, decomposable logic, Computational modeling, first-order theory, many-dimensional modal logic, Computer science, modal theory, computational complexity]
Automatic Sequences and Zip-Specifications
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We consider infinite sequences of symbols, also known as streams, and the decidability question for equality of streams defined in a restricted format. (Some formats lead to undecidable equivalence problems.) This restricted format consists of prefixing a symbol at the head of a stream, of the stream function `zip', and recursion variables. Here `zip' interleaves the elements of two streams alternatingly. The celebrated Thue- Morse sequence is obtained by the succinct `zip-specification' M = 0 : X X = 1 : zip(X, Y) Y = 0 : zip(Y, X) The main results are as follows. We establish decidability of equivalence of zip-specifications, by employing bisimilarity of observation graphs based on a suitably chosen cobasis. Furthermore, our analysis, based on term rewriting and coalgebraic techniques, reveals an intimate connection between zip-specifications and automatic sequences. This leads to a new and simple characterization of automatic sequences. The study of zip-specifications is placed in a wider perspective by employing observation graphs in a dynamic logic setting, yielding yet another alternative characterization of automatic sequences. By the first characterization result, zip-specifications can be perceived as a term rewriting syntax for automatic sequences. For streams &#x03C3; the following are equivalent: (a) &#x03C3; can be specified using zip; (b) &#x03C3; is 2-automatic; and (c) &#x03C3; has a finite observation graph using the cobasis (hd, even, odd). Here even and odd are defined by even(a : s) = a : odd(s), and odd(a : s) = even(s). The generalization to zip-k specifications (with zip-k interleaving k streams) and to k-automaticity is straightforward. As a natural extension of the class of automatic sequences, we also consider `zip-mix' specifications that use zips of different arities in one specification. The corresponding notion of automaton employs a state-dependent input-alphabet, with a number representation (n)A = d<sub>m</sub> ... d<sub>0</sub> where the base of digit di is determined by the automaton A on input d<sub>i-1</sub> ... d<sub>0</sub>. Finally we show that equivalence is undecidable for a simple extension of the zip-mix format with projections analogous to even and odd.
[coalgebra, automata theory, graph theory, coalgebraic techniques, algebra, Electronic mail, k-automaticity, formal specification, dynamic logic setting, decidability, recursion variables, term rewriting syntax, cobasis, equivalence decidability, equational specifications, Productivity, rewriting systems, formal languages, stream function zip, finite observation graph, term rewriting, streams, Educational institutions, Thue-Morse sequence, symbol infinite sequences, zip-mix specifications, Equations, Computer science, automaton, Automata, Syntactics, state-dependent input-alphabet, binary sequences, stream equality, dynamic logic, observation graph bisimilarity, automatic sequences]
Functionals Using Bounded Information and the Dynamics of Algorithms
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We consider computable functionals mapping the Baire space into the set of integers. By continuity, the value of the functional on a given function depends only on a "critical" finite part of this function. Care: there is in general no way to compute this critical finite part without querying the function on an arbitrarily larger finite part! Nevertheless, things are different in case there is a uniform bound on the size of the domain of this critical finite part. We prove that, modulo a quadratic blow-up of the bound, one can compute the value of the functional by an algorithm which queries the input function on a uniformly bounded finite part. Up to a constant factor, this quadratic blow-up is optimal. We also characterize such functionals in topological terms using uniformities. As an application of these results, we get a topological characterization of the dynamics of algorithms as modeled by Gurevich's Abstract State Machines.
[Algorithm design and analysis, Theory of Algorithms, Heuristic algorithms, Computational modeling, Operational semantics, functional analysis, computability, Topology, abstract state machines, Computer science, bounded information, Semantics, Type 2 computability, Abstracts, Abstract state machines, Baire space, computable functionals mapping, critical finite part, quadratic blow-up]
The Ordinal-Recursive Complexity of Timed-arc Petri Nets, Data Nets, and Other Enriched Nets
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We show how to reliably compute fast-growing functions with timed-arc Petri nets and data nets. This construction provides ordinal-recursive lower bounds on the complexity of the main decidable properties (safety, termination, regular simulation, etc.) of these models. Since these new lower bounds match the upper bounds that one can derive from wqo theory, they precisely characterise the computational power of these so-called "enriched" nets.
[termination, ordinal-recursive lower bound, Radiation detectors, Petri nets, Vectors, Encoding, recursive functions, Complexity theory, enriched nets, data nets, decidable properties, ordinal-recursive complexity, Upper bound, timed-arc Petri nets, Handheld computers, decidability, formal verification, safety, regular simulation, fast-growing hierarchy, well-structured systems, computational complexity]
A Constructive Proof of Dependent Choice, Compatible with Classical Logic
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Martin-Lo&#x0308;f's type theory has strong existential elimination (dependent sum type) that allows to prove the full axiom of choice. However the theory is intuitionistic. We give a condition on strong existential elimination that makes it computationally compatible with classical logic. With this restriction, we lose the full axiom of choice but, thanks to a lazily-evaluated coinductive representation of quantification, we are still able to constructively prove the axiom of countable choice, the axiom of dependent choice, and a form of bar induction in ways that make each of them computationally compatible with classical logic.
[Context, Dependent choice, Calculus, type theory, Synchronization, formal logic, Computer languages, Semantics, strong existential, constructive proof, dependent sum type, Distance measurement, strong existential elimination, dependent choice, constructive logic, classical logic, Martin-Lof type theory]
Better Abstractions for Timed Automata
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We consider the reachability problem for timed automata. A standard solution to this problem involves computing a search tree whose nodes are abstractions of zones. These abstractions preserve underlying simulation relations on the state space of the automaton. For both effectiveness and efficiency reasons, they are parameterized by the maximal lower and upper bounds (LU-bounds) occurring in the guards of the automaton. We consider the aLU abstraction defined by Behrmann et al. Since this abstraction can potentially yield non-convex sets, it has not been used in implementations. We prove that aLU abstraction is the coarsest abstraction with respect to LU-bounds that is sound and complete for reachability. We also provide an efficient technique to use the aLU abstraction to solve the reachability problem.
[Real time systems, reachability analysis, aLU abstraction, Computational modeling, automata theory, trees (mathematics), nonconvex set, reachability problem, set theory, Approximation methods, Reachability analysis, Cost accounting, Upper bound, search tree, Automata, Abstracts, coarsest abstraction, timed automata, search problems, Clocks]
Step Indexed Realizability Semantics for a Call-by-Value Language Based on Basic Combinatorial Objects
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We propose a mathematical framework for step indexed realizability semantics of a call-by-value polymorphic lambda calculus with recursion, existential types and recursive types. Our framework subsumes step indexed realizability semantics by untyped call-by-value lambda calculi as well as categorical abstract machines. Starting from an extension of Hofstra's basic combinatorial objects, we construct a step indexed categorical realizability semantics. Our main result is soundness and adequacy of our step indexed realizability semantics. As an application, we show that a small step operational semantics captures the big step operational semantics of the call-by-value polymorphic lambda calculus. We also give a safe implementation of the call-by-value polymorphic lambda calculus into a categorical abstract machine.
[lambda calculus, finite automata, operational semantics, Calculus, programming language semantics, basic combinatorial objects, untyped call-by-value lambda calculi, Algebra, big step operational semantics, Semantics, call-by-value polymorphic lambda calculus, categorical abstract machines, Abstracts, Syntactics, step indexed realizability semantics, call-by-value language, Mathematical model, denotational semantics, Indexing, Semantics of Programming Languages]
Extending Type Theory with Forcing
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
This paper presents an intuitionistic forcing translation for the Calculus of Constructions (CoC), a translation that corresponds to an internalization of the presheaf construction in CoC. Depending on the chosen set of forcing conditions, the resulting type theory can be extended with extra logical principles. The translation is proven correct---in the sense that it preserves type checking---and has been implemented in Coq. As a case study, we show how the forcing translation on integers (which corresponds to the internalization of the topos of trees) allows us to define general inductive types in Coq, without the strict positivity condition. Using such general inductive types, we can construct a shallow embedding of the pure lambda-calculus in Coq, without defining an axiom on the existence of an universal domain. We also build another forcing layer where we prove the negation of the continuum hypothesis.
[Context, lambda calculus, Coq, Force, type checking, presheaf construction, pure lambda-calculus, intuitionistic forcing translation, Calculus, Cognition, type theory, Approximation methods, logical principles, Reactive power, general inductive types, Semantics, continuum hypothesis, Presheaves, calculus of constructions, Forcing, Type Theory, forcing conditions]
The Complexity of Verbal Languages over Groups
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
This paper investigates the complexity of verbal languages and pattern languages of Thurston automatic groups in terms of the Chomsky hierarchy. Here the language generated by a pattern is taken as the set of representatives of all strings obtained when chosing values for the various variables. For noncommutative free groups, it is shown that the complexity of the verbal and pattern languages (in terms of level on the Chomsky hierarchy) does not depend on the Thurston automatic representation and that verbal languages cannot be context-free (unless they are either the empty word or the full group). They can however be indexed languages. Furthermore, it is shown that in the general case, it might depend on the exactly chosen Thurston automatic representation which level a verbal language takes in the Chomsky hierarchy. There are examples of groups where, in an appropriate representation, all pattern languages are regular or context-free, respectively.
[Complexity theory, Electronic mail, full group, Chomsky hierarchy, regular language, verbal language complexity, context-free languages, empty word, Production, string representative, Thurston automatic group, noncommutative free groups, Chomsky Hierarchy, indexed language, Thurston automatic representation, Generators, Grammar, Verbal Languages, Computer science, group theory, pattern language complexity, Thurston Automatic Groups, Free Groups, Automata, context-free language, computational complexity]
Decidability of DPDA Language Equivalence via First-Order Grammars
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Decidability of language equivalence of deterministic pushdown automata (DPDA) was established by G. Senizergues (1997), who thus solved a famous long-standing open problem. A simplified proof, also providing a primitive recursive complexity upper bound, was given by C. Stirling (2002). In this paper, the decidability is re-proved in the framework of first-order terms and grammars (given by finite sets of root-rewriting rules). The proof is based on the abstract ideas used in the previous proofs, but the chosen framework seems to be more natural for the problem and allows a short presentation which should be transparent for a general computer science audience.
[rewriting systems, deterministic pushdown automata, first-order grammar, computer science audience, pushdown automata, Grammar, Complexity theory, first-order terms, Reactive power, first-order grammars, Upper bound, decidability, deterministic pushdown automaton, Automata, Games, DPDA language equivalence, Tin, primitive recursive complexity upper bound, root-rewriting rules, language equivalence]
Capsules and Separation
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We study a formulation of separation logic using capsules, a representation of the state of a computation in higher-order programming languages with mutable variables. We prove soundness of the frame rule in this context and investigate alternative formulations with weaker side conditions.
[Context, high level languages, frame rule, programming language semantics, Standards, formal logic, Reactive power, Computer languages, Semantics, separation logic, mutable variables, Syntactics, higher-order programming languages, capsules]
Two-Variable First-Order Logic with Equivalence Closure
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We consider the satisfiability and finite satisfiability problems for extensions of the two-variable fragment of first-order logic in which an equivalence closure operator can be applied to a fixed number of binary predicates. We show that the satisfiability problem for two-variable, first-order logic with equivalence closure applied to two binary predicates is in 2NEXPTIME, and we obtain a matching lower bound by showing that the satisfiability problem for two-variable first-order logic in the presence of two equivalence relations is 2NEXPTIME-hard. The logics in question lack the finite model property; however, we show that the same complexity bounds hold for the corresponding finite satisfiability problems. We further show that the satisfiability (=finite satisfiability) problem for the two-variable fragment of first-order logic with equivalence closure applied to a single binary predicate is NEXPTIME-complete.
[2NEXPTIME problem, Computational modeling, equivalence closure operator, computability, two-variable first-order logic, Educational institutions, finite satisfiability problems, Complexity theory, Indexes, matching lower bound, complexity bounds, Computer science, 2NEXPTIME-hard problem, decidability, Syntactics, NEXPTIME-complete problem, finite model, Bipartite graph, binary predicates, computational complexity]
Learning Probabilistic Systems from Tree Samples
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We consider the problem of learning a non-deterministic probabilistic system consistent with a given finite set of positive and negative tree samples. Consistency is defined with respect to strong simulation conformance. We propose learning algorithms that use traditional and a new stochastic state-space partitioning, the latter resulting in the minimum number of states. We then use them to solve the problem of active learning, that uses a knowledgeable teacher to generate samples as counterexamples to simulation equivalence queries. We show that the problem is undecidable in general, but that it becomes decidable under a suitable condition on the teacher which comes naturally from the way samples are generated from failed simulation checks. The latter problem is shown to be undecidable if we impose an additional condition on the learner to always conjecture a minimum state hypothesis. We therefore propose a semi-algorithm using stochastic partitions. Finally, we apply the proposed (semi-) algorithms to infer intermediate assumptions in an automated assume-guarantee verification framework for probabilistic systems.
[negative tree sample, Stochastic processes, simulation, assume-guarantee, stochastic partition, simulation conformance, Cognition, failed simulation check, semi-algorithm, positive tree sample, stochastic state-space partitioning, active learning, decidability, partition, stochastic processes, minimum state hypothesis, Learning automata, Computational modeling, probability, trees (mathematics), conformance, tree, Probabilistic logic, Partitioning algorithms, knowledgeable teacher, transition, simulation equivalence query, Upper bound, system, automated assume-guarantee verification framework, nondeterministic probabilistic system learning]
Non-definability of Languages by Generalized First-order Formulas over (N,+)
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We consider first-order logic with monoidal quantifiers over words. We show that all languages with a neutral letter, definable using the addition predicate are also definable with the order predicate as the only numerical predicate. Let S be a subset of monoids. Let L be the logic closed under quantification over the monoids in S. Then we prove that L[&lt;;,+] and L[&lt;;] define the same neutral letter languages. Our result can be interpreted as the Crane Beach conjecture to hold for the logic L[&lt;;,+]. As a consequence we get the result of Roy and Straubing that FO+MOD[&lt;;,+] collapses to FO+MOD[&lt;;]. For cyclic groups, we answer an open question of Roy and Straubing, proving that MOD[&lt;;,+] collapses to MOD[&lt;;]. Our result also shows that multiplication as a numerical predicate is necessary for Barrington's theorem to hold and also to simulate majority quantifiers. All these results can be viewed as separation results for highly uniform circuit classes. For example we separate FO[&lt;;,+]-uniform CC0 from FO[&lt;;,+]-uniform ACC0.
[Context, cyclic groups, Cranes, logic on words, extended first-order logic, computational linguistics, first-order logic, descriptive complexity, monoidal quantifiers, crane-beach conjecture, Complexity theory, Electronic mail, Indexes, generalized first-order formulas, Computer science, formal logic, numerical predicate, neutral letter, language nondefinability, Polynomials, Barrington theorem, neutral letter languages, crane beach conjecture]
A Kantorovich-Monadic Powerdomain for Information Hiding, with Probability and Nondeterminism
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We propose a novel domain-theoretic model for nondeterminism, probability and hidden state, with relations on it that compare information flow. One relation is Smyth-like, based on a structural, refinement-like order between semantic elements; the other is a testing order that generalises several extant entropy-based techniques. Our principal theorem is that the two orders are equivalent. The model is based on the Giry/Kantorovich monads, and it abstracts Partially Observable Markov Decision Processes by discarding observables' actual values but retaining the effect they had on an observer's knowledge. We illustrate the model, and its orders, on some small examples, where we find that our formalism provides the apparatus for comparing systems in terms of the information they leak.
[principal theorem, partially observable Markov decision processes, structural refinement-like order, extant entropy-based techniques, Entropy, quantitative information flow, semantic elements, information flow, probabilistic domains, Algebra, entropy, hidden state, Semantics, Smyth-like relation, domain-theoretic model, Testing, nondeterminism, testing order, probability, information hiding, Probabilistic logic, Extraterrestrial measurements, probabilistic monads, observer knowledge, security of data, Kantorovich-Monadic powerdomain, refinement orders, information leakage, Hidden Markov models, decision making, Markov processes, Giry-Kantorovich monads, data encapsulation, observers]
An Infinitary Affine Lambda-Calculus Isomorphic to the Full Lambda-Calculus
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
It is well known that the real numbers arise from the metric completion of the rational numbers, with the metric induced by the usual absolute value. We seek a computational version of this phenomenon, with the idea that the role of the rationals should be played by the affine lambda-calculus, whose dynamics is finitary; the full lambda-calculus should then appear as a suitable metric completion of the affine lambda-calculus. This paper proposes a technical realization of this idea: an affine lambda-calculus is introduced, based on a fragment of intuitionistic multiplicative linear logic; the calculus is endowed with a notion of distance making the set of terms an incomplete metric space; the completion of this space is shown to yield an infinitary affine lambda-calculus, whose quotient under a suitable partial equivalence relation is exactly the full (non-affine) lambda-calculus. We also show how this construction brings interesting insights on some standard rewriting properties of the lambda-calculus (finite developments, confluence, standardization, head normalization and solvability).
[confluence, computability, standardization, Calculus, lambda-calculus, Convergence, standard rewriting properties, full lambda-calculus, metric completion, finite developments, head normalization, intuitionistic multiplicative linear logic, infinitary affine lambda-calculus, Context, lambda calculus, rewriting systems, rational numbers, topology, Extraterrestrial measurements, Topology, solvability, incomplete metric space, infinitary rewriting, Computation theory, Vegetation, partial equivalence relation, real numbers]
Game Semantics in String Diagrams
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
A dialogue category is a symmetric monoidal category equipped with a notion of tensorial negation. We establish that the free dialogue category is a category of dialogue games and total innocent strategies. The connection clarifies the algebraic and logical nature of dialogue games, and their intrinsic connection to linear continuations. The proof of the statement is based on an algebraic presentation of dialogue categories inspired by knot theory, and a factorization theorem established by rewriting techniques.
[string diagrams, coherence theorems, knot theory, algebraic presentation, computational linguistics, dialogue games, ribbon categories, Semantics, linear continuations, interactive systems, logical nature, dialogue categories, innocent strategies, tensorial negation, Dialogue games, rewriting systems, free dialogue category, algebraic nature, factorization theorem, Generators, Vectors, game semantics, symmetric monoidal category, intensity measurement, total innocent strategies, Tensile stress, rewriting techniques, Games, Coherence, Syntactics, 2-dimensional algebra]
Decidable Elementary Modal Logics
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
In this paper, the modal logic over classes of structures definable by universal first-order Horn formulas is studied. We show that the satisfiability problems for that logics are decidable, confirming the conjecture from [E. Hemaspaandra and H. Schnoor, On the Complexity of Elementary Modal Logics, STACS 08]. We provide a full classification of logics defined by universal first-order Horn formulas, with respect to the complexity of satisfiability of modal logic over the classes of frames they define. It appears, that except for the trivial case of inconsistent formulas for which the problem is in P, local satisfiability is either NP-complete or PSPACE-complete, and global satisfiability is NP-complete, PSPACE-complete, or EXPTIME-complete. While our results holds even if we allow to use equality, we show that inequality leads to undecidability.
[complexity, EXPTIME-complete problem, Force, computability, Complexity theory, local satisfiability, NP-complete problem, modal logic, Standards, decidable elementary modal logics, undecidability, Computer science, decidability, logics classification, global satisfiability, Semantics, satisfiability problem, PSPACE-complete problem, Polynomials, elementary logic, Labeling, universal first-order Horn formula, computational complexity]
Short Propositional Refutations for Dense Random 3CNF Formulas
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Random 3CNF formulas constitute an important distribution for measuring the average-case behavior of propositional proof systems. Lower bounds for random 3CNF refutations in many propositional proof systems are known. Most notable are the exponential-size resolution refutation lower bounds for random 3CNF formulas with &#x03A9;(n1.5-&#x03B5;) clauses (Chvatal and Szemeredi [13], Ben-Sasson and Wigderson [9]). On the other hand, the only known non-trivial upper bound on the size of random 3CNF refutations in a non-abstract propositional proof system is for resolution with &#x03A9;(n2/ log n) clauses, shown by Beame et al. [5]. In this paper we show that already standard propositional proof systems, within the hierarchy of Frege proofs, admit short refutations for random 3CNF formulas, for sufficiently large clause-to-variable ratio. Specifically, we demonstrate polynomialsize propositional refutations whose lines are TC0 formulas (i.e., TC0-Frege proofs) for random 3CNF formulas with n variables and &#x03A9;(n1.4) clauses. The idea is based on demonstrating efficient propositional correctness proofs of the random 3CNF unsatisfiability witnesses given by Feige, Kim and Ofek [19]. Since the soundness of these witnesses is verified using spectral techniques, we develop an appropriate way to reason about eigenvectors in propositional systems. To carry out the full argument we work inside weak formal systems of arithmetic and use a general translation scheme to propositional proofs.
[dense random 3CNF formulas, computability, refutation algorithms, Calculus, 3CNF unsatisfiability witnesses, Complexity theory, exponential-size resolution refutation lower bounds, threshold logic, Approximation methods, Standards, translation scheme, Upper bound, clause-to-variable ratio, propositional proof systems, Abstracts, average-case behavior, Proof complexity, random 3-SAT, Polynomials, theorem proving, Frege proofs, short propositional refutations, polynomial-size propositional refutations]
On the Complexity of Linear Authorization Logics
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Linear authorization logics (LAL) are logics based on linear logic that can be used for modeling effect-based authentication policies. LAL has been used in the context of the Proof-Carrying Authorization framework, where formal proofs are constructed in order for a principal to gain access to some resource elsewhere. This paper investigates the complexity of the provability problem, that is, determining whether a linear authorization logic formula is provable or not. We show that the multiplicative propositional fragment of LAL is already undecidable in the presence of two principals. On the other hand, we also identify a first-order fragment of LAL for which provability is PSPACE-complete. Finally, we argue by example that the latter fragment is natural and can be used in practice.
[Context, complexity, linear authorization logics, proof-carrying authorization framework, linear logic, formal proofs, multiplicative propositional fragment, Encoding, Complexity theory, Registers, Indexes, Linear Logic, Authorization Logics, Subexponentials, Complexity, Authorization, formal logic, linear authorization logic formula, effect-based authentication policies, PSPACE-complete problem, theorem proving, provability problem, Principal component analysis, computational complexity]
On the Significance of the Collapse Operation
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We show that deterministic collapsible pushdown automata of second level can recognize a language which is not recognizable by any deterministic higher order pushdown automaton (without collapse) of any level. This implies that there exists a tree generated by a second level collapsible pushdown system (equivalently: by a recursion scheme of second level), which is not generated by any deterministic higher order pushdown system (without collapse) of any level (equivalently: by any safe recursion scheme of any level). As a side effect, we present a pumping lemma for deterministic higher order pushdown automata, which potentially can be useful for other applications.
[formal languages, language recognition, second-level recursion scheme, higher-order recursion schemes, Higher-order pushdown systems, trees (mathematics), pushdown automata, Educational institutions, recursive functions, History, Indexes, trees, Computer science, deterministic automata, pumping lemma, Automata, Silicon, deterministic higher-order pushdown automaton, Informatics, second-level deterministic collapsible pushdown automata, collapse]
A Higher-Order Distributed Calculus with Name Creation
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
This paper introduces HOpiPn, the higher-order pi-calculus with passivation and name creation, and develops an equivalence theory for this calculus. Passivation [Schmitt and Stefani] is a language construct that elegantly models higher-order distributed behaviours like failure, migration, or duplication (e.g. when a running process or virtual machine is copied), and name creation consists in generating a fresh name instead of hiding one. Combined with higher-order distribution, name creation leads to different semantics from name hiding, and is closer to implementations of distributed systems. We define for this new calculus a theory of sound and complete environmental bisimulation to prove reduction-closed barbed equivalence and (a reasonable form of) congruence. We furthermore define environmental simulations to prove behavioural approximation, and use these theories to show non-trivial examples of equivalence or approximation. Those examples could not be proven with previous theories, which were either unsound or incomplete under the presence of process duplication and name restriction, or else required universal quantification over general contexts.
[reduction-closed barbed equivalence, Calculus, Approximation methods, higher-order distributed behaviours, Process equivalence, pi calculus, name creation, language construct, higher-order distribution, Semantics, behavioural approximation, Higher-order pi-calculus, Passivation, Context, equivalence theory, Observers, process duplication, passivation, higher-order pi-calculus, congruence, name restriction, Environmental bisimulation, HOpiPn, higher-order distributed calculus, failure, Syntactics, migration, Name restriction and creation, environmental bisimulation, Distribution and passivation]
The Complete Proof Theory of Hybrid Systems
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Hybrid systems are a fusion of continuous dynamical systems and discrete dynamical systems. They freely combine dynamical features from both worlds. For that reason, it has often been claimed that hybrid systems are more challenging than continuous dynamical systems and than discrete systems. We now show that, proof-theoretically, this is not the case. We present a complete proof-theoretical alignment that interreduces the discrete dynamics and the continuous dynamics of hybrid systems. We give a sound and complete axiomatization of hybrid systems relative to continuous dynamical systems and a sound and complete axiomatization of hybrid systems relative to discrete dynamical systems. Thanks to our axiomatization, proving properties of hybrid systems is exactly the same as proving properties of continuous dynamical systems and again, exactly the same as proving properties of discrete dynamical systems. This fundamental cornerstone sheds light on the nature of hybridness and enables flexible and provably perfect combinations of discrete reasoning with continuous reasoning that lift to all aspects of hybrid systems and their fragments.
[axiomatization, discrete dynamical systems, discrete systems, hybrid dynamical systems, discrete reasoning, Cognition, Vectors, completeness, Approximation methods, inference mechanisms, proof theory, Computer science, complete proof-theoretical alignment, continuous reasoning, Differential equations, Polynomials, differential dynamic logic, theorem proving, continuous systems, hybrid system axiomatization, continuous dynamical systems]
Interpretations in Trees with Countably Many Branches
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We study the expressive power of logical interpretations on the class of scattered trees, namely those with countably many infinite branches. Scattered trees can be thought of as the tree analogue of scattered linear orders. Every scattered tree has an ordinal rank that reflects the structure of its infinite branches. We prove, roughly, that trees and orders of large rank cannot be interpreted in scattered trees of small rank. We consider a quite general notion of interpretation: each element of the interpreted structure is represented by a set of tuples of subsets of the interpreting tree. Our trees are countable, not necessarily finitely branching, and may have finitely many unary predicates as labellings. We also show how to replace injective set-interpretations in (not necessarily scattered) trees by a&#x0302;finitary' set-interpretations.
[infinite scattered trees, Terminology, finitely-many-unary predicates, countably-many-infinite branches, set theory, logical interpretations, formal logic, injective-set interpretations, Bismuth, finitary-set interpretations, finitely-branching tree, monadic second order logic, Labeling, scattered linear-order tree analogue, finite-set interpretations, trees (mathematics), labellings, Educational institutions, ordinal-rank scattered tree, countable trees, Vegetation, Binary trees, Programmable logic arrays, Composition method, tuples, subsets]
Conservative Concurrency in Haskell
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
The calculus CHF models Concurrent Haskell extended by concurrent, implicit futures. It is a lambda and process calculus with concurrent threads, monadic concurrent evaluation, and includes a pure functional lambda-calculus PF which comprises data constructors, case-expressions, letrec-expressions, and Haskell's seq. Our main result is conservativity of CHF as extension of PF. This allows us to argue that compiler optimizations and transformations from pure Haskell remain valid in Concurrent Haskell even if it is extended by futures. We also show that conservativity does no longer hold if the extension includes Concurrent Haskell and unsafe Interleave IO.
[Context, lambda calculus, concurrent Haskell, Instruction sets, monadic concurrent evaluation, calculus CHF models, Programming, concurrency theory, Calculus, Cognition, concatenated codes, Contextual equivalence, conservative concurrency, Semantics, Concurrency, Syntactics, unsafe interleave IO, Haskell, process calculus, concurrent threads, Functional programming, functional languages]
Constructing Fully Complete Models for Multiplicative Linear Logic
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We demonstrate how the Hyland-Tan double glueing construction produces a fully complete model of the unit-free multiplicative fragment of Linear Logic when applied to any of a large family of degenerative ones. This process explains as special cases a number of such models which appear in the literature. In order to achieve this result, we make use of a tensor calculus for compact closed categories with finite biproducts. We show how the combinatorial properties required for a fully complete model are obtained by the construction adding to those already available from the original category.
[Double Glueing, Computational modeling, Switches, Full Completeness, tensor calculus, Calculus, tensors, Indexes, Linear Logic, Computer science, formal logic, Compact Closure, Tensile stress, combinatorial property, Algebra, Hyland-Tan double glueing construction, unit-free multiplicative fragment, compact closed category, multiplicative linear logic, finite biproduct]
Induction in Algebra: A First Case Study
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Many a concrete theorem of abstract algebra admits a short and elegant proof by contradiction but with Zorn's Lemma (ZL). A few of these theorems have recently turned out to follow in a direct and elementary way from the Principle of Open Induction distinguished by Raoult. The ideal objects characteristic of any invocation of ZL are eliminated, and it is made possible to pass from classical to intuitionistic logic. If the theorem has finite input data, then a finite partial order carries the required instance of induction, which thus is constructively provable. A typical example is the well-known theorem "every nonconstant coefficient of an invertible polynomial is nilpotent".
[nonconstant coefficient, intutionistic logic, intuitionistic logic, Zorn's Lemma, algebra, Topology, ideal objects characteristic, Computer science, formal logic, constructive algebra, abstract algebra, open induction, finite partial order, concrete theorem, Set theory, Polynomials, Modules (abstract algebra), invertible polynomial, Hilbert's Programme]
An Automata Model for Trees with Ordered Data Values
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Data trees are trees in which each node, besides carrying a label from a finite alphabet, also carries a data value from an infinite domain. They have been used as an abstraction model for reasoning tasks on XML and verification. However, most existing approaches consider the case where only equality test can be performed on the data values. In this paper we study data trees in which the data values come from a linearly ordered domain, and in addition to equality test, we can test whether the data value in a node is greater than the one in another node. We introduce an automata model for them which we call ordered-data tree automata (ODTA), provide its logical characterisation, and prove that its emptiness problem is decidable in 3-NEXPTIME. We also show that the two-variable logic on unranked trees, studied by Bojanczyk, Muscholl, Schwentick and Segoufin in 2009, corresponds precisely to a special subclass of this automata model. Then we define a slightly weaker version of ODTA, which we call weak ODTA, and provide its logical characterisation. The complexity of the emptiness problem drops to NP. However, a number of existing formalisms and models studied in the literature can be captured already by weak ODTA. We also show that the definition of ODTA can be easily modified, to the case where the data values come from a tree-like partially ordered domain, such as strings.
[data unranked trees, automata theory, data trees, Cognition, emptiness problem, Registers, Complexity theory, reasoning tasks, equality test, ordered-data tree automata, tree-like partially ordered domain, decidability, formal verification, unranked trees, 3-NEXPTIME, two-variable logic, verification, Transducers, formal languages, automata model, trees (mathematics), ODTA, ordered data values, linearly ordered domain, finite alphabet, inference mechanisms, logical characterisation, Automata, XML, Data models, abstraction model, logic, computational complexity]
Foundational, Compositional (Co)datatypes for Higher-Order Logic: Category Theory Applied to Theorem Proving
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Interactive theorem provers based on higher-order logic (HOL) traditionally follow the definitional approach, reducing high-level specifications to logical primitives. This also applies to the support for datatype definitions. However, the internal datatype construction used in HOL4, HOL Light, and Isabelle/HOL is fundamentally noncompositional, limiting its efficiency and flexibility, and it does not cater for codatatypes. We present a fully modular framework for constructing (co)datatypes in HOL, with support for mixed mutual and nested (co)recursion. Mixed (co)recursion enables type definitions involving both datatypes and codatatypes, such as the type of finitely branching trees of possibly infinite depth. Our framework draws heavily from category theory. The key notion is that of a bounded natural functor---an enriched type constructor satisfying specific properties preserved by interesting categorical operations. Our ideas are implemented as a definitional package in Isabelle, addressing a frequent request from users.
[higher-order logic, (co)datatypes, Shape, compositional datatype, definitional package, HOL4, formal logic, foundational datatype, fully modular framework, datatype definition, bounded natural functor, Semantics, internal datatype construction, Abstracts, categorical operation, interactive theorem proving, theorem proving, logical primitive, trees (mathematics), high-level specification, HOL Light, nested recursion, Standards, mixed mutual recursion, Isabelle/HOL, finitely branching tree, Category theory, Set theory, category theory, interactive theorem prover, cardinals]
Higher Semantics of Quantum Protocols
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
We propose a higher semantics for the description of quantum protocols, which deals with quantum and classical information in a unified way. Central to our approach is the modelling of classical data by information transfer to the environment, and the use of 2-category theory to formalize the resulting framework. This 2-categorical semantics has a graphical calculus, the diagrams of which correspond exactly to physically-implementable quantum procedures. Quantum teleportation in its most general sense is reformulated as the ability to remove correlations between a quantum system and its environment, and is represented by an elegant graphical identity. We use this new formalism to describe two new families of quantum protocols.
[Protocols, Calculus, calculus, classical information, Semantics, classical data, physically-implementable quantum procedures, Hilbert space, Mathematical model, quantum teleportation, higher semantics, quantum theory, Teleportation, graphical calculus, quantum protocols, quantum information, Equations, 2-categorical semantics, higher categories, quantum computing, elegant graphical identity, category theory, quantum system, information transfer, 2-category theory]
[Publisher's information]
2012 27th Annual IEEE Symposium on Logic in Computer Science
None
2012
Provides a listing of current staff, committee members and society officers.
[]
Foreword
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Presents the introductory welcome message from the conference proceedings.
[]
Conference Organization
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Provides a listing of current committee members and society officers.
[]
LICS: Logic in Computer Security -- Some Attacker's Models and Related Decision Problems
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Logic plays an important role in formal aspects of computer security, for instance in access control, security of communications or even intrusion detection. The peculiarity of security problems is the presence of an attacker, whose goal is to break the intended properties of a system/database/protocol... In this tutorial, we will consider several attacker's models and study how to find attacks (or to get security guarantees) on communication protocols in these different models.
[Protocols, cryptographic protocols, Computational modeling, Tutorials, communication protocols, security guarantees, intrusion detection, security problems, LICS, Computer science, formal logic, attackers model, authorisation, communication security, logic in computer security, access control, Cryptography, Computer security, formal aspects]
Duality in Logic and Computation
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
I give a brief introduction to Stone duality and then survey a number of duality theories that arise in logic and computer science. I mention some more unfamiliar dualities at the end which may be of importance to emerging fields within computer science.
[Stone duality, duality theories, Probabilistic logic, Vectors, Boolean algebra, completeness, semantics, Computer science, computer science, Semantics, duality (mathematics), category theory, logic, Mirrors]
Timed and Probabilistic I/O Automata
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Summary form only given. The Timed I/O Automata (TIOA) modeling framework has been used for describing and analyzing many distributed algorithms, ranging from data-management algorithms to clock-synchronization algorithms to robot-coordination algorithms. These algorithms include timing aspects, and both discrete and continuous behavior. In this talk, I will describe the TIOA framework in some detail, and summarize many of the examples to which it has been applied. Then, I will discuss the extensions that are needed to enable it to handle more kinds of algorithms. These extensions will mainly involve adding and integrating features for handling probabilistic choices. I will review the state of the art for Probabilistic Timed I/O Automata models, and describe the work that I think is still needed.
[data-management algorithm, TIOA modeling framework, Computational modeling, Laboratories, probabilistic choice handling, Probabilistic logic, robot-coordination algorithm, continuous behavior, Computer science, distributed algorithm, probabilistic automata, clock-synchronization algorithm, discrete behavior, distributed algorithms, Automata, Abstracts, probabilistic I/O automata, timed I/O automata modeling framework, timing aspect, Artificial intelligence]
Regular Functions and Cost Register Automata
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We propose a deterministic model for associating costs with strings that is parameterized by operations of interest (such as addition, scaling, and minimum), a notion of regularity that provides a yardstick to measure expressiveness, and study decision problems and theoretical properties of resulting classes of cost functions. Our definition of regularity relies on the theory of string-to-tree transducers, and allows associating costs with events that are conditioned on regular properties of future events. Our model of cost register automata allows computation of regular functions using multiple &#x201C;write-only&#x201D; registers whose values can be combined using the allowed set of operations. We show that the classical shortest-path algorithms as well as the algorithms designed for computing discounted costs can be adapted for solving the min-cost problems for the more general classes of functions specified in our model. Cost register automata with the operations of minimum and increment give a deterministic model that is equivalent to weighted automata, an extensively studied nondeterministic model, and this connection results in new insights and new open problems.
[Transducers, deterministic model, Computational modeling, Commutation, graph theory, weighted automata, string-to-tree transducer, Registers, Grammar, regular function, deterministic automata, Automata, cost register automata, cost function, shortest-path algorithm, Cost function, min-cost problem]
Presburger Vector Addition Systems
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
The reachability problem for Vector Addition Systems (VAS) is a central problem of net theory. The problem is known to be decidable by inductive invariants definable in the Presburger arithmetic. When the reachability set is definable in the Presburger arithmetic, the existence of such an inductive invariant is immediate. However, in this case, the computation of a Presburger formula denoting the reachability set is an open problem. In this paper we close this problem by proving that if the reachability set of a VAS is definable in the Presburger arithmetic, then the VAS is flatable, i.e. its reachability set can be obtained by runs labeled by words in a bounded language. As a direct consequence, classical algorithms based on acceleration techniques effectively compute a formula in the Presburger arithmetic denoting the reachability set.
[TV, reachability analysis, inductive invariants, Petri nets, Lattices, Infinite State Systems, arithmetic, Vectors, reachability problem, Complexity theory, set theory, Vector Addition Systems, reachability set, Presburger arithmetic, Reachability, vector addition systems, net theory, flatability, Presburger, Acceleration]
Reasoning about Data Repetitions with Counter Systems
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We study linear-time temporal logics interpreted over data words with multiple attributes. We restrict the atomic formulas to equalities of attribute values in successive positions and to repetitions of attribute values in the future or past. We demonstrate correspondences between satisfiability problems for logics and reachability-like decision problems for counter systems. We show that allowing/disallowing atomic formulas expressing repetitions of values in the past corresponds to the reachability/coverability problem in Petri nets. This gives us 2EXPSPACE upper bounds for several satisfiability problems. We prove matching lower bounds by reduction from a reachability problem for a newly introduced class of counter systems. This new class is a succinct version of vector addition systems with states in which counters are accessed via pointers, a potentially useful feature in other contexts. We strengthen further the correspondences between data logics and counter systems by characterizing the complexity of fragments, extensions and variants of the logic. For instance, we precisely characterize the relationship between the number of attributes allowed in the logic and the number of counters needed in the counter system.
[Petri nets, repeating values, computability, temporal logic, Complexity theory, data words, Cost accounting, coverability problem, satisfiability problem, satisfiability, data logics, atomic formula, reachability, linear-time temporal logic, attribute value, data word, reachability analysis, Radiation detectors, 2EXPSPACE upper bound, reachability-like decision problem, data repetition, counter systems, counter system, Encoding, Upper bound, vectors, Automata, fragment complexity, vector addition system, coverability]
On the Context-Freeness Problem for Vector Addition Systems
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Petri nets, or equivalently vector addition systems (VAS), are widely recognized as a central model for concurrent systems. Many interesting properties are decidable for this class, such as boundedness, reachability, regularity, as well as context-freeness, which is the focus of this paper. The context-freeness problem asks whether the trace language of a given VAS is context-free. This problem was shown to be decidable by Schwer in 1992, but the proof is very complex and intricate. The resulting decision procedure relies on five technical conditions over a customized coverability graph. These five conditions are shown to be necessary, but the proof that they are sufficient is only sketched. In this paper, we revisit the context-freeness problem for VAS, and give a simpler proof of decidability. Our approach is based on witnesses of non-context-freeness, that are bounded regular languages satisfying a nesting condition. As a corollary, we obtain that the trace language of a VAS is context-free if, and only if, it has a context-free intersection with every bounded regular language.
[decision theory, graph theory, Petri nets, pushdown automata, VAS, context-freeness, nesting condition, context-free languages, decidability, bounded regular language, Semantics, customized coverability graph, context-free intersection, theorem proving, proof, Labeling, trace language, Computational modeling, Vector addition systems, concurrent system, Educational institutions, concurrency theory, Vectors, Indexes, semilinear sets, context-freeness problem, Automata, decision procedure, bounded languages, vector addition system]
Groupoids, Hypergraphs, and Symmetries in Finite Models
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We propose a novel construction of finite hypergraphs and relational structures that is based on reduced products with Cayley graphs of groupoids. The universal algebraic and combinatorial properties of groupoids are abstracted form the composition behaviour of partial injections and support a very natural approach to the construction of certain highly symmetric finite instances of hypergraphs and relational structures. The typical task of this kind asks for regular realisations of a locally specified overlap pattern between pieces (hyperedges, guarded substructures). We show that reduced products with groupoids provide a generic and versatile tool towards such constructions; they are explored in applications to the construction of finite hypergraph coverings, to finite model constructions for the guarded fragment, and to extension properties for partial isomorphisms of relational structures (in the sense of Hrushovski, Herwig, Lascar). To this end we construct groupoids whose Cayley graphs have large girth not just in the usual sense, but with respect to a discounted distance measure that contracts edges from the same sub-groupoid (colour) and only counts transitions between cosets (different colours), and show that their acyclicity properties guarantee corresponding degrees of acyclicity in reduced products.
[partial isomorphism, graph theory, Length measurement, algebra, universal algebraic property, groupoids, formal logic, acyclicity property, combinatorial property, Databases, partial injection, Abstracts, finite hypergraph coverings, finite model, composition behaviour, Labeling, combinatorics, Color, Generators, Cayley graph, relational structure, Computer science, symmetries, hypergraphs, finite model theory, guarded logics]
An Optimal Gaifman Normal Form Construction for Structures of Bounded Degree
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
This paper's main result presents a 3-fold exponential algorithm that transforms a first-order formula &#x03C6; together with a number d into a formula in Gaifman normal form that is equivalent to &#x03C6; on the class of structures of degree at most d. For structures of polynomial growth, we even get a 2-fold exponential algorithm. These results are complemented by matching lower bounds: We show that for structures of degree 2, a 2-fold exponential blow-up in the size of formulas cannot be avoided. And for structures of degree 3, a 3-fold exponential blow-up is unavoidable. As a result of independent interest we obtain a 1-fold exponential algorithm which transforms a given first-order sentence &#x03C6; of a very restricted shape into a sentence in Gaifman normal form that is equivalent to &#x03C6; on all structures.
[Algorithm design and analysis, 3-fold exponential blow-up, model theory, structures of bounded degree, polynomials, 2-fold exponential algorithm, computational logic, first-order logic, Transforms, first-order sentence, 3-fold exponential algorithm, Electronic mail, 2-fold exponential blow-up, formal logic, Reactive power, first-order formula, Upper bound, optimal Gaifman normal form construction, polynomial growth structures, 1-fold exponential algorithm, bounded degree structures, Approximation algorithms, Polynomials, Gaifmans locality theorem]
Two-Variable Logic with Counting and Trees
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We consider the two-variable logic with counting quantifiers (C2) interpreted over finite structures that contain two forests of ranked trees. This logic is strictly more expressive than standard C2 and it is no longer a fragment of the first order logic. In particular, it can express that a structure is a ranked tree, a cycle or a connected graph of bounded degree. It is also strictly more expressive than the first-order logic with two variables and two successor relations of two finite linear orders. We give a decision procedure for the satisfiability problem for this logic. The procedure runs in NEXPTIME, which is optimal since the satisfiability problem for plain C2 is NEXPTIME-complete.
[Vocabulary, counting quantifiers, finite structures, ranked trees, computability, Data structures, Complexity theory, Computer science, bounded degree, satisfiability problem, satisfiability, Surgery, Vegetation, Implants, finite linear orders, ranked tree, first order logic, connected graph, NEXPTIME-complete, two-variable logic]
Measurable Spaces and Their Effect Logic
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
So-called effect algebras and modules are basic mathematical structures that were first identified in mathematical physics, for the study of quantum logic and quantum probability. They incorporate a double negation law p&#x22A5;&#x22A5; = p. Since then it has been realised that these effect structures form a useful abstraction that covers not only quantum logic, but also Boolean logic and probabilistic logic. Moreover, the duality between effect and convex structures lies at the heart of the duality between predicates and states. These insights are leading to a uniform framework for the semantics of computation and logic. This framework has been elaborated elsewhere for settheoretic, discrete probabilistic, and quantum computation. Here the missing case of continuous probability is shown to fit in the same uniform framework. On a technical level, this involves an investigation of the logical aspects of the Giry monad on measurable spaces and of Lebesgue integration.
[Probabilistic system, probabilistic logic, set theory, continuous probability, effect algebras, Giry monad, Quantum computing, Boolean functions, Algebra, measurable spaces, effect modules, effect-convex structures duality, quantum computation, set theoretic computation, probability, Extraterrestrial measurements, Probabilistic logic, quantum logic, Lebesgue integration, duality, Equations, effect logic, effect algebra, discrete probabilistic computation, Atmospheric measurements, Boolean logic, quantum computing, quantum probability, computation semantics, Particle measurements, logic semantics, measurable space]
Topological Structure of Quantum Algorithms
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We use a categorical topological semantics to examine the Deutsch-Jozsa, hidden subgroup and single-shot Grover algorithms. This reveals important structures hidden by conventional algebraic presentations, and allows novel proofs of correctness via local topological operations, giving for the first time a satisfying high-level explanation for why these procedures work. We also investigate generalizations of these algorithms, providing improved analyses of those already in the literature, and a new generalization of the single-shot Grover algorithm.
[Algorithm design and analysis, Fourier transforms, Protocols, single-shot Grover algorithms, Heuristic algorithms, local topological operations, topology, high-level explanation, categorical topological semantics, conventional algebraic presentations, proof of correctness, Equations, Deutsch-Jozsa, Algebra, topological structure, hidden subgroup, quantum computing, category theory, Finite element analysis, theorem proving, quantum algorithms]
On the Query Complexity of Real Functionals
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Recently Kawamura and Cook developed a framework to define the computational complexity of operators arising in analysis. Our goal is to understand the effects of complexity restrictions on the analytical properties of the operator. We focus on the case of norms over C[0,1] and introduce the notion of dependence of a norm on a point and relate it to the query complexity of the norm. We show that the dependence of almost every point is of the order of the query complexity of the norm. A norm with small complexity depends on a few points but, as compensation, highly depends on them. We characterize the functionals that are computable using one oracle call only and discuss the uniformity of that characterization.
[polynomial time computable functional, query complexity, Extraterrestrial measurements, Computable analysis, Topology, Electronic mail, complexity restriction, Computational complexity, norm, Turing machines, operators, Polynomials, oracle Turing machine, computational complexity]
Quantitative Monadic Second-Order Logic
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
While monadic second-order logic is a prominent logic for specifying languages of finite words, it lacks the power to compute quantitative properties, e.g. to count. An automata model capable of computing such properties are weighted automata, but logics equivalent to these automata have only recently emerged. We propose a new framework for adding quantitative properties to logics specifying Boolean properties of words. We use this to define Quantitative Monadic Second-Order Logic (QMSO). In this way we obtain a simple logic which is equally expressive to weighted automata. We analyse its evaluation complexity, both data and combined complexity, and show completeness results for combined complexity. We further refine the analysis of this logic and obtain fragments that characterise exactly subclasses of weighted automata defined by the level of ambiguity allowed in the automata. In this way, we define a quantitative logic which has good decidability properties while being resonably expressive and enjoying a simple syntactical definition.
[automata model, Computational modeling, automata theory, quantitative logic, weighted automata, quantitative property, Complexity theory, Standards, syntactical definition, Computer science, quantitative monadic second-order logic, evaluation complexity, Boolean functions, decidability, Semantics, Automata, finite words, data complexity, decidability property, Syntactics, Boolean property, QMSO, computational complexity, combined complexity]
Magnitude Monadic Logic over Words and the Use of Relative Internal Set Theory
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Cost monadic logic extends monadic second-order logic with the ability to measure the cardinality of sets and comes with decision procedures for boundedness related questions. We provide new decidability results allowing the systematic investigation of questions involving &#x201C;relative boundedness&#x201D;. We first introduce a suitable logic, magnitude monadic logic. We then establish the decidability of this logic over finite words. We finally advocate that developing the proofs in the axiomatic system of &#x201C;relative internal set theory&#x201D;, a variant of nonstandard analysis, entails a significant simplification of the proofs.
[Context, set theory, relative internal set theory, Standards, axiomatic system, cardinality of sets, Upper bound, decidability, cost monadic logic, relative boundedness, Automata, Games, Syntactics, Set theory, magnitude monadic logic, monadic second-order logic]
Quantitative Reasoning for Proving Lock-Freedom
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
This article describes a novel quantitative proof technique for the modular and local verification of lock-freedom. In contrast to proofs based on temporal rely-guarantee requirements, this new quantitative reasoning method can be directly integrated in modern program logics that are designed for the verification of safety properties. Using a single formalism for verifying memory safety and lock-freedom allows a combined correctness proof that verifies both properties simultaneously. This article presents one possible formalization of this quantitative proof technique by developing a variant of concurrent separation logic (CSL) for total correctness. To enable quantitative reasoning, CSL is extended with a predicate for affine tokens to account for, and provide an upper bound on the number of loop iterations in a program. Lock-freedom is then reduced to total-correctness proofs. Quantitative reasoning is demonstrated in detail, both informally and formally, by verifying the lock-freedom of Treiber's non-blocking stack. Furthermore, it is shown how the technique is used to verify the lock-freedom of more advanced shared-memory data structures that use elimination-backoff schemes and hazard-pointers.
[lock-freedom, memory safety verification, temporal rely-guarantee requirement, Liveness, local verification, temporal logic, Cognition, Lock-Freedom, Non-Blocking Data Structures, quantitative reasoning, modular verification, concurrent separation logic, Quantitative Analysis, quantitative proof technique, formal verification, Concurrency, shared memory systems, Safety, theorem proving, CSL, program loop iteration, program control structures, Interference, shared-memory data structure, Treiber nonblocking stack, Data structures, Educational institutions, concurrency theory, Synchronization, inference mechanisms, elimination-backoff scheme, hazard-pointer, Upper bound, affine token, total-correctness proof, modern program logic, Separation Logic, safety properties]
Model Checking for Successor-Invariant First-Order Logic on Minor-Closed Graph Classes
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Model checking problems for first- and monadic second-order logic on graphs have received considerable attention in the past, not the least due to their connections to problems in algorithmic graph structure theory. While the model checking problem for these logics on general graphs is computationally intractable, it becomes tractable on important classes of graphs such as those of bounded tree-width, planar graphs or more generally, classes of graphs excluding a fixed minor. It is well known that allowing an order relation or successor function can greatly increase the expressive power of the respective logics. This remains true even in cases where we require the formulas to be order- or successor-invariant, that is, while they can use an order relation, their truth in a given graph must not depend on the particular ordering or successor function chosen. Naturally, the question arises whether this increase in expressive power comes at a cost in terms of tractability on specific classes of graphs. In LICS 2012, Engelmann et al. studied this problem and showed that order-invariant monadic second-order logic (MSO) remains tractable on the same classes of graphs than MSO without an ordering. That is, adding order-invariance to MSO essentially comes at no extra cost in terms of model checking complexity. For successor-invariant first-order logic something similar should be true. However, they only managed to show that successor-invariant first-order logic is tractable on the class of planar graphs which is very far from the best tractability results currently known for first-order logic. In this paper we significantly improve the latter result and show that successor-invariant first-order logic is tractable on any class of graphs excluding a fixed minor. This is much closer to the best results known for FO without an ordering. The proof relies on the construction of k-walks in suitable supergraphs of the input graphs, i.e., walks which visit every vertex at least once and at most k times, for some k depending on the excluded minor H. The supergraphs may in general contain H minors, but they still exclude some possible larger minor H', so by results of Flum and Grohe [20] model checking on these graphs is still fixed-parameter tractable.
[Context, Torso, Vocabulary, trees (mathematics), planar graphs, Complexity theory, bounded tree-width, formal logic, Databases, formal verification, model checking, Model checking, Polynomials, monadic second-order logic, graph structure theory, successor-invariant first-order logic, minor-closed graph classes]
Dynamic Logic of Propositional Assignments: A Well-Behaved Variant of PDL
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We study a version of Propositional Dynamic Logic (PDL) that we call Dynamic Logic of Propositional Assignments (DL-PA). The atomic programs of DL-PA are assignments of propositional variables to true or to false. We show that DL-PA behaves better than PDL, having e.g. compactness and eliminability of the Kleene star. We establish tight complexity results: both satisfiability and model checking are EXPTIME-complete.
[Computational modeling, Radiation detectors, Kleene star eliminability, computability, EXPTIME-complete, Complexity theory, dynamic logic of propositional assignments, Cost accounting, Handheld computers, formal verification, model checking, satisfiability, Kleene star compactness, Abstracts, DL-PA, Model checking, PDL, propositional variable assignment, computational complexity]
Model-Checking Parse Trees
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Parse trees are fundamental syntactic structures in both computational linguistics and programming language design. We argue in this paper that, in both fields, there are good incentives for model-checking sets of parse trees for some word according to a context-free grammar. We put forward the adequacy of propositional dynamic logic (PDL) on trees in these applications, and study as a sanity check the complexity of the corresponding model-checking problem: although complete for exponential time in the general case, we find natural restrictions on grammars for our applications and establish complexities ranging from nondeterministic polynomial time to polynomial space in the relevant cases.
[Computational modeling, propositional dynamic logic, polynomial space, computational linguistics, Grammar, tree searching, model checking parse trees, formal logic, syntactic structures, formal verification, exponential time, context free grammar, programming language design, Automata, Vegetation, Production, Syntactics, nondeterministic polynomial time, sanity check, model checking set, context-free grammars, model checking problem, Computational linguistics, tree data structures]
The Complexity of Model Checking Multi-stack Systems
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We consider the linear-time model checking problem for boolean concurrent programs with recursive procedure calls. While sequential recursive programs are usually modeled as pushdown automata, concurrent recursive programs involve several processes and can be naturally abstracted as pushdown automata with multiple stacks. Their behavior can be understood as words with multiple nesting relations, each relation connecting a procedure call with its corresponding return. To reason about multiply nested words, we consider the class of all temporal logics as defined in the book by Gabbay, Hodkinson, and Reynolds (1994). The unifying feature of these temporal logics is that their modalities are defined in monadic second-order (MSO) logic. In particular, this captures numerous temporal logics over concurrent and/or recursive programs that have been defined so far. Since the general model checking problem is undecidable, we restrict attention to phase bounded executions as proposed by La Torre, Madhusudan, and Parlato (LICS 2007). While the MSO model checking problem in this case is non-elementary, our main result states that the model checking (and satisfiability) problem for all MSO-definable temporal logics is decidable in elementary time. More precisely, it is solvable in (n + 2)-EXPTIME where n is the maximal level of the MSO modalities in the monadic quantifier alternation hierarchy. We complement this result and provide, for each level n, a temporal logic whose model checking problem is n-EXPSPACE-hard.
[MSO logic, multistack system, linear-time model checking problem, pushdown automata, computability, temporal logic, sequential recursive program, temporal logics, EXPTIME, concurrent recursive program, Boolean functions, multiple nesting relation, formal verification, Semantics, satisfiability, satisfiability problem, Abstracts, Model checking, recursive procedure call, Encoding, monadic quantifier alternation hierarchy, nested words, Upper bound, model checking, Automata, n-EXPSPACE-hard, Boolean concurrent program, multiply nested words, monadic second-order logic, Manganese, computational complexity]
Maximum Matching and Linear Programming in Fixed-Point Logic with Counting
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We establish the expressibility in fixed-point logic with counting (FPC) of a number of natural polynomial-time problems. In particular, we show that the size of a maximum matching in a graph is definable in FPC. This settles an open problem first posed by Blass, Gurevich and Shelah [1], who asked whether the existence of perfect matchings in general graphs could be determined in the more powerful formalism of choiceless polynomial time with counting. Our result is established by noting that the ellipsoid method for solving linear programs of full dimension can be implemented in FPC. This allows us to prove that linear programs of full dimension can be optimised in FPC if the corresponding separation oracle problem can be defined in FPC. On the way to defining a suitable separation oracle for the maximum matching problem, we provide FPC formulas defining maximum flows and canonical minimum cuts in capacitated graphs.
[Vocabulary, pattern matching, graph theory, linear programming, separation oracle problem, Ellipsoids, Optimization, formal logic, maximum matching problem, ellipsoid method, perfect matching, Polynomials, maximum matching, capacitated graph, general graph, fixed-point logic with counting, canonical minimum cut, choiceless polynomial time, natural polynomial-time problem, Linear programming, Vectors, Encoding, minimum odd cut, minimum cut, FPC, maximum flow, computational complexity]
Turing Machines with Atoms
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We study Turing machines over sets with atoms, also known as nominal sets. Our main result is that deterministic machines are weaker than nondeterministic ones; in particular, P&#x2260;NP in sets with atoms. Our main construction is closely related to the Cai-Furer-Immerman graphs used in descriptive complexity theory.
[nominal sets, Cai-Furer-Immerman graphs, Law, Computational modeling, graph theory, Orbits, Magnetic heads, set theory, atoms, Sets with atoms; Turing machines, Turing machines, nondeterministic machines, descriptive complexity theory, P&#x2260;NP, Polynomials, computational complexity]
Adding an Equivalence Relation to the Interval Logic ABB: Complexity and Expressiveness
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Interval temporal logics provide a general framework for temporal representation and reasoning, where classical (point-based) linear temporal logics can be recovered as special cases. In this paper, we study the effects of the addition of an equivalence relation to one of the most representative interval temporal logics, namely, the logic ABB&#x0305; of Allen's relations meets, begun by, and begins. We first prove that the satisfiability problem for the resulting logic ABB&#x0305; &#x2115; remains decidable over finite linear orders, but it becomes nonprimitive recursive, while decidability is lost over N. We also show that decidability over can be recovered by restricting to a suitable subset of models. Then, we show that ABB&#x0305; &#x2115; is expressive enough to define &#x03C9;S-regular languages, thus establishing a promising connection between interval temporal logics and extended &#x03C9;-regular languages.
[complexity, Decidability, &#x03C9;S-regular language, computability, temporal logic, Cognition, Complexity theory, interval temporal logic, finite linear order, Complexity, decidability, Semantics, satisfiability problem, interval logic ABB, point-based linear temporal logic, expressiveness, Interval Temporal Logic, temporal representation, Allen relation, formal languages, Extension of Omega Languages, Radiation detectors, Computational modeling, Compass, extended &#x03C9;-regular language, temporal reasoning, Syntactics, equivalence relation, equivalence classes, computational complexity]
Decidability of Weak Simulation on One-Counter Nets
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
One-counter nets (OCN) are Petri nets with exactly one unbounded place. They are equivalent to a subclass of one-counter automata with only a weak test for zero. We show that weak simulation preorder is decidable for OCN and that weak simulation approximants do not converge at level &#x03C9;, but only at &#x03C9;2. In contrast, other semantic relations like weak bisimulation are undecidable for OCN [1], and so are weak (and strong) trace inclusion (Sec. VII).
[one-counter nets, weak simulation decidability, semantic relations, Radiation detectors, Computational modeling, automata theory, Petri nets, weak test, Educational institutions, weak trace inclusion, One-counter machines, one-counter automata, weak simulation preorder, decidability, Semantics, Automata, Automata theory, Games, Model checking, bisimulation equivalence, OCN, weak bisimulation]
Intensional Type Theory with Guarded Recursive Types qua Fixed Points on Universes
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Guarded recursive functions and types are useful for giving semantics to advanced programming languages and for higher-order programming with infinite data types, such as streams, e.g., for modeling reactive systems. We propose an extension of intensional type theory with rules for forming fixed points of guarded recursive functions. Guarded recursive types can be formed simply by taking fixed points of guarded recursive functions on the universe of types. Moreover, we present a general model construction for constructing models of the intensional type theory with guarded recursive functions and types. When applied to the groupoid model of intensional type theory with the universe of small discrete groupoids, the construction gives a model of guarded recursion for which there is a one-to-one correspondence between fixed points of functions on the universe of types and fixed points of (suitable) operators on types. In particular, we find that the functor category Grpd&#x03C9;op from the preordered set of natural numbers to the category of groupoids is a model of intensional type theory with guarded recursive types.
[Programming, type theory, semantics, intensional type theory, Semantics, guarded recursive function, natural number, Mathematical model, Productivity, functor category, model construction, Computational modeling, fixed points, infinite data type, groupoid category, recursive functions, programming language semantics, advanced programming language, one-to-one correspondence, Equations, group theory, Syntactics, discrete groupoid, category theory, higher-order programming, guarded recursive type, groupoid model]
Calculating the Fundamental Group of the Circle in Homotopy Type Theory
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Recent work on homotopy type theory exploits an exciting new correspondence between Martin-Lof's dependent type theory and the mathematical disciplines of category theory and homotopy theory. The mathematics suggests new principles to add to type theory, while the type theory can be used in novel ways to do computer-checked proofs in a proof assistant. In this paper, we formalize a basic result in algebraic topology, that the fundamental group of the circle is the integers. Our proof illustrates the new features of homotopy type theory, such as higher inductive types and Voevodsky's univalence axiom. It also introduces a new method for calculating the path space of a type, which has proved useful in many other examples.
[homotopy theory, inductive types, algebraic topology, Frequency modulation, fundamental group, topology, Generators, type theory, Voevodsky's univalence axiom, Topology, Decoding, Martin-Lof's dependent type theory, mathematical disciplines, Geometry, homotopy type theory, computer-checked proofs, category theory, theorem proving, proof assistant, Clocks]
Type-Based Productivity of Stream Definitions in the Calculus of Constructions
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Productivity of corecursive definitions is an essential property in proof assistants since it ensures logical consistency and decidability of type checking. Type-based mechanisms for ensuring productivity use types annotated with size information to track the number of elements produced in corecursive definitions. In this paper, we propose an extension of the Calculus of Constructions-the theory underlying the Coq proof assistant-with a type-based criterion for ensuring productivity of stream definitions. We prove strong normalization and logical consistency. Furthermore, we define an algorithm for inferring size annotations in types. These results can be easily extended to handle general coinductive types.
[Adaptation models, logical consistency, type checking decidability, Calculus, type theory, type-based mechanisms, corecursive definition productivity, stream definition type-based productivity, decidability, calculus of constructions, type-based criterion, theorem proving, Kernel, Productivity, Context, general coinductive types, Type-Based Productivity, Coq proof assistant, Grammar, strong normalization, Coinduction, Strong Normalization, Dependent Types, Tin, size information]
Fibred Data Types
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Data types are undergoing a major leap forward in their sophistication driven by a conjunction of i) theoretical advances in the foundations of data types; and ii) requirements of programmers for ever more control of the data structures they work with. In this paper we develop a theory of indexed data types where, crucially, the indices are generated inductively at the same time as the data. In order to avoid commitment to any specific notion of indexing we take an axiomatic approach to such data types using fibrations - thus giving us a theory of what we call fibred data types. The genesis of these fibred data types can be traced within the literature, most notably to Dybjer and Setzer's introduction of the concept of induction-recursion. This paper, while drawing heavily on their seminal work for inspiration, gives a categorical reformulation of Dybjer and Setzer's original work which leads to a large number of extensions of induction-recursion. Concretely, the paper provides i) conceptual clarity as to what inductionrecursion fundamentally is about; ii) greater expressiveness in allowing not just the inductive-recursive definition of families of sets, or even indexed families of sets, but rather the inductiverecursive definition of a whole host of other structures; iii) a semantics for induction-recursion based not on the specific model of families, but rather an axiomatic model based upon fibrations which therefore encompasses diverse structures (domain theoretic, realisability, games etc) arising in the semantics of programming languages; and iv) technical justification as to why these fibred data types exist using large cardinals from set theory.
[induction recursion, axiomatic model, indexing, Containers, inductive recursive definition, Decoding, set theory, Computer languages, Algebra, initial algebras, Semantics, categorical reformulation, fibrations, data structures, data types, fibred data types, cardinals, Indexing]
Arbitrary Action Model Logic and Action Model Synthesis
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We present a method for synthesising action models that result in a given post-condition when executed on any Kripke model. Action models represent social actions that affect the knowledge or beliefs of agents in multi-agent systems. In the consideration of action model synthesis, we introduce an extension of the action model logic of Baltag, Moss and Solecki [3] with an action model quantifier, &#x2203;&#x03C6; which stands for &#x201C;there is an action model that results in the post-condition &#x03C6;&#x201D;. We show that this quantifier is equivalent to the refinement quantifier of van Ditmarsch and French [10], and provide a sound and complete axiomatisation for the resulting logic, along with decidability and expressivity results.
[social actions, Doxastic logic, Uncertainty, multi-agent systems, Computational modeling, Kripke model, action model quantifier, Multi-agent system, Epistemic logic, axiomatisation, refinement quantifier, Educational institutions, Action Models, Temporal epistemic Logic, action model synthesis, Refinement quantifier, Computer science, decidability, Semantics, arbitrary action model logic, Modal logic, Australia, Multi-agent systems, multiagent systems]
On the Boundary of Behavioral Strategies
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
In the setting of multi-agent games, considerable effort has been devoted to the definition of modal logics for strategic reasoning. In this area, a recent contribution is given by the introduction of Strategy Logic (SL, for short) by Mogavero, Murano, and Vardi. This logic allows to reason explicitly about strategies as first order objects and express in a very natural and elegant way several solution concepts like Nash, resilient, and secure equilibria, dominant strategies, etc. The price that one has to pay for the high expressiveness of SL semantics is that agents strategies it admits may be not behavioral, i.e., a choice of an agent, at a given moment of a play, may depend on the choices another agent can make in another counterfactual play. As the latter moves are unpredictable, this kind of strategies cannot be synthesized in practice. In this paper, we investigate two syntactical fragments of SL, namely the conjunctive-goal and disjunctive-goal, called SL[CG] and SL[DG] for short, and prove that their semantics admit behavioral strategies only. These logics are obtained by forcing SL formulas to be only of the form of conjunctions or disjunctions of goals, which are temporal assertions associated with a binding of agents with strategies. As SL formulas with any Boolean combination of goals turn out to be non behavioral, we have that SL[CG] and SL[DG] represent the maximal fragments of SL describing agent behaviors that are synthesizable. As a consequence of the above results, the model-checking problem for both SL[CG] and SL[DG] is shown to be solvable in 2EXPTIME, as it is for the subsumed logic ATL*.
[DG, multiagent game, strategy logic, Nash equilibrium, Cognition, History, modal logic, first order object, formal logic, Reactive power, Semantics, strategic reasoning, price, behavioral strategy, syntactical fragment, CG, game theory, agents strategy, Indexes, conjunctive-goal, dominant strategy, SL[CG, SL semantics, disjunctive-goal, Games, Syntactics, computational complexity]
A Relatively Complete Generic Hoare Logic for Order-Enriched Effects
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Monads are the basis of a well-established method of encapsulating side-effects in semantics and programming. There have been a number of proposals for monadic program logics in the setting of plain monads, while much of the recent work on monadic semantics is concerned with monads on enriched categories, in particular in domain-theoretic settings, which allow for recursive monadic programs. Here, we lay out a definition of order-enriched monad which imposes cpo structure on the monad itself rather than on base category. Starting from the observation that order-enrichment of a monad induces a weak truth-value object, we develop a generic Hoare calculus for monadic side-effecting programs. For this calculus, we prove relative completeness via a calculus of weakest preconditions, which we also relate to strongest postconditions.
[monadic program logics, order-enriched monad, weakest precondition, order-enriched effect, Calculus, recursive monadic program, enriched categories, Algebra, base category, truth-value object, weakest preconditions, Semantics, strongest postconditions, domain-theoretic setting, programming, Context, monadic semantics, complete generic Hoare logic, recursive functions, Topology, monads, programming language semantics, cpo structure, Standards, Equations, computational effects, category theory, monadic side-effecting program, Hoare logic]
Unifying Classical and Intuitionistic Logics for Computational Control
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We show that control operators and other extensions of the Curry-Howard isomorphism can be achieved without collapsing all of intuitionistic logic into classical logic. For this purpose we introduce a unified propositional logic using polarized formulas. We define a Kripke semantics for this logic. Our proof system extends an intuitionistic system that already allows multiple conclusions. This arrangement reveals a greater range of computational possibilities, including a form of dynamic scoping. We demonstrate the utility of this logic by showing how it can improve the formulation of exception handling in programming languages, including the ability to distinguish between different kinds of exceptions and constraining when an exception can be thrown, thus providing more refined control over computation compared to classical logic. We also describe some significant fragments of this logic and discuss its extension to second-order logic.
[propositional logic, exception handling, intuitionistic logic, computational control, intuitionistic system, Calculus, polarized formulas, programming languages, computational possibility, formal logic, Semantics, Abstracts, control operators, theorem proving, classical logic, Kripke semantics, dynamic scoping, Krikpe semantics, Context, Java, proof system, Curry-Howard isomorphism, proof theory, second-order logic, computational complexity]
The Cost of Usage in the ?-Calculus
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
A new &#x201C;inductive&#x201D; approach to standardization for the &#x03BB;-calculus has been recently introduced by Xi, allowing him to establish a double-exponential upper bound |M|2|&#x03C3;| for the length of the standard reduction relative to an arbitrary reduction &#x03C3; originated in M. In this paper we refine Xi's analysis, obtaining much better bounds, especially for computations producing small normal forms. For instance, for terms reducing to a boolean, we are able to prove that the length of the standard reduction is at most a mere factorial of the length of the shortest reduction sequence. The methodological innovation of our approach is that instead of counting the cost for producing something, as is customary, we count the cost of consuming things. The key observation is that the part of a &#x03BB;-term that is needed to produce the normal form (or an arbitrary rigid prefix) may rapidly augment along a computation, but can only decrease very slowly (actually, linearly).
[Context, lambda calculus, double-exponential upper bound, standardization, Electronic mail, Standards, Upper bound, prefixes, &#x03BB;-calculus, standard reduction, Production, shortest reduction sequence, beta reduction, stability, Manganese]
Weighted Relational Models of Typed Lambda-Calculi
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
The category Rel of sets and relations yields one of the simplest denotational semantics of Linear Logic (LL). It is known that Rel is the biproduct completion of the Boolean ring. We consider the generalization of this construction to an arbitrary continuous semiring R, producing a cpo-enriched category which is a semantics of LL, and its (co)Kleisli category is an adequate model of an extension of PCF, parametrized by R. Specific instances of R allow us to compare programs not only with respect to &#x201C;what they can do&#x201D;, but also &#x201C;in how many steps&#x201D; or &#x201C;in how many different ways&#x201D; (for non-deterministic PCF) or even &#x201C;with what probability&#x201D; (for probabilistic PCF).
[LL, probabilistic logic, linear logic, probabilistic PCF, typed lambda-calculi, type theory, set theory, lambda-calculus, quantitative semantics, Kleisli category, Boolean functions, arbitrary continuous semiring, Semantics, category Rel, denotational semantics, lambda calculus, Computational modeling, sets, Boolean ring, cpo-enriched category, Probabilistic logic, biproduct completion, programming language semantics, Tensile stress, Equalizers, weighted relational model, Games, Coherence, category theory, nondeterministic PCF]
Atomic Lambda Calculus: A Typed Lambda-Calculus with Explicit Sharing
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
An explicit-sharing lambda-calculus is presented, based on a Curry-Howard-style interpretation of the deep inference proof formalism. Duplication of subterms during reduction proceeds `atomically', i.e. on individual constructors, similar to optimal graph reduction in the style of Lamping. The calculus preserves strong normalisation with respect to the lambda-calculus, and achieves fully lazy sharing.
[Context, lambda calculus, Frequency modulation, typed lambda-calculus, graph theory, Calculus, type theory, atomic lambda-calculus, Grammar, inference mechanisms, Curry-Howard-style interpretation, Standards, Computer science, individual constructors, normalisation, Wires, lazy sharing, optimal graph reduction, deep inference proof formalism, theorem proving, explicit-sharing lambda-calculus]
Stone Duality for Markov Processes
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We define Aumann algebras, an algebraic analog of probabilistic modal logic. An Aumann algebra consists of a Boolean algebra with operators modeling probabilistic transitions. We prove a Stone-type duality theorem between countable Aumann algebras and countably-generated continuous-space Markov processes. Our results subsume existing results on completeness of probabilistic modal logics for Markov processes.
[Probabilistic modal logics, probability, Stone-type duality, countable Aumann algebra, Probabilistic logic, Extraterrestrial measurements, Boolean algebra, Topology, completeness, probabilistic modal logics completeness, Labelled Markov processes, stone duality, Computer science, formal logic, algebraic analog, stone-type duality theorem, Markov processes, duality (mathematics), probabilistic transition modeling, countably-generated continuous-space Markov processes]
Trading Performance for Stability in Markov Decision Processes
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We study the complexity of central controller synthesis problems for finite-state Markov decision processes, where the objective is to optimize both the expected mean-payoff performance of the system and its stability. We argue that the basic theoretical notion of expressing the stability in terms of the variance of the mean-payoff (called global variance in our paper) is not always sumcient, since it ignores possible instabilities on respective runs. For this reason we propose alernative definitions of stability, which we call local and hybrid variance, and which express how rewards on each run deviate from the run's own mean-payoff and from the expected mean-payoff, respectively. We show that a strategy ensuring both the expected mean-payoff and the variance below given bounds requires randomization and memory, under all the above semantics of variance. We then look at the problem of determining whether there is a such a strategy. For the global variance, we show that the problem is in PSPACE, and that the answer can be approximated in pseudo-polynomial time. For the hybrid variance, the analogous decision problem is in NP, and a polynomial-time approximating algorithm also exists. For local variance, we show that the decision problem is in NP. Since the overall performance can be traded for stability (and vice versa), we also present algorithms for approximating the associated Pareto curve in all the three cases. Finally, we study a special case of the decision problems, where we require a given expected mean-payoff together with zero variance. Here we show that the problems can be all solved in polynomial time.
[complexity, NP, decision theory, memory, Pareto optimization, Complexity theory, Approximation methods, trading performance, local variance, Pareto curve, optimization, randomization, variance semantics, polynomial-time approximating algorithm, stability, hybrid variance, Pareto optimisation, finite-state Markov decision process, Stability analysis, programming language semantics, PSPACE, global variance, randomised algorithms, analogous decision problem, Markov decision processes, Memory management, Markov processes, Approximation algorithms, central controller synthesis problem, pseudopolynomial time, mean payoff, mean-payoff performance, computational complexity]
Solving Partial-Information Stochastic Parity Games
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We study one-sided partial-information 2-player concurrent stochastic games with parity objectives. In such a game, one of the players has only partial visibility of the state of the game, while the other player has complete knowledge. In general, such games are known to be undecidable, even for the case of a single player (POMDP). These undecidability results depend crucially on player strategies that exploit an infinite amount of memory. However, in many applications of games, one is usually more interested in finding a finite-memory strategy. We consider the problem of whether the player with partial information has a finite-memory winning strategy when the player with complete information is allowed to use an arbitrary amount of memory. We show that this problem is decidable.
[complete information player, Transducers, Partial-observation games, partial information player, Probabilistic logic, player strategy, undecidability, Finite-memory strategy, Stochastic games, decidability, one-sided partial-information 2-player concurrent stochastic parity games, Memory management, Alternating tree automata, Automata, POMDP, Games, Markov processes, finite-memory winning strategy, stochastic games]
Expressive Completeness for Metric Temporal Logic
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Metric Temporal Logic (MTL) is a generalisation of Linear Temporal Logic in which the Until and Since modalities are annotated with intervals that express metric constraints. Hirshfeld and Rabinovich have shown that over the reals, firstorder logic with binary order relation &lt;; and unary function +1 is strictly more expressive than MTL with integer constants. Indeed they prove that no temporal logic whose modalities are definable by formulas of bounded quantifier depth can be expressively complete for FO(&lt;;, +1). In this paper we show that if we allow unary functions +q, q &#x2208; Q, in first-order logic and correspondingly allow rational constants in MTL, then the two logics have the same expressive power. This gives the first generalisation of Kamp's theorem on the expressive completeness of LTL for FO(&lt;;) to the quantitative setting. The proof of this result involves a generalisation of Gabbay's notion of separation to the metric setting.
[until modality, integer constants, MTL, Metric Temporal Logic, metric constraints, binary order relation, first-order logic, temporal logic, expressive completeness, since modality, Time-domain analysis, unary function, Expressive Completeness, Kamp's theorem, Semantics, bounded quantifier depth, Silicon, First-Order Logic, metric temporal logic, Linear Temporal Logic, linear temporal logic, Computer science, metric setting, rational constants, generalisation, Syntactics, first order logic, Timing, quantitative setting]
One-Path Reachability Logic
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
This paper introduces (one-path) reachability logic, a language-independent proof system for program verification, which takes an operational semantics as axioms and derives reachability rules, which generalize Hoare triples. This system improves on previous work by allowing operational semantics given with conditional rewrite rules, which are known to support all major styles of operational semantics. In particular, Kahn's big-step and Plotkin's small-step semantic styles are now supported. The reachability logic proof system is shown sound (i.e., partially correct) and (relatively) complete. Reachability logic thus eliminates the need to independently define an axiomatic and an operational semantics for each language, and the nonnegligible effort to prove the former sound and complete w.r.t. the latter. The soundness result has also been formalized in Coq, allowing reachability logic derivations to serve as formal proof certificates that rely only on the operational semantics.
[program verification, operational semantics, reachability logic derivation, Cognition, Plotkin small-step semantic style, Cost accounting, formal logic, Reactive power, formal proof certificate, Semantics, reachability logic proof system, Abstracts, axiomatic semantics, theorem proving, language-independent proof system, Kahn big-step semantic style, reachability analysis, Hoare triple, Coq, one-path reachability logic, conditional rewrite rule, Syntactics, logic, Pattern matching, Hoare logic]
Substructure Temporal Logic
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
In formal verification and design, reasoning about substructures is a crucial aspect for several fundamental problems, whose solution often requires to select a portion of the model of interest on which to verify a specific property. In this paper, we present a new branching-time temporal logic, called Substructure Temporal Logic (STL*, for short), whose distinctive feature is to allow for quantifying over the possible substructure of a given structure. This logic is obtained by adding two new operators to CTL*, whose interpretation is given relative to the partial order induced by a suitable substructure relation. STL* turns out to be very expressive and allows to capture in a very natural way many well known problems, such as module checking, reactive synthesis and reasoning about games. A formal account of the model theoretic properties of the new logic and results about (un)decidability and complexity of related decision problems are also provided.
[complexity, substructure relation, Computational modeling, temporal logic, Cognition, STL, inference mechanisms, substructure reasoning, decidability, formal verification, Semantics, Games, substructure temporal logic, game reasoning, Syntactics, Model checking, branching-time temporal logic, formal design, CTL, reactive synthesis, Labeling, module checking, logic model theoretic property, computational complexity]
Name-Passing Calculi: From Fusions to Preorders and Types
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
The fusion calculi are a simplification of the pi-calculus in which input and output are symmetric and restriction is the only binder. We highlight a major difference between these calculi and the pi-calculus from the point of view of types, proving some impossibility results for subtyping in fusion calculi. We propose a modification of fusion calculi in which the name equivalences produced by fusions are replaced by name preorders, and with a distinction between positive and negative occurrences of names. The resulting calculus allows us to import subtype systems, and related results, from the pi-calculus. We examine the consequences of the modification on behavioural equivalence (e.g., context-free characterisations of barbed congruence) and expressiveness (e.g., full abstraction of the embedding of the asynchronous pi-calculus).
[Context, reorders, types, Fuses, fusions, Calculus, Encoding, type theory, Standards, fusion calculi, subtyping, pi calculus, subtype system, Semantics, Syntactics, name passing calculi, process calculus]
A Compositional Semantics for the Reversible p-Calculus
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We introduce a labelled transition semantics for the reversible &#x03C0;-calculus. It is the first account of a compositional definition of a reversible calculus, that has both concurrency primitives and name mobility. The notion of reversibility is strictly linked to the notion of causality. We discuss the notion of causality induced by our calculus, and we compare it with the existing notions in the literature, in particular for what concerns the syntactic feature of scope extrusion, typical of the &#x03C0;-calculus.
[Context, reversible &#x03C0;-calculus, compositional definition, syntactic feature, Calculus, Synchronization, reversible p -calculus, name mobility, Concurrent computing, pi calculus, concurrency primitive, labelled transition semantics, Semantics, compositional, Syntactics, scope extrusion, compositional semantics, Concrete]
Pumping by Typing
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Higher-order recursion schemes (HORS), which are higher-order grammars for generating infinite trees, have recently been studied extensively in the context of model checking and its applications to higher-order program verification. We develop a pumping lemma for HORS by using a novel but simple intersection type system for reasoning about reductions of &#x03BB;-terms. Our proof is arguably much simpler than the proof of Kartzow and Parys' pumping lemma for collapsible pushdown automata. As an application, we give an alternative proof of Kartzow and Parys' result about the strictness of the hierarchy of trees generated by HORS.
[program verification, infinite trees, pushdown automata, reasoning, Cognition, type theory, &#x03BB;-term reduction, Model checking, theorem proving, collapsible pushdown automata, trees hierarchy, Context, trees (mathematics), higher-order program verification, HORS, Generators, Grammar, inference mechanisms, Standards, model checking, grammars, pumping lemma, higher-order recursion scheme, higher-order grammar, Automata, typing, Kartzow and Parys proof, intersection type system]
From Frame Properties to Hypersequent Rules in Modal Logics
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We provide a general method for generating cutfree and/or analytic hypersequent Gentzen-type calculi for a variety of normal modal logics. The method applies to all modal logics characterized by Kripke frames, transitive Kripke frames, or symmetric Kripke frames satisfying some properties, given by first-order formulas of a certain simple form. This includes the logics KT, KD, S4, S5, K4D, K4.2, K4.3, KBD, KBT, and other modal logics, for some of which no Gentzen calculi was presented before. Cut-admissibility (or analyticity in the case of symmetric Kripke frames) is proved semantically in a uniform way for all constructed calculi. The decidability of each modal logic in this class immediately follows.
[K4.2 modal logic, KD modal logic, K4.3 modal logic, Calculus, constructed calculi, calculus, modal logic, analytic hypersequent Gentzen-type calculi, decidability, frame property, Semantics, normal modal logics, symmetric Kripke frames, K4D modal logic, theorem proving, Context, first-order formulas, KT modal logic, Gentzen calculi, frame properties, cutfree hypersequent Gentzen-type calculi, Educational institutions, S5 modal logic, hypersequent calculi, S4 modal logic, Standards, proof theory, Computer science, hypersequent rules, Syntactics, KBD modal logic, KBT modal logic, transitive Kripke frames, cut-admissibility]
The Logic of Exact Covers: Completeness and Uniform Interpolation
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We show that all (not necessarily normal or monotone) modal logics that can be axiomatised in rank-1 have the interpolation property, and that in fact interpolation is uniform if the logics just have finitely many modal operators. As immediate applications, we obtain previously unknown interpolation theorems for a range of modal logics, containing probabilistic and graded modal logic, alternating temporal logic and some variants of conditional logic. Technically, this is achieved by translating to and from a new (coalgebraic) logic introduced in this paper, the logic of exact covers. It is interpreted over coalgebrasfor an endofunctor on the category of sets that also directly determines the syntax. Apart from closure under bisimulation quantifiers (and hence interpolation), we also provide a complete tableaux calculus and establish both the Hennessy-Milner and the small model property for this logic.
[modal logics, tableaux calculus, graded modal logic, probabilistic logic, modal operators, exact cover logic, Hennessy-Milner property, temporal logic, Probabilistic logic, Educational institutions, Calculus, completeness, alternating temporal logic, Standards, uniform interpolation property, Interpolation, Semantics, Syntactics, bisimulation quantifiers, endofunctor, bisimulation equivalence, conditional logic, coalgebrasfor, small model property]
Compressing Polarized Boxes
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
The sequential nature of sequent calculus provides a simple definition of cut-elimination rules that duplicate or erase sub-proofs. The parallel nature of proof nets, instead, requires the introduction of explicit boxes, which are global and synchronous constraints on the structure of graphs. We show that logical polarity can be exploited to obtain an implicit, compact, and natural representation of boxes: in an expressive polarized dialect of linear logic, boxes may be represented by simply recording some of the polarity changes occurring in the box at level 0. The content of the box can then be recovered locally and unambiguously. Moreover, implicit boxes are more parallel than explicit boxes, as they realize a larger quotient. We provide a correctness criterion and study the novel and subtle cut-elimination dynamics induced by implicit boxes, proving confluence and strong normalization.
[sequent calculus, multiplicative and exponential polarized linear logic, Correctness Criteria, Shape, graph theory, linear logic, synchronous constraint, Calculus, Proof Nets, Linear Logic, subproofs duplication, formal logic, explicit box, Semantics, normalization, Confluence, correctness criterion, Polarity, logical polarity, polarized box compression, Cut-elimination, cut-elimination dynamics, Encoding, Termination, Standards, graph, Games, Syntactics, global constraint, cut-elimination rule, subproof erasing]
Kripke Semantics for Modal Bilattice Logic
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We employ the well-developed and powerful techniques of algebraic semantics and Priestley duality to set up a Kripke semantics for a modal expansion of Arieli and Avron's bilattice logic, itself based on Belnap's four-valued logic. We obtain soundness and completeness of a Hilbert-style derivation system for this logic with respect to four-valued Kripke frames, the standard notion of model in this setting. The proof is via intermediary relational structures which are analysed through a topological reading of one of the axioms of the logic. Both local and global consequence on the models are covered.
[modal bilattice logic, Priestley duality, intermediary relational structure, Lattices, algebraic semantics, Educational institutions, Hilbert spaces, Bilattice logic, Calculus, four-valued logic, modal logic, Standards, Computer science, formal logic, Algebra, Semantics, algebraic logic, four-valued Kripke frames, duality (mathematics), Hilbert-style derivation system, Kripke semantics]
Forcing MSO on Infinite Words in Weak MSO
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We propose a forcing-based interpretation of monadic second-order logic (MSO) on infinite (omega) words in Weak MSO (WMSO). The interpretation is purely syntactic. We show that a formula with parameters is true in MSO if and only if its interpretation is true in WMSO. We also show that a closed formula is true in MSO if and only if its interpretation is provable under some axioms which hold for WMSO, but without axiomatizing it. We use model-theoretic arguments. Our approach is inspired from point-free topology: infinite words, seen as topological points, are approximated by filters of bounded segments. We devise forcing conditions such that the corresponding generic filters approximate Ramseyan factorizations of infinite words modulo satisfaction of formulas of a given quantifier depth. Our interpretation parallels some approaches to McNaughton's Theorem (equivalence between non-deterministic B&#x03C5;&#x0308;chi automata and deterministic Rabin automata) but the obtained formulas do not describe deterministic automata.
[Additives, Merging, bounded segment, infinite words modulo satisfaction, nondeterministic Buchi automata, topological point, Approximation methods, point-free topology, forcing MSO, syntactic interpretation, quantifier depth, deterministic automata, McNaughton theorem, WMSO, Ramseyan factorization, approximation theory, formal languages, equivalence, forcing-based interpretation, topology, infinite omega word, Topology, Standards, generic filter approximation, forcing condition, Automata, model-theoretic argument, deterministic Rabin automata, monadic second-order logic, weak MSO, axiom]
From Monadic Second-Order Definable String Transformations to Transducers
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Courcelle (1992) proposed the idea of using logic, in particular Monadic second-order logic (MSO), to define graph to graph transformations. Transducers, on the other hand, are executable machine models to define transformations, and are typically studied in the context of string-to-string transformations. Engelfriet and Hoogeboom (2001) studied two-way finite state string-to-string transducers and showed that their expressiveness matches MSO-definable transformations (MSOT). Alur and Cerny (2011) presented streaming transducers-one-way transducers equipped with multiple registers that can store output strings, as an equi-expressive model. Natural generalizations of streaming transducers to string-to-tree (Alur and D'Antoni, 2012) and infinite-string-to-string (Alur, Filiot, and Trivedi, 2012) cases preserve MSO-expressiveness. While earlier reductions from MSOT to streaming transducers used two-way transducers as the intermediate model, we revisit the earlier reductions in a more general, and previously unexplored, setting of infinite-string-to-tree transformations, and provide a direct reduction. Proof techniques used for this new reduction exploit the conceptual tools (composition theorem and finite additive coloring theorem) presented by Shelah (1975) in his alternative proof of B&#x03C5;&#x0308;chi's theorem. Using such streaming string-to-tree transducers we show the decidability of functional equivalence for MSO-definable infinite-string-to-tree transducers.
[streaming transducers, string-to-string transformations, Streaming string transducers, Additives, two-way finite state string-to-string transducers, executable machine models, two-way transducers, monadic second-order definable string transformations, Registers, proof techniques, output strings, finite state machines, alternative proof, streaming string-to-tree transducers, composition theorem, Cost accounting, graph grammars, decidability, finite additive coloring theorem, MSO-expressiveness, graph to graph transformations, $\\omega$-regular transformations, theorem proving, Context, MSO-definable transformations, Transducers, Computational modeling, multiple registers, trees (mathematics), conceptual tools, infinite-string-to-tree transformations, Monadic second-order logic, equi-expressive model, MSOT, functional equivalence, natural generalizations, intermediate model, tree transducers, Automata, MSO-definable infinite-string-to-tree transducers, B&#x03C5;&#x0308;chi's theorem, string matching, monadic second-order logic, direct reduction, infinite-string-to-string case, string-to-tree case]
From Two-Way to One-Way Finite State Transducers
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Any two-way finite state automaton is equivalent to some one-way finite state automaton. This well-known result, shown by Rabin and Scott and independently by Shepherdson, states that two-way finite state automata (even non-deterministic) characterize the class of regular languages. It is also known that this result does not extend to finite string transductions: (deterministic) two-way finite state transducers strictly extend the expressive power of (functional) one-way transducers. In particular deterministic two-way transducers capture exactly the class of MSO-transductions of finite strings. In this paper, we address the following definability problem: given a function defined by a two-way finite state transducer, is it definable by a one-way finite state transducer? By extending Rabin and Scott's proof to transductions, we show that this problem is decidable. Our procedure builds a one-way transducer, which is equivalent to the two-way transducer, whenever one exists.
[Context, Transducers, formal languages, Shape, two-way finite state transducer, regular languages, Educational institutions, finite state machines, one-way finite state automaton, decidability, two-way finite state automaton, Rabin and Scott transduction proof, Memory management, Automata, XML, finite string MSO-transductions, deterministic two-way transducers, one-way finite state transducer, definability problem, finite string transductions]
A Characterization Theorem for the Alternation-Free Fragment of the Modal &#x00B5;-Calculus
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We provide a characterization theorem, in the style of van Benthem and Janin-Walukiewicz, for the alternation-free fragment of the modal μ-calculus. For this purpose we introduce a variant of standard monadic second-order logic (MSO), which we call well-founded monadic second-order logic (WFMSO). When interpreted in a tree model, the second-order quantifiers of WFMSO range over subsets of conversely well-founded subtrees. The first main result of the paper states that the expressive power of WFMSO over trees exactly corresponds to that of weak MSO-automata. Using this automata-theoretic characterization, we then show that, over the class of all transition structures, the bisimulation-invariant fragment of WFMSO is the alternation-free fragment of the modal μ-calculus. As a corollary, we find that the logics WFMSO and WMSO (weak monadic second-order logic, where second-order quantification concerns finite subsets), are incomparable in expressive power.
[second-order quantifier, automata theory, Characterization results, MSO-automata, bisimulation-invariant fragment, modal μ-calculus, WFMSO, Semantics, Alternating parity automata, bisimulation equivalence, tree model, characterization theorem, well-founded monadic second-order logic, Context, Weak monadic second-order logic, Computational modeling, trees (mathematics), standard monadic second-order logic, well-founded subtrees, Standards, alternation-free fragment, Modal mu-calculus, Automata, Games, Binary trees, weak monadic second-order logic]
Bisimilarity of Pushdown Automata is Nonelementary
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Given two pushdown automata, the bisimilarity problem asks whether the infinite transition systems they induce are bisimilar. While this problem is known to be decidable our main result states that it is nonelementary, improving EXPTIME-hardness, which was the best previously known lower bound for this problem. Our lower bound result holds for normed pushdown automata as well.
[Transducers, Radiation detectors, automata theory, Poles and towers, EXPTIME-hardness, pushdown automata, bisimilarity, infinite transition system, Turing machines, Games, Personal digital assistants, computational complexity, bisimilarity problem]
Rabin-Mostowski Index Problem: A Step beyond Deterministic Automata
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
For a given regular language of infinite trees, one can ask about the minimal number of priorities needed to recognise this language with a non-deterministic or alternating parity automaton. These questions are known as, respectively, the non-deterministic and the alternating Rabin-Mostowski index problems. Whether they can be answered effectively is a long-standing open problem, solved so far only for languages recognisable by deterministic automata (the alternating variant trivialises). We investigate a wider class of regular languages, recognisable by so-called game automata, which can be seen as the closure of deterministic ones under complementation and composition. Game automata are known to recognise languages arbitrarily high in the alternating Rabin-Mostowski index hierarchy, i.e., the alternating index problem does not trivialise any more. Our main contribution is that both index problems are decidable for languages recognisable by game automata. Additionally, we show that it is decidable whether a given regular language can be recognised by a game automaton.
[alternating variant trivialises, nondeterministic index problem, Complexity theory, regular language, infinite tree, Rabin-Mostowski index, nondeterministic, decidability, deterministic automata, nondeterministic parity automaton, formal languages, language recognition, game automata, trees (mathematics), game theory, alternating parity automaton, Indexes, Character recognition, parity automata, game automaton, Standards, alternating, Automata, Games, alternating Rabin-Mostowski index problem]
Regular Real Analysis
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We initiate the study of regular real analysis, or the analysis of real functions that can be encoded by automata on infinite words. It is known that &#x03C9;-automata can be used to represent relations between real vectors, reals being represented in exact precision as infinite streams. The regular functions studied here constitute the functional subset of such relations. We show that some classic questions in function analysis can become elegantly computable in the context of regular real analysis. Specifically, we present an automatatheoretic technique for reasoning about limit behaviors of regular functions, and obtain, using this method, a decision procedure to verify the continuity of a regular function. Several other decision procedures for regular functions-for finding roots, fixpoints, minima, etc.-are also presented. At the same time, we show that the class of regular functions is quite rich, and includes functions that are highly challenging to encode using traditional symbolic notation.
[automata theory, regular real analysis, reasoning, computability, Cognition, Calculus, Fractals, real function analysis, relation representation, Real analysis, automata theoretic technique, fixpoint finding, Decision procedures, minima finding, symbolic notation, real vectors, root finding, formal languages, Educational institutions, Vectors, Encoding, &#x03C9;-automata, infinite words, regular function continuity, limit behavior, Automata, decision procedure, infinite streams]
Instances of Computational Effects: An Algebraic Perspective
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We investigate the connections between computational effects, algebraic theories, and monads on functor categories. We develop a syntactic framework with variable binding that allows us to describe equations between programs while taking into account the idea that there may be different instances of a particular computational effect. We use our framework to give a general account of several notions of computation that had previously been analyzed in terms of monads on presheaf categories: the analysis of local store by Plotkin and Power; the analysis of restriction by Pitts; and the analysis of the pi calculus by Stark.
[Context, algebra, monads, variable binding, computational effect, Equations, pi calculus, Analytical models, presheaf categories, Communication channels, Writing, category theory, syntactic framework, functor categories, Mathematical model, Testing, algebraic theories]
Multiversal Polymorphic Algebraic Theories: Syntax, Semantics, Translations, and Equational Logic
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We formalise and study the notion of polymorphic algebraic theory, as understood in the mathematical vernacular as a theory presented by equations between polymorphically-typed terms with both type and term variable binding. The prototypical example of a polymorphic algebraic theory is System F, but our framework applies more widely. The extra generality stems from a mathematical analysis that has led to a unified theory of polymorphic algebraic theories with the following ingredients: ; polymorphic signatures that specify arbitrary polymorphic operators (e.g. as in extended &#x03BB;-calculi and algebraic effects); ; metavariables, both for types and terms, that enable the generic description of meta-theories; ; multiple type universes that allow a notion of translation between theories that is parametric over different type universes; ; polymorphic structures that provide a general notion of algebraic model (including the PL-category semantics of System F); ; a Polymorphic Equational Logic that constitutes a sound and complete logical framework for equational reasoning. Our work is semantically driven, being based on a hierarchical two-levelled algebraic modelling of abstract syntax with variable binding.
[polymorphic operator, presheaves, algebra, type variable binding, polymorphism, polymorphic equational logic, abstract syntax, polymorphically-typed term, Algebra, Semantics, System F, Abstracts, term variable binding, metavariable, Polynomials, Mathematical model, equational logic, mathematical vernacular, polymorphic signature, Context, multiversal polymorphic algebraic theory, categorical semantics, mathematical analysis, the Grothendieck construction, algebraic model notion, multiple type universe, Syntactics, equational reasoning framework]
A Categorical Treatment of Ornaments
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Ornaments aim at taming the multiplication of special-purpose datatypes in dependently typed programming languages. In type theory, purpose is logic. By presenting datatypes as the combination of a structure and a logic, ornaments relate these special-purpose datatypes through their common structure. In the original presentation, the concept of ornament was introduced concretely for an example universe of inductive families in type theory, but it was clear that the notion was more general. This paper digs out the abstract notion of ornaments in the form of a categorical model. As a necessary first step, we abstract the universe of datatypes using the theory of polynomial functors. We are then able to characterise ornaments as cartesian morphisms between polynomial functors. We thus gain access to powerful mathematical tools that shall help us understand and develop ornaments. We shall also illustrate the adequacy of our model. Firstly, we rephrase the standard ornamental constructions into our framework. Thanks to its conciseness, we gain a deeper understanding of the structures at play. Secondly, we develop new ornamental constructions, by translating categorical structures into type theoretic artefacts.
[ornament categorical treatment, Type theory, categorical structures, Shape, polynomials, inductive families, polynomial functor morphism, Containers, Vectors, type theory, Indexes, programming languages, formal logic, Reactive power, polynomial functor theory, special-purpose datatype multiplication, Syntactics, standard ornamental constructions, category theory, categorical model, Polynomials, logic, typed programming languages, type theoretic artifact]
Converging to the Chase -- A Tool for Finite Controllability
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We solve a problem, stated in [CGP10], showing that Sticky Datalog&#x2203;, defined in the cited paper as an element of the Datalog&#x00B1; project, has the finite controllability property. In order to do that, we develop a technique, which we believe can have further applications, of approximating Chase(D, T), for a database instance D and a set of tuple generating dependencies and datalog rules T, by an infinite sequence of finite structures, all of them being models of T and D.
[Context, finite structures, Data structures, DATALOG, infinite sequence, database theory, Computer science, Tuple generating dependencies, Boolean functions, Databases, controllability, finite controllability property, tuple generating dependencies, Controllability, Sticky Logic, Finite element analysis, Finite Controllability, database instance, datalog rules]
Why is it Hard to Obtain a Dichotomy for Consistent Query Answering?
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
A database may for various reasons become inconsistent with respect to a given set of integrity constraints. To overcome the problem, a formal approach to querying such inconsistent databases has been proposed and since then, a lot of efforts have been spent to classify the complexity of consistent query answering under various classes of constraints. It is known that for the most common constraints and queries, the problem is in CONP and might be CONP-hard, yet several relevant tractable classes have been identified. Additionally, the results that emerged suggested that given a set of key constraints and a conjunctive query, the problem of consistent query answering is either in PTIME or is CONP-complete. However, despite all the work, as of today this dichotomy remains a conjecture. The main contribution of this paper is to explain why it appears so difficult to obtain a dichotomy result in the setting of consistent query answering. Namely, we prove that such a dichotomy w.r.t. common classes of constraints and queries, is harder to achieve than a dichotomy for the constraint satisfaction problem, which is a famous open problem since the 1990s.
[complexity, dichotomy, tractable classes, key constraint, Maintenance engineering, Educational institutions, constraint satisfaction problem, Complexity theory, Computer science, query processing, query answering, CONP-hard, constraint satisfaction problems, Databases, PTIME, CONP-complete, Data integration, integrity constraint, conjunctive query, database querying, Polynomials, constraint handling, computational complexity]
Abstract Machines for Game Semantics, Revisited
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
We define new abstract machines for game semantics which correspond to networks of conventional computers, and can be used as an intermediate representation for compilation targeting distributed systems. This is achieved in two steps. First we introduce the HRAM, a Heap and Register Abstract Machine, an abstraction of a conventional computer, which can be structured into HRAM nets, an abstract point-to-point network model. HRAMs are multi-threaded and subsume communication by tokens (cf. IAM) or jumps. Game Abstract Machines (GAM), are HRAMs with additional structure at the interface level, but no special operational capabilities. We show that GAMs cannot be naively composed, but composition must be mediated using appropriate HRAM combinators. HRAMs are flexible enough to allow the representation of game models for languages with state (non-innocent games) or concurrency (non-alternating games). We illustrate the potential of this technique by implementing a toy distributed compiler for ICA, a higher-order programming language with shared state concurrency, thus significantly extending our previous distributed PCF compiler. We show that compilation is sound and memory-safe, i.e. no (distributed or local) garbage collection is necessary.
[abstract machines, finite automata, toy distributed compiler, Ports (Computers), ICA, game theory, Registers, game semantics, program compilers, abstract point-to-point network model, game abstract machine, Engines, heap-and-register abstract machine, HRAM nets, GAM, distributed compilation, Semantics, Games, Abstracts, shared state concurrency, higher-order programming language, Message systems, distributed PCF compiler]
[Publisher's information]
2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2013
Provides a listing of current committee members and society officers.
[]
Foreword
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Presents the introductory welcome message from the conference proceedings. May include the conference officers' congratulations to all involved with the conference event and publication of the proceedings record.
[]
Conference Organization
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Provides a listing of current committee members and society officers.
[]
Higher-Order Model Checking: An Overview
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Higher-order model checking is about the model checking of trees generated by recursion schemes. The past fifteen years or so have seen considerable progress in both theory and practice. Advances have been made in determining the expressive power of recursion schemes and other higher-order families of generators, automata-theoretic characterisations of these generator families, and the algorithmics and semantics of higher-order model checking and allied methods of formal analysis. Because the trees generated by recursion schemes are computation trees of higher-order functional programs, higher-order model checking provides a foundation for model checkers of such programming languages as Haskell, F# and Erlang. This paper aims to give an overview of recent developments in higher-order model checking.
[Haskell programming language, automata theory, Model Checking, formal verification, Lambda Calculus, higher-order model checking, Semantics, automata-theoretic characterisations, Model checking, formal analysis, Safety, program control structures, trees (mathematics), Generators, Grammar, Handheld computers, Program Verification, Recursion Schemes, computation trees, Automata, recursion schemes, Erlang programming language, Functional Programs, functional languages, F# programming language]
Privacy and the Price of Data
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Several important application areas in data science involve assigning numbers to (possibly randomized) algorithms. In the case of statistical privacy, it is important to quantify the amount of information leaked by a data processing algorithm. In the case of data marketplaces, it is important to properly set the prices for data queries (which, in general, can be specified by arbitrary algorithms). In both cases, it is also important to quantify application-specific utility of the outputs of an algorithm or query. For example, if a user has a choice of purchasing some combination of query answers, the user's decision should be guided by the consideration of a utility/price trade-off. These numbers cannot be assigned to algorithms in an arbitrary manner - there are common-sense restrictions that must be enforced. For example, the answer to an expensive query should not be derivable from a much cheaper query. Each application has its own set of restrictions but when they are formulated mathematically, common patterns emerge. Thus technical results from one area can often be ported to the others.
[Data privacy, query pricing, statistical privacy, data queries, Data processing, data marketplaces, utility, database management systems, data price, Computer science, query processing, Privacy, Databases, application-specific utility, utility/price trade-off, data marketplace, data science, data processing algorithm, randomized algorithms, Pricing, data sets, data privacy, Accidents]
From Categorical Logic to Facebook Engineering
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
I chart a line of development from category-theoretic models of programs and logics to automatic program verification/analysis techniques that are in deployment at Facebook. Our journey takes in a number of concepts from the computer science logician's toolkit -- including categorical logic and model theory, denotational semantics, the Curry-Howard isomorphism, sub structural logic, Hoare Logic and Separation Logic, abstract interpretation, compositional program analysis, the frame problem, and abductive inference.
[Shape, program verification, compositional program analysis, Cognition, Facebook engineering, formal logic, automatic program verification/analysis technique, Semantics, Mathematical model, categorical logic, Facebook, denotational semantics, model theory, abductive inference, program diagnostics, abstract interpretation, category-theoretic model, inference mechanisms, Curry-Howard isomorphism, Computer science, separation logic, Syntactics, category theory, substructural logic, Hoare logic]
Names and Symmetry in Computer Science (Invited Tutorial)
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Nominal sets provide a mathematical theory for some of the key concepts that arise when representing and computing with data involving atomic (or 'pure') names: freshness, abstraction and scoping of names, and finiteness modulo symmetry. This tutorial introduces the notion of nominal set and explains selected applications of it to logic in computer science, to automata, languages and programming.
[Computers, formal languages, nominal sets, automata theory, languages, Tutorials, mathematical theory, Cognition, set theory, Computer science, names, computer science, Semantics, Automata, Syntactics, automata, finiteness modulo symmetry, programming]
Recent Developments in Quantitative Information Flow (Invited Tutorial)
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
In computer security, it is frequently necessary in practice to accept some leakage of confidential information. This motivates the development of theories of Quantitative Information Flow aimed at showing that some leaks are "small" and therefore tolerable. We describe the fundamental view of channels as mappings from prior distributions on secrets to hyper-distributions, which are distributions on posterior distributions, and we show how g-leakage provides a rich family of operationally-significant measures of leakage. We also discuss two approaches to achieving robust judgments about leakage: notions of capacity and a robust leakage ordering called composition refinement.
[Additives, Uncertainty, leakage operationally-significant measures, confidentiality, cryptography, Entropy, posterior distributions, robust leakage ordering, confidential information leakage, quantitative information flow, composition refinement, computer security, hyper-distributions, security, g-leakage, Robustness, information theory, Mathematical model, Mutual information, Cancer]
Reachability in Two-Dimensional Vector Addition Systems with States Is PSPACE-Complete
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Known to be decidable since 1981, there still remains a huge gap between the best known lower and upper bounds for the reach ability problem for vector addition systems with states (VASS). Here the problem is shown PSPACE-complete in the two-dimensional case, vastly improving on the doubly exponential time bound established in 1986 by Howell, Rosier, Huynh and Yen. Cover ability and bounded ness for two-dimensional VASS are also shown PSPACE-complete, and reach ability in two-dimensional VASS and in integer VASS under unary encoding are considered.
[Petri nets, upper bounds, reachability problem, Complexity theory, two-dimensional VASS, decidability, doubly-exponential time bound improvement, semi-linear sets, Polynomials, reachability, boundedness, reachability analysis, Radiation detectors, integer VASS, vector addition systems with states, Encoding, lower bounds, unary encoding, Upper bound, two-dimensional vector addition system-with-states, bounded regular languages, Automata, PSPACE-complete problem, Parikh images, coverability, computational complexity]
Long-Run Average Behaviour of Probabilistic Vector Addition Systems
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We study the pattern frequency vector for runs in probabilistic Vector Addition Systems with States (pVASS). Intuitively, each configuration of a given pVASS is assigned one of finitely many patterns, and every run can thus be seen as an infinite sequence of these patterns. The pattern frequency vector assigns to each run the limit of pattern frequencies computed for longer and longer prefixes of the run. If the limit does not exist, then the vector is undefined. We show that for one-counter pVASS, the pattern frequency vector is defined and takes one of finitely many values for almost all runs. Further, these values and their associated probabilities can be approximated up to an arbitrarily small relative error in polynomial time. For stable two-counter pVASS, we show the same result, but we do not provide any upper complexity bound. As a byproduct of our study, we discover counterexamples falsifying some classical results about stochastic Petri nets published in the 80s.
[Radiation detectors, Petri nets, probability, Probabilistic logic, pVASS, Complexity theory, SPN, vectors, long-run average behaviour, stochastic Petri net, probabilistic vector addition systems with states, Markov processes, pattern frequency vector, Polynomials, polynomial time, stochastic processes, pattern sequence, computational complexity]
Demystifying Reachability in Vector Addition Systems
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
More than 30 years after their inception, the decidability proofs for reach ability in vector addition systems (VAS) still retain much of their mystery. These proofs rely crucially on a decomposition of runs successively refined by Mayr, Kosaraju, and Lambert, which appears rather magical, and for which no complexity upper bound is known. We first offer a justification for this decomposition technique, by showing that it computes the ideal decomposition of the set of runs, using the natural embedding relation between runs as well quasi ordering. In a second part, we apply recent results on the complexity of termination thanks to well quasi orders and well orders to obtain a cubic Ackermann upper bound for the decomposition algorithms, thus providing the first known upper bounds for general VAS reach ability.
[Algorithm design and analysis, Vector addition system, program verification, Petri nets, Cognition, Complexity theory, cubic Ackermann upper bound, vector addition systems, natural embedding relation, decidability, reachability, termination complexity, reachability analysis, VAS reachability, ideal, complexity upper bound, quasiordering, decomposition technique, Computer science, decidability proof, well quasi order, Upper bound, fast-growing complexity, Finite element analysis, computational complexity, decomposition algorithm]
Petri Automata for Kleene Allegories
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Kleene algebra axioms are complete with respect to both language models and binary relation models. In particular, two regular expressions recognise the same language if and only if they are universally equivalent in the model of binary relations. We consider Kleene allegories, i.e., Kleene algebras with two additional operations which are natural in binary relation models: intersection and converse. While regular languages are closed under those operations, the above characterisation breaks. Instead, we give a characterisation in terms of languages of directed and labelled graphs. We then design a finite automata model allowing to recognise such graphs, by taking inspiration from Petri nets. This model allows us to obtain decidability of identity-free relational Kleene lattices, i.e., The equational theory generated by binary relations on the signature of regular expressions with intersection, but where one forbids unit. This restriction is used to ensure that the corresponding graphs are a cyclic. The decidability of graph-language equivalence in the full model remains open.
[finite automata, graph language, Petri nets, intersection model, algebra, Petri automata, labelled graphs, Kleene allegories, Algebra, decidability, intersection, Kleene algebra axioms, regular expressions, graph-language equivalence decidability, Mathematical model, language models, finite automata model, formal languages, Computational modeling, lattice theory, allegories, Standards, converse model, directed graphs, Automata, decision procedure, converse, Joining processes, free relational Kleene lattice decidability, binary relation models]
A Cubical Approach to Synthetic Homotopy Theory
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Homotopy theory can be developed synthetically in homotopy type theory, using types to describe spaces, the identity type to describe paths in a space, and iterated identity types to describe higher-dimensional paths. While some aspects of homotopy theory have been developed synthetically and formalized in proof assistants, some seemingly easy examples have proved difficult because the required manipulations of paths becomes complicated. In this paper, we describe a cubical approach to developing homotopy theory within type theory. The identity type is complemented with higher-dimensional cube types, such as a type of squares, dependent on four points and four lines, and a type of three-dimensional cubes, dependent on the boundary of a cube. Path-over-a-path types and higher generalizations are used to describe cubes in a fibration over a cube in the base. These higher-dimensional cube and path-over types can be defined from the usual identity type, but isolating them as independent conceptual abstractions has allowed for the formalization of some previously difficult examples.
[Context, proof assistants, square type, Government, Aerospace electronics, type theory, path manipulations, cubical approach, cube boundary, Computer science, independent conceptual abstractions, higher generalizations, higher-dimensional paths, homotopy type theory, Semantics, iterated identity types, synthetic homotopy theory, path-over-a-path types, Libraries, theorem proving, three-dimensional cubes, Mathematical model, higher-dimensional cube types]
Game Semantics for Type Soundness
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
The key idea of game semantics is that a term can interact with its enclosing context via various events, such as function calls and returns. A trace is a sequence of such interaction events. The meaning of the term is then naturally represented by the set of all event traces that the term can generate. Game semantics allows us to define the meaning of both expressions and types in the same domain which enables an interesting alternative to subject reduction for proving type soundness. This paper uses game semantics to define the meaning of and verify type soundness for a sequence of programming languages, starting with a functional sequential language (the call-by-value simply-typed lambda calculus), and then extending that proof with sub typing, side effects, control effects, and concurrency. These proofs are reasonably short and fairly semantic in structure, focusing on the relationship between the meanings of each term and its corresponding type. In particular, we show that the typing and sub typing relations are both conservative approximations of alternating trace containment.
[Context, alternating trace containment, function calls, game theory, Calculus, Cognition, programming language semantics, game semantics, programming languages, subtyping relations, subject reduction, Computer languages, type soundness, interaction events, Semantics, functional sequential language, Games, Syntactics, functional languages]
Programs for Cheap!
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Write down the definition of a recursion operator on a piece of paper. Tell me its type, but be careful not to let me see the operator's definition. I will tell you an optimization theorem that the operator satisfies. As an added bonus, I will also give you a proof of correctness for the optimisation, along with a formal guarantee about its effect on performance. The purpose of this paper is to explain these tricks.
[Context, program control structures, recursive program optimisation, Diamonds, optimization theorem, Optimization, Standards, correctness proof, Computer languages, optimisation, Semantics, recursion operator, theorem proving]
Polarised Intermediate Representation of Lambda Calculus with Sums
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
The theory of the &#x03BB;-calculus with extensional sums is more complex than with only pairs and functions. We propose an untyped representation-an intermediate calculus-for the &#x03BB;-calculus with sums, based on the following principles: 1) Computation is described as the reduction of pairs of an expression and a context; the context must be represented inside-out, 2) operations are represented abstractly by their transition rule, 3) Positive and negative expressions are respectively eager and lazy; this polarity is an approximation of the type. We offer an introduction from the ground up to our approach, and we review the benefits. A structure of alternating phases naturally emerges through the study of normal forms, offering a reconstruction of focusing. Considering further purity assumption, we obtain maximal multifocusing. As an application, we can deduce a syntax-directed algorithm to decide the equivalence of normal forms in the simply-typed &#x03BB;-calculus with sums, and justify it with our intermediate calculus.
[Optical fibers, lambda calculus, Polarization, Defunctionalization, transition rule, Intuitionistic logic, Abstract machines, Focalization, &amp;amp;#x03BB;-calculus with sums, syntax directed algorithm, extensional sums, intermediate calculus, Data structures, &#x03BB;-calculus theory, Uninterruptible power systems, Global Positioning System, Sequent calculus, Computer science, Boolean functions, polarised intermediate representation, Power capacitors, Continuation-passing style, sums]
On the Relative Usefulness of Fireballs
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
In CSL-LICS 2014, Accattoli and Dal Lago [1] showed that there is an implementation of the ordinary (i.e. strong, pure, call-by-name) &#x03BB;-calculus into models like RAM machines which is polynomial in the number of &#x03B2;-steps, answering a long-standing question. The key ingredient was the use of a calculus with useful sharing, a new notion whose complexity was shown to be polynomial, but whose implementation was not explored. This paper, meant to be complementary, studies useful sharing in a call-by-value scenario and from a practical point of view. We introduce the Fireball Calculus, a natural extension of call-by-value to open terms, that is an intermediary step towards the strong case, and we present three results. First, we adapt useful sharing, refining the meta-theory. Then, we introduce the GLAMOUr a simple abstract machine implementing the Fireball Calculus extended with useful sharing. Its key feature is that usefulness of a step is tested-surprisingly-in constant time. Third, we provide a further optimisation that leads to an implementation having only a linear overhead with respect to the number of &#x03B2;-steps.
[Context, lambda calculus, call-by-value scenario, finite automata, functional programming, Random access memory, useful sharing, Calculus, Explosions, Complexity theory, meta-theory, functional programming languages, abstract machine, Fireball Calculus, &#x03BB;-calculus, Syntactics, GLAMOUr, Polynomials, RAM machines, fireballs relative usefulness]
Bisimilarity in Fresh-Register Automata
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Register automata are a basic model of computation over infinite alphabets. Fresh-register automata extend register automata with the capability to generate fresh symbols in order to model computational scenarios involving name creation. This paper investigates the complexity of the bisimilarity problem for classes of register and fresh-register automata. We examine all main disciplines that have appeared in the literature: general register assignments, assignments where duplicate register values are disallowed, and assignments without duplicates in which registers cannot be empty. In the general case, we show that the problem is EXPTIME-complete. However, the absence of duplicate values in registers enables us to identify inherent symmetries inside the associated bisimulation relations, which can be used to establish a polynomial bound on the depth of Attacker-winning strategies. Furthermore, they enable a highly succinct representation of the corresponding bisimulations. By exploiting results from group theory and computational group theory, we can then show solvability in PSPACE and NP respectively for the latter two register disciplines. In each case, we find that freshness does not affect the complexity class of the problem. The results allow us to close a complexity gap for language equivalence of deterministic register automata. We show that deterministic language in equivalence for the no-duplicates fragment is NP-complete, which disproves an old conjecture of Sakamoto. Finally, we discover that, unlike in the finite-alphabet case, the addition of pushdown store makes bisimilarity undecidable, even in the case of visibly pushdown storage.
[PSPACE-problem, complexity class, no-duplicate fragment, computability, symmetry identification, Registers, Complexity theory, History, register classes, infinite alphabets, name creation, deterministic automata, bisimulation relations, deterministic register automata, register automata, Polynomials, bisimulation equivalence, complexity gap, polynomial bound, formal languages, EXPTIME-complete problem, fresh-register automata, Computational modeling, computational scenarios, solvability, attacker-winning strategies, NP-complete problem, duplicate values, bisimilarity, automata over infinite alphabets, group theory, pushdown storage, Automata, undecidable bisimilarity, Games, computational group theory, general register assignments, deterministic language inequivalence, equivalence classes, bisimilarity problem complexity, computational complexity, register values]
Branching Bisimilarity of Normed BPA Processes Is in NEXPTIME
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Branching bisimilarity of nor med Basic Process Algebra (BPA) processes was shown to be decidable by Yuxi Fu (ICALP 2013) but his proof has not provided any upper complexity bound. We present a simpler approach based on relative prime decompositions that leads to a nondeterministic exponential-time algorithm, this is "close" to the known exponential-time lower bound. We also derive that semantic finiteness (the question if a given nor med BPA process is branching bisimilar with some finite-state process) belongs to NExpTime as well.
[exponential-time lower bound, branching bisimulation, normed BPA process, branching bisimilarity, Complexity theory, Electronic mail, Grammar, finite state machines, nondeterministic exponential-time algorithm, Standards, normed basic process algebra process, decidability, process algebra, Semantics, basic process algebra, Automata, semantic finiteness, finite-state process, Polynomials, complexity bound, process calculi, NEXPTIME, verification, computational complexity]
Branching Bisimilarity on Normed BPA Is EXPTIME-Complete
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We put forward an exponential-time algorithm for deciding branching bisimilarity on nor med BPA (Bacis Process Algebra) systems. The decidability of branching bisimilarity on nor med BPA was once a long-standing open problem which was closed by Yuxi Fu. The EXPTIME-hardness is an inference of a slight modification of the reduction presented by Richard Mayr. The result in this paper claims that this problem is EXPTIME-complete.
[exponential-time algorithm, EXPTIME-complete, branching bisimilarity, Grammar, Approximation methods, Computer science, Algebra, decidability, process algebra, Semantics, basic process algebra, Syntactics, Polynomials, normed BPA, computational complexity]
Distributed Graph Automata
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Combining ideas from distributed algorithms and alternating automata, we introduce a new class of finite graph automata that recognize precisely the languages of finite graphs definable in monadic second-order logic. By restricting transitions to be nondeterministic or deterministic, we also obtain two strictly weaker variants of our automata for which the emptiness problem is decidable.
[Terminology, finite automata, graph theory, alternating automata, Color, finite graph automata, MSO-logic, emptiness problem, Indexes, Standards, Computer science, decidability, Finite automata, distributed algorithms, Automata, distributed graph automata, Graphs, monadic second-order logic, Distributed algorithms, finite graphs languages]
Separating Regular Languages with Two Quantifiers Alternations
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We investigate the quantifier alternation hierarchy of first-order logic over finite words. To do so, we rely on the separation problem. For each level in the hierarchy, this problem takes two regular languages as input and asks whether there exists a formula of the level that accepts all words in the first language and no word in the second one. Usually, obtaining an algorithm that solves this problem requires a deep understanding of the level under investigation. We present such an algorithm for the level &#x03A3;<sub>3</sub> (formulas having at most 2 alternations beginning with an existential block). We also obtain as a corollary that one can decide whether a regular language is definable by a &#x03A3;<sub>4</sub> formula (formulas having at most 3 alternations beginning with an existential block).
[Context, Regular languages, First-order logic, Separation, Quantifier alternation, computational linguistics, regular languages, Expressive power, Electronic mail, separating regular languages, Decidable characterizations, Computer science, formal logic, existential block, Bibliographies, Automata, Vegetation, finite words, Words, Syntactics, first order logic, quantifier alternation hierarchy, two quantifiers alternations]
Star Height via Games
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
This paper proposes a new algorithm deciding the star height problem. As shown by Kirsten, the star height problem reduces to a problem concerning automata with counters, called limitedness. The new contribution is a different algorithm for the limitedness problem, which reduces it to solving a Gale-Stewart game with an &#x03C9;-regular winning condition.
[Computer science, Radiation detectors, automata theory, Automata, Games, game theory, Gale-Stewart game, limitedness problem, Polynomials, Nickel, Complexity theory, star height problem]
Nondeterminism in Game Semantics via Sheaves
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Harmer and McCusker have developed a fully abstract game model for nondeterministic Idealised Algol and, at the same time, revealed difficulties in constructing game models for stateless nondeterministic languages and infinite nondeterminism. We propose a novel approach in which a strategy is not a set, but a tree, of plays, and develop a fully abstract game model for a nondeterministic stateless language. Mathematically such a strategy is formalised as a sheaf over an appropriate site of plays. We conclude with a study on the difficulties pointed out by Harmer and McCusker in terms of the structure of the coverage of the sites.
[formal languages, Computational modeling, game theory, infinite nondeterminism, programming language semantics, game semantics, Standards, ALGOL, sheaf, nondeterministic stateless language, sheaves, abstract game model, Semantics, Games, nondeterministic idealised Algol, Labeling, Mathematical model, Manganese, nondeterminism]
The Parallel Intensionally Fully Abstract Games Model of PCF
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We describe a framework for truly concurrent game semantics of programming languages, based on Rideau and Winskel's concurrent games on event structures. The model supports a notion of innocent strategy that permits concurrent and non-deterministic behaviour, but which coincides with traditional Hyland-Ong innocent strategies if one restricts to the deterministic sequential case. In this framework we give an alternative interpretation of Plot kin's PCF, that takes advantage of the concurrent nature of strategies and formalizes the idea that although PCF is a sequential language, certain sub-computations are independent and can be computed in a parallel fashion. We show that just as Hyland and Ong's sequential interpretation of PCF, our parallel interpretation yields a model that is intensionally fully abstract for PCF.
[parallel intensionally fully abstract game model, Computational modeling, game theory, concurrent game semantics, concurrency theory, Indexes, programming language semantics, Concurrent computing, PCF, Semantics, Games, programming language, Labeling, Mathematical model]
Unifying Two Views on Multiple Mean-Payoff Objectives in Markov Decision Processes
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We consider Markov decision processes (MDPs) with multiple limit-average (or mean-payoff) objectives. There exist two different views: (i) the expectation semantics, where the goal is to optimize the expected mean-payoff objective, and (ii) the satisfaction semantics, where the goal is to maximize the probability of runs such that the mean-payoff value stays above a given vector. We consider optimization with respect to both objectives at once, thus unifying the existing semantics. Precisely, the goal is to optimize the expectation while ensuring the satisfaction constraint. Our problem captures the notion of optimization with respect to strategies that are risk-averse (i.e., ensure certain probabilistic guarantee). Our main results are as follows: First, we present algorithms for the decision problems, which are always polynomial in the size of the MDP. We also show that an approximation of the Pareto curve can be computed in time polynomial in the size of the MDP, and the approximation factor, but exponential in the number of dimensions. Second, we present a complete characterization of the strategy complexity (in terms of memory bounds and randomization) required to solve our problem.
[decision problem, decision theory, multiple mean-payoff objectives, memory bound, limit average reward, Complexity theory, Optimization, approximation factor, Semantics, randomization, Pareto curve approximation, MDP, Polynomials, Joints, expectation semantics, Pareto optimisation, probability, Probabilistic logic, satisfaction semantics, run probability maximization, expected mean-payoff objective optimization, strategy complexity, Markov decision processes, mean-payoff value, Markov processes, time polynomial, multiple limit-average objectives, mean payoff, computational complexity]
Multidimensional beyond Worst-Case and Almost-Sure Problems for Mean-Payoff Objectives
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
The beyond worst-case threshold problem (BWC), recently introduced by Bruye&#x0300;re et al., asks given a quantitative game graph for the synthesis of a strategy that i) enforces some minimal level of performance against any adversary, and ii) achieves a good expectation against a stochastic model of the adversary. They solved the BWC problem for finite-memory strategies and unidimensional mean-payoff objectives and they showed membership of the problem in NP&#x2229;coNP. They also noted that infinite-memory strategies are more powerful than finite-memory ones, but the respective threshold problem was left open. We extend these results in several directions. First, we consider multidimensional mean-payoff objectives. Second, we study both finite-memory and infinite-memory strategies. We show that the multidimensional BWC problem is coNPc in both cases. Third, in the special case when the worst-case objective is unidimensional (but the expectation objective is still multidimensional) we show that the complexity decreases to NP&#x2229;coNP. This solves the infinite-memory threshold problem left open by Bruye&#x0300;re et al., and this complexity cannot be improved without improving the currently known complexity of classical mean-payoff games. Finally, we introduce a natural relaxation of the BWC problem, the beyond almost-sure threshold problem (BAS), which asks for the synthesis of a strategy that ensures some minimal level of performance with probability one and a good expectation against the stochastic model of the adversary. We show that the multidimensional BAS threshold problem is solvable in P.
[complexity, graph theory, unidimensional mean-payoff objectives, infinite-memory strategies, computability, Complexity theory, infinite-memory threshold problem, Approximation methods, beyond worst-case threshold problem, controller synthesis, Analytical models, relaxation theory, multidimensional BWC problem, stochastic processes, natural relaxation, NP&#x2229;coNP, multidimensional mean-payoff objectives, quantitative game graph, probability, game theory, solvability, Game theory, beyond almost-sure threshold problem, mean-payoff games, Markov decision processes, BAS threshold problem, Games, Markov processes, stochastic model, computational complexity]
Improved Algorithms for One-Pair and k-Pair Streett Objectives
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
The computation of the winning set for one-pair Streett objectives and for k-pair Streett objectives in (standard) graphs as well as in game graphs are central problems in computer-aided verification, with application to the verification of closed systems with strong fairness conditions, the verification of open systems, checking interface compatibility, well-formed ness of specifications, and the synthesis of reactive systems. We give faster algorithms for the computation of the winning set for (1) one-pair Streett objectives (aka parity-3 problem) in game graphs and (2) for k-pair Streett objectives in graphs. For both problems this represents the first improvement in asymptotic running time in 15 years.
[Graph games, k-pair Streett objectives, game graphs, automata theory, graph theory, Computer-aided verification, computer-aided verification, Parity games, Runtime, formal verification, Synthesis, closed systems verification, interface compatibility, Image edge detection, game theory, Standards, open systems verification, Computer science, reactive systems synthesis, Automata, Games, Open systems, Streett automata, Graph algorithms, one-pair Streett objectives]
The Hunt for a Red Spider: Conjunctive Query Determinacy Is Undecidable
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We solve a well known, long-standing open problem in relational databases theory, showing that the conjunctive query determinacy problem (in its "unrestricted" version) is undecidable.
[Context, Legged locomotion, relational database theory, Head, undecidable problem, conjunctive query determinacy problem, relational databases, chase, Standards, determinacy, query processing, Databases, Image color analysis, decidability, conjunctive queries, Periodic structures]
The Complexity of Boundedness for Guarded Logics
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Given a formula phi(x, X) positive in X, the bounded ness problem asks whether the fix point induced by phi is reached within some uniform bound independent of the structure (i.e. Whether the fix point is spurious, and can in fact be captured by a finite unfolding of the formula). In this paper, we study the bounded ness problem when phi is in the guarded fragment or guarded negation fragment of first-order logic, or the fix point extensions of these logics. It is known that guarded logics have many desirable computational and model theoretic properties, including in some cases decidable bounded ness. We prove that bounded ness for the guarded negation fragment is decidable in elementary time, and, making use of an unpublished result of Colcombet, even 2EXPTIME-complete. Our proof extends the connection between guarded logics and automata, reducing bounded ness for guarded logics to a question about cost automata on trees, a type of automaton with counters that assigns a natural number to each input rather than just a boolean.
[Context, Radiation detectors, automata theory, guarded logic, trees (mathematics), first-order logic, tree, Complexity theory, Integrated circuits, formal logic, cost automata, Automata, Games, Cost function, boundedness complexity, computational complexity]
Finite Open-World Query Answering with Number Restrictions
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Open-world query answering is the problem of deciding, given a set of facts, conjunction of constraints, and query, whether the facts and constraints imply the query. This amounts to reasoning over all instances that include the facts and satisfy the constraints. We study finite open-world query answering (FQA), which assumes that the underlying world is finite and thus only considers the finite completions of the instance. The major known decidable cases of FQA derive from the following: the guarded fragment of first-order logic, which can express referential constraints (data in one place points to data in another) but cannot express number restrictions such as functional dependencies, and the guarded fragment with number restrictions but on a signature of arity only two. In this paper, we give the first decidability results for FQA that combine both referential constraints and number restrictions for arbitrary signatures: we show that, for unary inclusion dependencies and functional dependencies, the finiteness assumption of FQA can be lifted up to taking the finite implication closure of the dependencies[5]. Our result relies on new techniques to construct finite universal models of such constraints, for any bound on the maximal query size.
[Context, arbitrary signatures, Computational modeling, first-order logic, unary inclusion dependencies, Complexity theory, Electronic mail, functional dependencies, Standards, number restrictions, formal logic, query processing, Databases, FQA, finite open-world query answering, referential constraints, Finite element analysis, finite universal models]
Tree-like Queries in OWL 2 QL: Succinctness and Complexity Results
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
This paper investigates the impact of query topology on the difficulty of answering conjunctive queries in the presence of OWL 2 QL ontologies. Our first contribution is to clarify the worst-case size of positive existential (PE), non-recursive Data log (NDL), and first-order (FO) rewritings for various classes of tree-like conjunctive queries, ranging from linear queries to bounded tree width queries. Perhaps our most surprising result is a super polynomial lower bound on the size of PE-rewritings that holds already for linear queries and ontologies of depth 2. More positively, we show that polynomial-size NDL-rewritings always exist for tree-shaped queries with a bounded number of leaves (and arbitrary ontologies), and for bounded tree width queries paired with bounded depth ontologies. For FO-rewritings, we equate the existence of polysize rewritings with well-known problems in Boolean circuit complexity. As our second contribution, we analyze the computational complexity of query answering and establish tractability results (either NL-or LOGCFL-completeness) for a range of query-ontology pairs. Combining our new results with those from the literature yields a complete picture of the succinctness and complexity landscapes for the considered classes of queries and ontologies.
[query topology, Ontologies, polysize rewritings, nonrecursive data log, OWL 2 QL ontologies, Complexity theory, bounded depth ontologies, query processing, tractability results, succinctness, superpolynomial lower bound, Boolean functions, Databases, bounded tree width queries, polynomial-size NDL-rewritings, Boolean circuit complexity, first-order rewritings, rewriting systems, OWL, Knowledge based systems, LOGCFL-completeness, trees (mathematics), conjunctive query answering, complexity landscape, NL-completeness, tree-like conjunctive queries, knowledge representation languages, Upper bound, positive existential, linear queries, ontologies (artificial intelligence), query-ontology pair, arbitrary ontologies, computational complexity]
Path Logics for Querying Graphs: Combining Expressiveness and Efficiency
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We study logics expressing properties of paths in graphs that are tailored to querying graph databases: a data model for new applications such as social networks, the Semantic Web, biological data, crime detection, and others. The basic construct of such logics, a regular path query, checks for paths whose labels belong to a regular language. These logics fail to capture two commonly needed features: counting properties, and the ability to compare paths. It is known that regular path-comparison relations (e.g., Prefix or equality) can be added without significant complexity overhead, however, adding common relations often demanded by applications (e.g., Sub word, subsequence, suffix) results in either undecidability or astronomical complexity. We propose, as a way around this problem, to use automata with counting functionalities, namely Parikh automata. They express many counting properties directly, and they approximate many relations of interest. We prove that with Parikh automata defining both languages and relations used in queries, we retain the low complexity of the standard path logics for graphs. In particular, this gives us efficient approximations to queries with prohibitively high complexity. We extend the best known decidability results by showing that even more expressive classes of relations are possible in query languages (sometimes with restriction on the shape of formulae). We also show that Parikh automata admit two convenient representations by analogs of regular expressions, making them usable in real-life querying.
[counting properties, automata theory, graph theory, query languages, Complexity theory, Approximation methods, database management systems, complexity overhead, Database languages, path logics, graph database querying, query processing, RPQ, decidability, regular path query, counting functionalities, crime detection, Parikh automata, rational relations, Radiation detectors, semantic Web, biological data, social networks, path-comparison relations, astronomical complexity, undecidability, parikh automata, Query processing, logics expressing properties, Automata, path checks, computational complexity, graph databases]
PDL Is the Bisimulation-Invariant Fragment of Weak Chain Logic
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We introduce a new class of parity automata which, on trees, captures the expressive power of weak chain logic. This logic is a variant of monadic second-order logic which quantifies over finite chains. Using this new tool, we show that the bisimulation-invariant fragment of weak chain logic is equivalent to propositional dynamic logic.
[Context, Additives, automata theory, propositional dynamic logic, trees (mathematics), Color, weak chain logic, parity automata, trees, Standards, finite chains, bisimulation-invariant fragment, Semantics, Automata, Games, PDL, bisimulation equivalence, monadic second-order logic]
Monadic Second-Order Logic and Bisimulation Invariance for Coalgebras
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Generalizing standard monadic second-order logic for Kripke models, we introduce monadic second-order logic MSO(T) interpreted over co algebras for an arbitrary set functor T. Similar to well-known results for monadic second-order logic over trees, we provide a translation of this logic into a class of automata, relative to the class of T-co algebras that admit a tree-like supporting Kripke frame. We then consider invariance under behavioral equivalence of MSO(T)-formulas, more in particular, we investigate whether the co algebraic mu-calculus is the bisimulation-invariant fragment of MSO(T). Building on recent results by the third author we show that in order to provide such a co algebraic generalization of the Janin-Walukiewicz Theorem, it suffices to find what we call an adequate uniform construction for the functor T. As applications of this result we obtain a partly new proof of the Janin-Walukiewicz Theorem, and bisimulation invariance results for the bag functor (graded modal logic) and all exponential polynomial functors. Finally, we consider in some detail the monotone neighborhood functor M, which provides co algebraic semantics for monotone modal logic. It turns out that there is no adequate uniform construction for M, whence the automata-theoretic approach towards bisimulation invariance does not apply directly. This problem can be overcome if we consider global bisimulations between neighborhood models: one of our main results provides a characterization of the monotone modal mu-calculus extended with the global modalities, as the fragment of monadic second order logic for the monotone neighborhood functor that is invariant for global bisimulations.
[coalgebra, behavioral equivalence, automata theory, T-co algebras, algebra, set theory, coalgebraic generalization, monotone modal mu-calculus, Cost accounting, bisimulation-invariant fragment, Reactive power, Semantics, bag functor, monotone modal logic, global bisimulations, bisimulation invariance, tree-like supporting Kripke frame, modal mu-calculus, global modalities, bisimulation equivalence, exponential polynomial functors, graded modal logic, trees (mathematics), automata-theoretic approach, standard monadic second-order logic, arbitrary set functor, Standards, MSO(T), coalgebras, Kripke models, coalgebraic mu-calculus, Janin-Walukiewicz theorem, monotone neighborhood functor, Automata, Games, neighborhood models, Syntactics, monadic second-order logic, automata, coalgebraic semantics]
Defining Winning Strategies in Fixed-Point Logic
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We study definability questions for positional winning strategies in infinite games on graphs. The quest for efficient algorithmic constructions of winning regions and winning strategies in infinite games, in particular parity games, is of importance in many branches of logic and computer science. A closely related, yet different, facet of this problem concerns the definability of winning regions and winning strategies in logical systems such as monadic second-order logic, least fixed-point logic LFP, the modal-calculus and some of its fragments. While a number of results concerning definability issues for winning regions have been established, so far almost nothing has been known concerning the definability of winning strategies. We make the notion of logical definability of positional winning strategies precise and study systematically the possibility of translations between definitions of winning regions and definitions of winning strategies. We present explicit LFP-definitions for winning strategies in games with relatively simple objectives, such as safety, reachability, eventual safety (Co-Buchi) and recurrent reachability (Buchi), and then prove, based on the Stage Comparison Theorem, that winning strategies for any class of parity games with a bounded number of priorities are LFP-definable. For parity games with an unbounded number of priorities, LFP-definitions of winning strategies are provably impossible on arbitrary (finite and infinite) game graphs. On finite game graphs however, this definability problem turns out to be equivalent to the fundamental open question about the algorithmic complexity of parity games. Indeed, based on a general argument about LFP-translations we prove that LFP-definable winning strategies on the class of all finite parity games exist if, and only if, parity games can be solved in polynomial time, despite the fact that LFP is, in general, strictly weaker than polynomial time.
[logical systems, Complexity theory, Classification algorithms, positional winning strategies, eventual safety, LFP, Polynomials, polynomial time, Safety, Games on graphs, reachability analysis, least fixed-point logic, stage comparison theorem, fixed point arithmetic, recurrent reachability, Color, game theory, fixed-point logic, Computer science, winning regions, algorithmic complexity, Games, arbitrary game graphs, algorithmic constructions, parity games, monadic second-order logic, infinite games, modal-calculus]
Interpolation with Decidable Fixpoint Logics
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
A logic satisfies Craig interpolation if whenever one formula &#x03C6;<sub>1</sub> in the logic entails another formula &#x03C6;<sub>2</sub> in the logic, there is an intermediate formula - one entailed by &#x03C6;<sub>1</sub> and entailing &#x03C6;<sub>2</sub> - using only relations in the common signature of &#x03C6;<sub>1</sub> and &#x03C6;<sub>2</sub>. Uniform interpolation strengthens this by requiring the interpolant to depend only on &#x03C6;<sub>1</sub> and the common signature. A uniform interpolant can thus be thought of as a minimal upper approximation of a formula within a subsignature. For first-order logic, interpolation holds but uniform interpolation fails. Uniform interpolation is known to hold for several modal and description logics, but little is known about uniform interpolation for fragments of predicate logic over relations with arbitrary arity. Further, little is known about ordinary Craig interpolation for logics over relations of arbitrary arity that have a recursion mechanism, such as fixpoint logics. In this work we take a step towards filling these gaps, proving interpolation for a decidable fragment of least fixpoint logic called unary negation fixpoint logic. We prove this by showing that for any fixed k, uniform interpolation holds for the k-variable fragment of the logic. In order to show this we develop the technique of reducing questions about logics with tree-like models to questions about modal logics, following an approach by Gradel, Hirsch, and Otto. While this technique has been applied to expressivity and satisfiability questions before, we show how to extend it to reduce interpolation questions about such logics to interpolation for the μ-calculus.
[unary negation fixpoint logic, modal logics, Craig interpolation, guarded logic, first-order logic, recursion mechanism, interpolation questions, intermediate formula, Encoding, Grammar, decidable fixpoint logics, Standards, formal logic, Interpolation, minimal upper approximation, description logics, interpolation, uniform interpolation, k-variable fragment, Semantics, Games, fixpoint logic]
A Complete Axiomatization of MSO on Infinite Trees
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We show that an adaptation of Peano's axioms for second-order arithmetic to the language of MSO completely axiomatizes the theory over infinite trees. This continues a line of work begun by Bu&#x0308;chi and Siefkes with axiomatizations of MSO over various classes of linear orders. Our proof formalizes, in the axiomatic theory, a translation of MSO formulas to alternating parity tree automata. The main ingredient is the formalized proof of positional determinacy for the corresponding parity games which, as usual, allows us to complement automata in order to deal with negation of MSO formulas. The Comprehension scheme of monadic second-order logic is used to obtain uniform winning strategies, whereas most usual proofs of positional determinacy rely on forms of the Axiom of Choice or transfinite induction.
[axiomatization, infinite trees, automata theory, uniform winning strategy, formal logic, MSO formula translation, theorem proving, Mathematical model, positional determinacy, alternating parity tree automata, Context, Peano axioms, formal languages, trees (mathematics), game theory, MSO, axiomatic theory, Encoding, Standards, axiom of choice, proof theory, MSO language, formalized proof, Automata, transfinite induction, Games, Syntactics, parity games, monadic second-order logic, MSO complete axiomatization, second-order arithmetic, linear orders, automata, comprehension scheme]
A Fibrational Account of Local States
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
One main challenge of the theory of computational effects is to understand how to combine various notions of effects in a meaningful way. Here, we study the particular case of the local state monad, which we would like to express as the result of combining together a family of global state monads parametrized by the number of available registers. To that purpose, we develop a notion of indexed monad which refines and generalizes Power's recent notion of indexed Lawvere theory. One main achievement of the paper is to integrate the block structure necessary to encode allocation as part of the resulting notion of indexed state monad. We then explain how to recover the local state monad from the functorial data provided by our notion of indexed state monad. This reconstruction is based on the guiding idea that an algebra of the indexed state monad should be defined as a section of a 2-categorical notion of fibration associated to the indexed state monad by a Grothendieck construction.
[Lawvere theories, functional programming, indexed state monad, Grothendieck construction, Lawvere theory, algebra, Registers, local state monad, Algebra, local states, block structure, Semantics, Memory management, computational effects, fibrational account, Computational effects, Tin, functorial data, fibration, 2-categories, Mathematical model, Resource management, state monad, algebraic theories]
Varieties of Languages in a Category
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Eilenberg's variety theorem, a centerpiece of algebraic automata theory, establishes a bijective correspondence between varieties of languages and pseudovarieties of monoids. In the present paper this result is generalized to an abstract pair of algebraic categories: we introduce varieties of languages in a category C, and prove that they correspond to pseudovarieties of monoids in a closed monoidal category D, provided that C and D are dual on the level of finite objects. By suitable choices of these categories our result uniformly covers Eilenberg's theorem and three variants due to Pin, Pola&#x0301;k and Reutenauer, respectively, and yields new Eilenberg-type correspondences.
[coalgebra, varieties of languages, finite object level, automata theory, Lattices, language varieties, monoids, algebra, Eilenberg's theorem, variety theorem, algebraic automata theory, monoid pseudovarieties, closed monoidal category, bijective correspondence, Structural rings, formal languages, Generators, Boolean algebra, duality, group theory, Eilenberg-type correspondences, Tensile stress, process algebra, Automata, category theory, automata, abstract algebraic category pair]
Extensions of Domain Maps in Differential and Integral Calculus
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We introduce in the context of differential and integral calculus several key extensions of higher order maps from a dense subset of a topological space into a continuous Scott domain. These higher order maps include the classical derivative operator and the Riemann integration operator. Using a sequence of test functions, we prove that the subspace of real-valued continuously differentiable functions on a finite dimensional Euclidean space is dense in the space of Lipschitz maps equipped with the L-topology. This provides a new result in basic mathematical analysis, which characterises the L-topology in terms of the limsup of the sequence of derivatives of a sequence of C1 maps that converges to a Lipschitz map. Using this result, it is also shown that the generalised (Clarke) gradient on Lipschitz maps is the extension of the derivative operator on C1 maps. We show that the generalised Riemann integral (R-integral) of a real-valued continuous function on a compact metric space with respect to a Borel measure can be extended to the integral of interval-valued functions on the metric space with respect to valuations on the probabilistic power domain of the space of non-empty and compact sets of the metric space. We also prove that the Lebesgue integral operator on integrable functions is the extension of the R-integral operator on continuous functions. We finally illustrate an application of these results by deriving a simple proof of Green's theorem for interval-valued vector fields.
[Riemann integration operator, finite dimensional Euclidean space, TV, differentiation, Aerospace electronics, Clarke gradient, Calculus, multidimensional systems, L-topology, domain maps, interval-valued vector fields, Mathematical analysis, Borel measure, gradient methods, differential calculus, Green's theorem, Extraterrestrial measurements, Topology, continuous Scott domain, mathematical analysis, Lebesgue integration, higher order maps, integral calculus, real-valued continuously differentiable functions, integral equations, generalised gradient, vectors, interval-valued functions, Generalised Riemann integration, Green's function methods, Lipschitz maps, Densely injective spaces, Green theorem]
Descriptive Set Theory in the Category of Represented Spaces
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We propose to extend descriptive set theory (DST) beyond its traditional setting of Polish spaces to the represented spaces. There, we can reformulate DST in terms of endofunctors on the categories of represented spaces and computable or continuous functions. In particular, this approach satisfies the demand for a uniform approach to both classic and effective DST -- computability follows naturally from the setting, rather than having to be explicitly demanded. The previous endeavour to extend DST to the Quasi-Polish spaces is subsumed by this work. In several cases the category-theoretic setting enables new, very succinct proofs, and sheds a new light on why certain results are true. The framework lets us make formal some natural questions not easily approachable by traditional methods.
[category-theoretic setting, DST, continuous function, computability, Extraterrestrial measurements, descriptive set theory, Topology, Complexity theory, set theory, Computer science, Density estimation robust algorithm, endofunctors, topos theory, represented spaces, Polish spaces, quasipolish spaces, extend descriptive set theory, Set theory, category theory, computable function, realizability, computable analysis]
Domains of Commutative C-Subalgebras
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Operator algebras provide uniform semantics for deterministic, reversible, probabilistic, and quantum computing, where intermediate results of partial computations are given by commutative sub algebras. We study this setting using domain theory, and show that a given operator algebra is scattered if and only if its associated partial order is, equivalently: continuous (a domain), algebraic, atomistic, quasi-continuous, or quasialgebraic. In that case, conversely, we prove that the Lawson topology, modelling information approximation, allows one to associate an operator algebra to the domain.
[approximation theory, Computational modeling, deterministic computing, commutative C*-subalgebras, Probabilistic logic, algebra, Topology, Approximation methods, uniform semantics, Lawson topology, modelling information approximation, Quantum computing, Algebra, Semantics, quantum computing, operator algebras, reversible computing, probabilistic computing, Domain, C-algebra, domain theory]
From Complexity to Algebra and Back: Digraph Classes, Collapsibility, and the PGP
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Inspired by computational complexity results for the quantified constraint satisfaction problem, we study the clones of idem potent polymorphisms of certain digraph classes. Our first results are two algebraic dichotomy, even "gap\
[QCSP, algebraic dichotomy theorems, Complexity theory, Electronic mail, gap theorems, idem potent polymorphisms, Algebra, Quantified Constraints, Polynomials, polynomially generated powers property, NL problem, Computational Complexity, Cloning, Polynomially Generated Powers, quantified constraint satisfaction problem, collapsibility, NP-complete problem, EGP, constraint satisfaction problems, digraph classes, directed graphs, clone algebra, PGP, exponentially generated powers property, Concrete, Pspace-complete problem, computational complexity]
Locally Finite Constraint Satisfaction Problems
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
First-order definable structures with atoms are infinite, but exhibit enough symmetry to be effectively manipulated. We study Constraint Satisfaction Problems (CSPs) where both the instance and the template are definable structures with atoms. As an initial step, we consider locally finite templates, which contain potentially infinitely many finite relations. We argue that such templates occur naturally in Descriptive Complexity Theory. We study CSPs over such templates for both finite and infinite, definable instances. In the latter case even decidability is not obvious, and to prove it we apply results from topological dynamics. For finite instances, we show that some central results from the classical algebraic theory of CSPs still hold: the complexity is determined by polymorphisms of the template, and the existence of certain polymorphisms, such as majority or Maltsev polymorphisms, guarantees the correctness of classical algorithms for solving finite CSP instances.
[CSP, Sets with atoms, Color, Orbits, algebra, locally finite templates, Complexity theory, set theory, Cost accounting, Standards, Constraint Satisfaction Problems, Upper bound, constraint satisfaction problems, locally finite constraint satisfaction problems, descriptive complexity theory, Polynomials, algebraic theory, Maltsev polymorphisms]
Descriptive Complexity of List H-Coloring Problems in Logspace: A Refined Dichotomy
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
The Dichotomy Conjecture for constraint satisfaction problems (CSPs) states that every CSP is in P or is NP-complete (Feder-Vardi, 1993). It has been verified for conservative problems (also known as list homomorphism problems) by A. Bulatov (2003). Egri et al. (SODA 2014) augmented this result by showing that for digraph templates H, every conservative CSP, denoted LHOM(H), is solvable in log space or is hard for NL. A conjecture of Larose and Tesson from 2007 forecasts that when LHOM(H) is in log space, then in fact, it falls in a small subclass of log space, the set of problems expressible in symmetric Data log. The present work verifies the conjecture for LHOM(H) (and, indeed, for the wider class of conservative CSPs with binary constraints), and by so doing sharpens the aforementioned dichotomy. A combinatorial characterization of symmetric Data log provides the language in which the algorithmic ideas of the paper, quite different from the ones in Egri et al., are formalized.
[Context, CSP, combinatorial mathematics, refined dichotomy, descriptive complexity, NP-complete, Complexity theory, Electronic mail, Standards, Constraint Satisfaction Problems, Computer science, dichotomy conjecture, Dichotomy Conjectures, constraint satisfaction problems, Algebra, Symmetric Datalog, symmetric data log, Games, list H-coloring problems, conservative problems, logspace, combinatorial characterization]
One Context Unification Problems Solvable in Polynomial Time
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
One context unification extends first-order unification by introducing a single context variable, possibly with multiple occurrences. One context unification is known to be in NP, but it is not known to be solvable in polynomial time. In this paper, we present a polynomial time algorithm for certain interesting classes of the one context unification problem. Our algorithm is presented as an inference system that non-trivially extends the usual inference rules for first-order unification. The algorithm is of independent value as it can be used, with slight modifications, to solve other problems, such as the first-order unification problem that tolerates one clash.
[Context, inference rules, one context unification problems, computability, Context Unification, Term DAGs, Time measurement, Polynomial-time, inference mechanisms, polynomial time algorithm, Standards, Computer science, inference system, Unification, Syntactics, first-order unification, Polynomials, Inference algorithms, single context variable, computational complexity, Higher-order Unification]
Extending ALCQIO with Trees
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We study the description logic ALCQIO, which extends the standard description logic ALC with nominals, inverses and counting quantifiers. ALCQIO is a fragment of first order logic and thus cannot define trees. We consider the satisfiability problem of ALCQIO over finite structures in which k relations are interpreted as forests of directed trees with unbounded out degrees. We show that the finite satisfiability problem of ALCQIO with forests is polynomial-time reducible to finite satisfiability of ALCQIO. As a consequence, we get that finite satisfiability is NEXPTIME-complete. Description logics with transitive closure constructors or fixed points have been studied before, but we give the first decidability result of the finite satisfiability problem for a description logic that contains nominals, inverse roles, and counting quantifiers and can define trees.
[transitive closure constructors, Terminology, directed trees, trees (mathematics), ALCQIO, computability, Data structures, trees, Standards, description logic, ALC description logic, decidability, Description logic, Semantics, polynomial-time reducible problem, Vegetation, first order logic, NEXPTIME-complete problem, Nickel, ALCQIO description logic, finite model reasoning, ALCQIO satisfiability problem, computational complexity]
Feedback Turing Computability, and Turing Computability as Feedback
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
The notion of a feedback query is a natural generalization of choosing for an oracle the set of indices of halting computations. Notice that, in that setting, the computations being run are different from the computations in the oracle: the former can query an oracle, whereas the latter cannot. A feedback computation is one that can query an oracle, which itself contains the halting information about all feedback computations. Although this is self-referential, sense can be made of at least some such computations. This threatens, though, to obliterate the distinction between con- and divergence: before running a computation, a machine can ask the oracle whether that computation converges, and then run it if and only if the oracle says "yes." This would quickly lead to a diagonalization paradox, except that a new distinction is introduced, this time between freezing and non-freezing computations. The freezing computations are even more extreme than the divergent ones, in that they prevent the dovetailing on all computations into a single run. In this paper, we study feedback around Turing computability. In one direction, we examine feedback Turing machines, and show that they provide exactly hyper arithmetic computability. In the other direction, Turing computability is itself feedback primitive recursion (at least, one version thereof). We also examine parallel feedback. Several different notions of parallelism in this context are identified. We show that parallel feedback Turing machines are strictly stronger than sequential feedback TMs, while in contrast parallel feedback p.r. Is the same as sequential feedback p.r.
[halting information, convergence, parallelism, computability, arithmetic, Electronic mail, Registers, feedback query, hyperarithmetic computability, feedback, feedback computation, hyper arithmetic computability, Turing machines, Computability theory, least fixed points, parallel feedback, feedback Turing computability, parallel algorithms, oracle query, diagonalization paradox, Computational modeling, nonfreezing computations, Indexes, Standards, divergence, Vegetation, feedback primitive recursion]
Regularity Preserving but Not Reflecting Encodings
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Encodings, that is, injective functions from words to words, have been studied extensively in several settings. In computability theory the notion of encoding is crucial for defining computability on arbitrary domains, as well as for comparing the power of models of computation. In language theory much attention has been devoted to regularity preserving functions. A natural question arising in these contexts is: Is there a bijective encoding such that its image function preserves regularity of languages, but its pre-image function does not? Our main result answers this question in the affirmative: For every countable class C of languages there exists a bijective encoding f such that for every language L &#x2208; L its image f[L] is regular. Our construction of such encodings has several noteworthy consequences. Firstly, anomalies arise when models of computation are compared with respect to a known concept of implementation that is based on encodings which are not required to be computable: Every countable decision model can be implemented, in this sense, by finite-state automata, even via bijective encodings. Hence deterministic finite-state automata would be equally powerful as Turing machine deciders. A second consequence concerns the recognizability of sets of natural numbers via number representations and finite automata. A set of numbers is said to be recognizable with respect to a representation if an automaton accepts the language of representations. Our result entails that there is one number representation with respect to which every recursive set is recognizable.
[reflecting encodings, natural numbers, finite automata, computability, Electronic mail, set theory, regularity preserving functions, Turing machine deciders, language theory, Image coding, Turing machines, deterministic automata, injective functions, number representations, sets recognizability, Context, formal languages, arbitrary domains, preimage function, bijective encoding, Computational modeling, deterministic finite-state automata, Encoding, countable decision model, languages regularity, Computer science, Automata, computability theory, number theory]
Hyper Natural Deduction
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We introduce a Hyper Natural Deduction system as an extension of Gentzen's Natural Deduction system. A Hyper Natural Deduction consists of a finite set of derivations which may use, beside typical Natural Deduction rules, additional rules providing means for communication between derivations. We show that our Hyper Natural Deduction system is sound and complete for infinite-valued propositional Go&#x0308;del Logic, by giving translations to and from Avron's Hyper sequent Calculus. We also provide conversions for normalisation and prove the existence of normal forms for our Hyper Natural Deduction system.
[hypernatural deduction system, Programming, Calculus, Electronic mail, Natural Deduction, Gödel Logic, Cost accounting, formal logic, Avron hypersequent calculus, Normalisation, Gentzen natural deduction system, Hyper Natural Deduction, Semantics, infinite-valued propositional Go&#x0308;del logic, Linearity, Hyper Sequent Calculus]
Parallelism and Synchronization in an Infinitary Context
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We study multitoken interaction machines in the context of a very expressive linear logical system with exponentials, fix points and synchronization. The advantage of such machines is to provide models in the style of the Geometry of Interaction, i.e., An interactive semantics which is close to low-level implementation. On the one hand, we prove that despite the inherent complexity of the framework, interaction is guaranteed to be deadlock-free. On the other hand, the resulting logical system is powerful enough to embed PCF and to adequately model its behaviour, both when call-by-name and when call-by-value evaluation are considered. This is not the case for single-token stateless interactive machines.
[Context, Abstract Machines, parallelism, Geometry of Interaction, linear logical system, Synchronization, single-token stateless interactive machines, infinitary context, Linear Logic, Machinery, deadlock-free, multitoken interaction machines, parallel programming, synchronisation, Geometry, geometry of interaction, Parallel Computation, interactive semantics, Semantics, Parallel processing, System recovery, interactive systems, logic programming, synchronization]
A Diagrammatic Axiomatisation for Qubit Entanglement
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Diagrammatic techniques for reasoning about monoidal categories provide an intuitive understanding of the symmetries and connections of interacting computational processes. In the context of categorical quantum mechanics, Coecke and Kissinger suggested that two 3-qubit states, GHZ and W, may be used as the building blocks of a new graphical calculus, aimed at a diagrammatic classification of multipartite qubit entanglement that would highlight the communicational properties of quantum states, and their potential uses in cryptographic schemes. In this paper, we present a full graphical axiomatisation of the relations between GHZ and W: the ZW calculus. This refines a version of the preexisting ZX calculus, while keeping its most desirable characteristics: undirected ness, a large degree of symmetry, and an algebraic underpinning. We prove that the ZW calculus is complete for the category of free abelian groups on a power of two generators - "qubits with integer coefficients" - and provide an explicit normalisation procedure.
[string diagrams, Correlation, categorical quantum mechanics, reasoning, Calculus, Cognition, cryptographic schemes, algebraic underpinning, Algebra, Wires, quantum cryptography, diagrammatic axiomatisation, multipartite qubit entanglement, quantum theory, graphical axiomatisation, Generators, graphical calculus, inference mechanisms, monoidal categories, communicational properties, multipartite entanglement, group theory, abelian groups, Quantum mechanics, compact closed categories, SLOCC classification, ZW calculus]
A Unifying Approach to the Gamma Question
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
The Gamma question was formulated by Andrews et al. In "Asymptotic density, computable trace ability and 1-randomness" (2013, available at http://www.math.wisc.edu/~lempp/papers/traceable.pdf). It is related to the recent notion of coarse computability which stems from complexity theory. The Gamma value of an oracle set measures to what extent each set computable with the oracle is approximable, in the sense of density, by a computable set. The closer to 1 this value is, the closer the oracle is to being computable. The Gamma question asks whether this value can be strictly in between 0 and 1/2. We say that an oracle is weakly Schnorr engulfing if it computes a Schnorr test that succeeds on all computable reals. We show that each non weakly Schnorr engulfing oracle has a Gamma value of at least 1/2. Together with a recent result of Kjos-Hanssen, Stephan, and Terwijn, this establishes new examples of such oracles. We also give a unifying approach to oracles with Gamma value 0. We say that an oracle is infinitely often equal with bound h if it computes a function that agrees infinitely often with each computable function bounded by h. We show that every oracle which is infinitely equal with bound 2dn for d&gt;1 has a Gamma value of 0. This provides new examples of such oracles as well. We present a combinatorial characterization of being weakly Schnorr engulfing via traces, which is inspired by the study of cardinal characteristics in set theory.
[Atomic measurements, complexity theory, Density measurement, combinatorial mathematics, Schnorr test, cardinal characteristics, computability, Encoding, Complexity theory, Electronic mail, set theory, coarse computability, Algorithmic randomness, Computer science, Gamma question, combinatorial characterization, Random sequences, computational complexity, nonweakly Schnorr engulfing oracle]
Abstract Hidden Markov Models: A Monadic Account of Quantitative Information Flow
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Hidden Markov Models, HMM's, are mathematical models of Markov processes whose state is hidden but from which information can leak via channels. They are typically represented as 3-way joint probability distributions. We use HMM's as denotations of probabilistic hidden-state sequential programs, after recasting them as &#x201C;abstract&#x201D; HMM's, i.e. computations in the Giry monad D, and equipping them with a partial order of increasing security. However to encode the monadic type with hiding over state X we use DX&#x2192;D2X rather than the conventional X&#x2192;DX. We illustrate this construction with a very small Haskell prototype. We then present uncertainty measures as a generalisation of the extant diversity of probabilistic entropies, and we propose characteristic analytic properties for them. Based on that, we give a &#x201C;backwards&#x201D;, uncertainty-transformer semantics for HMM's, dual to the &#x201C;forwards&#x201D; abstract HMM's. Finally, we discuss the Dalenius desideratum for statistical databases as an issue in semantic compositionality, and propose a means for taking it into account.
[Markov process, uncertainty-transformer semantics, abstract hidden Markov models, Uncertainty, semantic compositionality, functional programming, statistical distributions, quantitative information flow, monadic account, Giry monad, probabilistic hidden-state sequential program, hidden Markov models, entropy, monadic type encoding, Semantics, uncertainty measure, statistical database, statistical databases, Abstract hidden Markov models, Joints, Quantitative information flow, Probabilistic logic, abstract HMM, programming language semantics, Giry Monad, Dalenius desideratum, Measurement uncertainty, Hidden Markov models, Markov processes, mathematical model, probabilistic entropy, 3-way joint probability distribution, Haskell prototype, functional languages]
How Good Is a Strategy in a Game with Nature?
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We consider games with two antagonistic players -- E&#x0301;loi&#x0308;se (modelling a program) and Abelard (modelling a byzantine environment) -- and a third, unpredictable and uncontrollable player, that we call Nature. Motivated by the fact that the usual probabilistic semantics very quickly leads to undecidability when considering either infinite game graphs or imperfect information, we propose two alternative semantics that leads to decidability where the probabilistic one fails: one based on counting and one based on topology.
[infinite game graphs, graph theory, probability, topology, Color, game theory, cardinality constraints, Probabilistic logic, qualitative study of games, large sets of branches, Probability distribution, Topology, E&#x0301;loi&#x0308;se, program modelling, Computer science, decidability, imperfect information, Semantics, antagonistic players, byzantine environment modelling, Games, Abelard, tree automata, probabilistic semantics]
Entailment among Probabilistic Implications
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We study a natural variant of the implicational fragment of propositional logic. Its formulas are pairs of conjunctions of positive literals, related together by an implicational-like connective, the semantics of this sort of implication is defined in terms of a threshold on a conditional probability of the consequent, given the antecedent: we are dealing with what the data analysis community calls confidence of partial implications or association rules. Existing studies of redundancy among these partial implications have characterized so far only entailment from one premise and entailment from two premises. By exploiting a previously noted alternative view of this entailment in terms of linear programming duality, we characterize exactly the cases of entailment from arbitrary numbers of premises. As a result, we obtain decision algorithms of better complexity, additionally, for each potential case of entailment, we identify a critical confidence threshold and show that it is, actually, intrinsic to each set of premises and antecedent of the conclusion.
[Context, Data analysis, confidence of partial implications, propositional logic, partial implication, Communities, Redundancy, data mining, probability, association rules, Linear programming, Probabilistic logic, linear programming, critical confidence threshold, formal logic, probabilistic implications, Semantics, conditional probability, duality (mathematics), implicational-like connective, confidence threshold, linear programming duality]
Metric reasoning about &#x003BB;-terms: The affine case
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Terms of Church's &#x03BB;-calculus can be considered equivalent along many different definitions, but context equiv-alence is certainly the most direct and universally accepted one. If the underlying calculus becomes probabilistic, however, equivalence is too discriminating: terms which have totally unrelated behaviours are treated the same as terms which behave very similarly. We study the problem of evaluating the distance between affine &#x03BB;-terms. A natural generalisation of context equiv-alence, is shown to be characterised by a notion of trace distance, and to be bounded from above by a co inductively defined distance based on the Kantorovich metric on distributions. A different, again fully-abstract, tuple-based notion of trace distance is shown to be able to handle nontrivial examples.
[Context, Measurement, lambda calculus, trace distance, pi-calculus, probability, Probability, Probabilistic logic, Trace Equivalence, metric reasoning about &#x03BB;-term, probabilistic calculus, Kantorovich metric, metric reasoning about ?-term, Probabilistic Computation, Convergence, Metrics, Lambda Calculus, Semantics, &#x03BB;-calculus, tuple-based notion, equivalence classes, Manganese, context equivalence]
On the Complexity of Temporal Equilibrium Logic
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Temporal Equilibrium Logic (TEL) [1] is a promising framework that extends the knowledge representation and reasoning capabilities of Answer Set Programming with temporal operators in the style of LTL. To our knowledge it is the first nonmonotonic logic that accommodates fully the syntax of a standard temporal logic (specifically LTL) without requiring further constructions. This paper provides a systematic complexity analysis for the (consistency) problem of checking the existence of a temporal equilibrium model of a TEL formula. It was previously shown that this problem in the general case lies somewhere between PSPACE and EXPSPACE. Here we establish a lower bound matching the EXPSPACE upper bound in [2]. Additionally we analyse the complexity for various natural subclasses of TEL formulas, identifying both tractable and intractable fragments. Finally the paper offers some new insights on the logic LTL by addressing satisfiability for minimal LTL models. The complexity results obtained highlight a substantial difference between interpreting LTL over finite or infinite words.
[temporal operators, temporal logic syntax, intractable fragments, temporal equilibrium model checking, computability, temporal logic, nonmonotonic logic, Cognition, Complexity theory, logic LTL, systematic complexity analysis, formal verification, Semantics, satisfiability, Polynomials, minimal LTL models, answer set programming, Nonmonotonic temporal logics, Decision problems, consistency problem, Computational modeling, lower bound matching, temporal equilibrium logic, TEL formula, Standards, infinite words, Complexity issues, knowledge representation, Answer Set Programming, reasoning capabilities, EXPSPACE upper bound, Syntactics, Linear-time Temporal Logics, computational complexity]
A Note on the Complexity of Classical and Intuitionistic Proofs
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We show an effective cut-free variant of Glivenko's theorem extended to formulas with weak quantifiers (those without eigenvariable conditions): &#x201C;There is an elementary function f such that if &#x03C6; is a cut-free LK proof of &#x22A2; A with symbol complexity &#x2264; c, then there exists a cut-free LJ proof of 1&#x22A2; &#x22A3;&#x22A3;A with symbol complexity &#x2264; f(c)&#x201D;. This follows from the more general result: &#x201C;There is an elementary function f such that if &#x03C6; is a cut-free LK proof of A &#x22A2; with symbol complexity &#x2264; c, then there exists a cut-free LJ proof of A &#x22A2; with symbol complexity &#x2264; f(c)&#x201D;. The result is proved using a suitable variant of cut-elimination by resolution (CERES) and subsumption.
[complexity, Merging, intuitionistic logic, Calculus, intuitionistic proofs, Complexity theory, CERES, formal logic, cut-free LK proof, Glivenko theorem, elementary function, subsumption, theorem proving, classical proofs, classical logic, Context, cut-elimination by resolution, Glivenko's theorem, symbol complexity, cut-free variant, Computer science, Geometry, weak quantifiers, cut-free LJ proof, computational complexity]
On the Complexity of Linear Arithmetic with Divisibility
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We consider the complexity of deciding the truth of first-order existential sentences of linear arithmetic with divisibility over both the integers and the p-adic numbers. We show that if an existential sentence of Presburger arithmetic with divisibility is satisfiable then the smallest satisfying assignment has size at most exponential in the size of the formula, showing that the decision problem for such sentences is in NEXPTIME. Establishing this upper bound requires subtle adaptations to an existing decidability proof of Lipshitz. We consider also the first-order linear theory of the p-adic numbers. Here divisibility can be expressed via the valuation function. The decision problem for existential sentences over the p-adic numbers is an important component of the decision procedure for existential Presburger arithmetic with divisibility. The problem is known to be NP-hard and in EXPTIME, as a second main contribution, we show that this problem lies in the Counting Hierarchy, and therefore in PSPACE.
[decision problem, decision theory, computability, p-adic number first-order linear theory, Complexity theory, PSPACE, Cost accounting, Zinc, Lipshitz decidability proof, Computer science, valuation function, Upper bound, Presburger arithmetic with divisibility, counting hierarchy, decidability, NP-hard problem, satisfiability, Automata, Polynomials, first-order existential sentences, NEXPTIME problem, linear arithmetic with divisibility, computational complexity]
Characterising Choiceless Polynomial Time with First-Order Interpretations
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Choice less Polynomial Time (CPT) is one of the candidates in the quest for a logic for polynomial time. It is a strict extension of fixed-point logic with counting, but to date the question is open whether it expresses all polynomial-time properties of finite structures. We present here alternative characterisations of Choice less Polynomial Time (with and without counting) based on iterated first-order interpretations. The fundamental mechanism of Choice less Polynomial Time is the manipulation of hereditarily finite sets over the input structure by means of set-theoretic operations and comprehension terms. While this is very convenient and powerful for the design of abstract computations on structures, it makes the analysis of the expressive power of CPT rather difficult. We aim to reduce this functional framework operating on higher-order objects to an approach that evaluates formulae on less complex objects. We propose a more model-theoretic formalism, called polynomial-time interpretation logic (PIL), that replaces the machinery of hereditarily finite sets and comprehension terms by traditional first-order interpretations, and handles counting by Ha&#x0308;rtig quantifiers. In our framework, computations on finite structures are captured by iterations of interpretations, and a run is a sequence of states, each of which is a finite structure of a fixed vocabulary. Our main result is that PIL has precisely the same expressive power as Choice less Polynomial Time. We also analyse the structure of PIL and show that many of the logical formalisms or database languages that have been proposed in the quest for a logic for polynomial time reappear as fragments of PIL, obtained by restricting interpretations in a natural way (e.g. By omitting congruences or using only one-dimensional interpretations).
[polynomial-time properties, abstract computation design, higher-order objects, CPT, polynomial-time interpretation logic, descriptive complexity, comprehension terms, Complexity theory, set theory, Database languages, expressive power, logical interpretations, logical formalisms, formal logic, Image color analysis, model-theoretic formalism, set-theoretic operations, state sequence, Polynomials, database languages, Computational modeling, finite structures, Color, choiceless polynomial time, fixed-point logic, input structure, fixed vocabulary, iterated first-order interpretations, Encoding, functional framework, hereditarily finite set manipulation, PIL, logic, finite model theory, Hartig quantifiers, computational complexity]
Universal Covers, Color Refinement, and Two-Variable Counting Logic: Lower Bounds for the Depth
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Given a connected graph G and its vertex x, let U(G,x) denote the universal cover of G obtained by unfolding G into a tree starting from x. Let T=T(n) be the minimum number such that, for graphs G and H with at most n vertices each, the isomorphism of U(G,x) and U(H,y) surely follows from the isomorphism of these rooted trees truncated at depth T. Motivated by applications in theory of distributed computing, Norris [Discrete Appl. Math. 1995] asks if the value of T(n) is bounded by n. We answer this question in the negative by establishing that T(n)=(2-o(1))n. Our solution uses basic tools of finite model theory such as a bisimulation version of the Immerman-Lander 2-pebble counting game. The graphs G and H we construct for each n to prove the lower bound for T(n) also show some other tight lower bounds. Both having n vertices, G and H can be distinguished in 2-variable counting logic only with quantifier depth (1-o(1))n. It follows that color refinement, the classical procedure used in isomorphism testing and other areas for computing the coarsest equitable partition of a graph, needs (1-o(1))n rounds to achieve color stabilization on each of G and H. Somewhat surprisingly, this number of rounds is not enough for color stabilization on the disjoint union of G and H, where (2-o(1))n rounds are needed.
[universal covers of graphs, two-variable logic with counting quantifiers, TV, Computational modeling, two-variable counting logic, trees (mathematics), Color, distributed processing, rooted tree, Distributed computing, bisimulation version, isomorphism, distributed computing, Immerman-Lander 2-pebble counting game, Program processors, Upper bound, quantifier depth, universal cover, color stabilization, Games, 2-variable counting logic, color refinement, bisimulation equivalence, connected graph]
A Canonical Form for Weighted Automata and Applications to Approximate Minimization
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
We study the problem of constructing approximations to a weighted automaton. Weighted finite automata (WFA) are closely related to the theory of rational series. A rational series is a function from strings to real numbers that can be computed by a WFA. Among others, this includes probability distributions generated by hidden Markov models and probabilistic automata. The relationship between rational series and WFA is analogous to the relationship between regular languages and ordinary automata. Associated with such rational series are infinite matrices called Hankel matrices which play a fundamental role in the theory of minimal WFA. Our contributions are: (1) an effective procedure for computing the singular value decomposition (SVD) of such infinite Hankel matrices based on their finite representation in terms of WFA, (2) a new canonical form for WFA based on this SVD decomposition, and, (3) an algorithm to construct approximate minimizations of a given WFA. The goal of our approximate minimization algorithm is to start from a minimal WFA and produce a smaller WFA that is close to the given one in a certain sense. The desired size of the approximating automaton is given as input. We give bounds describing how well the approximation emulates the behavior of the original WFA. The study of this problem is motivated by the analysis of machine learning algorithms that synthesize weighted automata from spectral decompositions of finite Hankel matrices. It is known that when the number of states of the target automaton is correctly guessed, these algorithms enjoy consistency and finite-sample guarantees in the probably approximately correct (PAC) learning model. It has also been suggested that asking the learning algorithm to produce a model smaller than the true one will still yield useful models with reduced complexity. Our results in this paper vindicate these ideas and confirm intuitions provided by empirical studies. Beyond learning problems, our techniques can also be used to reduce the complexity of any algorithm working with WFA, at the expense of incurring a small, controlled amount of error.
[SVD, rational series, finite automata, Hankel matrices, Approximation methods, finite representation, hidden Markov models, probabilistic automata, WFA, probability distributions, Hafnium, PAC learning model, learning (artificial intelligence), machine learning algorithms, singular value decomposition, ordinary automata, approximation theory, regular languages, weighted automata, canonical form, Minimization, spectral decompositions, Matrix decomposition, approximate minimization, weighted finite automata, infinite matrices, Automata, Hidden Markov models, approximate minimization algorithm, Approximation algorithms, probably approximately correct]
Automata-Based Abstraction Refinement for &#x00B5;HORS Model Checking
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
The model checking of higher-order recursion schemes (HORS), aka. Higher-order model checking, is the problem of checking whether the tree generated by a given HORS satisfies a given property. It has recently been studied actively and applied to automated verification of higher-order programs. Kobayashi and Igarashi studied an extension of higher-order model checking called muHORS model checking, where HORS has been extended with recursive types, so that a wider range of programs, including object-oriented programs and multi-threaded programs, can be precisely modeled and verified. Although the muHORS model checking is undecidable in general, they developed a sound but incomplete procedure for muHORS model checking. Unfortunately, however, their procedure was not scalable enough. Inspired by recent progress of (ordinary) HORS model checking, we propose a new procedure for muHORS model checking, based on automata-based abstraction refinement. We have implemented the new procedure and confirmed that it often outperforms the previous procedure.
[Context, object-oriented programming, multi-threading, Object oriented modeling, automata theory, μHORS, Transforms, higher order statistics, Grammar, abstraction refinement, object-oriented program, formal verification, higher-order model checking, higher-order recursion scheme, Automata, Model checking, Syntactics, recursive estimation, automata-based abstraction refinement, multithreaded program, tree automata]
Nested Weighted Automata
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Recently there has been a significant effort to handle quantitative properties in formal verification and synthesis. While weighted automata over finite and infinite words provide a natural and flexible framework to express quantitative properties, perhaps surprisingly, some basic system properties such as average response time cannot be expressed using weighted automata, nor in any other know decidable formalism. In this work, we introduce nested weighted automata as a natural extension of weighted automata which makes it possible to express important quantitative properties such as average response time. In nested weighted automata, a master automaton spins off and collects results from weighted slave automata, each of which computes a quantity along a finite portion of an infinite word. Nested weighted automata can be viewed as the quantitative analogue of monitor automata, which are used in run-time verification. We establish an almost complete decidability picture for the basic decision problems about nested weighted automata, and illustrate their applicability in several domains. In particular, nested weighted automata can be used to decide average response time properties.
[run-time verification, Weighted Automata, automata theory, average response time, monitor automata, Complexity theory, system properties, nested weighted automata, quantitative properties, decidability, formal verification, Semantics, Robustness, weighted slave automata, Monitoring, synthesis, Quantitative properties, Nested Automata, Standards, infinite words, master automaton, Model measuring, Automata, decision problems, Time factors, quantitative analogue, Limit-average value functions]
Timed Pushdown Automata Revisited
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
This paper contains two results on timed extensions of pushdown automata (PDA). As our first result we prove that the model of dense-timed PDA of Abdulla et al. Collapses: it is expressively equivalent to dense-timed PDA with timeless stack. Motivated by this result, we advocate the framework of first-order definable PDA, a specialization of PDA in sets with atoms, as the right setting to define and investigate timed extensions of PDA. The general model obtained in this way is Turing complete. As our second result we prove NEXPTIME upper complexity bound for the non-emptiness problem for an expressive subclass. As a byproduct, we obtain a tight EXPTIME complexity bound for a more restrictive subclass of PDA with timeless stack, thus subsuming the complexity bound known for dense-timed PDA.
[orbit-finite, pushdown automata, Orbits, Registers, Complexity theory, PDA, Atomic clocks, timed extension, Handheld computers, Turing machines, Automata, sets with atoms, timed automata, Turing complete, computational complexity, NEXPTIME upper complexity bound]
The Target Discounted-Sum Problem
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
The target discounted-sum problem is the following: Given a rational discount factor 0 &lt;; &#x03BB; &lt;; 1 and three rational values a, b, and t, does there exist a finite or an infinite sequence w &#x2208; {a, b}* or w &#x2208; {a, b}&#x03C9;, such that &#x03A3;<sub>i=0</sub>|w| w(i)&#x03BB;i equals t? The problem turns out to relate to many fields of mathematics and computer science, and its decidability question is surprisingly hard to solve. We solve the finite version of the problem, and show the hardness of the infinite version, linking it to various areas and open problems in mathematics and computer science: &#x03B2;-expansions, discounted-sum automata, piecewise affine maps, and generalizations of the Cantor set. We provide some partial results to the infinite version, among which are solutions to its restriction to eventually-periodic sequences and to the cases that &#x03BB; &#x2265; 1/2 or &#x03BB; =1/n, for every n &#x2208; N. We use our results for solving some open problems on discounted-sum automata, among which are the exact-value problem for nondeterministic automata over finite words and the universality and inclusion problems for functional automata.
[automata theory, mathematics, Mathematics, Orbits, Electronic mail, set theory, target discounted-sum problem, infinite sequence, decidability question, rational value, Cantor set, decidability, computer science, functional automata, Discrete mathematics, exact-value problem, eventually-periodic sequence, &#x03B2;-expansion, nondeterministic automata, discounted-sum automata, piecewise affine map, Standards, Computer science, Discounted-sum automata, Algorithms, Automata, Joining processes, rational discount factor]
[Publisher's information]
2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science
None
2015
Provides a listing of current committee members and society officers.
[]
LICS 2017 foreword
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
This volume contains the proceedings of the 2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS), held at Reykjav&#x00ED;k University in Iceland from 20 to 23 June 2017. LICS is an annual international forum on the broad range of topics that lie at the intersection of computer science and mathematical logic. In addition to the main symposium, seven workshops were co-located with LICS 2017: &#x2022; INFINITY: Verification of Infinite-State Systems &#x2022; LearnAut: Learning and Automata &#x2022; LCC: Logic and Computational Complexit &#x2022; LMW: Logic Mentoring Workshop &#x2022; LOLA: Syntax and Semantics of Low-Level Languages &#x2022; Metafinite model theory and definability and complexity of numeric graph parameters &#x2022; WiL: Women in Logic
[]
Committees
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Provides a listing of current committee members and society officers.
[]
Logic and regular cost functions
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Regular cost functions offer a toolbox for automatically solving problems of existence of bounds, in a way similar to the theory of regular languages. More precisely, it allows to test the existence of bounds for quantities that can be defined in cost monadic second-order logic (a quantitative variant of monadic second-order logic) with inputs that range over finite words, infinite words, finite trees, and (sometimes) infinite trees. Though the initial results date from the works of Hashiguchi in the early eighties, it is during the last decade that the theory took its current shape and that many new results and applications have been established. In this tutorial, two connections linking logic with the theory of regular cost functions will be described. The first connection is a proof of a result of Blumensath, Otto and Weyer stating that it is decidable whether the fixpoint of a monadic secondorder formula is reached within a bounded number of iterations over the class of infinite trees. The second connection is how nonstandard models (and more precisely non-standard analysis) give rise to a unification of the theory of regular cost functions with the one of regular languages.
[formal languages, finite trees, infinite trees, regular languages, Europe, monadic second-order formula, nonstandard analysis, Tutorials, Standards, infinite words, formal logic, regular cost functions, Automata, Vegetation, Games, finite words, Cost function, nonstandard models, monadic second-order logic]
Symbolic execution and probabilistic reasoning
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Summary form only given. Symbolic execution is a systematic program analysis technique which explores multiple program behaviors all at once by collecting and solving symbolic path conditions over program paths. The technique has been recently extended with probabilistic reasoning. This approach computes the conditions to reach target program events of interest and uses model counting to quantify the fraction of the input domain satisfying these conditions thus computing the probability of event occurrence. This probabilistic information can be used for example to compute the reliability of an aircraft controller under different wind conditions (modeled probabilistically) or to quantify the leakage of sensitive data in a software system, using information theory metrics such as Shannon entropy. In this talk we review recent advances in symbolic execution and probabilistic reasoning and we discuss how they can be used to ensure the safety and security of software systems.
[Atmospheric modeling, Computational modeling, program diagnostics, probability, program behaviors, safety-critical software, Reliability theory, Probabilistic logic, software system safety, Cognition, inference mechanisms, event occurrence probability, probabilistic reasoning, Systematics, software system security, systematic program analysis technique, symbolic execution, program paths, Software systems, symbolic path conditions]
Algorithms for some infinite-state MDPs and stochastic games
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
I will survey a body of work, developed over the past decade or so, on algorithms for, and the computational complexity of, analyzing and model checking some important families of countably infinite-state Markov chains, Markov decision processes (MDPs), and stochastic games. These models arise by adding natural forms of recursion, branching, or a counter, to finite-state models, and they correspond to probabilistic/control/game extensions of classic automata-theoretic models like pushdown automata, context-free grammars, and one-counter automata. They subsume some classic stochastic processes such as multi-type branching processes and quasi-birth-death processes. They also provide a natural model for probabilistic procedural programs with recursion.
[infinite-state MDP, Computational modeling, pushdown automata, classic automata-theoretic models, one-counter automata, model checking, Markov decision processes, Automata, Games, Markov processes, context-free grammars, countably infinite-state Markov chains, Mathematical model, probabilistic procedural programs, stochastic games, Context modeling, computational complexity]
Quantitative semantics of the lambda calculus: Some generalisations of the relational model
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We present an overview of some recent work on the quantitative semantics of the &#x03BB;-calculus. Our starting point is the fundamental degenerate model of linear logic, the relational model MRel. We show that three quantitative semantics of the simply-typed &#x03BB;-calculus are equivalent: the relational semantics, HO/N game semantics, and the Taylor expansion semantics. We then consider two recent generalisations of the relational model: first, R-weighted relational models where R is a complete commutative semiring, as studied by Laird et al.; secondly, generalised species of structures, as introduced by Fiore et al. In each case, we briefly discuss some applications to quantitative analysis of higher-order programs.
[lambda calculus, Computational modeling, linear logic, higher-order programs, MRel relational model, Taylor series, Probabilistic logic, Calculus, HO/N game semantics, quantitative semantics, formal logic, Computer languages, R-weighted relational models, Semantics, Games, simply-typed &#x03BB;-calculus, relational model, quantitative analysis, Taylor expansion semantics]
Linear combinations of unordered data vectors
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Data vectors generalise finite multisets: they are finitely supported functions into a commutative monoid. We study the question whether a given data vector can be expressed as a finite sum of others, only assuming that 1) the domain is countable and 2) the given set of base vectors is finite up to permutations of the domain. Based on a succinct representation of the involved permutations as integer linear constraints, we derive that positive instances can be witnessed in a bounded subset of the domain. For data vectors over a group we moreover study when a data vector is reversible, that is, if its inverse is expressible using only nonnegative coefficients. We show that if all base vectors are reversible then the expressibility problem reduces to checking membership in finitely generated subgroups. Moreover, checking reversibility also reduces to such membership tests. These questions naturally appear in the analysis of counter machines extended with unordered data: namely, for data vectors over (&#x2124;d, +) expressibility directly corresponds to checking state equations for Coloured Petri nets where tokens can only be tested for equality. We derive that in this case, expressibility is in NP, and in P for reversible instances. These upper bounds are tight: they match the lower bounds for standard integer vectors (over singleton domains).
[Linear systems, Radiation detectors, Commutation, Petri nets, membership tests, integer linear constraints, singleton domains, Histograms, unordered data vectors, Upper bound, vectors, commutative monoid, Mathematical model, nonnegative coefficients, coloured Petri nets]
An interpretation of system F through bar recursion
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
There are two possible computational interpretations of second-order arithmetic: Girard's system F or Spector's bar recursion and its variants. While the logic is the same, the programs obtained from these two interpretations have a fundamentally different computational behavior and their relationship is not well understood. We make a step towards a comparison by defining the first translation of system F into a simply-typed total language with a variant of bar recursion. This translation relies on a realizability interpretation of second-order arithmetic. Due to Go&#x0308;del's incompleteness theorem there is no proof of termination of system F within second-order arithmetic. However, for each individual term of system F there is a proof in second-order arithmetic that it terminates, with its realizability interpretation providing a bound on the number of reduction steps to reach a normal form. Using this bound, we compute the normal form through primitive recursion. Moreover, since the normalization proof of system F proceeds by induction on typing derivations, the translation is compositional. The flexibility of our method opens the possibility of getting a more direct translation that will provide an alternative approach to the study of polymorphism, namely through bar recursion.
[Spector's bar recursion, computational interpretation, Go&#x0308;del's incompleteness theorem, Encoding, Indexes, Cost accounting, reduction steps, computational behavior, simply-typed total language, Semantics, Syntactics, Set theory, typing derivations, Girard's system, realizability interpretation, theorem proving, second-order arithmetic, normalization proof, Bars, computational complexity]
On the extension of computable real functions
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We investigate interrelationships among different notions from mathematical analysis, effective topology, and classical computability theory. Our main object of study is the class of computable functions defined over an interval with the boundary being a left-c.e. real number. We investigate necessary and sufficient conditions under which such functions can be computably extended. It turns out that this depends on the behavior of the function near the boundary as well as on the class of left-c.e. real numbers to which the boundary belongs, that is, how it can be constructed. Of particular interest a class of functions is investigated: sawtooth functions constructed from computable enumerations of c.e. sets.
[effective topology, computable real functions, classical computability theory, functions, computable functions, topology, c.e. sets, computability, Extraterrestrial measurements, Encoding, left-c.e. real number, Topology, Electronic mail, mathematical analysis, set theory, sawtooth functions, Mathematical analysis, necessary and sufficient conditions, Organizations, computable enumerations]
Logics for continuous reachability in Petri nets and vector addition systems with states
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
This paper studies sets of rational numbers definable by continuous Petri nets and extensions thereof. First, we identify a polynomial-time decidable fragment of existential FO(&#x211A;,+,&lt;;) and show that the sets of rationals definable in this fragment coincide with reachability sets of continuous Petri nets. Next, we introduce and study continuous vector addition systems with states (CVASS), which are vector addition systems with states in which counters may hold non-negative rational values, and in which the effect of a transition can be scaled by a positive rational number smaller or equal to one. This class strictly generalizes continuous Petri nets by additionally allowing for discrete control-state information. We prove that reachability sets of CVASS are equivalent to the sets of rational numbers definable in existential FO(&#x211A;,+,&lt;;) from which we can conclude that reachability in CVASS is NP-complete. Finally, our results explain and yield as corollaries a number of polynomial-time algorithms for decision problems that have recently been studied in the literature.
[positive rational number, reachability analysis, Radiation detectors, polynomial-time decidable fragment, Petri nets, nonnegative rational values, continuous Petri nets, CVASS reachability sets, continuous reachability, Standards, Computer science, discrete control-state information, vector addition systems, Semantics, continuous vector addition system-with-states, NP-complete problems, polynomial-time algorithms, decision problems, Mathematical model, existential FO, Artificial intelligence, computational complexity]
Foundation for a series of efficient simulation algorithms
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Compute the coarsest simulation preorder included in an initial preorder is used to reduce the resources needed to analyze a given transition system. This technique is applied on many models like Kripke structures, labeled graphs, labeled transition systems or even word and tree automata. Let (Q,&#x2192;) be a given transition system and &#x211B;<sub>init</sub> be an initial preorder over Q. Until now, algorithms to compute &#x211B;<sub>sim</sub>, the coarsest simulation included in &#x211B;<sub>init</sub>, are either memory efficient or time efficient but not both. In this paper we propose the foundation for a series of efficient simulation algorithms with the introduction of the notion of maximal transitions and the notion of stability of a preorder with respect to a coarser one. As an illustration we solve an open problem by providing the first algorithm with the best published time complexity, O(|P<sub>sim</sub>|.|&#x2192;|), and a bit space complexity in O(|P<sub>sim</sub>|2.log(|P<sub>sim</sub>|)+|Q|.log(|Q|)), with P<sub>sim</sub> the partition induced by &#x211B;<sub>sim</sub>.
[Kripke structures, Computational modeling, Radiation detectors, simulation, time complexity, Stability analysis, Partitioning algorithms, labeled graphs, coarsest simulation preorder, word automata, labeled transition systems, tree automata, Mathematical model, Time complexity, transition system, space complexity, computational complexity, simulation algorithms]
Separation for dot-depth two
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
The dot-depth hierarchy of Brzozowski and Cohen is a classification of all first-order definable languages. It rose to prominence following the work of Thomas, who established an exact correspondence with the quantifier alternation hierarchy of first-order logic: each level contains languages that can be defined with a prescribed number of quantifier blocks. One of the most famous open problems in automata theory is to obtain membership algorithms for all levels in this hierarchy. For a fixed level, the membership problem asks whether an input regular language belongs to this level. Despite a significant research effort, membership by itself has only been solved for low levels. Recently, a breakthrough was made by replacing membership with a more general problem called separation. This problem asks whether, for two input languages, there exists a third language in the investigated level containing the first language and disjoint from the second. The motivation for looking at separation is threefold: (1) while more difficult, it is more rewarding; (2) being more general, it provides a more convenient framework, and (3) all recent membership algorithms are actually reductions to separation for lower levels. This paper presents a separation algorithm for dot-depth 2. A crucial point is that while dot-depth 2 is our main application, we prove a much more general theorem. Indeed, dot-depth belongs to a family of hierarchies which all share the same generic construction process: starting from an initial class of languages called the basis, one applies generic operations to build new levels. We prove that for any such hierarchy whose basis is a finite class, level 1 has decidable separation. In the special case of dot-depth, this generic result can easily be lifted to level 2.
[formal languages, automata theory, Europe, first-order logic, dot-depth hierarchy, membership algorithms, first-order definable languages, dot-depth two, quantifier blocks, quantifier alternation hierarchy]
Foundational nonuniform (Co)datatypes for higher-order logic
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Nonuniform (or &#x201C;nested&#x201D; or &#x201C;heterogeneous&#x201D;) datatypes are recursively defined types in which the type arguments vary recursively. They arise in the implementation of finger trees and other efficient functional data structures. We show how to reduce a large class of nonuniform datatypes and codatatypes to uniform types in higher-order logic. We programmed this reduction in the Isabelle/HOL proof assistant, thereby enriching its specification language. Moreover, we derive (co)induction and (co)recursion principles based on a weak variant of parametricity.
[higher-order logic, recursively defined types, foundational nonuniform datatypes, Encoding, algebra, type arguments, Grammar, recursion principle, Standards, Computer science, formal logic, Information security, Binary trees, parametricity variant, induction principle, data structures, Isabelle/HOL proof assistant, specification language]
Common knowledge and multi-scale locality analysis in Cayley structures
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We investigate multi-agent epistemic modal logic with common knowledge modalities for groups of agents and obtain van Benthem style model-theoretic characterisations, in terms of bisimulation invariance of classical first-order logic over the non-elementary classes of (finite or arbitrary) common knowledge Kripke frames. The fixpoint character of common knowledge modalities and the ro&#x0302;le that reachability and transitive closures play for the derived accessibility relations take our analysis beyond classical model-theoretic terrain and technically pose a novel challenge to the analysis of model-theoretic games. Over and above the more familiar locality-based techniques we exploit a specific structure theory for specially adapted Cayley groups: through the association of agents with sets of generators, all epistemic frames can be represented up to bisimilarity by suitable Cayley groups with specific acyclicity properties; these support a locality analysis at different levels of granularity as induced by distance measures w.r.t. various coalitions of agents.
[Adaptation models, multi-agent systems, structure theory, Terminology, Analytical models, multiagent epistemic modal logic, accessibility relations, Semantics, bisimulation invariance, distance measures, bisimulation equivalence, van Benthem style model-theoretic characterisations, reachability, common knowledge Kripke frames, reachability analysis, transitive closures, classical first-order logic, game theory, epistemic frames, locality-based techniques, nonelementary classes, Standards, Cayley groups, common knowledge modalities, Games, acyclicity properties, model-theoretic games, knowledge modalities, Periodic structures]
Herbrand property, finite quasi-Herbrand models, and a Chandra-Merlin theorem for quantified conjunctive queries
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
A structure enjoys the Herbrand property if, whenever it satisfies an equality between some terms, these terms are unifiable. On such structures the expressive power of equalities becomes trivial, as their semantic satisfiability is reduced to a purely syntactic check. In this work, we introduce the notion of Herbrand property and develop it in a finite model-theoretic perspective. We provide, indeed, a canonical realization of the new concept by what we call quasi-Herbrand models and observe that, in stark contrast with the naive implementation of the property via standard Herbrand models, their universe can be finite even in presence of functions in the vocabulary. We exploit this feature to decide and collapse the general and finite version of the satisfiability and entailment problems for previously unsettled fragments of first-order logic. We take advantage of the Herbrand property also to establish novel and tight complexity results for the aforementioned decision questions. In particular, we show that the finite containment problem for quantified conjunctive queries is NPTIME-complete, tightening along two dimensions the known 3EXPTIME upper bound for the general version of the problem (Chen, Madelaine, and Martin, LICS'08). We finally present an alternative view on this result by generalizing to such queries the classic characterization of conjunctive query containment via polynomial-time verifiable homomorphisms (Chandra and Merlin, STOC'77).
[finite containment, Vocabulary, quasiHerbrand models, NPTIME-complete, computability, conjunctive query containment, Complexity theory, query processing, canonical realization, vocabulary, quantified conjunctive queries, Semantics, Mathematical model, equality, 3EXPTIME upper bound, polynomial-time verifiable homomorphisms, tight complexity, semantic satisfiability, Computational modeling, purely syntactic check, standard Herbrand models, entailment problems, Herbrand property, finite model-theoretic perspective, Standards, Syntactics, computational complexity]
Bar induction: The good, the bad, and the ugly
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We present an extension of the computation system and logic of the Nuprl proof assistant with intuitionistic principles, namely versions of Brouwer's bar induction principle, which is equivalent to transfinite induction. We have substantially extended the formalization of Nuprl's type theory within the Coq proof assistant to show that two such bar induction principles are valid w.r.t. Nuprl's semantics (the Good): one for sequences of numbers that involved only minor changes to the system, and a more general one for sequences of name-free (the Ugly) closed terms that involved adding a limit constructor to Nuprl's term syntax in our model of Nuprl's logic. We have proved that these additions preserve Nuprl's key metatheoretical properties such as consistency. Finally, we show some new insights regarding bar induction, such as the non-truncated version of bar induction on monotone bars is intuitionistically false (the Bad).
[Fans, monotone bars, Brouwer's bar induction principle, Coq proof assistant, Nuprl's semantics, Mathematics, Electronic mail, programming language semantics, Standards, formal logic, Nuprl's type theory, Nuprl's logic, Nuprl's key metatheoretical properties, intuitionistically false bar induction, Semantics, intuitionistic principles, transfinite induction, Syntactics, name-free closed terms, Nuprl's term syntax, theorem proving, Nuprl proof assistant, Bars, bar induction principles]
Gödel logic: From natural deduction to parallel computation
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Propositional Go&#x0308;del logic G extends intuitionistic logic with the non-constructive principle of linearity (A &#x2192; B) &#x22C1; (B &#x2192; A). We introduce a Curry-Howard correspondence for G and show that a simple natural deduction calculus can be used as a typing system. The resulting functional language extends the simply typed &#x03BB;-calculus via a synchronous communication mechanism between parallel processes, which increases its expressive power. The normalization proof employs original termination arguments and proof transformations implementing forms of code mobility. Our results provide a computational interpretation of G, thus proving A. Avron's 1991 thesis.
[lambda calculus, synchronous communication mechanism, Particle separators, code mobility, intuitionistic logic, Calculus, type theory, proof transformations, Standards, propositional Go&#x0308;del logic, natural deduction calculus, Computer languages, nonconstructive linearity principle, Linearity, Communication channels, Curry-Howard correspondence, functional language, simply-typed &#x03BB;-calculus, theorem proving, parallel processes, normalization proof, functional languages, termination arguments]
Higher-order parity automata
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We introduce a notion of higher-order parity automaton which extends to infinitary simply-typed &#x03BB;-terms the traditional notion of parity tree automaton on infinitary ranked trees. Our main result is that the acceptance of an infinitary &#x03BB;-term by a higher-order parity automaton A is decidable, whenever the infinitary &#x03BB;-term is generated by a finite and simply-typed &#x03BB;Y-term. The decidability theorem is established by combining ideas coming from linear logic, from denotational semantics and from infinitary rewriting theory.
[rewriting systems, finite automata, simply-typed &#x03BB;Y-term, parity tree automaton, linear logic, trees (mathematics), programming language semantics, infinitary &#x03BB;-term, infinitary ranked trees, infinitary rewriting theory, decidability, higher-order parity automata, decidability theorem, denotational semantics, simply-typed &#x03BB;-terms, finite typed &#x03BB;Y-term]
Large scale geometries of infinite strings
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We introduce geometric consideration into the theory of formal languages. We aim to shed light on our understanding of global patterns that occur on infinite strings. We utilise methods of geometric group theory. Our emphasis is on large scale geometries. Two infinite strings have the same large scale geometry if there are colour preserving bi-Lipschitz maps with distortions between the strings. Call these maps quasi-isometries. Introduction of large scale geometries poses several questions. The first question asks to study the partial order induced by quasi-isometries. This partial order compares large scale geometries; as such it presents an algebraic tool for classification of global patterns. We prove there is a greatest large scale geometry and infinitely many minimal large scale geometries. The second question is related to understanding the quasi-isometric maps on various classes of strings. The third question investigates the sets of large scale geometries of strings accepted by computational models, e.g. Bu&#x0308;chi automata. We provide an algorithm that describes large scale geometries of strings accepted by Bu&#x0308;chi automata. This links large scale geometries with automata theory. The fourth question studies the complexity of the quasi-isometry problem. We show the problem is &#x03A3;<sub>3</sub>0-complete thus providing a bridge with computability theory. Finally, the fifth question asks to build algebraic structures that are invariants of large scale geometries. We invoke asymptotic cones, a key concept in geometric group theory, defined via model-theoretic notion of ultra-product. Partly, we study asymptotic cones of algorithmically random strings thus connecting the topic with algorithmic randomness.
[pattern classification, formal languages, automata theory, Formal languages, Color, computability, Extraterrestrial measurements, quasi-isometry problem complexity, Complexity theory, infinite strings, Geometry, group theory, geometric group theory, algebraic tool, large-scale geometries, Automata, Buchi automata, colour preserving bi-Lipschitz maps, computability theory, computational complexity, global pattern classification]
Regular separability of one counter automata
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
The regular separability problem asks, for two given languages, if there exists a regular language including one of them but disjoint from the other. Our main result is decidability, and PSPACE-completeness, of the regular separability problem for languages of one counter automata without zero tests (also known as one counter nets). This contrasts with undecidability of the regularity problem for one counter nets, and with undecidability of the regular separability problem for one counter automata, which is our second result.
[formal languages, regular separability problem, Radiation detectors, Particle separators, automata theory, Formal languages, PSPACE-completeness, Encoding, Complexity theory, Standards, regular language, one-counter automata, Automata, regularity problem undecidability]
Learning first-order definable concepts over structures of small degree
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We consider a declarative framework for machine learning where concepts and hypotheses are defined by formulas of a logic over some &#x201C;background structure&#x201D;. We show that within this framework, concepts defined by first-order formulas over a background structure of at most polylogarithmic degree can be learned in polylogarithmic time in the &#x201C;probably approximately correct&#x201D; learning sense.
[Algorithm design and analysis, first-order formulas, first-order definable concept learning, Machine learning algorithms, Computational modeling, machine learning, Training, Support vector machines, formal logic, polylogarithmic degree, background structure, Approximation algorithms, declarative framework, learning (artificial intelligence), polylogarithmic time, Periodic structures, computational complexity, probably-approximately correct learning]
Descriptive complexity of linear equation systems and applications to propositional proof complexity
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We prove that the solvability of systems of linear equations and related linear algebraic properties are definable in a fragment of fixed-point logic with counting that only allows polylogarithmically many iterations of the fixed-point operators. This enables us to separate the descriptive complexity of solving linear equations from full fixed-point logic with counting by logical means. As an application of these results, we separate an extension of first-order logic with a rank operator from fixed-point logic with counting, solving an open problem due to Holm [21]. We then draw a connection from this work in descriptive complexity theory to graph isomorphism testing and propositional proof complexity. Answering an open question from [7], we separate the strength of certain algebraic graph-isomorphism tests. This result can also be phrased as a separation of the algebraic propositional proof systems &#x201C;Nullstellensatz&#x201D; and &#x201C;monomial PC&#x201D;.
[Vocabulary, graph theory, fixed-point operators, first-order logic, Transforms, descriptive complexity, computability, Complexity theory, algebraic graph-isomorphism tests, linear equations systems, rank operator, linear algebraic properties, algebraic propositional proof systems, monomial PC, theorem proving, Mathematical model, linear algebra, Testing, fixed-point logic, Encoding, Nullstellensatz, mathematical operators, propositional proof complexity, descriptive complexity theory, Distance measurement, computational complexity]
Definability of summation problems for Abelian groups and semigroups
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We study the descriptive complexity of summation problems in Abelian groups and semigroups. In general, an input to the summation problem consists of an Abelian semigroup G, explicitly represented by its multiplication table, and a subset X of G. The task is to determine the sum over all elements of X. Algorithmically this is a very simple problem. If the elements of X come in some order, then we can process these elements along that order and calculate the sum in a trivial way. However, what makes this fundamental problem so interesting for us is that from the viewpoint of logical definability its tractability is much more delicate. If we consider the semigroup G as an abstract structure and X as an abstract set, without a linear order and hence without a canonical way to process the elements one by one, then it is unclear how to define the sum in any logic that does not have the power to quantify over a linear order. Indeed the trivial summation algorithm cannot be expressed in any polynomial-time logic or, in fact, in any computational model which works on abstract mathematical structures in an isomorphism-invariant way without violating polynomial resource bounds. The surprising difficulty, in terms of logical definability, of this basic mathematical problem is the reason why Ben Rossman asked, more than ten years ago, whether it can be expressed in the logic Choiceless Polynomial Time with counting (CPT). Note that, to date, CPT is one of the most powerful known candidates for a logic that might be capable of defining every polynomial-time property of finite structures. In this paper we clarify the status of the definability for the summation problem for Abelian groups and semigroups in important polynomial-time logics. In our first main result we show that the problem can be defined in fixed-point logic with counting (FPC). Since FPC is contained in CPT this settles Rossman's question. Our proof is based on a dynamic programming approach and heavily uses the counting mechanism of FPC. In our second main result we give a matching lower bound and show that the use of counting operators cannot be avoided: the summation problem, even over Abelian groups, cannot be defined in pure fixed-point logic without counting. Our proof is based on a probabilistic argument.
[fixed-point logic with counting, Computational modeling, CPT, dynamic programming approach, choiceless polynomial time with counting, dynamic programming, summation problems, Probabilistic logic, Complexity theory, Computer science, Integrated circuits, formal logic, group theory, Abelian semigroups, Abelian groups, polynomial-time logics, FPC, probabilistic argument, Dynamic programming, Mathematical model]
Timed pushdown automata and branching vector addition systems
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We prove that non-emptiness of timed register pushdown automata is decidable in doubly exponential time. This is a very expressive class of automata, whose transitions may involve state and top-of-stack clocks with unbounded differences. It strictly subsumes pushdown timed automata of Bouajjani et al., dense-timed pushdown automata of Abdulla et al., and orbit-finite timed register pushdown automata of Clemente and Lasota. Along the way, we prove two further decidability results of independent interest: for non-emptiness of least solutions to systems of equations over sets of integers with addition, union and intersections with &#x2115; and -&#x2115;, and for reachability in one-dimensional branching vector addition systems with states and subtraction, both in exponential time.
[reachability analysis, orbit-finite timed register pushdown automata, pushdown automata, doubly exponential time, Orbits, Registers, one-dimensional branching vector addition systems, intersection operation, addition operation, union operation, Upper bound, vectors, Handheld computers, decidability, automata nonemptiness, Automata, reachability, Mathematical model, least solutions non-emptiness, Clocks, computational complexity, dense-timed pushdown automata]
Fibred fibration categories
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We introduce fibred type-theoretic fibration categories which are fibred categories between categorical models of Martin-Lo&#x0308;f type theory. Fibred type-theoretic fibration categories give a categorical description of logical predicates for identity types. As an application, we show a relational parametricity result for homotopy type theory. As a corollary, it follows that every closed term of type of polymorphic endofunctions on a loop space is homotopic to some iterated concatenation of a loop.
[loop space, relational parametricity, Tools, type theory, Electronic mail, Standards, logical predicates, polymorphic endofunctions, fibred type-theoretic fibration categories, homotopy type theory, Semantics, Syntactics, category theory, Hilbert space, homotopic closed term, Mathematical model, identity types, iterated loop concatenation, Martin-Lof type theory]
The logic of counting query answers
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We consider the problem of counting the number of answers to a first-order formula on a finite structure. We present and study an extension of first-order logic in which algorithms for this counting problem can be naturally and conveniently expressed, in senses that are made precise and that are motivated by the wish to understand tractable cases of the counting problem.
[query answer counting problem, Computational modeling, trees (mathematics), first-order logic, Complexity theory, Database languages, finite structure, formal logic, query processing, Query processing, Model checking, Syntactics, computational complexity]
Enumeration reducibility in closure spaces with applications to logic and algebra
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
In many instances in first order logic or computable algebra, classical theorems show that many problems are undecidable for general structures, but become decidable if some rigidity is imposed on the structure. For example, the set of theorems in many finitely axiomatisable theories is nonrecursive, but the set of theorems for any finitely axiomatisable complete theory is recursive. Finitely presented groups might have an nonrecursive word problem, but finitely presented simple groups have a recursive word problem. In this article we introduce a topological framework based on closure spaces to show that many of these proofs can be obtained in a similar setting. We will show in particular that these statements can be generalized to cover arbitrary structures, with no finite or recursive presentation/axiomatization. This generalizes in particular work by Kuznetsov and others. Examples from first order logic and symbolic dynamics will be discussed at length.
[recursive word problem, Vocabulary, finitely axiomatisable theories, Lattices, topology, Topology, Indexes, topological framework, Computability, formal logic, nonrecursive word problem, Algebra, process algebra, computable algebra, first order logic, Universal Algebra, Computable Mathematics, Logic, closure spaces, Symbolic Dynamics]
The limits of SDP relaxations for general-valued CSPs
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
It has been shown that for a general-valued constraint language &#x0393; the following statements are equivalent: (1) any instance of VCSP(&#x0393;) can be solved to optimality using a constant level of the Sherali-Adams LP hierarchy; (2) any instance of VCSP(&#x0393;) can be solved to optimality using the third level of the Sherali-Adams LP hierarchy; (3) the support of &#x0393; satisfies the &#x201C;bounded width condition&#x201D;, i.e., it contains weak near-unanimity operations of all arities. We show that if the support of &#x0393; violates the bounded with condition then not only is VCSP(&#x0393;) not solved by a constant level of the Sherali-Adams LP hierarchy but it is also not solved by &#x03A9;(n) levels of the Lasserre SDP hierarchy (also known as the sum-of-squares SDP hierarchy). For &#x0393; corresponding to linear equations in an Abelian group, this result follows from existing work on inapproximability of Max-CSPs. By a breakthrough result of Lee, Raghavendra, and Steurer [STOC'15], our result implies that for any &#x0393; whose support violates the bounded width condition no SDP relaxation of polynomial-size solves VCSP(&#x0393;). We establish our result by proving that various reductions preserve exact solvability by the Lasserre SDP hierarchy (up to a constant factor in the level of the hierarchy). Our results hold for general-valued constraint languages, i.e., sets of functions on a fixed finite domain that take on rational or infinite values, and thus also hold in notable special cases of {0, &#x221E;}-valued languages (CSPs), {0, 1}-valued languages (Min-CSPs/Max-CSPs), and Qvalued languages (finite-valued CSPs).
[formal languages, VCSP, minCSP-maxCSP, Abelian group, finite-valued CSP, Europe, Programming, Linear programming, linear programming, Complexity theory, Optimization, maxCSP inapproximability, general-valued constraint language, constraint satisfaction problems, Lasserre SDP hierarchy, general-valued CSP, SDP relaxations, Sherali-Adams LP hierarchy, Robustness, Q-valued languages, Mathematical model, bounded width condition, linear equations]
Cut-free completeness for modal mu-calculus
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We present two finitary cut-free sequent calculi for the modal μ-calculus. One is a variant of Kozen's axiomatisation in which cut is replaced by a strengthening of the induction rule for greatest fixed point. The second calculus derives annotated sequents in the style of Stirling's `tableau proof system with names' (2014) and features a generalisation of the &#x03BD;-regeneration rule that allows discharging open assumptions. Soundness and completeness for the two calculi is proved by establishing a sequence of embeddings between proof systems, starting at Stirling's tableau-proofs and ending at the original axiomatisation of the μ-calculus due to Kozen. As a corollary we obtain a new, constructive, proof of completeness for Kozen's axiomatisation which avoids the usual detour through automata and games.
[greatest fixed point, Calculus, calculus, Cost accounting, induction rule, modal μ-calculus, Reactive power, Semantics, Automata, Kozen's axiomatisation, Games, Syntactics, Stirling's tableau-proof system, &#x03BD;-regeneration rule, theorem proving, cut-free completeness, games. finitary cut-free sequent calculi]
Dual-context calculi for modal logic
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We show how to derive natural deduction systems for the necessity fragment of various constructive modal logics by exploiting a pattern found in sequent calculi. The resulting systems are dual-context systems, in the style pioneered by Girard, Barber, Plotkin, Pfenning, Davies, and others. This amounts to a full extension of the Curry-Howard-Lambek correspondence to the necessity fragments of a constructive variant of the modal logics K, K4, GL, T, and S4. We investigate the metatheory of these calculi, as well as their categorical semantics. Finally, we speculate on their computational interpretation.
[dual-context calculi, computational interpretation, constructive modal logics, categorical semantics, Calculus, Diamond, sequent calculi, Electronic mail, necessity fragment, programming language semantics, metatheory, formal logic, Computer languages, Curry-Howard-Lambek extension, Semantics, constructive variant, natural deduction systems, Syntactics, duality (mathematics), dual-context systems]
Computing quantiles in Markov chains with multi-dimensional costs
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Probabilistic systems that accumulate quantities such as energy or cost are naturally modelled by cost chains, which are Markov chains whose transitions are labelled with a vector of numerical costs. Computing information on the probability distribution of the total accumulated cost is a fundamental problem in this model. In this paper, we study the so-called cost problem, which is to compute quantiles of the total cost, such as the median cost or the probability of large costs. While it is an open problem whether such probabilities are always computable or even rational, we present an algorithm that allows to approximate the probabilities with arbitrary precision. The algorithm is simple to state and implement, and exploits strong results from graph theory such as the so-called BEST theorem for efficiently computing the number of Eulerian circuits in a directed graph. Moreover, our algorithm enables us to show that a decision version of the cost problem lies in the counting hierarchy, a counting analogue to the polynomial-time hierarchy that contains the latter and is included in PSPACE. Finally, we demonstrate the applicability of our algorithm by evaluating it experimentally.
[cost problem, Computational modeling, total accumulated cost, cost chains, BEST theorem, Probabilistic logic, Markov chains, Probability distribution, Complexity theory, Eulerian circuits, polynomial-time hierarchy, directed graphs, quantiles computing, numerical costs, directed graph, Markov processes, probability distribution, Approximation algorithms, Numerical models, probabilistic systems, computational complexity, multidimensional costs]
Riesz Modal logic for Markov processes
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We investigate a modal logic for expressing properties of Markov processes whose semantics is real-valued, rather than Boolean, and based on the mathematical theory of Riesz spaces. We use the duality theory of Riesz spaces to provide a connection between Markov processes and the logic. This takes the form of a duality between the category of coalgebras of the Radon monad (modeling Markov processes) and the category of a new class of algebras (algebraizing the logic) which we call modal Riesz spaces. As a result, we obtain a sound and complete axiomatization of the Riesz Modal logic.
[Radon, Lattices, modal Riesz spaces, Extraterrestrial measurements, Probabilistic logic, mathematical theory, Calculus, algebra, Topology, modal logic, Radon monad, real-valued semantics, formal logic, coalgebra category, duality theory, complete axiomatization, Markov processes, category theory, duality (mathematics)]
Succinct progress measures for solving parity games
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
The recent breakthrough paper by Calude et al. has given the first algorithm for solving parity games in quasi-polynomial time, where previously the best algorithms were mildly subexponential. We devise an alternative quasi-polynomial time algorithm based on progress measures, which allows us to reduce the space required from quasi-polynomial to nearly linear. Our key technical tools are a novel concept of ordered tree coding, and a succinct tree coding result that we prove using bounded adaptive multi-counters, both of which are interesting in their own right.
[quasipolynomial time algorithm, trees (mathematics), game theory, succinct progress measures, ordered tree coding concept, parity games, succinct tree coding, bounded adaptive multicounters, computational complexity]
Generalised species of rigid resource terms
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
This paper introduces a variant of the resource calculus, the rigid resource calculus, in which a permutation of elements in a bag is distinct from but isomorphic to the original bag. It is designed so that the Taylor expansion within it coincides with the interpretation by generalised species of Fiore et al., which generalises both Joyal's combinatorial species and Girard's normal functors, and which can be seen as a proof-relevant extension of the relational model. As an application, we prove the commutation between computing Bo&#x0308;hm trees and (standard) Taylor expansions for a particular nondeterministic calculus.
[Computational modeling, nondeterministic calculus, trees (mathematics), Taylor series, rigid resource calculus, Calculus, generalised species, calculus, Standards, Joyal's combinatorial species, Girard's normal functors, Semantics, Games, Vegetation, Taylor expansion, relational model, theorem proving, proof-relevant extension, Bo&#x0308;hm trees]
A fine-grained hierarchy of hard problems in the separated fragment
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Recently, the separated fragment (SF) has been introduced and proved to be decidable. Its defining principle is that universally and existentially quantified variables may not occur together in atoms. The known upper bound on the time required to decide SF's satisfiability problem is formulated in terms of quantifier alternations: Given an SF sentence &#x2203;z&#x20D7;&#x2200;x&#x20D7;<sub>1</sub>&#x2203;y&#x20D7;<sub>1</sub>...&#x2200;x&#x20D7;<sub>n</sub>&#x2203;y&#x20D7;<sub>n</sub>.&#x03C8; in which &#x03C8; is quantifier free, satisfiability can be decided in non-deterministic n-fold exponential time. In the present paper, we conduct a more fine-grained analysis of the complexity of SF-satisfiability. We derive an upper and a lower bound in terms of the degree &#x2202; of interaction of existential variables (short: degree)-a novel measure of how many separate existential quantifier blocks in a sentence are connected via joint occurrences of variables in atoms. Our main result is the k-NEXPTIME-completeness of the satisfiability problem for the set SF<sub>&#x2202;&#x2264;k</sub> of all SF sentences that have degree k or smaller. Consequently, we show that SF-satisfiability is non-elementary in general, since SF is defined without restrictions on the degree. Beyond trivial lower bounds, nothing has been known about the hardness of SF-satisfiability so far.
[Atomic measurements, k-NEXPTIME-completeness, existential quantifier blocks, Computational modeling, nonelementary SF-satisfiability, SF-satisfiability complexity, computability, fine-grained analysis, separated fragment, Complexity theory, lower bound, Standards, existential variables, existentially quantified variables, nondeterministic n-fold exponential time, Upper bound, universally quantified variables, SF sentence&#x2203;~z, SF-satisfiability hardness, joint occurrences, Informatics, Lenses, computational complexity]
A categorical semantics for causal structure
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We present a categorical construction for modelling both definite and indefinite causal structures within a general class of process theories that include classical probability theory and quantum theory. Unlike prior constructions within categorical quantum mechanics, the objects of this theory encode fine-grained causal relationships between subsystems and give a new method for expressing and deriving consequences for a broad class of causal structures. To illustrate this point, we show that this framework admits processes with definite causal structures, namely one-way signalling processes, non-signalling processes, and quantum n-combs, as well as processes with indefinite causal structure, such as the quantum switch and the process matrices of Oreshkov, Costa, and Brukner. We furthermore give derivations of their operational behaviour using simple, diagrammatic axioms.
[process theories, classical probability theory, quantum n-combs, probability, categorical semantics, fine-grained causal relationships, quantum theory, indefinite causal structure, one-way signalling processes, programming language semantics, categorical construction, definite causal structures, indefinite causal structures modelling, operational behaviour, definite causal structures modelling, category theory, simple diagrammatic axioms, nonsignalling processes]
On delay and regret determinization of max-plus automata
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Decidability of the determinization problem for weighted automata over the semiring (&#x2124;&#x222A;{-&#x221E;}, max; +), WA for short, is a long-standing open question. We propose two ways of approaching it by constraining the search space of deterministic WA: k-delay and r-regret. A WA N is k-delay determinizable if there exists a deterministic automaton D that defines the same function as N and for all words &#x03B1; in the language of N, the accepting run of D on &#x03B1; is always at most k-away from a maximal accepting run of N on &#x03B1;. That is, along all prefixes of the same length, the absolute difference between the running sums of weights of the two runs is at most k. A WA N is r-regret determinizable if for all words &#x03B1; in its language, its non-determinism can be resolved on the fly to construct a run of N such that the absolute difference between its value and the value assigned to &#x03B1; by N is at most r. We show that a WA is determinizable if and only if it is k-delay determinizable for some k. Hence deciding the existence of some k is as difficult as the general determinization problem. When k and r are given as input, the k-delay and r-regret determinization problems are shown to be EXPTIME-complete. We also show that determining whether a WA is r-regret determinizable for some r is in EXPTIME.
[Regret, Transducers, Weighted Automata, automata theory, weighted automata, Observers, EXPTIME-complete, IEEE Fellows, Determinization, r-regret, decidability, k-delay, Automata, Games, general determinization problem, Approximation algorithms, Delays, max-plus automata, deterministic automaton, computational complexity]
The clocks are ticking: No more delays!
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Guarded recursion in the sense of Nakano allows general recursive types and terms to be added to type theory without breaking consistency. Recent work has demonstrated applications of guarded recursion such as programming with codata, reasoning about coinductive types, as well as constructing and reasoning about denotational models of general recursive types. Guarded recursion can also be used as an abstract form of step-indexing for reasoning about programming languages with advanced features. Ultimately, we would like to have an implementation of a type theory with guarded recursion in which all these applications can be carried out and machine-checked. In this paper, we take a step towards this goal by devising a suitable reduction semantics. We present Clocked Type Theory, a new type theory for guarded recursion that is more suitable for reduction semantics than the existing ones. We prove confluence, strong normalisation and canonicity for its reduction semantics, constructing the theoretical basis for a future implementation. We show how coinductive types as exemplified by streams can be encoded, and derive that the type system ensures productivity of stream definitions.
[Productivity, clocked type theory, Programming, guarded recursion, reduction semantics, Cognition, Calculus, type theory, programming languages, Computer languages, Semantics, denotational models, Clocks]
Revisiting reachability in timed automata
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We revisit a fundamental result in real-time verification, namely that the binary reachability relation between configurations of a given timed automaton is definable in linear arithmetic over the integers and reals. In this paper we give a new and simpler proof of this result, building on the well-known reachability analysis of timed automata involving difference bound matrices. Using this new proof, we give an exponential-space procedure for model checking the reachability fragment of the logic parametric TCTL. Finally we show that the latter problem is NEXPTIME-hard.
[TCTL, reachability analysis, exponential-space procedure, automata theory, linear arithmetic, NEXPTIME-hard, Difference Bound Matrices, Reachability, Integrated circuits, Model Checking, Linear Arithmetic, Timed automata, Automata, timed automata, binary reachability relation, computational complexity]
Uniform, integral and efficient proofs for the determinant identities
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We give a uniform and integral version of the short propositional proofs for the determinant identities demonstrated over GF(2) in Hrubes&#x030C;-Tzameret [9]. Specifically, we show that the multiplicativity of the determinant function over the integers is provable in the bounded arithmetic theory VNC2, which is a first-order theory corresponding to the complexity class NC2. This also establishes the existence of uniform polynomial-size and O(log2n)-depth Circuit-Frege (equivalently, Extended Frege) proofs over the integers, of the basic determinant identities (previous proofs hold only over GF(2)). In doing so, we give uniform NC2-algorithms for homogenizing algebraic circuits, balancing algebraic circuits (given as input an upper bound on the syntactic-degree of the circuit), and converting circuits with divisions into circuits with a single division gate-all (&#x03A3;<sub>1</sub>B-) definable in VNC2. This also implies an NC2-algorithm for evaluating algebraic circuits of any depth.
[uniform proof, determinant identities, first-order theory, complexity class, Cognition, algebra, Complexity theory, Standards, determinant function, Computer science, short propositional proofs, algebraic circuits, Upper bound, Logic gates, Parallel processing, polynomial-size proof, NC2-algorithms, computational complexity, bounded arithmetic theory]
Parity objectives in countable MDPs
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We study countably infinite MDPs with parity objectives, and special cases with a bounded number of colors in the Mostowski hierarchy (including reachability, safety, Bu&#x0308;chi and co-Bu&#x0308;chi). In finite MDPs there always exist optimal memoryless deterministic (MD) strategies for parity objectives, but this does not generally hold for countably infinite MDPs. In particular, optimal strategies need not exist. For countable infinite MDPs, we provide a complete picture of the memory requirements of optimal (resp., c-optimal) strategies for all objectives in the Mostowski hierarchy. In particular, there is a strong dichotomy between two different types of objectives. For the first type, optimal strategies, if they exist, can be chosen MD, while for the second type optimal strategies require infinite memory. (I.e., for all objectives in the Mostowski hierarchy, if finite-memory randomized strategies suffice then also MD-strategies suffice.) Similarly, some objectives admit c-optimal MD-strategies, while for others c-optimal strategies require infinite memory. Such a dichotomy also holds for the subclass of countably infinite MDPs that are finitely branching, though more objectives admit MD-strategies here.
[countable MDPs, countable infinite MDP, Complexity theory, set theory, bounded colors, memory requirement, statistical distributions, formal logic, second type optimal strategies, safety, Safety, reachability, strategies, Color, Probabilistic logic, &#x03B5;-optimal MD-strategies, randomised algorithms, finite-memory randomized strategies, Markov decision processes, Memory management, Mostowski hierarchy, Games, Markov processes, co-Buchi, parity objectives]
Polynomial automata: Zeroness and applications
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We introduce a generalisation of weighted automata over a field, called polynomial automata, and we analyse the complexity of the Zeroness Problem in this model, that is, whether a given automaton outputs zero on all words. While this problem is non-primitive recursive in general, we highlight a subclass of polynomial automata for which the Zeroness Problem is primitive recursive. Refining further, we identify a subclass of affine VAS for which coverability is in 2EXPSPACE. We also use polynomial automata to obtain new proofs that equivalence of streaming string transducers is decidable, and that equivalence of copyless streaming string transducers is in PSPACE.
[streaming string transducers, polynomial automata, Transducers, automata theory, polynomials, Petri nets, weighted automata, Complexity theory, Registers, Standards, Upper bound, Automata, zeroness problem, computational complexity]
On the axiomatizability of quantitative algebras
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Quantitative algebras (QAs) are algebras over metric spaces defined by quantitative equational theories as introduced by us in 2016. They provide the mathematical foundation for metric semantics of probabilistic, stochastic and other quantitative systems. This paper considers the issue of axiomatizability of QAs. We investigate the entire spectrum of types of quantitative equations that can be used to axiomatize theories: (i) simple quantitative equations; (ii) Horn clauses with no more than c equations between variables as hypotheses, where c is a cardinal and (iii) the most general case of Horn clauses. In each case we characterize the class of QAs and prove variety/quasivariety theorems that extend and generalize classical results from model theory for algebras and first-order structures.
[quantitative algebra axiomatizability, mathematical foundation, quantitative equations, Extraterrestrial measurements, Cognition, algebra, variety-quasivariety theorems, Standards, quantitative equational theories, quantitative systems, Algebra, Semantics, first-order structures, Mathematical model, QA axiomatizability]
Infinitary intersection types as sequences: A new answer to Klop's problem
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We provide a type-theoretical characterization of weakly-normalizing terms in an infinitary lambda-calculus. We adapt for this purpose the standard quantitative (with non-idempotent intersections) type assignment system of the lambda-calculus to our infinite calculus. Our work provides a positive answer to a semi-open question known as Klop's Problem, namely, finding out if there is a type system characterizing the set of hereditary head-normalizing (HHN) lambda-terms. Tatsuta showed in 2007 that HHN could not be characterized by a finite type system. We prove that an infinitary type system endowed with a validity condition called approximability can achieve it. As it turns out, approximability cannot be expressed when intersection is represented by means of multisets. Multisets are then replaced coinductively by sequences of types indexed by integers, thus defining a type system called System S.
[Klop problem, lambda calculus, HHN lambda-terms, Europe, Calculus, Electronic mail, Grammar, set theory, Noise measurement, infinitary lambda-calculus, Standards, hereditary head-normalizing, infinitary intersection types, type-theoretical characterization, Vegetation, multisets, quantitative type assignment system]
Foundations of information integration under bag semantics
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
During the past several decades, the database theory community has successfully investigated several different facets of the principles of database systems, including the development of various data models, the systematic exploration of the expressive power of database query languages, and, more recently, the study of the foundations of information integration via schema mappings. For the most part, all these investigations have been carried out under set semantics, that is, both the database relations and the answers to database queries are sets. In contrast, SQL deploys bag (multiset) semantics and, as a result, theory and practice diverge at this crucial point. Our main goal in this paper is to embark on the development of the foundations of information integration under bag semantics, thus taking the first step towards bridging the gap between theory and practice in this area. Our first contribution is conceptual, namely, we give rigorous bag semantics to GLAV mappings and to the certain answers of conjunctive queries in the context of data exchange and data integration. In fact, we introduce and explore two different versions of bag semantics that, intuitively, correspond to the maximum-based union of bags and to the sum-based union of bags. After this, we establish a number of technical results, including results about the computational complexity of the certain answers of conjunctive queries under bag semantics and about the existence and computation of universal solutions under these two versions of bag semantics. Our results reveal that the adoption of more realistic semantics comes at a price, namely, algorithmic problems in data exchange and data integration that were tractable under set semantics become intractable under bag semantics.
[data exchange, bag semantics, Complexity theory, database management systems, Database languages, SQL, query processing, database theory community, Structured Query Languages, maximum-based union of bags, sum-based union of bags, Semantics, information integration, Data integration, Data models, Database systems, schema mappings, database queries, database systems principles, data integration, GLAV mappings]
Perfect half space games
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We introduce perfect half space games, in which the goal of Player 2 is to make the sums of encountered multi-dimensional weights diverge in a direction which is consistent with a chosen sequence of perfect half spaces (chosen dynamically by Player 2). We establish that the bounding games of Jurdzin&#x0301;ski et al. (ICALP 2015) can be reduced to perfect half space games, which in turn can be translated to the lexicographic energy games of Colcombet and Niwin&#x0301;ski, and are positionally determined in a strong sense (Player 2 can play without knowing the current perfect half space). We finally show how perfect half space games and bounding games can be employed to solve multi-dimensional energy parity games in pseudo-polynomial time when both the numbers of energy dimensions and of priorities are fixed, regardless of whether the initial credit is given as part of the input or existentially quantified. This also yields an optimal 2-EXPTIME complexity with given initial credit, where the best known upper bound was non-elementary.
[bounding games, perfect half space games, multidimensional energy parity games, optimal 2-EXPTIME complexity, lexicographic energy games, multidimensional weights, game theory, pseudopolynomial time, computational complexity]
The homomorphism problem for regular graph patterns
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
The evaluation of conjunctive regular path queries - which form the navigational core of the query languages for graph databases - raises challenges in the context of the homomorphism problem that are not fully addressed by existing techniques. We start a systematic investigation of such challenges using a notion of homomorphism for regular graph patterns (RGPs). We observe that the RGP homomorphism problem cannot be reduced to known instances of the homomorphism problem, and new techniques need to be developed for its study. We first show that the non-uniform version of the problem is computationally harder than for the usual homomorphism problem. By establishing a connection between both problems, in turn, we postulate a dichotomy conjecture, analogous to the algebraic dichotomy conjecture held in CSP. We also look at which structural restrictions on left-hand side instances of the RGP homomorphism problem ensure efficiency. We study restrictions based on the notion of bounded treewidth modulo equivalence, which characterizes tractability for the usual homomorphism notion. We propose two such notions, based on different interpretations of RGP equivalence, and show that they both ensure the efficiency of the RGP homomorphism problem.
[CSP, formal languages, Navigation, algebraic dichotomy conjecture, graph theory, Relational databases, conjunctive regular path query evaluation, RGP homomorphism problem, RGP equivalence, Tools, query languages, constraint satisfaction problem, bounded treewidth modulo equivalence, Database languages, query processing, Systematics, constraint satisfaction problems, regular graph patterns, graph databases]
The Weisfeiler-Leman dimension of planar graphs is at most 3
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We prove that the Weisfeiler-Leman (WL) dimension of the class of all finite planar graphs is at most 3. In particular, every finite planar graph is definable in first-order logic with counting using at most 4 variables. The previously best known upper bounds for the dimension and number of variables were 14 and 15, respectively. First we show that, for dimension 3 and higher, the WL-algorithm correctly tests isomorphism of graphs in a minor-closed class whenever it determines the orbits of the automorphism group of any arc-colored 3-connected graph belonging to this class. Then we prove that, apart from several exceptional graphs (which have WL-dimension at most 2), the individualization of two correctly chosen vertices of a colored 3-connected planar graph followed by the 1-dimensional WL-algorithm produces the discrete vertex partition. This implies that the 3-dimensional WL-algorithm determines the orbits of a colored 3-connected planar graph. As a byproduct of the proof, we get a classification of the 3-connected planar graphs with fixing number 3.
[discrete vertex partition, Particle separators, graph theory, first-order logic, 1-dimensional WL-algorithm, Color, Orbits, Partitioning algorithms, minor-closed class, formal logic, Upper bound, finite planar graphs, automorphism group, arc-colored 3-connected graph, Weisfeiler-Leman dimension, Testing]
Definability of semidefinite programming and lasserre lower bounds for CSPs
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We show that the ellipsoid method for solving semidefinite programs (SDPs) can be expressed in fixed-point logic with counting (FPC). This generalizes an earlier result that the optimal value of a linear program can be expressed in this logic. As an application, we establish lower bounds on the number of levels of the Lasserre hierarchy required to solve many optimization problems, namely those that can be expressed as finite-valued constraint satisfaction problems (VCSPs). In particular, we establish a dichotomy on the number of levels of the Lasserre hierarchy that are required to solve the problem exactly. We show that if a finite-valued constraint problem is not solved exactly by its basic linear programming relaxation, it is also not solved exactly by any sub-linear number of levels of the Lasserre hierarchy. The lower bounds are established through logical undefinability results. We show that the SDP corresponding to any fixed level of the Lasserre hierarchy is interpretable in a VCSP instance by means of FPC formulas. Our definability result of the ellipsoid method then implies that the solution of this SDP can be expressed in this logic. Together, these results give a way of translating lower bounds on the number of variables required in counting logic to express a VCSP into lower bounds on the number of levels required in the Lasserre hierarchy to eliminate the integrality gap. As a special case, we obtain the same dichotomy for the class of MAXCSP problems, generalizing earlier Lasserre lower bound results by Schoenebeck [17]. Recently, and independently of the work reported here, a similar linear lower bound in the Lasserre hierarchy for general-valued CSPs has also been announced by Thapper and Zivny [20], using different techniques.
[CSP, Symmetric matrices, fixed-point logic with counting, integrality gap, Programming, Lasserre lower bounds, Linear programming, Optimization, Standards, Ellipsoids, mathematical programming, finite-valued constraint satisfaction problems, semidefinite programming, Systematics, constraint satisfaction problems, FPC, linear programming relaxation, Lasserre hierarchy, SDP, computational complexity]
A monad for full ground reference cells
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We present a denotational account of dynamic allocation of potentially cyclic memory cells using a monad on a functor category. We identify the collection of heaps as an object in a different functor category equipped with a monad for adding hiding/encapsulation capabilities to the heaps. We derive a monad for full ground references supporting effect masking by applying a state monad transformer to the encapsulation monad. To evaluate the monad, we present a denotational semantics for a call-by-value calculus with full ground references, and validate associated code transformations.
[formal logic, functor category, encapsulation monad, call-by-value calculus, Resource management, calculus, full ground reference cells, Erbium, state monad transformer]
Quotients in monadic programming: Projective algebras are equivalent to coalgebras
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
In monadic programming, datatypes are presented as free algebras, generated by data values, and by the algebraic operations and equations capturing some computational effects. These algebras are free in the sense that they satisfy just the equations imposed by their algebraic theory, and remain free of any additional equations. The consequence is that they do not admit quotient types. This is, of course, often inconvenient. Whenever a computation involves data with multiple representatives, and they need to be identified according to some equations that are not satisfied by all data, the monadic programmer has to leave the universe of free algebras, and resort to explicit destructors. We characterize the situation when these destructors are preserved under all operations, and the resulting quotients of free algebras are also their subalgebras. Such quotients are called projective. Although popular in universal algebra, projective algebras did not attract much attention in the monadic setting, where they turn out to have a surprising avatar: for any given monad, a suitable category of projective algebras is equivalent with the category of coalgebras for the comonad induced by any monad resolution. For a monadic programmer, this equivalence provides a convenient way to implement polymorphic quotients as coalgebras. The dual correspondence of injective coalgebras and all algebras leads to a different family of quotient types, which seems to have a different family of applications. Both equivalences also entail several general corollaries concerning monadicity and comonadicity.
[functional programming, computational monad, Programming, Orbits, algebra, algebraic operations, datatypes, Authorization, polymorphic quotients, Algebra, Databases, adjunction, Mathematical model, universal algebra, monadic programming, comonad, projective algebras, Standards, monad resolution, coalgebras, data values, injective coalgebras, quotient type, subalgebras, categorical model, free algebras, algebraic theory, equivalence classes]
Register automata with linear arithmetic
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We propose a novel automata model over the alphabet of rational numbers, which we call register automata over the rationals (RA<sub>&#x211A;</sub>). It reads a sequence of rational numbers and outputs another rational number. RA<sub>&#x211A;</sub> is an extension of the well-known register automata (RA) over infinite alphabets, which are finite automata equipped with a finite number of registers/variables for storing values. Like in the standard RA, the RA<sub>&#x211A;</sub> model allows both equality and ordering tests between values. It, moreover, allows to perform linear arithmetic between certain variables. The model is quite expressive: in addition to the standard RA, it also generalizes other well-known models such as affine programs and arithmetic circuits. The main feature of RA<sub>&#x211A;</sub> is that despite the use of linear arithmetic, the so-called invariant problem-a generalization of the standard non-emptiness problem-is decidable. We also investigate other natural decision problems, namely, commutativity, equivalence, and reachability. For deterministic RA<sub>&#x211A;</sub>, commutativity and equivalence are polynomial-time inter-reducible with the invariant problem.
[rational numbers, arithmetic circuits, Computational modeling, automata theory, affine programs, standard nonemptiness problem, linear arithmetic, reachability problem, Registers, Standards, RA, Computer science, Analytical models, infinite alphabets, equivalence problem, polynomial-time inter-reducible, Automata, register automata, commutativity problem, Integrated circuit modeling, computational complexity]
The geometry of concurrent interaction: Handling multiple ports by way of multiple tokens
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We introduce a geometry of interaction model for Mazza's multiport interaction combinators, a graph-theoretic formalism which is able to faithfully capture concurrent computation as embodied by process algebras like the &#x03C0;-calculus. The introduced model is based on token machines in which not one but multiple tokens are allowed to traverse the underlying net at the same time. We prove soundness and adequacy of the introduced model. The former is proved as a simulation result between the token machines one obtains along any reduction sequence. The latter is obtained by a fine analysis of convergence, both in nets and in token machines.
[Computational modeling, game theory, concurrent interaction geometry, interaction model, token machines, Geometry, Concurrent computing, Microwave integrated circuits, Mazza multiport interaction combinators, Algebra, process algebra, Semantics, graph-theoretic formalism, Games]
An effectful way to eliminate addiction to dependence
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We define a monadic translation of type theory, called the weaning translation, that allows for a large range of effects in dependent type theory-such as exceptions, non-termination, non-determinism or writing operations. Through the light of a call-by-push-value decomposition, we explain why the traditional approach fails with type dependency and justify our approach. Crucially, the construction requires that the universe of algebras of the monad forms itself an algebra. The weaning translation applies to a version of the Calculus of Inductive Constructions (CIC) with a restricted version of dependent elimination. Finally, we show how to recover a translation of full CIC by mixing parametricity techniques with the weaning translation. This provides the first effectful version of CIC.
[parametricity techniques, nontermination operation, Calculus, calculus of inductive constructions, writing operation, program interpreters, exception operation, Algebra, call-by-push-value decomposition, weaning translation, nondeterminism operation, Coherence, dependent type theory, Syntactics, Writing, Mathematical model, Functional programming, monadic translation, CIC]
Equivalence of inductive definitions and cyclic proofs under arithmetic
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
A cyclic proof system, called CLKID-omega, gives us another way of representing inductive definitions and efficient proof search. The 2011 paper by Brotherston and Simpson showed that the provability of CLKID-omega includes the provability of the classical system of Martin-Lof's inductive definitions, called LKID, and conjectured the equivalence. By this year the equivalence has been left an open question. In general, the conjecture was proved to be false in FoSSaCS 2017 paper by Berardi and Tatsuta. However, if we restrict both systems to only the natural number inductive predicate and add Peano arithmetic to both systems, the conjecture was proved to be true in FoSSaCS 2017 paper by Simpson. This paper shows that if we add arithmetic to both systems, they become equivalent, namely, the conjecture holds. The result of this paper includes that of the paper by Simpson as a special case. In order to construct a proof of LKID for a given cyclic proof, this paper shows every bud in the cyclic proof is provable in LKID, by cutting the cyclic proof into subproofs such that in each subproof the conclusion is a companion and the assumptions are buds. The global trace condition gives some induction principle, by using an extension of Podelski-Rybalchenko termination theorem from well-foundedness to induction schema. In order to prove this extension, this paper also shows that infinite Ramsey theorem is formalizable in Peano arithmetic.
[Peano arithmetic, Podelski-Rybalchenko termination theorem, global trace condition, infinite Ramsey theorem, Transforms, Data structures, proof search, Electronic mail, subproofs, Standards, Computer science, cyclic proof system, Production, Martin-Lof's inductive definitions, induction principle, CLKID-omega, theorem proving, Informatics, equivalence classes, natural number inductive predicate]
Model-checking for successor-invariant first-order formulas on graph classes of bounded expansion
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
A successor-invariant first-order formula is a formula that has access to an auxiliary successor relation on a structure's universe, but the model relation is independent of the particular interpretation of this relation. It is well known that successor-invariant formulas are more expressive on finite structures than plain first-order formulas without a successor relation. This naturally raises the question whether this increase in expressive power comes at an extra cost to solve the model-checking problem, that is, the problem to decide whether a given structure together with some (and hence every) successor relation is a model of a given formula. It was shown earlier that adding successor-invariance to first-order logic essentially comes at no extra cost for the model-checking problem on classes of finite structures whose underlying Gaifman graph is planar [1], excludes a fixed minor [2] or a fixed topological minor [3], [4]. In this work we show that the model-checking problem for successor-invariant formulas is fixed-parameter tractable on any class of finite structures whose underlying Gaifman graphs form a class of bounded expansion. Our result generalises all earlier results and comes close to the best tractability results on nowhere dense classes of graphs currently known for plain first-order logic.
[successor relation, fixed topological minor, Computational modeling, finite structures, Gaifman graph, graph theory, Europe, model relation, Complexity theory, Electronic mail, formal logic, graph class, Semantics, plain first-order logic, Model checking, Logic gates, successor-invariant first-order formula]
The complexity of minimal inference problem for conservative constraint languages
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We study the complexity of the inference problem for propositional circumscription (the minimal inference problem) over arbitrary finite domains. The problem is of fundamental importance in nonmonotonic logics and commonsense reasoning. The complexity of the problem for the two-element domain has been completely classified [Durand, Hermann, and Nordh, Trichotomy in the complexity of minimal inference, LICS 2009]. In this paper, we classify the complexity of the problem over all conservative languages. We consider a version of the problem parameterized by a set of relations (a constraint language), from which we are allowed to build a knowledge base, and where a linear order used to compare models is a part of an input. We show that in this setting the problem is either &#x03A0;<sub>2</sub>P-complete, coNP-complete, or in P. The classification is based on a coNP-hardness proof for a new class of languages, an analysis of languages that do not express any member of the class and a new general polynomial-time algorithm solving the minimal inference problem for a large class of languages.
[knowledge base, linear order, common-sense reasoning, Cognition, Complexity theory, two-element domain, conservative languages, nonmonotonic logics, coNP-complete problem, knowledge based systems, minimal inference problem, polynomial-time algorithm, propositional circumscription, commonsense reasoning, arbitrary finite domains, pattern classification, formal languages, Computational modeling, Knowledge based systems, Cloning, inference problem complexity, classification, nonmonotonic reasoning, Computer science, Inference algorithms, &#x03A0;<sub>2</sub>P-complete problem, coNP-hardness proof, computational complexity]
Effectful applicative bisimilarity: Monads, relators, and Howe's method
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We study Abramsky's applicative bisimilarity abstractly, in the context of call-by-value &#x03BB;-calculi with algebraic effects. We first of all endow a computational &#x03BB;-calculus with a monadic operational semantics. We then show how the theory of relators provides precisely what is needed to generalise applicative bisimilarity to such a calculus, and to single out those monads and relators for which applicative bisimilarity is a congruence, thus a sound methodology for program equivalence. This is done by studying Howe's method in the abstract.
[lambda calculus, algebraic effects, Probabilistic logic, Linear programming, Calculus, Howe's method, Complexity theory, monads, programming language semantics, calculus, relators, program equivalence, Semantics, Abramsky's applicative bisimilarity, Concrete, computational &#x03BB;-calculus, equivalence classes, monadic operational semantics, call-by-value &#x03BB;-calculi]
Fully abstract encodings of &#x03BB;-calculus in HOcore through abstract machines
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We present fully abstract encodings of the call-by-name &#x03BB;-calculus into HOcore, a minimal higher-order process calculus with no name restriction. We consider several equivalences on the &#x03BB;-calculus side - normal-form bisimilarity, applicative bisimilarity, and contextual equivalence - that we internalize into abstract machines in order to prove full abstraction.
[abstract machines, HOcore, finite automata, Interference, higher-order process calculus, normal-form bisimilarity, Encoding, Calculus, Magnetic heads, pi calculus, contextual equivalence, Semantics, &#x03BB;-calculus, Communication channels, Syntactics, applicative bisimilarity]
The continuity of monadic stream functions
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Brouwer's continuity principle states that all functions from infinite sequences of naturals to naturals are continuous, that is, for every sequence the result depends only on a finite initial segment. It is an intuitionistic axiom that is incompatible with classical mathematics. Recently Marti&#x0301;n Escard&#x03BF;&#x0301; proved that it is also inconsistent in type theory. This shows that we cannot internalize the meta-theoretical observation that every definable function is continuous. However, we can adapt Brouwer's ideas to an important class of functions and propose a reformulation of the continuity principle that is internally provable. We note that Brouwer talked about functions on choice sequences, which are described as free progressions of values not necessarily generated by a rule. The functions must produce their results independently of how the sequences are generated. We formalize them as monadic streams, potentially unending sequences of values produced by steps triggered by a monadic action, possibly involving side effects. We consider functions on them that are uniform, in the sense that they operate in the same way independently of the particular monad that provides the specific side effects. Formally this is done by requiring a form of naturality in the monad. Functions on monadic streams have not only a foundational importance, but have also practical applications in signal processing and reactive programming. We give algorithms to determine the modulus of continuity of monadic stream functions and to generate dialogue trees for them (trees whose nodes and branches describe the interaction of the process with the environment).
[strategy trees, Shape, functional programming, signal processing, trees (mathematics), infinite sequences, Containers, Programming, continuity, Data structures, monadic stream functions, Mathematics, type theory, formal logic, intuitionistic axiom, reactive programming, dialogue trees, continuity principle, stream, Syntactics, monad, monadic stream function]
A cartesian-closed category for higher-order model checking
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
In previous work we have described the construction of an abstract lattice from a given Bu&#x0308;chi automaton. The abstract lattice is finite and has the following key properties. (i) There is a Galois insertion between it and the lattice of languages of finite and infinite words over a given alphabet. (ii) The abstraction is faithful with respect to acceptance by the automaton. (iii) Least fixpoints and &#x03C9;-iterations (but not in general greatest fixpoints) can be computed on the level of the abstract lattice. This allows one to decide whether finite and infinite traces of first-order recursive boolean programs are accepted by the automaton and can further be used to derive a type-and-effect system for infinitary properties. In this paper, we show how to derive from the abstract lattice a cartesian-closed category with fixpoint operator in such a way that the interpretation of a higher-order recursive program yields precisely the abstraction of its set of finite and infinite traces and thus provides a new algorithm for the higher-order model checking problem for trace properties. All previous algorithms for higher-order model checking [2], [16] work inherently on arbitrary tree properties and no apparent simplification appears when instantiating them with trace properties. The algorithm presented here, while necessarily having the same asymptotic complexity, is considerably simpler since it merely involves the interpretation of the program in a cartesian-closed category. The construction of the cartesian closed category from a lattice is new as well and may be of independent interest.
[Galois insertion, first-order recursive boolean programs, Lattices, Calculus, Electronic mail, Galois fields, abstract lattice, Boolean functions, Algebra, formal verification, higher-order model checking, asymptotic complexity, Automata, Model checking, Bu&#x0308;chi automaton, Finite element analysis, cartesian closed category]
Understanding the complexity of #SAT using knowledge compilation
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Two main techniques have been used so far to solve the #P-hard problem #SAT. The first one, used in practice, is based on an extension of DPLL for model counting called exhaustive DPLL. The second approach, more theoretical, exploits the structure of the input to compute the number of satisfying assignments by usually using a dynamic programming scheme on a decomposition of the formula. In this paper, we make a first step toward the separation of these two techniques by exhibiting a family of formulas that can be solved in polynomial time with the first technique but needs an exponential time with the second one. We show this by observing that both techniques implicitly construct a very specific Boolean circuit equivalent to the input formula. We then show that every &#x03B2;-acyclic formula can be represented by a polynomial size circuit corresponding to the first method and exhibit a family of &#x03B2;-acyclic formulas which cannot be represented by polynomial size circuits corresponding to the second method. This result sheds a new light on the complexity of #SAT and related problems on &#x03B2;-acyclic formulas. As a byproduct, we give new handy tools to design algorithms on &#x03B2;-acyclic hypergraphs.
[#P-hard problem, Heuristic algorithms, Tools, computability, dynamic programming, Probabilistic logic, Complexity theory, Standards, knowledge compilation, exhaustive DPLL, model counting, Boolean functions, #SAT, Databases, exponential time, &#x03B2;-acyclic formula, Boolean circuit, polynomial time, computational complexity, dynamic programming scheme]
The primitivity of operators in the algebra of binary relations under conjunctions of containments
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
The algebra of binary relations provides union and composition as basic operators, with the empty set as neutral element for union and the identity relation as neutral element for composition. The basic algebra can be enriched with additional features. We consider the diversity relation, the full relation, intersection, set difference, projection, coprojection, converse, and transitive closure. It is customary to express boolean queries on binary relational structures as finite conjunctions of containments. We investigate which features are primitive in this setting, in the sense that omitting the feature would allow strictly less boolean queries to be expressible. Our main result is that, modulo a finite list of elementary interdependencies among the features, every feature is indeed primitive.
[Vocabulary, binary relation algebra, composition operator, relational algebra, binary relational structures, identity relation, coprojection, set theory, Database languages, query processing, operator primitivity, Algebra, Semantics, set difference, intersection, transitive closure, finite conjunctions, Testing, neutral element, containment conjunctions, union operator, diversity relation, Boolean queries, Boolean algebra, mathematical operators, full relation, Query processing, converse]
Capturing polynomial time using Modular Decomposition
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
The question of whether there is a logic that captures polynomial time is one of the main open problems in descriptive complexity theory and database theory. In 2010 Grohe showed that fixed point logic with counting captures polynomial time on all classes of graphs with excluded minors. We now consider classes of graphs with excluded induced subgraphs. For such graph classes, an effective graph decomposition, called modular decomposition, was introduced by Gallai in 1976. The graphs that are non-decomposable with respect to modular decomposition are called prime. We present a tool, the Modular Decomposition Theorem, that reduces (definable) canonization of a graph class C to (definable) canonization of the class of prime graphs of C that are colored with binary relations on a linearly ordered set. By an application of the Modular Decomposition Theorem, we show that fixed point logic with counting also captures polynomial time on the class of permutation graphs. As a side effect of the Modular Decomposition Theorem, we further obtain that the modular decomposition tree is computable in logarithmic space. It follows that cograph recognition and cograph canonization is computable in logarithmic space.
[Gold, modular decomposition theorem, effective graph decomposition, modular decomposition tree, Color, Tools, linearly ordered set, Complexity theory, Electronic mail, polynomial time algorithm, binary relations, graph colouring, fixed point logic, permutation graphs, Computer science, formal logic, Databases, definable-prime graph class canonization, cograph recognition, logarithmic space, colored graphs, computational complexity, cograph canonization]
A type-theoretical definition of weak &#x03C9;-categories
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We introduce a dependent type theory whose models are weak &#x03C9;-categories, generalizing Brunerie's definition of &#x03C9;-groupoids. Our type theory is based on the definition of &#x03C9;-categories given by Maltsiniotis, himself inspired by Grothendieck's approach to the definition of &#x03C9;-groupoids. In this setup, &#x03C9;-categories are defined as presheaves preserving globular colimits over a certain category, called a coherator. The coherator encodes all operations required to be present in an &#x03C9;-category: both the compositions of pasting schemes as well as their coherences. Our main contribution is to provide a canonical type-theoretical characterization of pasting schemes as contexts which can be derived from inference rules. Finally, we present an implementation of a corresponding proof system.
[canonical type-theoretical characterization, Shape, proof system, Tools, type theory, weak &#x03C9;-categories, Proposals, coherator, Coherence, dependent type theory, Syntactics, category theory, Concrete, Inference algorithms, theorem proving, globular colimits]
Games with costs and delays
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We demonstrate the usefulness of adding delay to infinite games with quantitative winning conditions. In a delay game, one of the players may delay her moves to obtain a lookahead on her opponent's moves. We show that determining the winner of delay games with winning conditions given by parity automata with costs is EXPTIME-complete and that exponential bounded lookahead is both sufficient and in general necessary. Thus, although the parity condition with costs is a quantitative extension of the parity condition, our results show that adding costs does not increase the complexity of delay games with parity conditions. Furthermore, we study a new phenomenon that appears in quantitative delay games: lookahead can be traded for the quality of winning strategies and vice versa. We determine the extent of this tradeoff. In particular, even the smallest lookahead allows to improve the quality of an optimal strategy from the worst possible value to almost the smallest possible one. Thus, the benefit of introducing lookahead is twofold: not only does it allow the delaying player to win games she would lose without, but lookahead also allows her to improve the quality of her winning strategies in games she wins even without lookahead.
[winning conditions, EXPTIME-complete problem, automata theory, Color, game theory, Complexity theory, parity automata, parity condition, Memory management, Automata, Games, delay game, exponential bounded lookahead, Delays, Safety, infinite games, quantitative winning condition, computational complexity]
Verification of randomized security protocols
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We consider the problem of verifying the security of finitely many sessions of a protocol that tosses coins in addition to standard cryptographic primitives against a Dolev-Yao adversary. Two properties are investigated here - secrecy, which asks if no adversary interacting with a protocol P can determine a secret sec with probability &gt; 1 - p; and indistinguishability, which asks if the probability observing any sequence 0&#x0305; in P<sub>1</sub> is the same as that of observing 0&#x0305; in P<sub>2</sub>, under the same adversary. Both secrecy and indistinguishability are known to be coNP-complete for non-randomized protocols. In contrast, we show that, for randomized protocols, secrecy and indistinguishability are both decidable in coNEXPTIME. We also prove a matching lower bound for the secrecy problem by reducing the non-satisfiability problem of monadic first order logic without equality.
[Protocols, nonsatisfiability problem, cryptographic protocols, secret sec, probability, computability, Encryption, Electronic mail, Complexity theory, sequences, matching lower bound, randomized security protocol Verification, formal logic, sequence, Upper bound, standard cryptographic primitives, indistinguishability, monadic first order logic, coNEXPTIME, secrecy problem, computational complexity]
Typability in bounded dimension
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Recently (authors, POPL 2017), a notion of dimensionality for intersection types was introduced, and it was shown that the bounded-dimensional inhabitation problem is decidable under a non-idempotent interpretation of intersection and undecidable in the standard set-theoretic model. In this paper we study the typability problem for bounded-dimensional intersection types and prove that the problem is decidable in both models. We establish a number of bounding principles depending on dimension. In particular, it is shown that dimensional bound on derivations gives rise to a bounded width property on types, which is related to a generalized subformula property for typings of arbitrary terms. Using the bounded width property we can construct a nondeterministic transformation of the typability problem to unification, and we prove that typability in the set-theoretic model is PSPACE-complete, whereas it is in NP in the multiset model.
[bounded-dimensional intersection types, set-theoretic model, PSPACE-complete, Calculus, type theory, Electronic mail, Complexity theory, set theory, bounded-dimensional inhabitation problem, Standards, Computer science, typability problem, Upper bound, generalized subformula property, nondeterministic transformation, Syntactics, computational complexity]
The equivalence of two dichotomy conjectures for infinite domain constraint satisfaction problems
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
There exist two conjectures for constraint satisfaction problems (CSPs) of reducts of finitely bounded homogeneous structures: the first one states that tractability of the CSP of such a structure is, when the structure is a model-complete core, equivalent to its polymorphism clone satisfying a certain non-trivial linear identity modulo outer embeddings. The second conjecture, challenging the approach via model-complete cores by reflections, states that tractability is equivalent to the linear identities (without outer embeddings) satisfied by its polymorphisms clone, together with the natural uniformity on it, being non-trivial. We prove that the identities satisfied in the polymorphism clone of a structure allow for conclusions about the orbit growth of its automorphism group, and apply this to show that the two conjectures are equivalent. We contrast this with a counterexample showing that &#x03C9;-categoricity alone is insufficient to imply the equivalence of the two conditions above in a model-complete core. Taking a different approach, we then show how the Ramsey property of a homogeneous structure can be utilized for obtaining a similar equivalence under different conditions. We then prove that any polymorphism of sufficiently large arity which is totally symmetric modulo outer embeddings of a finitely bounded structure can be turned into a non-trivial system of linear identities, and obtain non-trivial linear identities for all tractable cases of reducts of the rational order, the random graph, and the random poset. Finally, we provide a new and short proof, in the language of monoids, of the theorem stating that every &#x03C9;-categorical structure is homomorphically equivalent to a model-complete core.
[CSP, random graph, graph theory, Cloning, outer embeddings, rational order, Orbits, finitely bounded homogeneous structures, model-complete core, Electronic mail, Complexity theory, polymorphisms clone, infinite domain constraint satisfaction problems, constraint satisfaction problems, two dichotomy conjectures equivalence, Algebra, automorphism group, random poset, Ramsey property, linear identities, non-trivial linear identity]
The pebbling comonad in Finite Model Theory
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Pebble games are a powerful tool in the study of finite model theory, constraint satisfaction and database theory. Monads and comonads are basic notions of category theory which are widely used in semantics of computation and in modern functional programming. We show that existential k-pebble games have a natural comonadic formulation. Winning strategies for Duplicator in the k-pebble game for structures A and B are equivalent to morphisms from A to B in the coKleisli category for this comonad. This leads on to comonadic characterisations of a number of central concepts in Finite Model Theory: &#x00B7; Isomorphism in the co-Kleisli category characterises elementary equivalence in the k-variable logic with counting quantifiers. &#x00B7; Symmetric games corresponding to equivalence in full k-variable logic are also characterized. &#x00B7; The treewidth of a structure A is characterised in terms of its coalgebra number: the least k for which there is a coalgebra structure on A for the k-pebbling comonad. &#x00B7; Co-Kleisli morphisms are used to characterize strong consistency, and to give an account of a Cai-Fu&#x0308;rer-Immerman construction. &#x00B7; The k-pebbling comonad is also used to give semantics to a novel modal operator. These results lay the basis for some new and promising connections between two areas within logic in computer science which have largely been disjoint: (1) finite and algorithmic model theory, and (2) semantics and categorical structures of computation.
[Computational modeling, pebble games, functional programming, game theory, algebra, coKleisli category, Indexes, finite and algorithmic model theory, database theory, Computer science, full k-variable logic, computer science, Semantics, constraint satisfaction, Games, computation semantics, category theory, pebbling comonad, Finite element analysis, finite model theory]
Stack semantics of type theory
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We give a model of dependent type theory with one univalent universe and propositional truncation interpreting a type as a stack, generalizing the groupoid model of type theory. As an application, we show that countable choice cannot be proved in dependent type theory with one univalent universe and propositional truncation.
[Geometry, Semantics, Buildings, dependent type theory model, stack semantics, univalent universe, Set theory, algebra, Mathematical model, propositional truncation, Periodic structures, computational complexity]
MDPs with energy-parity objectives
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Energy-parity objectives combine &#x03C9;-regular with quantitative objectives of reward MDPs. The controller needs to avoid to run out of energy while satisfying a parity objective. We refute the common belief that, if an energy-parity objective holds almost-surely, then this can be realised by some finite memory strategy. We provide a surprisingly simple counterexample that only uses coBuchi conditions. We introduce the new class of bounded (energy) storage objectives that, when combined with parity objectives, preserve the finite memory property. Based on these, we show that almostsure and limit-sure energy-parity objectives, as well as almostsure and limit-sure storage parity objectives, are in NP &#x2229; coNP and can be solved in pseudo-polynomial time for energy-parity MDPs.
[Color, Probabilistic logic, Probability distribution, energy-parity objectives, Memory management, &#x03C9;-regular, finite memory strategy, almostsure objective, Games, Markov processes, MDP, coBuchi conditions, Markov decision process, pseudopolynomial time, Energy storage, computational complexity]
Partial derivatives on graphs for Kleene allegories
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Brunet and Pous showed at LICS 2015 that the equational theory of identity-free relational Kleene lattices (a fragment of Kleene allegories) is decidable in EXPSPACE. In this paper, we show that the equational theory of Kleene allegories is decidable, and is EXPSPACE-complete, answering the first open question posed by their work. The proof proceeds by designing partial derivatives on graphs, which are generalizations of partial derivatives on strings for regular expressions, called Antimirov's partial derivatives. The partial derivatives on graphs give a finite automata construction algorithm as with the partial derivatives on strings.
[Algorithm design and analysis, finite automata, graph theory, Lattices, Grammar, Electronic mail, Kleene allegories, Algebra, decidability, Automata, regular expressions, EXPSPACE-complete, Mathematical model, partial derivatives, finite automata construction algorithm, computational complexity]
First-order logic with counting
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We introduce the logic FOCN(P) which extends first-order logic by counting and by numerical predicates from a set P, and which can be viewed as a natural generalisation of various counting logics that have been studied in the literature.
[formal logic, Reactive power, Heuristic algorithms, Query processing, first-order logic with counting, Semantics, counting logic, Model checking, Delays, FOCN(P) logic, numerical predicates]
On strong determinacy of countable stochastic games
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We study 2-player turn-based perfect-information stochastic games with countably infinite state space. The players aim at maximizing/minimizing the probability of a given event (i.e., measurable set of infinite plays), such as reachability, Bu&#x0308;chi, &#x03C9;-regular or more general objectives. These games are known to be weakly determined, i.e., they have value. However, strong determinacy of threshold objectives (given by an event &#x03B5; and a threshold c &#x2208; [0,1]) was open in many cases: is it always the case that the maximizer or the minimizer has a winning strategy, i.e., one that enforces, against all strategies of the other player, that &#x03B5; is satisfied with probability &#x2265; c (resp. &lt;; c)? We show that almost-sure objectives (where c = 1) are strongly determined. This vastly generalizes a previous result on finite games with almost-sure tail objectives. On the other hand we show that &#x2265; 1/2 (co-)Biichi objectives are not strongly determined, not even if the game is finitely branching. Moreover, for almost-sure reachability and almost-sure Biichi objectives in finitely branching games, we strengthen strong determinacy by showing that one of the players must have a memory less deterministic (MD) winning strategy.
[strong determinacy, reachability analysis, countable stochastic games, game theory, Biichi objectives, infinite state space, general objectives, Memory management, Games, reachability, minimisation, stochastic processes, perfect-information stochastic games, stochastic games]
Domains and event structures for fusions
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Stable event structures, and their duality with prime algebraic domains (arising as partial orders of configurations), are a landmark of concurrency theory, providing a clear characterisation of causality in computations. They have been used for defining a concurrent semantics of several formalisms, from Petri nets to linear graph rewriting systems, which in turn lay at the basis of many visual frameworks. Stability however is restrictive for dealing with formalisms where a computational step can merge parts of the state, like graph rewriting systems with non-linear rules, which are needed to cover some relevant applications (such as the graphical encoding of calculi with name passing). We characterise, as a natural generalisation of prime algebraic domains, a class of domains that is well-suited to model the semantics of formalisms with fusions. We then identify a corresponding class of event structures, that we call connected event structures, via a duality result formalised as an equivalence of categories.We show that connected event structures are exactly the class of event structures that arise as the semantics of nonlinear graph rewriting systems. Interestingly, the category of general unstable event structures coreflects into our category of domains, so that our result provides a characterisation of the partial orders of configurations of such event structures.
[rewriting systems, partial-configuration orders, Computational modeling, stable event structures, Petri nets, graph theory, category equivalence, prime algebraic domains, fusions, concurrency theory, Stability analysis, graph rewriting, History, duality, Standards, nonlinear graph rewriting system semantics, Concurrent computing, concurrent semantics, general unstable event structure category, Semantics, Event structures, formalism semantics, connected event structures, process calculi]
Strategy logic with imperfect information
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We introduce an extension of Strategy logic for the imperfect-information setting, called SL<sub>ii</sub>, and study its model-checking problem. As this logic naturally captures multi-player games with imperfect information, the problem turns out to be undecidable. We introduce a syntactical class of &#x201C;hierarchical instances&#x201D; for which, intuitively, as one goes down the syntactic tree of the formula, strategy quantifications are concerned with finer observations of the model. We prove that model-checking SL<sub>ii</sub> restricted to hierarchical instances is decidable. This result, because it allows for complex patterns of existential and universal quantification on strategies, greatly generalises previous ones, such as decidability of multi-player games with imperfect information and hierarchical observations, and decidability of distributed synthesis for hierarchical systems. To establish the decidability result, we introduce and study QCTL<sub>ii</sub>*, an extension of QCTL (itself an extension of CTL with second-order quantification over atomic propositions) by parameterising its quantifiers with observations. The simple syntax of QCTL<sub>ii</sub>* allows us to provide a conceptually neat reduction of SL<sub>ii</sub> to QCTL<sub>ii</sub>* that separates concerns, allowing one to forget about strategies and players and focus solely on second-order quantification. While the model-checking problem of QCTL<sub>ii</sub>* is, in general, undecidable, we identify a syntactic fragment of hierarchical formulas and prove, using an automata-theoretic approach, that it is decidable. The decidability result for SL<sub>ii</sub> follows since the reduction maps hierarchical instances of SL<sub>ii</sub> to hierarchical formulas of QCTL<sub>ii</sub>*.
[strategy quantifications, automata theory, decidable hierarchical instances, strategy logic, reduction maps, game theory, Tools, syntactical class, automata-theoretic approach, Nash equilibrium, Cognition, complex patterns, atomic propositions, syntactic tree, multiplayer game decidability, distributed synthesis, decidability, imperfect information, model-checking problem, Automata, Games, Syntactics, Model checking, second-order quantification]
A convenient category for higher-order probability theory
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Higher-order probabilistic programming languages allow programmers to write sophisticated models in machine learning and statistics in a succinct and structured way, but step outside the standard measure-theoretic formalization of probability theory. Programs may use both higher-order functions and continuous distributions, or even define a probability distribution on functions. But standard probability theory does not handle higher-order functions well: the category of measurable spaces is not cartesian closed. Here we introduce quasi-Borel spaces. We show that these spaces: form a new formalization of probability theory replacing measurable spaces; form a cartesian closed category and so support higher-order functions; form a well-pointed category and so support good proof principles for equational reasoning; and support continuous probability distributions. We demonstrate the use of quasi-Borel spaces for higher-order functions and probability by: showing that a well-known construction of probability theory involving random functions gains a cleaner expression; and generalizing de Finetti's theorem, that is a crucial theorem in probability theory, to quasi-Borel spaces.
[Cartesian closed category, well-pointed category, higher-order probabilistic programming languages, higher-order functions, Extraterrestrial measurements, Probabilistic logic, Probability distribution, statistical distributions, equational reasoning, Standards, randomised algorithms, de Finetti's theorem, continuous probability distributions, category theory, quasiBorel spaces, random functions, Silicon, probability theory formalization, Random variables]
Untwisting two-way transducers in elementary time
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Functional transductions realized by two-way transducers (equivalently, by streaming transducers and by MSO transductions) are the natural and standard notion of &#x201C;regular&#x201D; mappings from words to words. It was shown recently (LICS'13) that it is decidable if such a transduction can be implemented by some one-way transducer, but the given algorithm has non-elementary complexity. We provide an algorithm of different flavor solving the above question, that has double exponential space complexity. We further apply our technique to decide whether the transduction realized by a two-way transducer can be implemented by a sweeping transducer, with either known or unknown number of passes.
[Computer science, Transducers, double exponential space complexity, sweeping transducer, Databases, two-way transducers, Automata, transducers, Distance measurement, Complexity theory, Standards, elementary time]
Bounded time computation on metric spaces and Banach spaces
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We extend Kawamura and Cook's framework for computational complexity for operators in analysis. This model is based on second-order complexity theory for functionals on the Baire space, which is lifted to metric spaces via representations. Time is measured in the length of the input encodings and the output precision. We propose the notions of complete and regular representations. Completeness is proven to ensure that any computable function has a time bound. Regularity relaxes Kawamura and Cook's notion of a second-order representation, while still guaranteeing fast computability of the length of encodings. We apply these notions to investigate relationships between metric properties of a space and existence of representations that render the metric bounded-time computable. We show that time bounds for the metric can straightforwardly be translated into size bounds of compact subsets of the space. Conversely, for compact spaces and for Banach spaces we construct admissible complete regular representations admitting fast computation of the metric and short encodings. Here it is necessary to trade time bounds off against length of encodings.
[Computational modeling, Kawamura and Cook framework, Extraterrestrial measurements, Encoding, Entropy, metric spaces, Complexity theory, Banach spaces, Banach space, Standards, bounded time computation, Baire space, second-order representation notion, computational complexity, second-order complexity theory]
Quantifiers on languages and codensity monads
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
This paper contributes to the techniques of topoalgebraic recognition for languages beyond the regular setting as they relate to logic on words. In particular, we provide a general construction on recognisers corresponding to adding one layer of various kinds of quantifiers and prove a related Reutenauer-type theorem. Our main tools are codensity monads and duality theory. Our construction yields, in particular, a new characterisation of the profinite monad of the free S-semimodule monad for finite and commutative semirings S, which generalises our earlier insight that the Vietoris monad on Boolean spaces is the codensity monad of the finite powerset functor.
[Vietoris monad, formal languages, languages, Europe, Tools, Boolean algebra, finite semirings, commutative semirings, finite powerset functor, codensity monads, duality theory, topoalgebraic recognition, Automata, Syntactics, Boolean space, Mathematical model, Reutenauer-type theorem]
Decidability, complexity, and expressiveness of first-order logic over the subword ordering
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We consider first-order logic over the subword ordering on finite words where each word is available as a constant. Our first result is that the &#x03A3;<sub>1</sub> theory is undecidable (already over two letters). We investigate the decidability border by considering fragments where all but a certain number of variables are alternation bounded, meaning that the variable must always be quantified over languages with a bounded number of letter alternations. We prove that when at most two variables are not alternation bounded, the &#x03A3;<sub>1</sub> fragment is decidable, and that it becomes undecidable when three variables are not alternation bounded. Regarding higher quantifier alternation depths, we prove that the &#x03A3;<sub>2</sub> fragment is undecidable already for one variable without alternation bound and that when all variables are alternation bounded, the entire first-order theory is decidable.
[subword ordering, Terminology, alternation bounded variables, complexity analysis, first-order logic, decidable &#x03A3;1 fragment, Cognition, Complexity theory, quantifier alternation depths, sequences, Computer science, decidability, DNA, finite words, undecidable &#x03A3;2 fragment, Distance measurement, string matching, undecidable &#x03A3;1 theory, expressiveness analysis, Pattern matching, computational complexity]
Lean and full congruence formats for recursion
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
In this paper I distinguish two (pre)congruence requirements for semantic equivalences and preorders on processes given as closed terms in a system description language with a recursion construct. A lean congruence preserves equivalence when replacing closed subexpressions of a process by equivalent alternatives. A full congruence moreover allows replacement within a recursive specification of subexpressions that may contain recursion variables bound outside of these subexpressions. I establish that bisimilarity is a lean (pre)congruence for recursion for all languages with a structural operational semantics in the ntyft/ntyxt format. Additionally, it is a full congruence for the tyft/tyxt format.
[subexpressions, lean precongruence, preorders, Tools, system description language, recursion construct, programming language semantics, recursive specification, bisimilarity, Reactive power, lean-congruence format, System verification, Semantics, recursion variables, ntyft/ntyxt format, structural operational semantics, System recovery, tyft/tyxt format, Silicon, precongruence requirements, Australia, semantic equivalences, equivalence classes, full-congruence format]
Differentiation in logical form
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We introduce a logical theory of differentiation for a real-valued function on a finite dimensional real Euclidean space. A real-valued continuous function is represented by a localic approximable mapping between two semi-strong proximity lattices, representing the two stably locally compact Euclidean spaces for the domain and the range of the function. Similarly, the Clarke subgradient, equivalently the L-derivative, of a locally Lipschitz map, which is non-empty, compact and convex valued, is represented by an approximable mapping. Approximable mappings of the latter type form a bounded complete domain isomorphic with the function space of Scott continuous functions of a real variable into the domain of non-empty compact and convex subsets of the finite dimensional Euclidean space partially ordered with reverse inclusion. Corresponding to the notion of a single-tie of a locally Lipschitz function, used to derive the domain-theoretic L-derivative of the function, we introduce the dual notion of a single-knot of approximable mappings which gives rise to Lipschitzian approximable mappings. We then develop the notion of a strong single-tie and that of a strong knot leading to a Stone duality result for locally Lipschitz maps and Lipschitzian approximable mappings. The strong single-knots, in which a Lipschitzian approximable mapping belongs, are employed to define the Lipschitzian derivative of the approximable mapping. The latter is dual to the Clarke subgradient of the corresponding locally Lipschitz map defined domain-theoretically using strong single-ties. A stricter notion of strong single-knots is subsequently developed which captures approximable mappings of continuously differentiable maps providing a gradient Stone duality for these maps. Finally, we derive a calculus for Lipschitzian derivative of approximable mapping for some basic constructors and show that it is dual to the calculus satisfied by the Clarke subgradient.
[finite dimensional Euclidean space, logical theory, differentiation, Instruction sets, Lattices, Clarke subgradient, Tools, Calculus, finite dimensional real Euclidean space, Topology, semistrong proximity lattices, Optimization, Computer science, locally Lipschitz map, Euclidean space, real-valued continuous function, localic approximable mapping, Lipschitzian approximable mappings, Scott continuous function]
Static analysis of deterministic negotiations
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Negotiation diagrams are a model of concurrent computation akin to workflow Petri nets. Deterministic negotiation diagrams, equivalent to the much studied and used free-choice workflow Petri nets, are surprisingly amenable to verification. Soundness (a property close to deadlock-freedom) can be decided in PTIME. Further, other fundamental questions like computing summaries or the expected cost, can also be solved in PTIME for sound deterministic negotiation diagrams, while they are PSPACE-complete in the general case.
[Algorithm design and analysis, decomposition theorem, static analysis problems, antipattern detection, Computational modeling, program diagnostics, Petri nets, Unified modeling language, flow graphs, PTIME algorithm, free-choice workflow Petri nets, Synchronization, deterministic algorithms, Concurrent computing, Analytical models, PSPACE-complete algorithm, MOP formulation, soundness property, meet-over-all-paths formulation, Mazurkiewicz-invariant analysis problems, deterministic negotiation diagrams, sequential flow-graph, computational complexity]
On shift-invariant maximal filters and hormonal cellular automata
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
This paper deals with the construction of shift-invariant maximal filters on &#x2124; and their relation to hormonal cellular automata, a generalization of the cellular automata computation model with some information about the global state shared among all the cells. We first design shift-invariant maximal filters in order to define this new model of computation. Starting from different assumptions, we show how to construct such filters, and analyze the computation power of the induced cellular automata computation model.
[Analytical models, Upper bound, computation power, Computational modeling, Atmospheric modeling, Biological system modeling, shift-invariant maximal filter design, cellular automata computation model generalization, Automata, hormonal cellular automata, induced cellular automata computation model, cellular automata]
The real projective spaces in homotopy type theory
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Homotopy type theory is a version of Martin-Lo&#x0308;f type theory taking advantage of its homotopical models. In particular, we can use and construct objects of homotopy theory and reason about them using higher inductive types. In this article, we construct the real projective spaces, key players in homotopy theory, as certain higher inductive types in homotopy type theory. The classical definition of &#x211D;Pn, as the quotient space identifying antipodal points of the n-sphere, does not translate directly to homotopy type theory. Instead, we define &#x211D;Pn by induction on n simultaneously with its tautological bundle of 2-element sets. As the base case, we take &#x211D;P-1 to be the empty type. In the inductive step, we take &#x211D;Pn+1 to be the mapping cone of the projection map of the tautological bundle of &#x211D;Pn, and we use its universal property and the univalence axiom to define the tautological bundle on &#x211D;Pn+1. By showing that the total space of the tautological bundle of &#x211D;Pn is the n-sphere Sn, we retrieve the classical description of &#x211D;Pn+1 as &#x211D;Pn with an (n + 1)-disk attached to it. The infinite dimensional real projective space &#x211D;P&#x221E;, defined as the sequential colimit of &#x211D;Pn with the canonical inclusion maps, is equivalent to the Eilenberg-MacLane space K(&#x2124;/2&#x2124;, 1), which here arises as the subtype of the universe consisting of 2-element types. Indeed, the infinite dimensional projective space classifies the 0-sphere bundles, which one can think of as synthetic line bundles. These constructions in homotopy type theory further illustrate the utility of homotopy type theory, including the interplay of type theoretic and homotopy theoretic ideas.
[Strips, Adaptation models, Eilenberg-MacLane space K, 2-element sets, Homotopy Type Theory, type theory, infinite dimensional projective space, Electronic mail, Topology, Real projective spaces, Manifolds, RPn tautological bundle, homotopy type theory, quotient space identifying antipodal points, homotopical models, Joining processes, 0-sphere bundles, Suspensions, infinite dimensional real projective space RP&#x221E;, Higher inductive types, Martin-Lof type theory, Univalence axiom]
Data structures for quasistrict higher categories
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We present new data structures for quasistrict higher categories, in which associativity and unit laws hold strictly. Our approach has low axiomatic complexity compared to traditional algebraic approaches, and gives a practical method for performing calculations in quasistrict 4-categories. It is amenable to computer implementation, and we exploit this to give a machine-verified algebraic proof that every adjunction of 1-cells in a quasistrict 4-category can be promoted to a coherent adjunction satisfying the butterfly equations.
[Computational modeling, Data structures, Generators, algebra, butterfly equations, Complexity theory, low axiomatic complexity, algebraic approach, Computer science, associativity law, unit law, machine-verified algebraic proof, data structures, quasistrict higher categories, Mathematical model, computational complexity]
A crevice on the Crane Beach: Finite-degree predicates
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
First-order logic (FO) over words is shown to be equiexpressive with FO equipped with a restricted set of numerical predicates, namely the order, a binary predicate MSB<sub>0</sub>, and the finite-degree predicates: FO[A<sub>RB</sub>] = FO[&#x2264;, MSB<sub>0</sub>, F<sub>IN</sub>]. The Crane Beach Property (CBP), introduced more than a decade ago, is true of a logic if all the expressible languages admitting a neutral letter are regular. Although it is known that FO[A<sub>RB</sub>] does not have the CBP, it is shown here that the (strong form of the) CBP holds for both FO[&#x2264;, F<sub>IN</sub>] and FO[&#x2264;, MSB<sub>0</sub>]. Thus FO[&#x2264;, F<sub>IN</sub>] exhibits a form of locality and the CBP, and can still express a wide variety of languages, while being one simple predicate away from the expressive power of FO[A<sub>RB</sub>]. The counting ability of FO[&#x2264;, F<sub>IN</sub>] is studied as an application.
[Cranes, Buildings, Europe, first-order logic, Tools, binary predicate, finite-degree predicates, FO, Complexity theory, Electronic mail, formal logic, CBP, expressible languages, neutral letter, Games, crane beach property, numerical predicates, computational complexity]
Constraint satisfaction problems over semilattice block Mal'tsev algebras
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
There are two well known types of algorithms for solving CSPs: local propagation and generating a basis of the solution space. For several years the focus of the CSP research has been on `hybrid' algorithms that somehow combine the two approaches. In this paper we present a new method of such hybridization that allows us to solve certain CSPs that has been out of reach for a quite a while. We consider these method on a fairly restricted class of CSPs given by algebras we will call semilattice block Mal'tsev. An algebra A is called semilattice block Mal'tsev if it has a binary operation f, a ternary operation m, and a congruence &#x03C3; such that the quotient A/<sub>&#x03C3;</sub> with operation f is a semilattice, f is a projection on every block of &#x03C3;, and every block of &#x03C3; is a Mal'tsev algebra with Mal'tsev operation m. We show that the constraint satisfaction problem over a semilattice block Mal'tsev algebra is solvable in polynomial time.
[Algorithm design and analysis, CSP research, semilattice block Mal'tsev algebras, computability, Graph theory, algebra, Complexity theory, ternary operation, Indexes, hybridization, binary operation, congruence, constraint satisfaction problems, Algebra, polynomial time, Reliability, Time factors, hybrid algorithms, computational complexity]
Descriptive Complexity for counting complexity classes
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Descriptive Complexity has been very successful in characterizing complexity classes of decision problems in terms of the properties definable in some logics. However, descriptive complexity for counting complexity classes, such as FP and #P, has not been systematically studied, and it is not as developed as its decision counterpart. In this paper, we propose a framework based on Weighted Logics to address this issue. Specifically, by focusing on the natural numbers we obtain a logic called Quantitative Second Order Logics (QSO), and show how some of its fragments can be used to capture fundamental counting complexity classes such as FP, #P and FPSPACE, among others. We also use QSO to define a hierarchy inside #P, identifying counting complexity classes with good closure and approximation properties, and which admit natural complete problems. Finally, we add recursion to QSO, and show how this extension naturally captures lower counting complexity classes such as #L.
[natural numbers, approximation theory, counting complexity classes, weighted logics, descriptive complexity, Search problems, #L, FP, Complexity theory, Grammar, Electronic mail, QSO, #P, formal logic, quantitative second order logics, approximation properties, FPSPACE, Focusing, fundamental counting complexity classes, natural complete problems, Syntactics, Robustness, decision problems, computational complexity]
Categorical liveness checking by corecursive algebras
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Final coalgebras as &#x201C;categorical greatest fixed points&#x201D; play a central role in the theory of coalgebras. Somewhat analogously, most proof methods studied therein have focused on greatest fixed-point properties like safety and bisimilarity. Here we make a step towards categorical proof methods for least fixed-point properties over dynamical systems modeled as coalgebras. Concretely, we seek a categorical axiomatization of well-known proof methods for liveness, namely ranking functions (in nondeterministic settings) and ranking supermartingales (in probabilistic ones). We find an answer in a suitable combination of coalgebraic simulation (studied previously by the authors) and corecursive algebra as a classifier for (non-)well-foundedness.
[coalgebraic simulation, ranking supermartingales, Probabilistic logic, algebra, categorical liveness checking, corecursive algebra, categorical proof methods, Standards, categorical greatest fixed points, Computer science, coalgebra theory, bisimilarity property, Algebra, categorical axiomatization, Games, ranking functions, Concrete, Safety, safety property]
Unrestricted stone duality for Markov processes
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
Stone duality relates logic, in the form of Boolean algebra, to spaces. Stone-type dualities abound in computer science and have been of great use in understanding the relationship between computational models and the languages used to reason about them. Recent work on probabilistic processes has established a Stone-type duality for a restricted class of Markov processes. The dual category was a new notion-Aumann algebras-which are Boolean algebras equipped with countable family of modalities indexed by rational probabilities. In this article we consider an alternative definition of Aumann algebra that leads to dual adjunction for Markov processes that is a duality for many measurable spaces occurring in practice. This extends a duality for measurable spaces due to Sikorski. In particular, we do not require that the probabilistic modalities preserve a distinguished base of clopen sets, nor that morphisms of Markov processes do so. The extra generality allows us to give a perspicuous definition of event bisimulation on Aumann algebras.
[computational models, Aumann algebras, Computational modeling, probabilistic modalities, unrestricted stone duality, Extraterrestrial measurements, Probabilistic logic, Boolean algebra, Topology, set theory, stone-type dualities, computer science, rational probabilities, probabilistic processes, Markov processes, duality (mathematics), Boolean algebras]
A weakest pre-expectation semantics for mixed-sign expectations
2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science
None
2017
We present a weakest-precondition-style calculus for reasoning about the expected values (pre-expectations) of mixed-sign unbounded random variables after execution of a probabilistic program. The semantics of a while-loop is defined as the limit of iteratively applying a functional to a zero-element just as in the traditional weakest pre-expectation calculus, even though a standard least fixed point argument is not applicable in our semantics. A striking feature of our semantics is that it is always well-defined, even if the expected values do not exist. We show that the calculus is sound and allows for compositional reasoning. Furthermore, we present an invariant-based approach for reasoning about pre-expectations of loops.
[expected values, Automation, random processes, invariant-based approach, Probabilistic logic, mixed-sign unbounded random variables, Cognition, Calculus, calculus, programming language semantics, zero-element, Standards, weakest-precondition-style calculus, Semantics, while-loop semantics, Random variables, compositional reasoning, probabilistic program]
