268
Overcoming the memory wall in packet processing: hammers or ladders?
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Overhead of memory accesses limits the performance of packet processing applications. To overcome this bottleneck, today's network processors can utilize a wide-range of mechanisms-such as multi-level memory hierarchy, wide-word accesses, special-purpose result-caches, asynchronous memory, and hardware multi-threading. However, supporting all of these mechanisms complicates programmability and hardware design, and wastes systemresources. In this paper, we address the following fundamental question: what minimal set of hardware mechanisms must a network processor support to achieve the twin goals of simplified programmability and high packet throughput? We show that no single mechanism sufficies; the minimal set must include data-caches and multi-threading. Data-caches and multi-threading are complementary; whereas data-caches exploit locality to reduce the number of context-switches and the off-chip memory bandwidth requirement, multi-threading exploits parallelism to hide long cache-miss latencies.
[Communication hardware, interfaces and storage, Networks, Computer systems organization, Network protocols, Network components, Routers, Intermediate nodes, Hardware]
A practical fast parallel routing architecture for Clos networks
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
Clos networks are an important class of switching networks due to their modular structure and much lower cost compared with crossbars. For routing I/O permutations of Clos networks, sequential routing algorithms are too slow, and all known parallel algorithms are not practical. We present the algorithm-hardware codesign of a unified fast parallel routing architecture called distributed pipeline routing (DPR) architecture for rearrangeable nonblocking and strictly nonblocking Clos networks. The DPR architecture uses a linear interconnection structure and processing elements that performs only shift and logic AND operations. We show that a DPR architecture can route any permutation in rearrangeable nonblocking and strictly nonblocking Clos networks in O(&#8730;N) time. The same architecture can be used to carry out control of any group of connection/disconnection requests for strictly nonblocking Clos networks in O(&#8730;N) time. Several speeding-up techniques are also presented. This architecture is applicable to packet and circuit switches of practical sizes.
[Integrated circuits, Interconnect, Computer systems organization, Networks, Network components, Routers, Intermediate nodes, Hardware, Parallel architectures, Architectures, Interconnection architectures]
Ruler: high-speed packet matching and rewriting on NPUs
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Programming specialized network processors (NPU) is inherently difficult. Unlike mainstream processors where architectural features such as out-of-order execution and caches hide most of the complexities of efficient program execution, programmers of NPUs face a 'bare-metal' view of the architecture. They have to deal with a multithreaded environment with a high degree of parallelism, pipelining and multiple, heterogeneous, execution units and memory banks. Software development on such architectures is expensive. Moreover, different NPUs, even within the same family, differ considerably in their architecture, making portability of the software a major concern. At the same time expensive network processing applications based on deep packet inspection are both in-creasingly important and increasingly difficult to realize due to high link rates. They could potentially benefit greatly from the hardware features offered by NPUs, provided they were easy to use. We therefore propose to use more abstract programming models that hide much of the complexity of 'bare-metal' architectures from the programmer. In this paper, we present one such programming model: Ruler, a flexible high-level language for deep packet in-spection (DPI) and packet rewriting that is easy to learn, platform independent and lets the programmer concentrate on the functionality of the application. Ruler provides packet matching and rewrit-ing based on regular expressions. We describe our implementa-tion on the Intel IXP2xxx NPU and show how it provides versatile packet processing at gigabit line rates.
[Computer systems organization, Embedded and cyber-physical systems, Real-time systems]
Design of a scalable network programming framework
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Nearly all programmable commercial hardware solutions offered for high-speed networking systems are capable of meeting the performance and flexibility requirements of equipment vendors. However, the primary obstacle to adoption lies with the software architectures and programming environments supported by these systems. Shortcomings include use of unfamiliar languages and libraries, portability and backwards compatibility, vendor lock-in, design and development learning curve, availability of competent developers, and a small existing base of software. Another key shortcoming of previous architectures is that either they are not multi-core oriented or they expose all the hardware details, making it very hard for programmers to deal with. In this paper, we present a practical software architecture for high-speed embedded systems that is portable, easy to learn and use, multicore oriented, and efficient.
[Computer systems organization, Networks, Embedded and cyber-physical systems, Real-time systems, Hardware, Robustness, Network services]
Fair multithreading on packet processors for scalable network virtualization
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Network virtualization requires careful control of networking resources, including link bandwidth, router memory, and packet processing time. Isolation and fair sharing of processing resources in current high-performance packet processors occur at the granularity of entire processor cores. Scaling of network virtualization to larger numbers of parallel slices requires a more fine-grained processor sharing mechanism. Our work presents a novel approach, called Fair Multithreading (FMT), that allows hardware threads to share a processor core while ensuring isolation and weighted fair access. We present an analysis of the FMT algorithm and a prototype implementation on a NetFPGA system. Our evaluation results indicate that FMT can be implemented at speeds that are necessary to make scheduling decisions at the instruction level. We show the impact of having such fine-grained processor schedulers in substrate nodes by comparing the resource utilization of virtual network slices in our system to traditional whole-core allocations. Our simulation results show the FMT-based substrate networks can be utilized more efficiently and more virtual network requests can be accommodated. These results indicate the significant improvement in system scalability that can be gained from our fine-grained processor scheduling system.
[Networks, Computer systems organization, Network components, Routers, Intermediate nodes, Parallel architectures, Architectures]
A block-based reservation architecture for the implementation of large packet buffers
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
DRAM is typically needed to implement large packet buffers, but DRAM devices have worst-case random access latencies that are too slow to match the bandwidth requirements of high-performance routers. Existing DRAM-based architectures for supporting linespeed queue operations can be classified into three categories: prefetching-based [1], randomization-based [2], and reservation-based [3]. They are all based on interleaving memory accesses across multiple parallel DRAM banks for achieving higher memory bandwidths, but they differ in their packet placement and memory operation scheduling mechanisms. Each class of architectures has its own benefits. For router architectures where the departure times of packets can be deterministically calculated before the packets are inserted into the packet buffer, the reservation-based approach has the nice property that in-time packet retrievals can be guaranteed. Reservation-based architectures work by constructive placement of packets and scheduling of memory operations based on the departure times of packets.
[]
NetSlices: scalable multi-core packet processing in user-space
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Modern commodity operating systems do not provide developers with user-space abstractions for building high-speed packet processing applications. The conventional raw socket is inefficient and unable to take advantage of the emerging hardware, like multi-core processors and multi-queue network adapters. In this paper we present the NetSlice operating system abstraction. Unlike the conventional raw socket, NetSlice tightly couples the hardware and software packet processing resources, and provides the application with control over these resources. To reduce shared resource contention, NetSlice performs domain specific, coarse-grained, spatial partitioning of CPU cores, memory, and NICs. Moreover, it provides a streamlined communication channel between NICs and user-space. Although backward compatible with the conventional socket API, the NetSlice API also provides batched (multi-) send / receive operations to amortize the cost of protection domain crossings. We show that complex user-space packet processors---like a protocol accelerator and an IPsec gateway---built from commodity components can scale linearly with the number of cores and operate at 10Gbps network line speeds.
[Networks, Communications management, Network components, Operating systems, Public Internet, Network types, Contextual software domains, Software organization and properties, Software and its engineering]
Future networking: reconfiguration heartland, challenge and revolution
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
In the context of network systems I will discuss the limits of reconfigurable systems. To this end, I will draw on examples from architectural trends, the silicon roadmap in a post Moore's law era, along with recent directions in future networking. I will then set out to map the current and future edges of reconfigurable systems in networking. In this talk I will discuss the state and future of SDN, showing how reconfiguration is an essential function of all networks. The role of reconfiguration has evolved from a prototyping technology to incorporate control technologies, and beyond this to hybrid host systems, adaptive interface design and use in the control of future network-transmission systems. As network reconfiguration must, by necessity, match the needs of both user and implementer, the emergence of SDN has, for reconfigurable systems, led to a new class of domain specific languages, a renewed interest in functional languages, and an ever-wider user base. I conclude with a discussion of current systems and ideas as future predictors for technologies beyond 100Gb/s. In particular I will talk to the opportunities enabled by tighter photonic integration. This is alongside a forecast of how technologies, limitations, and usage will impacts the future of networking reconfiguration.
[Networks, Network components, Network architectures, Public Internet, Network types]
ElastiCon: an elastic distributed sdn controller
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Software Defined Networking (SDN) has become a popular paradigm for centralized control in many modern networking scenarios such as data centers and cloud. For large data centers hosting many hundreds of thousands of servers, there are few thousands of switches that need to be managed in a centralized fashion, which cannot be done using a single controller node. Previous works have proposed distributed controller architectures to address scalability issues. A key limitation of these works, however, is that the mapping between a switch and a controller is statically configured, which may result in uneven load distribution among the controllers as traffic conditions change dynamically. To address this problem, we propose ElastiCon, an elastic distributed controller architecture in which the controller pool is dynamically grown or shrunk according to traffic conditions. To address the load imbalance caused due to spatial and temporal variations in the traffic conditions, ElastiCon automatically balances the load across controllers thus ensuring good performance at all times irrespective of the traffic dynamics. We propose a novel switch migration protocol for enabling such load shifting, which conforms with the Openflow standard. We further design the algorithms for controller load balancing and elasticity. We also build a prototype of ElastiCon and evaluate it extensively to demonstrate the efficacy of our design.
[Software system structures, Organizing principles for web applications, Software organization and properties, Software and its engineering, Distributed systems organizing principles]
HyPaFilter: A Versatile Hybrid FPGA Packet Filter
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
With network traffic rates continuously growing, security systems like firewalls are facing increasing challenges to process incoming packets at line speed without sacrificing protection. Accordingly, specialized hardware firewalls are increasingly used in high-speed environments. Hardware solutions, though, are inherently limited in terms of the complexity of the policies they can implement, often forcing users to choose between throughput and comprehensive analysis. On the contrary, complex rules typically constitute only a small fraction of the rule set. This motivates the combination of massively parallel, yet complexity-limited specialized circuitry with a slower, but semantically powerful software firewall. The key challenge in such a design arises from the dependencies between classification rules due to their relative priorities within the rule set: complex rules requiring software-based processing may be interleaved at arbitrary positions between those where hardware processing is feasible. We therefore discuss approaches for partitioning and transforming rule sets for hybrid packet processing, and propose HyPaFilter, a hybrid classification system based on tailored circuitry on an FPGA as an accelerator for a Linux netfilter firewall. Our evaluation demonstrates 30-fold performance gains in comparison to software-only processing.
[Communication hardware, interfaces and storage, Network security, Systems security, Networking hardware, Integrated circuits, Denial-of-service attacks, Security and privacy, Reconfigurable logic and FPGAs, Hardware accelerators, Hardware, Reconfigurable logic applications, Firewalls]
Architectural impact of stateful networking applications
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
The explosive and robust growth of the Internet owes a lot to the "end-to-end principle", which pushes stateful operations to the end-points. The Internet grew both in traffic volume, and in the richness of the applications it supports. The growth also brought along new security issues and network monitoring applications. Edge devices, in particular, tend to perform upper layer packet processing. A whole new class of applications require stateful processing.In this paper we study the impact of stateful networking applications on architectural bottlenecks. The analysis covers applications with a variety of statefulness levels. The study emphasizes the data cache behavior. Nevertheless, we also discuss other issues, such as branch prediction and ILP. Additionally, we analyze the architectural impact through the TCP connection life. Our results show an important memory bottleneck due to maintaining the states. Moreover, depending on the target of the application, the memory bottleneck may be concentrated within a set of packets or distributed along the TCP connection lifetime.
[Computer systems organization, Embedded and cyber-physical systems, Hardware validation, Hardware, Real-time systems]
Resource mapping and scheduling for heterogeneous network processor systems
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Task to resource mapping problems are encountered during (i) hardware-software co-design and (ii) performance optimization of Network Processor systems. The goal of the first problem is to find the task to resource mapping that minimizes the design cost subject to all design constraints. The goal of the second problem is to find the mapping that maximizes the performance, subject to all architectural constraints. To meet the design goals in performance, it may be necessary to allow multiple packets to be inside the system at any given instance of time and this may give rise to the resource contention between packets. In this paper, a Randomized Rounding (RR) based solution is presented for the task to resource mapping and scheduling problem. We also proposed two techniques to detect and eliminate the resource contention. We evaluate the efficacy of our RR approach through extensive simulation. The simulation results demonstrate that this approach produces near optimal solutions in almost all instances of the problem in a fraction of time needed to find the optimal solution. The quality of the solution produced by this approach is also better than often used list scheduling algorithm for task to resource mapping problem. Finally, we demonstrate with a case study, the results of a Network Processor design and scheduling problem using our techniques.
[Hardware validation, Hardware]
Group round robin: improving the fairness and complexity of packet scheduling
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
We present Group Round-Robin (GRR) scheduling, a hybrid fair packet scheduling framework based on a grouping strategy that narrows down the traditional trade-off between fairness and computational complexity. GRR combines its grouping strategy with a specialized round-robin scheduling algorithm that utilizes the properties of GRR groups to schedule flows within groups in a manner that provides O(1) bounds on fairness with only O(1) time complexity. Under the practical assumption that GRR employs a small constant number of groups, we apply GRR to popular fair queuing scheduling algorithms and show how GRR can be used to achieve constant bounds on fairness and time complexity for these algorithms. We also present and prove new results on the fairness bounds for several of these fair queuing algorithms using a consistent fairness measure. We analyze the behavior of GRR and present experimental results that demonstrate how GRR can be combined with existing scheduling algorithms to provide much lower scheduling overhead and more than an order of magnitude better scheduling accuracy in practice than scheduling algorithms without GRR.
[Theory of computation, Theory and algorithms for application domains, Online algorithms, Scheduling algorithms, Machine learning theory, Online learning algorithms, Reinforcement learning, Sequential decision making, Approximation algorithms analysis, Design and analysis of algorithms]
Pipelined two step iterative matching algorithms for CIOQ crossbar switches
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Traditional iterative matching algorithms for VOQ switches need three steps, i.e., request, grant and accept. By incorporating arbitration into the request step, two step iterative matching can be achieved. This enables simpler implementation and shorter scheduling time, while maintaining almost identical performance. As an example of the two step iterative matching algorithms, in this paper we present Two Step Parallel Iterative Matching (PIM2), and theoretically prove that its average convergence iterations are less than ln N + e/(e-1) for an N x N switch. Furthermore, two step iterative matching algorithms can be efficiently pipelined on CIOQ switches so that two matchings can be obtained in each time slot. We propose a scheme called Second of Line (SOL) matching to provide two independent virtual switches, with which the pipelining can be achieved without additional scheduling time and arbitration hardware. More importantly, the pipelined algorithms are theoretically guaranteed to achieve 100% throughput for any admissible traffic. Extensive simulations are conducted to show that our analytical result on the average convergence iterations ln N + e/(e-1) is more accurate than the classical result log2 N + 4/3, and to test the performance of different pipelined algorithms on CIOQ switches.
[Networks, Packet-switching networks, Network types]
Gigabit routing on a software-exposed tiled-microprocessor
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
This paper investigates the suitability of emerging tiled-architectures, equipped with low-latency on-chip networks, for high-performance network routing. In this paper, we present the design, implementation and evaluation of a continuum of software-based routers on the MIT RAW microprocessor. The routers presented in this paper explore 1) several design choices for mapping the routing functions to the RAW tiles, 2) the role and behavior of RAW on-chip interconnects for transporting and switching packets, and 3) the placement of packet buffers and their interaction with the RAW on-chip networks. Our experiments evaluate the performance benefit of streaming on-chip networks for transporting packet payloads, effect of buffering on the linecards, and the cost of scaling our design. Our software-based routers on RAW can achieve a throughput of 15Gb/sec -- an order of magnitude improvement over previous software routers on traditional general-purpose architectures and at least four times faster than Intel's IXP1200 Network Processor.
[Networks, Network components, Routers, Intermediate nodes]
An operating system architecture for network processors
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Network devices have become significantly more complex in recent years, with the most sophisticated current devices incorporating one or more general-purpose CPUs as part of their hardware. The need for such processing capability is motivated by the desire to move greater amounts of functionality, of ever-increasing complexity, from the host CPU to the network device itself. A significant challenge in doing so is managing the complexity of the software running on the network device.We believe that the complexity of this software has reached the point where it is now on a par with many general-purpose systems, and thus requires the same management infrastructure--an operating system for network processors.In this paper we describe an architecture for such an OS, presenting the features most relevant to network processors and describing similarities to and differences from a general-purpose OS. We present a prototype implementation using an SMP system as a virtual network processor, and show how our prototype was used to evaluate a novel user-space interface to a network device.
[Designing software, Software creation and management, Operating systems, Contextual software domains, Software organization and properties, Software and its engineering]
Design considerations for network processor operating systems
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Network processors (NPs) promise a flexible, programmable packet processing infrastructure for network systems. To make full use of the capabilities of network processors, it is imperative to provide the ability to dynamically adapt to changing traffic patterns and to provide run-time support in the form of a network processor operating system. The differences to existing operating systems and the main challenges lie in the multiprocessor nature of NPs, their on-chip resources constraints, and the real-time processing requirements. In this paper, we explore the key design tradeoffs that need to be considered when designing a network processor operating system. In particular, we explore the performance impact of (1) application analysis for partitioning, (2) network traffic characterization, (3) workload mapping, and (4) run-time adaptation. We present and discuss qualitative and quantitative results in the context of a particular application analysis and mapping framework, but the observations and conclusions are generally applicable to any run-time environment for network processors.
[Operating systems, Contextual software domains, Software organization and properties, Software and its engineering, Process management]
A novel reconfigurable hardware architecture for IP address lookup
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
IP address lookup is one of the most challenging problems of Internet routers. In this paper, an IP lookup rate of 263 Mlps (Million lookups per second) is achieved using a novel architecture on reconfigurable hardware platform. A partial reconfiguration may be needed for a small fraction of route updates. Prefixes can be added or removed at a rate of 2 million updates per second, including this hardware reconfiguration overhead. A route update may fail due to the physical resource limitations. In this case, which is rare if the architecture is properly configured initially, a full reconfiguration is needed to allocate more resources to the lookup unit.
[Networks, Network components, Routers, Intermediate nodes, Application specific processors, Hardware, Very large scale integration design, Application-specific VLSI designs]
Segmented hash: an efficient hash table implementation for high performance networking subsystems
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Hash tables provide efficient table implementations, achieving O(1), query, insert and delete operations at low loads. However, at moderate or high loads collisions are quite frequent, resulting in decreased performance. In this paper, we propose the segmented hash table architecture, which ensures constant time hash operations at high loads with high probability. To achieve this, the hash memory is divided into N logical segments so that each incoming key has N potential storage locations; the destination segment is chosen so as to minimize collisions. In this way, collisions, and the associated probe sequences, are dramatically reduced. In order to keep memory utilization minimized, probabilistic filters are kept on-chip to allow the N segments to be accessed without in-creasing the number of off-chip memory operations. These filters are kept small and accurate with the help of a novel algorithm, called selective filter insertion, which keeps the segments balanced while minimizing false positive rates (i.e., incorrect filter predictions). The performance of our scheme is quantified via analytical modeling and software simulations. Moreover, we discuss efficient implementations that are easily realizable in modern device technologies. The performance benefits are significant: average search cost is reduced by 40% or more, while the likelihood of requiring more than one memory operation per search is reduced by several orders of magnitude.
[Hardware validation, Hardware]
SSA: a power and memory efficient scheme to multi-match packet classification
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
New network applications like intrusion detection systems and packet-level accounting require multi-match packet classification, where all matching filters need to be reported. Ternary Content Addressable Memories (TCAMs) have been adopted to solve the multi-match classification problem due to their ability to perform fast parallel matching. However, TCAM is expensive and consumes large amounts of power. None of the previously published multi-match classification schemes is both memory and power efficient. In this paper, we develop a novel scheme that meets both requirements by using a new Set Splitting Algorithm (SSA). The main idea of SSA is that it splits filters into multiple groups and performs separate TCAM lookups into these groups. It guarantees the removal of at least half the intersections when a filter set is split into two sets, thus resulting in low TCAM memory usage. SSA also accesses filters in the TCAM only once per packet, leading to low power consumption. We compare SSA with two best known schemes: MUD [1] and Geometric Intersection-based solutions [2]. Simulation results based on the SNORT filter sets show that SSA uses approximately the same amount of TCAM memory as MUD, but yields a 75% to 95% reduction in power consumption. Compared with Geometric Intersection-based solutions, SSA uses 90% less TCAM memory and power at the cost of one additional TCAM lookup per packet.
[Networks, Network components, Routers, Intermediate nodes]
Network processor acceleration for a Linux* netfilter firewall
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Network firewalls occupy a central role in computer security, protecting data, compute, and networking resources while still allowing useful packets to flow. Increases in both the work per network packet and packet rate make it increasingly difficult for general-purpose processor based firewalls to maintain line rate. In a bid to address these evolving requirements we have prototyped a hybrid firewall, using a simple firewall running on a network processor to accelerate a Linux* Netfilter Firewall executing on a general purpose processor. The simple firewall on the network processor provides high rate packet processing for all the packets while the general-purpose processor delivers high rate, full featured firewall processing for those packets that need it. This paper describes the hybrid firewall prototype with a focus on the software created to accelerate Netfilter with a network processor resident firewall. Measurements show our hybrid firewall able to maintain close to 2 Gb/sec line rate for all packet sizes, a significant improvement over the original firewall. We also include the hard won lessons learned while implementing the hybrid firewall.
[Security and privacy, Network security]
Addressing data compatibility on programmable network platforms
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Large-scale applications require the efficient exchange of data across their distributed components, including data from heterogeneous sources and to widely varying clients. Inherent to such data exchanges are (1) discrepancies among the data representations used by sources, clients, or intermediate application components (e.g., due to natural mismatches or due to dynamic component evolution), and (2) requirements to route, combine, or otherwise manipulate data as it is being transferred. As a result, there is an ever growing need for data conversion services, handled by stubs in application servers, by middleware or messaging services, by the operating system, or by the network. This paper's goal is to demonstrate and evaluate the ability of modern network processors to efficiently address data compatibility issues, when data is 'in transit' between application-level services. Toward this end, we present the design and implementation of a network-level execution environment that permits systems to dynamically deploy and configure application-level data conversion services 'into' the network infrastructure. Experimental results obtained with a prototype implementation on Intel's IXP2400 network processors include measurements of XML-like data format conversions implemented with efficient binary data formats.
[Computer systems organization, Software system structures, Distributed architectures, Operating systems, Contextual software domains, Software organization and properties, Software and its engineering, Process management, Architectures, Distributed systems organizing principles]
SpliceNP: a TCP splicer using a network processor
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
TCP Splicing can be used in content-aware switches to tremendously reduce overall request latency. In order to reduce the processing latency further, we propose to offload the protocol processing onto network processors (NPs). An NP consists of a multithreaded multiprocessor architecture that can provide high throughput for packet processing or forwarding. However, offloading any protocol software to an NP needs to be carefully designed due to its low-level programming and limited control memory size.In this paper, we first analyze the operation of TCP Splicing in detail and evaluate its performance through measurements on a Linux-based switch. Then various possibilities of workload allocation among different computation resources in an NP are presented, and the design tradeoffs are discussed. A content aware switch is implemented using IXP 2400 NP and evaluated for performance comparison. The measurement results demonstrate that our NP-based switch can reduce the http processing latency by an average of 83.3% for a 1K byte web page. The amount of reduction increases with larger file sizes. It is also shown that the packet throughput can be improved by up to 5.7x across a range of files by taking advantage of multithreading and multiprocessing, available in the NP.
[Networks, Network protocols]
A scalable load balancer for forwarding internet traffic: exploiting flow-level burstiness
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Packet scheduling in parallel forwarding systems is a hard problem. Two major goals of a scheduler that distributes incoming packets to multiple forwarding engines are to achieve high system utilization (by balancing the load evenly among the multiple engines) and to maintain packet ordering within individual flows. Additionally, from the viewpoint of the overall performance, the system should exhibit a good cache behavior by preserving temporal locality in the workload of each forwarding engine. In this paper, we show how the burstiness in Internet flows can be exploited to improve the performance of the scheduler. Specifically, TCP flows, which contribute to over 90 percent of the Internet traffic, transmit in bursts with relatively large delays in between. We propose a load balancing scheme based on this insight to achieve the scheduling goals. Our design is verified by simulations driven by real-world traces.
[Networks, Network architectures]
Minimizing the overhead in implementing flow-aware networking
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
An enhanced flow-aware Internet is arguably a more effective means of ensuring adequate performance than implementing the complex standardized QoS architectures. This flow-aware network would provide flow-level performance guarantees for real time and data applications by implementing per-flow fair queueing and by limiting the impact of overload through flow level admission control. The paper discusses the feasibility of the implied router mechanisms and proposes original solutions that minimize the necessary overhead with respect to the current best effort network. Preferred solutions significantly reduce requirements for flow state by employing directly addressed bitmaps to record flow status, as necessary for scheduling and admission control, respectively.
[Networks, Packet-switching networks, Network types]
Framework for supporting multi-service edge packet processing on network processors
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Network edge packet-processing systems, as are commonly implemented on network processor platforms, are increasingly required to support a rich set of services. These multi-service systems are also subjected to widely varying and unpredictable traffic. Current network processor systems do not simultaneously deal well with a variety of services and fluctuating workloads. For example, current methods of worst-case, static provisioning can meet performance requirements for any workload, but provisioning each service for its worst case reduces the total number of services that can be supported. Alternately, profile-driven automatic-partitioning compilers create efficient binaries for multi-service applications for specific workloads but they are sensitive to workload fluctuations.Run-time adaptation is a potential solution to this problem. With run-time adaptation, the mapping of services to system resources can be dynamically adjusted based on the workload. We have implemented an adaptive system that automatically changes the mapping of services to processors, and handles migration of services between different processor core types to match the current workload. In this paper we explain our adaptive system built on the Intel&#174; IXP2400 network processor. We demonstrate that it outperforms multiple different profile-driven compiled solutions for most workloads and performs within 20% of the optimal compiled solution for the remaining workloads.
[Communication hardware, interfaces and storage, Measurement, Networks, Cross-computing tools and techniques, Embedded and cyber-physical systems, Scheduling, Contextual software domains, Embedded software, Computer systems organization, Software system structures, Multiprocessing / multiprogramming / multitasking, Embedded systems, Metrics, Operating systems, Hardware, Performance, General and reference, Software organization and properties, Software and its engineering, Process management, Real-time systems software]
Design and analysis of an NoC architecture from performance, reliability and energy perspective
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Network-on-Chip (NoC) architectures employing packet-based communication are being increasingly adopted in System-on-Chip (SoC) designs. In addition to providing high performance, the fault tolerance and reliability of these networks is becoming a critical issue due to several artifacts of deep sub-micron technologies. Consequently, it is important for a designer to have access to fast methods for evaluating the performance, reliability, and energy-efficiency of an on-chip network. Towards this end, first, we propose a novel path-sensitive router architecture for low-latency applications. Next, we present a queuing-theory-based model for evaluating the performance and energy behavior of on-chip networks. Then the model is used to demonstrate the effectiveness of our proposed router. The performance (average latency) and energy consumption results from the analytical model are validated with those obtained from a cycle-accurate simulator. Finally, we explore error detection and correction mechanisms that provide different energy-reliability- performance tradeoffs and extend our model to evaluate the on-chip network in the presence of these error protection schemes. Our reliability exploration culminates with the introduction of an array of transient fault protection techniques, both architectural and algorithmic, to tackle reliability issues within the router's individual hardware components. We propose a complete solution safeguarding against both the traditional link faults and internal router upsets, without incurring any significant latency, area and power overhead.
[Integrated circuits, Interconnect, Hardware validation, Hardware]
Fast and scalable pattern matching for content filtering
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
High-speed packet content inspection and filtering devices rely on a fast multi-pattern matching algorithm which is used to detect predefined keywords or signatures in the packets. Multi-pattern matching is known to require intensive memory accesses and is often a performance bottleneck. Hence specialized hardware-accelerated algorithms are being developed for line-speed packet processing. While several pattern matching algorithms have already been developed for such applications, we find that most of them suffer from scalability issues. To support a large number of patterns, the throughput is compromised or vice versa.We present a hardware-implementable pattern matching algorithm for content filtering applications, which is scalable in terms of speed, the number of patterns and the pattern length. We modify the classic Aho-Corasick algorithm to consider multiple characters at a time for higher throughput. Furthermore, we suppress a large fraction of memory accesses by using Bloom filters implemented with a small amount of on-chip memory. The resulting algorithm can support matching of several thousands of patterns at more than 10 Gbps with the help of a less than 50 KBytes of embedded memory and a few megabytes of external SRAM. We demonstrate the merit of our algorithm through theoretical analysis and simulations performed on Snort's string set.
[Networks, Network monitoring, Network services]
High-throughput linked-pattern matching for intrusion detection systems
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
This paper presents a hardware architecture for highly efficient intrusion detection systems. In addition, a software tool for automatically generating the hardware is presented.Intrusion detection for network security is a compute-intensive application demanding high system performance. By moving both the string matching and the linking of multi-part rules to hardware, our architecture leaves the host system free for higher-level analysis. The tool automates the creation of efficient Field Programmable Gate Array architectures (FPGA). The generated hardware allows an FPGA-based system to perform deep-packet inspection of streams at up to 10 Gb/s line rates at a high level of area efficiency. Going beyond previous basic string-matching implementations that offer only single-string matching, the architecture provides support for rules requiring complex, linked (correlated-content) constructions. This allows most Snort content-linking extensions including `distance' and `within' bounding restrictions.
[Computer systems organization, Embedded and cyber-physical systems, Real-time systems]
Optimal XOR hashing for a linearly distributed address lookup in computer networks
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Hashing algorithms have been widely adopted to provide a fast address look-up process which involves a search through a large database to find a record associated with a given key. Modern examples include address-lookup in network routers for a forwarding outgoing link, rule-matching in intrusion detection systems comparing incoming packets with a large database, etc. Hashing algorithms involve transforming a key inside each target data to a hash value hoping that the hashing would render the database a uniform distribution with respect to this new hash value. When the database are already key-wise uniformly distributed, any regular hashing algorithm would easily lead to perfectly uniform distribution after the hashing. On the other hand, if records in the database are instead not uniformly distributed, then different hashing functions would lead to different performance. This paper addresses the case when such distribution follows a natural negative linear distribution, which is found to approximate distributions in many various applications. For this distribution, we derive a general formula for calculating the distribution variance produced by any given non-overlapped bit-grouping XOR hashing function. Such a distribution variance from the hashing directly translates to performance variations in searching. In this paper, the best XOR hashing function is determined for any given key size and any given hashing target size.
[]
Fast payload-based flow estimation for traffic monitoring and network security
Proceedings of the 2005 ACM symposium on Architecture for networking and communications systems
None
2005
Real-time IP flow estimation has many potential applications in network management, monitoring, security, and traffic engineering. Existing techniques typically rely on flow definitions being constrained as subsets of the fields in packet headers. This makes flow-membership tests relatively inexpensive. In this paper, we consider a more general flow estimation problem that needs complex packet-payload based tests for flow-membership. An example is to estimate traffic with common strings in the payload and detect potential virus signatures for early alarm generation. We develop a fast, memory efficient algorithm for solving this problem as a variant of the longest common subsequence problem. This is done via an application of Rabin fingerprinting in combination with Bloom Filters. Both analysis and simulation show the effectiveness of the developed method.
[Communication hardware, interfaces and storage, Networks, Management of computing and information systems, Professional topics, Hardware, Social and professional topics]
A proposed architecture for the GENI backbone platform
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
The GENI Project (Global Environment for Network Innovation) is a major NSF-sponsored initiative that seeks to create a national research facility to enable experimental deployment of innovative new network architectures on a sufficient scale to enable realistic evaluation. One key component of the GENI system will be the GENI Backbone Platform (GBP) that provides the resources needed to allow multiple experimental networks to co-exist within the shared GENI infrastructure. This paper reviews the objectives for the GBP, the key issues that affect its design and develops a reference architecture that provides a concrete example for how the objectives can be met, using commercially available subsystems.
[Networks, Network protocols]
Towards an efficient switch architecture for high-radix switches
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
The interconnection network plays a key role in the overall performance achieved by high performance computing systems, also contributing an increasing fraction of its cost and power consumption. Current trends in interconnection network technology suggest that high-radix switches will be preferred as networks will become smaller (in terms of switch count) with the associated savings in packet latency, cost, and power consumption. Unfortunately, current switch architectures have scalability problems that prevent them from being effective when implemented with a high number of ports.In this paper, an efficient and cost-effective architecture for high-radix switches is proposed. The architecture, referred to as Partitioned Crossbar Input Queued (PCIQ), relies on three key components: a partitioned crossbar organization that allows the use of simple arbiters and crossbars, a packet based arbiter, and a mechanism to eliminate the switch-level HOL blocking.Under uniform traffic, maximum switch efficiency is achieved. Furthermore, switch-level HOL blocking is completely eliminated under hot-spot traffic, again delivering maximum throughput. Additionally, PCIQ inherently implements an efficient congestion management technique that eliminates all the network-wide HOL blocking. On the contrary, the previously proposed architectures either show poor performance or they require significantly higher costs than PCIQ (in both components and complexity).
[Communication hardware, interfaces and storage, Networks, Packet-switching networks, Hardware, Network types]
Design of a web switch in a reconfigurable platform
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
The increase of the web traffic has created the need for web switches that are able to balance the traffic to the server farms based on their contents (e.g. layer 7 switching). In this paper we present a web switch implemented in a multi-processor reconfigurable platform augmented with hardware co-processors. The system supports the TCP splicing scheme to accelerate the routing of the packets by forwarding packets at the IP layer after a connection has been spliced. The processors are alleviated using special co-processors for the management of the spliced connection and the URL string parsing. The proposed scheme can sustain up to 927Mbps throughput for 64KB request file size consuming less than 1Watt in a Xilinx Virtex4 FPGA. Hence, the system provides an efficient combination of processor's flexibility and ASIC's performance. Finally, the system is compared against a network processor-based and a software content-based switch in terms of performance, area, and power.
[Networks, Network architectures]
Packet classification using coarse-grained tuple spaces
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
While the problem of high performance packet classification has received a great deal of attention in recent years, the research community has yet to develop algorithmic methods that can overcome the drawbacks of TCAM-based solutions. This paper introduces a hybrid approach, which partitions the filter set into subsets that are easy to search efficiently. The partitioning strategy groups filters that are close to one another in tuple space [10], which makes it possible to use information from single field lookups to limit the number of subsets that must be searched. We can trade-off running time against space consumption by adjusting the coarseness of the tuple space partition. We find that for two-dimensional filter sets, the method finds the best-matching filter with just four hash probes while limiting the memory space expansion factor to about 2. We also introduce a novel method for Longest Prefix Matching (LPM), which we use as a component of the overall packet classification algorithm. Our LPM method uses a small amount of on-chip memory to speedup the search of an off-chip data structure, but uses significantly less on-chip memory than earlier methods based on Bloom filters.
[Networks, Network components, Routers, Intermediate nodes]
CAMP: fast and efficient IP lookup architecture
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
A large body of research literature has focused on improving the performance of longest prefix match IP-lookup. More recently, embedded memory based architectures have been proposed, which delivers very high lookup and update throughput. These architectures often use a pipeline of embedded memories, where each stage stores a single or set of levels of the lookup trie. A stream of lookup requests are issued into the pipeline, one every cycle, in order to achieve high throughput. Most recently, Baboescu et al. [21] have proposed a novel architecture, which uses circular memory pipeline and dynamically maps parts of the lookup trie to different stages.In this paper we extend this approach with an architecture called Circular, Adaptive and Monotonic Pipeline (CAMP), which is based upon the key observation that circular pipeline allows decoupling the number of pipeline stages from the number of levels in the trie. This provides much more flexibility in mapping nodes of the lookup trie to the stages. The flexibility, in turn, improves the memory utilization and also reduces the total memory and power consumption. The flexibility comes at a cost however; since the requests are issued at an arbitrary stage, they may get blocked if their entry stage is busy. In an extreme case, a request may block for a time equal to the pipeline depth, which may severely affect the pipeline utilization. We show that fairly straightforward techniques can ensure nearly full utilization of the pipeline. These techniques, coupled with an adaptive mapping of trie nodes to the circular pipeline, create a pipelined architecture which can operate at high rates irrespective of the trie size.
[Networks, Document types, General and reference, Computing standards, RFCs and guidelines]
Fast packet classification using bloom filters
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
Ternary Content Addressable Memory (TCAM), although widely used for general packet classification, is an expensive and high power-consuming device. Algorithmic solutions which rely on commodity memory chips are relatively inexpensive and power-efficient but have not been able to match the generality and performance of TCAMs. Therefore, the development of fast and power-efficient algorithmic packet classification techniques continues to be a research subject.In this paper we propose a new approach to packet classification which combines architectural and algorithmic techniques. Our starting point is the well-known crossproduct algorithm which is fast but has significant memory overhead due to the extra rules needed to represent the crossproducts. We show how to modify the crossproduct method in a way that drastically reduces the memory requirement without compromising on performance. Unnecessary accesses to the off-chip memory are avoided by filtering them through on-chip Bloom filters. For packets that match p rules in a rule set, our algorithm requires just 4 + p + &#949; independent memory accesses to return all matching rules, where &#949; &lt;&lt; 1 is a small constant that depends on the false positive rate of the Bloom filters. Using two commodity SRAM chips, a throughput of 38 Million packets per second can be achieved. For rule set sizes ranging from a few hundred to several thousand filters, the average rule set expansion factor attributable to the algorithm is just 1.2 to 1.4. The average memory consumption per rule is 32 to 45 bytes.
[Networks, Network components, Routers, Intermediate nodes]
Efficient memory utilization on network processors for deep packet inspection
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
Deep Packet Inspection (DPI) refers to examining both packet header and payload to look for predefined patterns, which is essential for network security, intrusion detection and content-aware switch etc. The increasing line speed and expanding pattern sets make DPI a challenging task. Network Processors (NPs) are chosen to perform DPI due to their packet processing performance and programmability. In this paper, we focus on achieving high performance DPI through exploitation of NP's on-chip resources (particularly memory) and inherent parallel processing capability. We study the parallelism in classical DPI algorithms and construct a memory model for different parallel matching methods. Based on the model, we find the optimal organization of state machines that requires minimal on-chip memory space and guides us to high performance NP architectures for DPI. The performance evaluation experiments show that our method can reduce the memory usage by up to 86%. With an Intel IXP28xx NP simulator, we observe that the estimated DPI throughput reaches up to 5 Gbps.
[Networks, Network monitoring, Network services]
Advanced algorithms for fast and scalable deep packet inspection
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
Modern deep packet inspection systems use regular expressions to define various patterns of interest in network data streams. Deterministic Finite Automata (DFA) are commonly used to parse regular expressions. DFAs are fast, but can require prohibitively large amounts of memory for patterns arising in network applications. Traditional DFA table compression only slightly reduces the memory required and requires an additional memory access per input character. Alternative representations of regular expressions, such as NFAs and Delayed Input DFAs (D2FA) require less memory but sacrifice throughput. In this paper we introduce the Content Addressed Delayed Input DFA (CD2FA), which provides a compact representation of regular expressions that match the throughput of traditional uncompressed DFAs. A CD2FA addresses successive states of a D2FA using their content, rather than a "content-less" identifier. This makes selected information available earlier in the state traversal process, which makes it possible to avoid unnecessary memory accesses. We demonstrate that such content-addressing can be effectively used to obtain automata that are very compact and can achieve high throughput. Specifically, we show that for an application using thousands of patterns defined by regular expressions, CD2FAs use as little as 10% of the space required by a conventional compressed DFA, and match the throughput of an uncompressed DFA.
[Security and privacy, Network security]
Fast and memory-efficient regular expression matching for deep packet inspection
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
Packet content scanning at high speed has become extremely important due to its applications in network security, network monitoring, HTTP load balancing, etc. In content scanning, the packet payload is compared against a set of patterns specified as regular expressions. In this paper, we first show that memory requirements using traditional methods are prohibitively high for many patterns used in packet scanning applications. We then propose regular expression rewrite techniques that can effectively reduce memory usage. Further, we develop a grouping scheme that can strategically compile a set of regular expressions into several engines, resulting in remarkable improvement of regular expression matching speed without much increase in memory usage. We implement a new DFA-based packet scanner using the above techniques. Our experimental results using real-world traffic and patterns show that our implementation achieves a factor of 12 to 42 performance improvement over a commonly used DFA-based scanner. Compared to the state-of-art NFA-based implementation, our DFA-based packet scanner achieves 50 to 700 times speedup.
[Security and privacy, Network security]
An effective network processor design framework: using multi-objective evolutionary algorithms and object oriented techniques to optimise the intel IXP1200 network processor
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
In this paper we present a framework for design space exploration of a network processor, that incorporates parameterisation, power and cost analysis. This method utilises multi-objective evolutionary algorithms and object oriented analysis and design. Using this approach an engineer specifies certain hard and soft performance requirements for a multi-processor system, and allows it to be generated automatically by competitive evolution/optimisation, thus obviating the need for detailed design. To make the proposal concrete, we use the Intel IXP1200 network processor as a baseline complex system design and show how various improvements can be make to this architecture by evolutionary/competitive design. Various approaches to multi-objective optimisation (Darwin, Lamarck Baldwin, etc.) are compared and contrasted in their ability to generate architectures meeting various constraints. We also present an assessment of a proposed architecture with reference to four different packet processing roles. The merits of an "island clocking" scheme versus a "common clocking" scheme are also discussed. Our paper highlights the flexibility that this framework bestows on the designer, along with the potential to achieve cost savings and performance improvement.
[Computer systems organization, Modeling and simulation, Computing methodologies, Multiple instruction, multiple data, Parallel architectures, Model development and analysis, Model verification and validation, Architectures]
A methodology for evaluating runtime support in network processors
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
Modern network processor systems require the ability to adapt their processing capabilities at runtime to changes in network traffic. Traditionally, network processor applications have been optimized for a single static workload scenario, but recently several approaches for run-time adaptation have been proposed. Comparing these approaches and developing novel run-time support algorithms is difficult due to the multicore system-on-a-chip nature of network processors. In this paper, we present a model for network processors that can aid in evaluating different run-time support systems. The model considers workload characteristics of applications and network traffic. We use a queuing network abstraction to model different runtime systems. We illustrate the effectiveness of this model by comparing the performance of two existing workload adaptation algorithms.
[Computer systems organization, Networks, Network components, Routers, Intermediate nodes, Parallel architectures, Architectures]
High-throughput sketch update on a low-power stream processor
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
Sketch algorithms are widely used for many networking applications, such as identifying frequent items, top-k flows, and traffic anomalies. This paper explores the implementation of the Count-Min sketch update using Indexed SRF accesses on a SIMD stream processor (Imagine). Both the sketch data structure and the packet stream are modeled as streams, and in-lane accesses to the stream register file (SRF) support concurrent updates without explicit synchronization. The 500-MHz stream processor is capable of supporting sketch update at 10 Gbps throughput for minimum-sized IP packets. This is nearly the same performance as the 1.4-GHz Intel IXP2800 (13 Gbps), using significantly less power (2.89W vs. 21W).
[Communication hardware, interfaces and storage, Computer systems organization, Networks, Single instruction, multiple data, Hardware, Parallel architectures, Architectures]
Symerton--using virtualization to accelerate packet processing
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
The complexity of packet-processing applications continues to grow, with encryption, compression, and XML processing becoming common on packet-processing devices at the edge of enterprise and service provider networks. While performance remains a key differentiator for these devices, the complexity and rate of change in the supported applications has made general-purpose platforms an attractive alternative to ASICs and network processors. General-purpose platforms offer excellent programmability and a wealth of existing software, in the form of operating systems, libraries, and applications that can be used to build a packet-processing system; however, the performance of general-purpose operating systems is unacceptable for many environments. This has driven developers to either make derivative versions of existing operating systems or to use special-purpose operating systems with a less comprehensive and familiar library of existing software.As part of the Symerton project, we propose using virtualization to address these issues. We have designed a system that has a virtual machine dedicated to high-performance networking, and a virtual machine dedicated to hosting non-performance critical tasks in a general-purpose operating system. Using a proof-of-concept implementation, we show that the resulting system outperforms a general-purpose operating system by an average of 22% for a real networking application. We also discuss tradeoffs that will need to be considered in further development of systems using this design.
[Computer systems organization, Networks, Network protocols, Embedded and cyber-physical systems, Real-time systems]
Sequence-preserving adaptive load balancers
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
Load balancing in packet-switched networks is a task of ever-growing importance. Network traffic properties, such as the Zipf-like flow length distribution and bursty transmission patterns, and requirements on packet ordering or stable flow mapping, make it a particularly difficult and complex task, needing adaptive heuristic solutions. In this paper, we present two main contributions:Firstly, we evaluate and compare two recently proposed algorithmic heuristics that attempt to adaptively balance load among the destination units. The evaluation on real life traces confirms the previously conjectured impact of the Zipf-like flow length distribution and traffic burstiness. Furthermore, we identify the distinction between the goals of preserving either the sequence order of packets, or the flow-to-destination mapping, showing different strengths of each algorithm. Secondly, we demonstrate a novel hybrid scheme that combines best of the flow-based and burst-based load balancing techniques and excels in both of the key metrics of flow remapping and packet reordering.
[Networks, Network architectures]
Localized asynchronous packet scheduling for buffered crossbar switches
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
Buffered crossbar switches are a special type of crossbar switches. In such a switch, besides normal input queues and output queues, a small buffer is associated with each crosspoint. Due to the introduction of crosspoint buffers, output and input contention is eliminated, and the scheduling process for buffered crossbar switches is greatly simplified. Moreover, crosspoint buffers enable the switch to work in an asynchronous mode and easily schedule and transmit variable length packets. Compared with fixed length packet scheduling or cell scheduling, variable length packet scheduling, or packet scheduling for short, has some unique advantages: higher throughput, shorter packet latency and lower hardware cost. In this paper, we present a fast and practical scheduling scheme for buffered crossbar switches called Localized Asynchronous Packet Scheduling (LAPS). With LAPS, an input port or output port makes scheduling decisions solely based on the state information of its local crosspoint buffers, i.e., the crosspoint buffers where the input port sends packets to or the output port retrieves packets from. The localization property makes LAPS suitable for a distributed implementation and thus highly scalable. Since no comparison operation is required in LAPS, scheduling arbiters can be efficiently implemented using priority encoders, which can make arbitration decisions quickly in hardware. Another advantage of LAPS is that each crosspoint needs only L (the maximum packet length) buffer space, which minimizes the hardware cost of the switches. We also theoretically analyze the performance of LAPS, and in particular we prove that LAPS achieves 100% throughput for any admissible traffic with speedup of two. Finally, simulations are conducted to verify the analytical results and measure the performance of LAPS.
[Networks, Packet-switching networks, Network types]
Scalable network-based buffer overflow attack detection
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
Buffer overflow attack is the main attack method that most if not all existing malicious worms use to propagate themselves from machine to machine. Although a great deal of research has been invested in defense mechanisms against buffer overflow attack, most of them require modifications to the network applications and/or the platforms that host them. Being an extension work of CTCP, this paper presents a network-based low performance overhead buffer overflow attack detection system called Nebula 1 NEtwork-based BUffer overfLow Attack detection, which can detect both known and zero-day buffer overflow attacks based solely on the packets observed without requiring any modifications to the end hosts. Moreover, instead of deriving a specific signature for each individual buffer overflow attack instance, Nebula uses a generalized signature that can capture all known variants of buffer overflow attacks while reducing the number of false positives to a negligible level. In addition, Nebula is built on a centralized TCP/IP architecture that effectively defeats all existing NIDS evasion techniques. Finally, Nebula incorporates a payload type identification mechanism that reduces further the false positive rate and scales the proposed buffer overflow attack detection scheme to gigabit network links.
[Security and privacy, Network security]
WormTerminator: an effective containment of unknown and polymorphic fast spreading worms
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
The fast spreading worm is becoming one of the most serious threats to today's networked information systems. A fast spreading worm could infect hundreds of thousands of hosts within a few minutes. In order to stop a fast spreading worm, we need the capability to detect and contain worms automatically in real-time. While signature based worm detection and containment are effective in detecting and containing known worms, they are inherently ineffective against previously unknown worms and polymorphic worms. Existing traffic anomaly pattern based approaches have the potential to detect and/or contain previously unknown and polymorphic worms, but they either impose too much constraint on normal traffic or allow too much infectious worm traffic to go out to the Internet before an unknown or polymorphic worm can be detected.In this paper, we present WormTerminator, which can detect and completely contain, at least in theory, almost all fast spreading worms in real-time while blocking virtually no normal traffic. WormTerminator detects and contains the fast spreading worm based on its defining characteristic -- a fast spreading worm will start to infect others as soon as it successfully infects one host. WormTerminator also exploits the observation that a fast spreading worm keeps exploiting the same set of vulnerabilities when infecting new machines. To prove the concept, we have implemented a prototype of WormTerminator and have examined its effectiveness against the real Internet worm Linux/Slapper.
[Transport protocols, Networks, Network protocols, Security and privacy, Intrusion/anomaly detection and malware mitigation, Systems security, Public Internet, Operating systems security, Network types]
Packet pre-filtering for network intrusion detection
Proceedings of the 2006 ACM/IEEE symposium on Architecture for networking and communications systems
None
2006
As Intrusion Detection Systems (IDS)utilize more complex syntax to efficiently describe complex attacks, their processing requirements increase rapidly. Hardware and, even more, software platforms face difficulties in keeping up with the computationally intensive IDS tasks, and face overheads that can substantially diminish performance.In this paper we introduce a packet pre-filtering approach as a means to resolve, or at least alleviate, the increasing needs of current and future intrusion detection systems. We observe that it is very rare for a single incoming packet to fully or partially match more than a few tens of IDS rules. We capitalize on this observation selecting a small portion from each IDS rule to be matched in the pre-filtering step. The result of this partial match is a small subset of rules that are candidates for a full match. Given this pruned set of rules that can apply to a packet, a second-stage, full-match engine can sustain higher throughput.We use DefCon traces and recent Snort IDS rule-set,and show that matching the header and up to an 8-character prefix for each payload rule on each incoming packet can determine that on average 1.8 rules may apply on each packet, while the maximum number of rules to be checked across all packets is 32. Effectively, packet pre-filtering prevents matching at least 99%of the SNORT rules per packet and as a result minimizes processing and improves the scalability of the system. We also propose and evaluate the cost and performance of a reconfigurable architecture that uses multiple processing engines in order to exploit the benefits of pre-filtering.
[Networks, Network monitoring, Network services]
Optimization of pattern matching algorithm for memory based architecture
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Due to the advantages of easy re-configurability and scalability, the memory-based string matching architecture is widely adopted by network intrusion detection systems (NIDS). In order to accommodate the increasing number of attack patterns and meet the throughput requirement of networks, a successful NIDS system must have a memory-efficient pattern-matching algorithm and hardware design. In this paper, we propose a memory-efficient pattern-matching algorithm which can significantly reduce the memory requirement. For total Snort string patterns, the new algorithm achieves 29% of memory reduction compared with the traditional Aho-Corasick algorithm [5]. Moreover, since our approach is orthogonal to other memory reduction approaches, we can obtain substantial gain even after applying the existing state-of-the-art algorithms. For example, after applying the bit-split algorithm [9], we can still gain an additional 22% of memory reduction.
[Security and privacy, Network security]
Towards high-performance flow-level packet processing on multi-core network processors
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
There is a growing interest in designing high-performance network devices to perform packet processing at flow level. Applications such as stateful access control, deep inspection and flow-based load balancing all require efficient flow-level packet processing. In this paper, we present a design of high-performance flow-level packet processing system based on multi-core network processors. Main contribution of this paper includes: a) A high performance flow classification algorithm optimized for network processors; b) An efficient flow state management scheme leveraging memory hierarchy to support large number of concurrent flows; c) Two hardware-optimized order-preserving strategies that preserve internal and external per-flow packet order. Experimental results show that: a) The proposed flow classification algorithm, AggreCuts, outperforms the well-known HiCuts algorithm in terms of classification rate and memory usage; b) The presented SigHash scheme can manage over 10M concurrent flow states on the Intel IXP2850 NP with extremely low collision rate; c) The performance of internal packet order-preserving scheme using SRAM queue-array is about 70% of that of external packet order-preserving scheme realized by ordered-thread execution.
[Design, Cross-computing tools and techniques, General and reference]
Frame shared memory: line-rate networking on commodity hardware
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Network processors provide an economical programmable platform to handle the high throughput and frame rates of modern and next-generation communication systems. However, these platforms have exchanged general-purpose capabilities for performance. This paper presents an alternative; a software network processor (Soft-NP) framework using commodity general-purpose platforms capable of high-rate and throughput sequential frame processing compatible with high-level languages and general-purpose operating systems. A cache-optimized concurrent lock free queue provides the necessary low-overhead core-to-core communication for sustained sequential frame processing beyond the realized 1.41 million frames per second (Gigabit Ethernet) while permitting perframe processing time expansion with pipeline parallelism.
[General programming languages, Computing methodologies, Parallel computing methodologies, Language types, Software notations and tools, Parallel programming languages, Software and its engineering]
Experimental evaluation of a coarse-grained switch scheduler
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Modern high performance routers rely on sophisticated interconnection networks to meet ever increasing demands on capacity. Previous studies have used a combination of analysis and idealized simulations to show that coarse-grained scheduling of traffic flows can be effective in preventing interconnect congestion while ensuring high utilization. In this work, we study the performance of a coarse-grained scheduler in a real router with a scalable architecture similar to those found in high performance commercial systems. Our results are obtained by taking fine-grained measurements within the router that provide a detailed picture of the scheduler's behavior under a variety of conditions, giving a more complete and realistic understanding of the short time-scale dynamics than previous studies could provide.
[Networks, Network protocols, Packet-switching networks, Network types]
Design of a network architecture with inherent data path security
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Next-generation Internet architectures require designs with inherent security guarantees.We present a network architecture that uses credentials to audit traffic in the data path, where defenses can be employed often more quickly and efficiently than on end-systems.
[Security and privacy, Network security]
Experimenting with buffer sizes in routers
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Recent theoretical results in buffer sizing research suggest that core Internet routers can achieve high link utilization, if they are capable of storing only a handful of packets. The underlying assumption is that the traffic is non-bursty, and that the system is operated below 85-90% utilization. In this paper, we present a test-bed for buffer sizing experiments using NetFPGA [2], a PCI-form factor board that contains reprogrammable FPGA elements, and four Gigabit Ethernet interfaces. We have designed and implemented a NetFPGA-based Ethernet switch with finely tunable buffer sizes, and an event capturing system to monitor buffer occupancies inside the switch. We show that reducing buffer sizes down to 20-50 packets does not necessarily degrade system performance.
[Networks, Network architectures]
To CMP or not to CMP: analyzing packet classification on modern and traditional parallel architectures
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Packet classification is central to modern network functionality, yet satisfactory memory usage and performance remains elusive at the highest speeds. The recent emergence of low-cost, highly parallel architectures provides a promising platform on which to realize increased classification performance. We analyze two classic algorithms (ABV and HiCuts) in multiple parallel contexts. Our results show that performance depends strongly on many factors, including algorithm choice, hardware platform, and parallelization scheme. We find that there is no clear "best solution," but in the best cases hardware constraints are mitigated by the parallelization scheme and vice versa, yielding near-linear speedups as the degree of parallelization increases.
[Computer systems organization, Networks, Network components, Routers, Intermediate nodes, Parallel architectures, Architectures]
Flow-slice: a novel load-balancing scheme for multi-path switching systems
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Multi-Path Switching systems (MPS) are intensively used in the state-of-the-art core routers. One of the most intractable issues is how to load-balance traffic across its multiple paths while not disturbing the intra-flow packet orders. In this paper, based on the studies of tens of real Internet traces, we develop a novel scheme, namely Flow-Slice (FS), which cuts off each flow into flow-slices at every intra-flow interval larger than a slicing threshold set to 1ms 4ms and balances the load on the finer granularity. Through theoretical analyses and comprehensive trace-driven simulations, we show that FS achieves impressive load-balancing performance with little hardware cost while limiting the packet out-of-order chances to a negligible level (below 10 -6).
[Networks, Packet-switching networks, Network types]
Design of adaptive communication channel buffers for low-power area-efficient network-on-chip architecture
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Network-on-Chip (NoC)architectures provide a scalable solution to the wire delay constraints in deep submicron VLSI designs. Recent research into the ptimization of NoC architectures has shown that the design of buffers in the NoC routers influences the power consumption, area overhead and performance of the entire network. In this paper, we propose a low-power area-efficient NoC architecture by reducing the number of router buffers. As a reduction in the number of buffers degrades the network's performance, we propose to use the existing repeaters along the inter-router links as adaptive channel buffers for storing data when required. We evaluate the proposed adaptive communication channel buffers under static and dynamic buffer allocation in 8 x 8 mesh and folded torus network topologies. Simulation results show that reducing the router buffer size in half and using the adaptive channel buffers reduces the buffer power by 40-52% and leads to a 17-20% savings in overall network power with a 50% reduction in router area. The design with dynamic buffer allocation shows a marginal 1-5% drop in performance, while static buffer allocation shows a 10-20% drop in performance, for various traffic patterns.
[Integrated circuits, Interconnect, VLSI system specification and constraints, Hardware, Very large scale integration design]
Performance scalability of a multi-core web server
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Today's large multi-core Internet servers support thousands of concurrent connections or ows. The computation ability of future server platforms will depend on increasing numbers of cores. The key to ensure that performance scales with cores is to ensure that systems software and hardware are designed to fully exploit the parallelism that is inherent in independent network ows. This paper identifies the major bottlenecks to scalability for a reference server workload on a commercial server platform. However, performance scaling on commercial web servers has proven elusive. We determined that on web server running a modified SPEC-web2005 Support workload, throughput scales only 4.8 x on eight cores. Our results show that the operating system, TCP/IP stack, and application exploited ow-level parallelism well with few exceptions, and that load imbalance and shared cache affected performance little. Having eliminated these potential bottlenecks, we determined that performance scaling was limited by the capacity of the address bus, which became saturated on all eight cores. If this key obstacle is addressed, commercial web server and systems software are well-positioned to scale to a large number of cores.
[Cross-computing tools and techniques, Middleware for databases, Client-server architectures, Application servers, Information systems, Computer systems organization, Distributed architectures, Database web servers, Data management systems, Performance, General and reference, Architectures]
Automated task distribution in multicore network processors using statistical analysis
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Chip multiprocessor designs are the most common types of architectures seen in Network Processors. As the Network Processors are used to implement increasingly complicated applications, task distribution among the cores is becoming an important problem. In this paper, we propose a new task allocation scheme for such architectures. This scheme relies on the inherent modular nature of the networking applications and intelligently distributes modules among different execution cores. Additionally, we selectively replicate modules to parallelize execution of tasks having longer processing time. We have developed a technique that uses the probability distribution of the execution times of different modules in the networking applications. The proposed schemes result in resource utilization of up to 95%, 89%, and 84% on average for the processors with 2, 4, and 8 cores, respectively. The schemes are highly scalable and can improve the throughput by 6.72 times for 8 core processors, aggregated over four representative applications. The combination of selective replication of modules and variation-aware task allocation result in up to 12.5% (9.9% on average) performance improvement as compared to a scheme based on just mean processing time.
[Networks, Packet-switching networks, Network types]
Optimal packet scheduling in output-buffered optical switches with limited-range wavelength conversion
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
All-optical packet switching is a promising candidate for future high-speed switching. However, due to the absence of optical Ran-dom Access Memory, the traditional Virtual Output Queue (VOQ) based input-queued switches are difficult to implement in optical domain. In this paper we consider output-buffered optical packet switches. We focus on packet scheduling in an output-buffered optical packet switch with limited-range wavelength conversion, aiming at maximizing throughput and minimizing average queuing delay simultaneously. We show that it can be converted to a minimum cost maximum network flow problem. To cope with the high complexity of general network flow algorithms, we further present a new algorithm that can determine an optimal scheduling in O (min {W2,BW}) time, where W is the number of wave-length channels in each fiber and B is the length of the output buffer. We also conduct simulations to test the performance of the proposed scheduling algorithm under different traffic models.
[Networks, Packet-switching networks, Network types]
Low-latency scheduling in large switches
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Scheduling in large switches is challenging. Arbiters must operate at high rates to keep up with the high switching rates demanded by multi-gigabit-per-second link rates and short cells. Low-latency requirements of some applications also challenge the design of schedulers. In this paper, we propose the Parallel Wrapped Wave Front Arbiter with Fast Scheduler (PWWFA-FS). We analyze its performance, present simulation results, discuss its implementation, and show how this scheme can provide low latency under light load while scaling to large switches with multi-terabit-per-second throughput and hundreds of ports.
[Networks, Network components, Routers, Intermediate nodes]
On LID assignment in infiniBand networks
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
To realize a path in an InfiniBand network, an address, known as Local IDentifier (LID)in the InfiniBand specification, must be assigned to the destination and used in the forwarding tables of intermediate switches to direct the traffic following the path. Hence, path computation in InfiniBand networks has two tasks: (1)computing the paths, and (2 )assigning LIDs to destinations (and using the LIDs in the forwarding tables to realize the paths). We will refer to the task of computing paths as routing and the task of assigning LIDs as LID assignment Existing path computation methods for InfiniBand networks integrate these two tasks in one phase. In this paper, we propose to separate routing and LID assignment into two phases so as to achieve the best performance for both routing and LID assignment. Since the routing component has been extensively studied and is fairly well understood, this paper focuses on LID assignment whose major issue is to minimize the number of LIDs required to support a routing. We prove that the problem of realizing a routing with a minimum number of LIDs is NP-complete, develop a number of heuristics for this problem, and evaluate the performance of the heuristics through simulation. Our results demonstrate that by separating routing from LID assignment and using the schemes that are known to achieve good performance for routing and LID assignment separately, more effective path computation methods than existing ones can be developed.
[Network properties, Networks, Network structure, Network protocols, Network management, Network services]
Frame-aggregated concurrent matching switch
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Network operators need high-capacity router architectures that can offer scalability, provide throughput and performance guarantees, and maintain packet ordering. However, previous router architectures based on centralized crossbar-based architectures cannot scale to fast line rates and high port counts. Recently, a new scalable router architecture called the Concurrent Matching Switch (CMS)[5]was introduced that offers scalability by utilizing a fully distributed architecture based on two identical stages of fixed configuration meshes. It has been shown that fixed configuration meshes can be scaled to very fast line rates and highport counts via optical implementations.It has also been shown that the CMS architecture can achieve 100% through-put and packet ordering with only sequential hardware and O (1) amortized time complexity operations at each linecard. However, no delay performance guarantees have been shown for CMS. In this paper, we demonstrate a general delay performance guarantee for CMS.Based on this guarantee, we propose a novel frame-based CMS architecture that can achieve a performance guarantee of O (N log N)average packet delay, where N is the number of switch ports, while retaining scalability,throughput guarantees, packet ordering, and O (1) time complexity. This architecture improves upon the best previously-known average delay bound of O (N 2)given these switch properties. We further introduce several alternative frame-based CMS architectures.
[Networks, Packet-switching networks, Network components, Routers, Intermediate nodes, Network types]
Congestion management for non-blocking clos networks
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
We propose a distributed congestion management scheme for non-blocking, 3-stage Clos networks, comprising plain buffered crossbar switches. VOQ requests are routed using multipath routing to the switching elements of the 3rd-stage, and grants travel back to the linecards the other way around. The fabric elements contain independent single-resource schedulers, that serve requests and grants in a pipeline. As any other network with limited capacity, this scheduling network may suffer from oversubscribed links, hotspot contention, etc., which we identify and tackle. We also reduce the cost of internal buffers, by reducing the data RTT, and by allowing sub-RTT crosspoint buffers. Performance simulations demonstrate that, with almost all outputs congested, packets destined to non-congested outputs experience very low delays ( ow isolation). For applications requiring very low communication delays, we propose a second, parallel operation mode, wherein linecards can forward a few packets eagerly, each, bypassing the request-grant latency overhead.
[Networks, Network components, Routers, Intermediate nodes]
Compiling PCRE to FPGA for accelerating SNORT IDS
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Deep Payload Inspection systems like SNORT and BRO utilize regular expression for their rules due to their high expressibility and compactness. The SNORT IDS system uses the PCRE Engine for regular expression matching on the payload. The software based PCRE Engine utilizes an NFA engine based on certain opcodes which are determined by the regular expression operators in a rule. Each rule in the SNORT ruleset is translated by PCRE compiler into an unique regular expression engine. Since the software based PCRE engine can match the payload with a single regular expression at a time, and needs to do so for multiple rules in the ruleset, the throughput of the SNORT IDS system dwindles as each packet is processed through a multitude of regular expressions. In this paper we detail our implementation of hardware based regular expression engines for the SNORT IDS by transforming the PCRE opcodes generated by the PCRE compiler from SNORT regular expression rules. Our compiler generates VHDL code corresponding to the opcodes generated for the SNORT regular expression rules. We have tuned our hardware implementation to utilize an NFA based regular expression engine, using greedy quantifiers, in much the same way as the software based PCRE engine. Our system implements a regular expression only once for each new rule in the SNORT ruleset, thus resulting in a fast system that scales well with new updates. We implement two hundred PCRE engines based on a plethora of SNORT IDS rules, and use a Virtex-4 LX200 FPGA, on the SGI RASC RC 100 Blade connected to the SGI ALTIX 4700 supercomputing system as a testbed. We obtain an interface through-put of (12.9 GBits/s) and also a maximum speedup of 353X over software based PCRE execution.
[Computer systems organization, Parallel architectures, Architectures]
High-speed packet classification using binary search on length
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Packet classification is one of the major challenges for next generation routers since it involves complicated multi-dimensional search as well as it should be performed in wire-speed for all incoming packets. Area-based quad-trie is an excellent algorithm in the sense that it constructs a two-dimensional trie using source and destination prefix fields for packet classification. However, it does not achieve good search performance since search is linearly performed for prefix length. In this paper, we propose a new packet classification algorithm which applies binary search on prefix length to the area-based quad-trie. In order to avoid the pre-computation required in the binary search on length, the proposed algorithm constructs multiple disjoint tries depending on relative levels in rule hierarchy. We also propose two new optimization techniques considering rule priorities. For different types of rule sets having about 5000 rules, performance evaluation result shows that the average number of memory accesses is 18 to 67 and the memory consumption is 22 to 41 bytes per rule.
[Networks, Network components, Routers, Intermediate nodes]
An improved algorithm to accelerate regular expression evaluation
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Modern network intrusion detection systems need to perform regular expression matching at line rate in order to detect the occurrence of critical patterns in packet payloads. While deterministic finite automata (DFAs) allow this operation to be performed in linear time, they may exhibit prohibitive memory requirements. In [9], Kumar et al. propose Delayed Input DFAs (D2FAs), which provide a trade-off between the memory requirements of the compressed DFA and the number of states visited for each character processed, which corresponds directly to the memory bandwidth required to evaluate regular expressions. In this paper we introduce a general compression technique that results in at most 2N state traversals when processing a string of length N. In comparison to the D2FA approach, our technique achieves comparable levels of compression, with lower provable bounds on memory bandwidth (or greater compression for a given bandwidth bound). Moreover, our proposed algorithm has lower complexity, is suitable for scenarios where a compressed DFA needs to be dynamically built or updated, and fosters locality in the traversal process. Finally, we also describe a novel alphabet reduction scheme for DFA-based structures that can yield further dramatic reductions in data structure size.
[Security and privacy, Network security]
Curing regular expressions matching algorithms from insomnia, amnesia, and acalculia
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
The importance of network security has grown tremendously and a collection of devices have been introduced, which can improve the security of a network. Network intrusion detection systems (NIDS) are among the most widely deployed such system; popular NIDS use a collection of signatures of known security threats and viruses, which are used to scan each packet's payload. Today, signatures are often specified as regular expressions; thus the core of the NIDS comprises of a regular expressions parser; such parsers are traditionally implemented as finite automata. Deterministic Finite Automata (DFA) are fast, therefore they are often desirable at high network link rates. DFA for the signatures, which are used in the current security devices, however require prohibitive amounts of memory, which limits their practical use. In this paper, we argue that the traditional DFA based NIDS has three main limitations: first they fail to exploit the fact that normal data streams rarely match any virus signature; second, DFAs are extremely inefficient in following multiple partially matching signatures and explodes in size, and third, finite automaton are incapable of efficiently keeping track of counts. We propose mechanisms to solve each of these drawbacks and demonstrate that our solutions can implement a NIDS much more securely and economically, and at the same time substantially improve the packet throughput.
[Security and privacy, Network security]
Enhancing interoperability and stateful analysis of cooperative network intrusion detection systems
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
A traditional Network Intrusion Detection System (NIDS) is based on a centralized architecture that does not satisfy the needs of most modern network infrastructures characterized by high traffic volumes and complex topologies. The of decentralized NIDS based on multiple sensors is that each of them gets just a partial view of the network traffic and this prevents a stateful and fully reliable traffic analysis. We propose a novel cooperation mechanism that the previous issues through an innovative state management and state migration framework. It allows multiple decentralized sensors to share their internal state, thus accomplishing innovative and powerful traffic analysis. The advanced functionalities and performance of the proposed cooperative framework for network intrusion detection systems are demonstrated through a fully operative prototype.
[Networks, Network monitoring, Network services]
High-speed detection of unsolicited bulk emails
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
We propose a Progressive Email Classifier (PEC) for high-speed classification of message patterns that are commonly associated with unsolicited bulk email (UNBE). PEC is designed to operate at the network access point, the ingress between the Internet Service Provider (ISP) and the enterprise network; so that a surge of UNBE containing fresh patterns can be detected before they spread into the enterprise network. A real-time scoreboard keeps track of detected feature instances (FI) based on a scoring and aging engine, until they are considered either from valid or UNBE sources. A FI of a valid email is discarded, but an anomalous one is passed to a blacklist to control (e.g., block or defer) subsequent emails containing the FI. The anomaly detector of PEC can be used at different protocol layers. To gain some insights on the performance of PEC, we implemented PEC and integrated it with the sendmail daemon to detect anomalous URL links from email streams. Arbitrarily chosen on-line texts and URL links extracted from a corpus of spamming-phishing emails were used to compose testing emails. Experimental results on a Xeon based server show that PEC can handle 1.2M score/age updates, parse 0.9M URL links (of average size 30 bytes) for hashing and matching, and parsing of 25,000 email bodies of average size 1.5kB per second. The lossy detection system can be easily scaled by progressive selection of detection features and detection thresholds. It can be used alone or as an early screening tool for an existing infrastructure to defeat major UNBE flooding.
[Design, Cross-computing tools and techniques, General and reference]
A programmable message classification engine for session initiation protocol (SIP)
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Session Initiation Protocol (SIP) has begun to be widely deployed for multiple services such as VoIP, Instant Messaging and Presence. Each of these services uses different SIP messages, and depending on the value of a service, e.g. revenue, the associated messages may need to be prioritized accordingly. Even within the same service, different messages may be assigned different priorities. In this paper, we present the design and implementation of a programmable classification engine for SIP messages in the Linux kernel. This design uses a novel algorithm that in addition to classifying messages can extract and maintain state information across multiple messages. We apply the classifier for overload control using operator-specified rules for categorizing messages and associated actions, augmented with a protocol-level understanding of SIP message structure. When faced with loads beyond their capacity (e.g., during catastrophic situations and major network outages), SIP servers must drop messages. It is therefore desirable that the server process high-value messages in preference to lower-value messages. We evaluated our in-kernel classifier implementation with an open source SIP server (SER) for such an overload scenario. The workload consists of a mix of call setup and call handoff messages, and the classifier is programmed with rules that prioritize handoffs over call setups. We show that, while SER can process about 40K messages/sec (in a FIFO manner), our classifier can examine and prioritize 105K messages/sec during overload. With the classifier operating at peak throughput, SER's processing rate drops to 31.6K messages/sec, but all of the available high-value messages are processed.
[Networks, Communications management, Network protocols, Operating systems, Network services, Contextual software domains, Buffering, Software organization and properties, Software and its engineering]
DPICO: a high speed deep packet inspection engine using compact finite automata
Proceedings of the 3rd ACM/IEEE Symposium on Architecture for networking and communications systems
None
2007
Deep Packet Inspection (DPI)has been widely adopted in detecting network threats such as intrusion, viruses and spam. It is challenging, however, to achieve high speed DPI due to the expanding rule sets and ever increasing line rates. A key issue is that the size of the finite automata falls beyond the capacity of on-chip memory thus incurring expensive off-chip accesses. In this paper we present DPICO a hardware based DPI engine that utilizes novel techniques to minimize the storage requirements for finite automata. The techniques proposed are modified content addressable memory (mCAM), interleaved memory banks, and data packing. The experiment results show the scalable performance of DPICO can achieve up to 17.7 Gbps throughput using a contemporary FPGA chip. Experiment data also show that a DPICO based accelerator can improve the pattern matching performance of a DPI server by up to 10 times.
[Networks, Network monitoring, Network services]
Implementing an OpenFlow switch on the NetFPGA platform
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
We describe the implementation of an OpenFlow Switch on the NetFPGA platform. OpenFlow is a way to deploy experimental or new protocols in networks that carry production traffic. An OpenFlow network consists of simple flow-based switches in the datapath, with a remote controller to manage several switches. In practice, OpenFlow is most often added as a feature to an existing Ethernet switch, IPv4 router or wireless access point. An OpenFlow-enabled device has an internal flow-table and a standardized interface to add and remove flow entries remotely. Our implementation of OpenFlow on the NetFPGA is one of several reference implementations we have implemented on different platforms. Our simple OpenFlow implementation is capable of running at line-rate and handling all the traffic that is going through the Stanford Electrical Engineering and Computer Science building. We compare our implementation's complexity to a basic IPv4 router implementation and a basic Ethernet learning switch implementation. We describe the OpenFlow deployment into the Stanford campus and the Internet2 backbone.
[Wide area networks, Networks, Network protocols, Routers, Intermediate nodes, Network range, Network architectures, Network types, Network properties, Network components, Public Internet, Local area networks]
A remotely accessible network processor-based router for network experimentation
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Over the last decade, programmable Network Processors (NPs) have become widely used in Internet routers and other network components. NPs enable rapid development of complex packet processing functions as well as rapid response to changing requirements. In the network research community, the use of NPs has been limited by the challenges associated with learning to program these devices and with using them for substantial research projects. This paper reports on an extension to the Open Network Laboratory testbed that seeks to reduce these "barriers to entry" by providing a complete and highly configurable NP-based router that users can access remotely and use for network experiments. The base router includes support for IP route lookup and general packet filtering, as well as a flexible queueing sub-system and extensive support for performance monitoring. In addition, it provides a plugin environment that can be used to extend the router's functionality, enabling users to carry out significant network experiments with a relatively modest investment of time and effort. This paper describes our NP router and explains how it can be used. We provide several examples of network experiments that have been implemented using the plugin environment, and provide some baseline performance data to characterize the overall system performance. We also report that these routers have already been used for ten non-trivial projects in an advanced architecture course where most of the students had no prior experience using NPs.
[Networks, Network protocols]
Compact architecture for high-throughput regular expression matching on FPGA
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
In this paper we present a novel architecture for high-speed and high-capacity regular expression matching (REM) on FPGA. The proposed REM architecture, based on nondeterministic finite automaton (RE-NFA), efficiently constructs regular expression matching engines (REME) of arbitrary regular patterns and character classes in a uniform structure, utilizing both logic slices and block memory (BRAM) available on modern FPGA devices. The resulting circuits take advantage of synthesis and routing optimizations to achieve high operating speed and area efficiency. The uniform structure of our RE-NFA design can be stacked in a simple way to produce multi-character input circuits to scale up throughput further. An n-state m-character input REME takes only O (n X log<sub>2</sub> m) time to construct and occupies no more than O (n X m) logic units. The REMEs can be staged and pipelined in large numbers to achieve high parallelism without sacrificing clock frequency. Using the proposed RE-NFA architecture, we are able to implement 3 copies of two-character input REMEs, each with 760 regular expressions, 18715 states and 371 character classes, onto a single Xilinx Virtex 4 LX-100-12 device. Each copy processes 2 characters per clock cycle at 300 MHz, resulting in a concurrent throughput of 14.4 Gbps for 760 REMEs. Compared with the automatic NFA-to-VHDL REME compilation [13], our approach achieves over 9x throughput efficiency (Gbps*state/LUT). Compared with state-of-the-art REMEs on FPGA, our approach also indicates up to 70% better throughput efficiency.
[Computer systems organization, Parallel architectures, Architectures]
Acceleration of decision tree searching for IP traffic classification
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Traffic classification remains a hot research problem, especially when facing new traffic trends and new hardware architectures. We propose a classification tree search method called explicit range search, motivated by the characteristics of machine learning based classification approaches. Our method differs from previously known algorithms such as HiCut and HyperCut in how to cut the ranges within a dimension and how to search within the ranges. By storing explicit marks and performing hardware supported parallel comparison, the explicit range search can reduce the worst-case number of memory accesses from 26 to 5 on a number of realistic rule sets generated from a well-known machine learning algorithm (C4.5). We also describe in this paper the proposed design based on FPGA devices.
[Networks, Network monitoring, Application specific processors, Hardware, Very large scale integration design, Network services, Application-specific VLSI designs]
Efficient regular expression evaluation: theory to practice
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Several algorithms and techniques have been proposed recently to accelerate regular expression matching and enable deep packet inspection at line rate. This work aims to provide a comprehensive practical evaluation of existing techniques, extending them and analyzing their compatibility. The study focuses on two hardware architectures: memory-based ASICs and FPGAs.
[Theory of computation, Grammars and context-free languages, Formal language definitions, Software notations and tools, Hardware, Robustness, Formal languages and automata theory, Software and its engineering]
A scalable multithreaded L7-filter design for multi-core servers
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
L7-filter is a significant component in Linux's QoS framework that classifies network traffic based on application layer data. It enables subsequent distribution of network resources in respect to the priority of applications. Considerable research has been reported to deploy multi-core architectures for computationally intensive applications. Unfortunately, the proliferation of multi-core architectures has not helped fast packet processing due to: 1) the lack of efficient parallelism in legacy network programs, and 2) the non-trivial configuration for scalable utilization on multi-core servers. In this paper, we propose a highly scalable parallelized L7-filter system architecture with affinity-based scheduling on a multi-core server. We start with an analytical study of the system architecture based on an offline design. Similar to Receive Side Scaling (RSS) in the NIC, we develop a model to explore the connection level parallelism in L7-filter and propose an affinity-based scheduler to optimize system scalability. Performance results show that our optimized L7-filter has superior scalability over the naive multithreaded version. It improves system performance by about 50% when all the cores are deployed.
[Computer systems organization, Multiple instruction, multiple data, Parallel architectures, Architectures]
On runtime management in multi-core packet processing systems
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Computer networks require increasingly complex packet processing in the data path to adapt to new functionality requirements. To meet performance demands, packet processing systems on routers employ multiple processor cores. We investigate the design of an efficient run-time management system that handles the allocation of processing tasks to processor cores. Using run-time profiling information about processing requirements and traffic characteristics, the system is able to adapt to dynamic changes in the workload and balance the utilization of all processing resources to maximize throughput. We present a prototype implementation of our system that is based on the Click modular router. Our results show that our prototype system can adapt to changing workloads and process computationally demanding packets at 1.32 times higher data rates than SMP Click.
[Networks, Computer systems organization, Network components, Routers, Intermediate nodes, Parallel architectures, Architectures]
MultiLayer processing - an execution model for parallel stateful packet processing
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Mostly emerging network applications comprise deep packet inspection and/or stateful capabilities. Stateful workloads present limitations that reduce the exploitation of parallelism, unlike other network applications that show marginal dependencies among packets. In addition, differences among packet processing lead to significant negative interaction between threads, especially in the memory hierarchy. We propose MultiLayer Processing (MLP) as an execution model to properly exploit the levels of parallelism of stateful applications. The goal of MLP is to increase the system throughput by increasing the synergy among threads in the memory hierarchy, and alleviating the contention in critical sections of parallel workloads. We show that MLP presents about 2.4x higher throughput than other execution models with large processor architectures.
[Computer systems organization, Hardware validation, Hardware, Multiple instruction, multiple data, Parallel architectures, Architectures]
BRICK: a novel exact active statistics counter architecture
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
In this paper, we present an exact active statistics counter architecture called BRICK (Bucketized Rank Indexed Counters) that can efficiently store per-flow variable-width statistics counters entirely in SRAM while supporting both fast updates and lookups (e.g., 40 Gb/s line rates). BRICK exploits statistical multiplexing by randomly bundling counters into small fixed-size buckets and supports dynamic sizing of counters by employing an innovative indexing scheme called rank-indexing. Experiments with Internet traces show that our solution can indeed maintain large arrays of exact active statistics counters with moderate amounts of SRAM.
[Networks, Network services]
Packet prediction for speculative cut-through switching
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
The amount of intelligent packet processing in an Ethernet switch continues to grow, in order to support of embedded applications such as network security, load balancing and quality of service assurance. This increased packet processing is contributing to greater per-packet latency through the switch. In addition, there is a growing interest in using Ethernet switches in low latency environments such as high-performance clusters, storage area networks and real-time media distribution. In this paper we propose Packet Prediction for Speculative Cut-through Switching (PPSCS), a novel approach to reducing the latency of modern Ethernet switches without sacrificing feature rich policy-based forwarding enabled by deep packet inspection. PPSCS exploits the temporal nature of network communications to predict the flow classification of incoming packets and begin the speculative forwarding of packets before complex lookup operations are complete. Simulation studies using actual network traces indicate that correct prediction rates of up to 97% are achievable using only a small amount of prediction circuitry per port. These studies also indicate that PPSCS can reduce the latency in traditional store-and-forward switches by nearly a factor of 8, and reduce the latency of cut-through switches by a factor of 3.
[Networks, Packet-switching networks, Network types]
A programmable architecture for scalable and real-time network traffic measurements
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Accurate and real-time traffic measurement is becoming increasingly critical for large variety of applications including accounting, bandwidth provisioning and security analysis. Existing network measurement techniques, however, have major difficulty dealing with large number of flows in today's high-speed networks and offer limited scalability with increasing link speeds. Consequently, the current state of the art solutions have to resort to conservative sampling of the traffic stream and/or accounting for only a few frequent flows that often fail to provide accurate estimates of traffic features. In this paper, we present a novel hardware-software co-designed solution that is programmable and adaptable to runtime situations offering high-throughputs that can easily match current link-speeds. The key to our design is orthogonalization of memory lookups from traffic measurements through our query-driven measurement scheme. We have prototyped our approach on a Xilinx platform using Microblaze soft-core processors integrated with Virtex-II Pro FPGA fabric. We demonstrate the scalability of our architecture and also compare it with a recent offline (non real-time) sampling-based software alternative. The comparison shows that our architecture performs orders better in terms of speed and throughput even while being used as an offline solution.
[Networks, Computer systems organization, Embedded and cyber-physical systems, Hardware, Real-time systems, Robustness, Network services]
Adaptive scheduling to maximize NIC throughput in a COTS router
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
In routers based on commodity off-the-shelf (COTS) hardware and open-source operating systems, there are correlations between the transmission and reception capabilities of individual network interface cards (NICs) and multiple NICs on the same bus because of NIC/bus bottlenecks. To manage the adverse effects of this correlation, we propose an adaptive scheduling mechanism based on system state information, which balances transmission and reception rates and increases the overall forwarding rate.
[Networks, Network types]
Input-queued switches with logarithmic delay: necessary conditions and a reconfigurable scheduling algorithm
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Typically, a scheduling algorithm for an n x n packet switch with a crossbar as the data fabric divides time into slots, each of duration t<sub>p</sub> sufficient to transmit a packet. If a scheduling round requires t<sub>r</sub> &gt; t<sub>p</sub> time, then the switch can transmit multiple packets, up to s = &lfloor;t<sub>r</sub>/t<sub>p</sub>&rfloor;, between each mapped input-output pair under the current mapping. If s = 1, there exists a frame-based scheduling algorithm with &Theta;(log n) delay. For uniform random traffic, we establish that the delay is &Omega;(n) for any s &gt; 1, hence, s = 1 is the only case where a &Theta;(log n) delay is achievable. Given the importance of achieving a low s, it is imperative to develop extremely fast scheduling algorithms (that reduce t<sub>r</sub>) on a mesh-based structure (corresponding to the crossbar topology of the switch). We present results for a fast scheduling algorithm that runs on a mesh-of-trees topology that can be overlaid on the crossbar switching fabric.
[Cross-computing tools and techniques, Machine learning theory, Online learning algorithms, Reinforcement learning, Theory of computation, Theory and algorithms for application domains, Statistical paradigms, Online algorithms, Scheduling algorithms, Discrete mathematics, Sequential decision making, Approximation algorithms analysis, Probability and statistics, Mathematics of computing, Performance, Design and analysis of algorithms, General and reference, Queueing theory]
SimNP: a flexible platform for the simulation of a network processing system
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
In this paper we present an open source flexible network processor simulation framework called SimNP. Allowing algorithms and applications to be implemented in high level languages such as C or C++, SimNP allows workload characterization, architecture development and performance evaluation. The simulator models several architectural features that are commonly employed by network processors, including multiple processing cores, integrated networking interface and memory controller, and hardware accelerators. Moreover, new features or new modules can also be easily added into this simulator.
[Computer systems organization, Parallel architectures, Architectures]
Towards effective network algorithms on multi-core network processors
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
To build high-performance network devices with holistic security protection, a large number of algorithms have been proposed. However, multi-core implementation of the existing algorithms suffers from three limitations: performance instability, data-structure heterogeneity, and hardware dependency. In this paper, we propose three principles for effective network processing on multi-core network processors. To verify the effectiveness of these principles, algorithms for two typical network processing tasks are redesigned and implemented on the Cavium Octeon3860 network processor. Test results show that our schemes achieve superior performance in comparison with existing best-known algorithms.
[Security and privacy, Network security]
Performing time-sensitive network experiments
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
It is commonly believed that the Internet has deficiencies that need to be fixed. However, making changes to the current Internet infrastructure is not easy, if possible at all. Any new protocol or design to be implemented on a global scale requires extensive experimental testing in sufficiently realistic settings; simulations alone are not enough. On the other hand, performing network experiments is intrinsically difficult for several reasons: i) Creating a network with multiple routers and a topology that is representative of a real backbone network requires significant resources, ii) Network components have proprietary architectures, which makes it almost impossible to figure out all of their internal details, iii) Making changes to network components is not always possible, iv) We cannot always use real network traces and generating high volumes of artificial traffic which closely resemble operational traffic is not trivial, and v) We need a measurement infrastructure which collects traces and measures various metrics throughout the network. These problems become even more pronounced in the context of time-sensitive network experiments. These are experiments that need very high-precision timings for packet injections into the network, or require packet-level traffic measurements with accurate timing. Experimenting with new congestion control algorithms, buffer sizing in Internet routers, and denial of service attacks which use low-rate packet injections are all examples of time-sensitive experiments, where a subtle variation in packet injection times can change the results significantly. In this work we study the challenges of conducting time-sensitive network experiments in a testbed. We provide a set of guidelines that aim at eliminating sources of inaccuracy in a time-sensitive network experiment. We should note that these guidelines are not meant to be comprehensive. For the sake of space, we only focus on issues that are most likely to be overlooked, and thus unknowingly distort the results of a time-sensitive network experiment.
[Communication hardware, interfaces and storage, Networks, Hardware]
Data path credentials for high-performance capabilities-based networks
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Capabilities-based networks present a fundamental shift in the security design of network architectures. Instead of permitting the transmission of packets from any source to any destination, routers deny forwarding by default. For a successful transmission, packets need to positively identify themselves and their permissions to the router. The analysis of the data path credentials data structure that we propose shows that as few as 128 bits are sufficient to reduce the probability of unauthorized traffic reaching its destination to a fraction of a percent.
[Security and privacy, Network security]
Low power architecture for high speed packet classification
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Today's routers need to perform packet classification at wire speed in order to provide critical services such as traffic billing, priority routing and blocking unwanted Internet traffic. With everincreasing ruleset size and line speed, the task of implementing wire speed packet classification with reduced power consumption remains difficult. Software approaches are unable to classify packets at wire speed as line rates reach OC-768, while state of the art hardware approaches such as TCAM still consume large amounts of power. This paper presents a low power architecture for a high speed packet classifier which can meet OC-768 line rate. The architecture consists of an adaptive clocking unit which dynamically changes the clock speed of an energy efficient packet classifier to match fluctuations in traffic on a router line card. It achieves this with the help of a scheme developed to keep clock frequencies at the lowest speed capable of servicing the line card while reducing frequency switches. The low power architecture has been tested on OC-48, OC-192 and OC-768 packet traces created from real life network traces obtained from NLANR while classifying packets using synthetic rulesets containing up to 25,000 rules. Simulation results of our classifier implemented on a Cyclone 3 and Stratix 3 FPGA, and as an ASIC show that power savings of between 17--88% can be achieved, using our adaptive clocking unit rather than a fixed clock speed.
[Communication hardware, interfaces and storage, Networks, Network components, Hardware, Public Internet, Network types]
Stateful hardware decompression in networking environment
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Compression and Decompression can significantly lower the network bandwidth requirements for common internet traffic. Driven by the demands of an enterprise network intrusion system, this paper defines and examines the requirements of popular dictionary-based decompression in the real-time network processing scenario. In particular, a "stateful" decompression is required that arises out of the packet oriented nature of current networks, where the decompression of the data of a packet depends on the decompressed contents of its preceeding packets composing the same data stream. We propose an effective hardware decompression acceleration engine, which fetches the history data into the accelerator's fast memory on-demand and hides the associated latency by exploring the parallelism of the dictionary-based decompression process. We specify and evaluate various design and implementation options of the fetch-on-demand mechanism, i.e. prefetch most frequently used history, on-accelerator history buffer management, and reuse of fetched history data. Through simulation-based performance study, we show the effectiveness of the proposed mechanism on hiding the overhead of stateful decompression. We further show the effects of the design options and the impact on the overall performance of the network service stack of an intrusion prevension system.
[Networks, Cross-computing tools and techniques, Data compression, Data structures, Dependable and fault-tolerant systems and networks, Data layout, Network services, Information systems, Computer systems organization, Data management systems, Performance, General and reference, Network performance evaluation]
On design of bandwidth scheduling algorithms for multiple data transfers in dedicated networks
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
The significance of high-performance dedicated networks has been well recognized due to the rapidly increasing number of large-scale applications that require high-speed data transfer. Efficient algorithms are needed for path computation and bandwidth scheduling in dedicated networks to improve the utilization of network resources and meet diverse user requests. We consider two periodic bandwidth scheduling problems: multiple data transfer allocation (MDTA) and multiple fixed-slot bandwidth reservation (MFBR), both of which schedule a number of user requests accumulated in a certain period. MDTA is to assign multiple data transfer requests on several pre-specified network paths to minimize the total data transfer end time, while MFBR is to satisfy multiple bandwidth reservation requests, each of which specifies a bandwidth and a time slot. For MDTA, we design an optimal algorithm and provide its correctness proof; for MFBR, we prove it to be NP-complete and propose a heuristic algorithm, Minimal Bandwidth and Distance Product Algorithm (MBDPA). Extensive simulation results illustrate the performance superiority of the proposed MBDPA over a greedy heuristic approach and provide valuable insight into the advantage of periodic bandwidth scheduling over instant bandwidth scheduling.
[Network properties, Wide area networks, Networks, Network range, Network architectures, Local area networks]
Software techniques to improve virtualized I/O performance on multi-core systems
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Virtualization technology is now widely deployed on high performance networks such as 10-Gigabit Ethernet (10GE). It offers useful features like functional isolation, manageability and live migration. Unfortunately, the overhead of network I/O virtualization significantly degrades the performance of network-intensive applications. Two major factors of loss in I/O performance result from the extra driver domain to process I/O requests and the extra scheduler inside the virtual machine monitor (VMM) for scheduling domains. In this paper we first examine the negative effect of virtualization in multi-core platforms with 10GE networking. We study virtualization overhead and develop two optimizations for the VMM scheduler to improve I/O performance. The first solution uses cache-aware scheduling to reduce inter-domain communication cost. The second solution steals scheduler credits to favor I/O VCPUs in the driver domain. We also propose two optimizations to improve packet processing in the driver domain. First we re-design a simple bridge for more efficient switching of packets. Second we develop a patch to make transmit (TX) queue length in the driver domain configurable and adaptable to 10GE networks. Using all the above techniques, our experiments show that virtualized I/O bandwidth can be increased by 96%. Our optimizations also improve the efficiency by saving 36% in core utilization per gigabit. All the optimizations are based on pure software approaches and do not hinder live migration. We believe that the findings from our study will be useful to guide future VMM development.
[Operating systems, Scheduling, Contextual software domains, Software organization and properties, Software and its engineering, Process management]
Design optimization of a highly parallel InfiniBand host channel adapter
Proceedings of the 4th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2008
Network processors use highly parallel architectures to improve performance and reach multi-gigabit line-speeds. In this paper, we emulate a pipeline in a highly parallel non-programmable industrial InfiniBand Host Channel Adapter to make a performance and bottleneck analysis and, at the same time, explore the potential of a pipelined architecture. Therefore, starting from the original Host Channel Adapter model with multiple send- and receive-side packet-processing units, we compare its performance capabilities with that of a pipelined design by introducing a central arbiter synchronizing the state machines of the different packet-processing instances to achieve a pipelined behavior. We show that the pipelined model achieves a performance comparable to that of the parallel design in most of our micro-benchmarks, making it a valid option for next-generation high-speed adapters. At the same time, our approach enables a deeper analysis of the original architecture and a better understanding of the actual processing requirements, and therefore offers valuable insights for future designs.
[High-level and register-transfer level synthesis, Hardware validation, Electronic design automation, Hardware]
A folded pipeline network processor architecture for 100 Gbit/s networks
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Ethernet, although initially conceived as a Local Area Network technology, has been steadily making inroads into access and core networks. This has led to a need for higher link speeds, which are now reaching 100 Gbit/s. Packet processing at this rate represents a significant challenge, that needs to be met efficiently, while minimizing power consumption and chip area. This level of throughput favours a pipelined approach, thus this paper takes a traditional pipeline and breaks it down to mini-pipelines, which can perform coarse-grained processing (like process an MPLS label to completion). These mini-pipelines are then parellelized and used to construct a folded pipeline architecture, which augments the traditional approach by significantly reducing power consumption, a key problem in future routers. The paper compares the two approaches, discusses their advantages and disadvantages and demonstrates by quantitative measures that the folded pipeline architecture is the better solution for 100 Gbit/s processing.
[]
Design of a secure packet processor
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Programmability in the data path of routers provides the basis for modern router implementations that can adapt to new functional requirements. This programmability is typically achieved through software-programmable packet processing systems. One key concern with the proliferation of these programmable devices throughout the Internet is the potential impact of software vulnerabilities that can be exploited remotely. We present a design and proof-of-concept implementation of a packet processing system that uses two security techniques to defend against potential attacks: a processing monitor is used to track operations on each processor core to detect attacks at the processing instruction level; an I/O monitor is used to track operations of the router to detect attacks at the protocol level. Our prototype implementation on the NetFPGA system shows that these monitors can be implemented to operate at high data rates and with little additional hardware resources.
[Networks, Network components, Routers, Intermediate nodes]
Airblue: a system for cross-layer wireless protocol development
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Over the past few years, researchers have developed many cross-layer wireless protocols to improve the performance of wireless networks. Experimental evaluations of these protocols have been carried out mostly using software-defined radios, which are typically two to three orders of magnitude slower than commodity hardware. FPGA-based platforms provide much better speeds but are quite difficult to modify because of the way high-speed designs are typically implemented. Experimenting with cross-layer protocols requires a flexible way to convey information beyond the data itself from lower to higher layers, and a way for higher layers to configure lower layers dynamically and within some latency bounds. One also needs to be able to modify a layer's processing pipeline without triggering a cascade of changes. We have developed Airblue, an FPGA-based software radio platform, that has all these properties and runs at speeds comparable to commodity hardware. We discuss the design philosophy underlying Airblue that makes it relatively easy to modify it, and present early experimental results.
[Networks, Mobile networks, Wireless access networks, Network types]
An architecture for software defined cognitive radio
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
As we move forward towards the next generation of wireless protocols, the push for a better radio physical layer is ever increasing. Conventional radio architectures are limited to narrow operating regions and fails to adapt with changing technology. This is further strengthened with the advent of cognitive radio, which needs a more versatile and flexible framework that is programmable within the timing constraints of a protocol. In this paper we present an architecture for Software Defined Cognitive Radio that caters to the specific baseband processing requirements in a changing environment. We aim to provide more flexibility by de-constructing the radio pipeline into a framework of user controlled kernels that can be reconfigured at run-time. This architecture provides the bare-bones of a OFDM based radio physical layer that can adapt to perform a varied number of tasks in different radio networks. We also present a novel message based real-time reconfiguration method to transmit and receive a wide range of waveforms used in concurrent wireless protocols.
[Communication hardware, interfaces and storage, Design, Cross-computing tools and techniques, Hardware, Signal processing systems, General and reference]
End-to-end congestion management for non-blocking multi-stage switching fabrics
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Packet-switched networks are encountered at the heart of scalable network routers and high-performance computer (or data center) interconnects. As these networks scale to larger port counts, and their utilization increases, congestion management becomes indispensable. At the same time, technology constraints rule out monolithic bufferless switches with centralized schedulers, and impose buffered multi-stage switching fabrics with distributed control. These trends have for some time now called forth research and products [1, 2, 3, 4, 5], which applied the request-grant philosophy of bufferless crossbars to make buffered multi-stage switching fabrics practical and efficient. In such proactive schemes, saturation-tree congestion is avoided by having inputs inform outputs of their demand, and inject data only after receiving output permission (grants). The per output admission arbiters can be located in a central scheduling unit, as in [3] [2] [4], can be distributed across the edge switches of the fabric [4], or can be placed in the respective output adapters [1] [5]. Such schemes have been quite successful, especially because they can be combined conveniently with reorder/reassembly buffer management, as well as with end-to-end reliable-delivery schemes.
[Networks, Network architectures]
High speed pattern matching algorithm based on deterministic finite automata with faulty transition table
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Regular expression matching is the time-critical operation of many modern intrusion detection systems (IDS). This paper proposes pattern matching algorithm to match regular expression against multigigabit data stream. As usually used regular expressions are only subjectively tested and often generates many false positives/negatives, proposed algorithm support the possibility to reduce memory requirements by introducing small amount of faults into the pattern matching. Algorithm is based on the perfect hashing and is suitable for hardware implementation.
[Security and privacy, Network security]
HELIOS: a high energy-efficiency locally-scheduled input-queued optical switch
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Fast growing traffic for both the Internet and within data centers has lead to an increasing demand for high-speed switching systems. In this paper, we propose a fully distributed scheduling algorithm with an O(1) complexity, for a switch with an optical switching fabric. The inputs only use local queue information to make their scheduling decisions, and the switch consumes much less power than an electronic switch. Therefore, we call the switch HELIOS: High Energy-efficiency Locally-scheduled Input-queued Optical Switch. HELIOS can achieve 100% throughput for any admissible Bernoulli i.i.d traffic. To our knowledge, this is the first distributed scheduling algorithm to guarantee 100% throughput for an input-queued optical switch.
[]
A traffic-aware top-N firewall ruleset approximation algorithm
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Packet classification is widely used in various network security and operation applications. Two of the main challenges are the increasing number of classification rules, amount of traffic and network line speed. In this poster, we investigate an approximation algorithm for selecting the top-N most frequently matched subset of rules from the original ruleset. Through simulations, we show that our approaches the optimal while runs in seconds, allowing online adaptation to changing traffic patterns.
[Security and privacy, Network security]
Bit-shuffled trie: a new approach for IP address lookup
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
IP address lookup is a fundamental operation in packet forwarding. Using multi-level index tables to find out the next-hop value is an attractive approach due to its simplicity. However, memory efficiency is relatively low because prefixes are sparsely distributed in the address space. In this poster, we shall outline a new approach to construct memory efficient index tables based on a technique called bit-shuffling. The proposed method is evaluated using a real-life IPv4 routing table with 321K prefixes. The lookup tables occupy 0.8MB memory.
[Computer systems organization, Networks, Network components, Routers, Embedded and cyber-physical systems, Intermediate nodes, Real-time systems]
Efficient packet classification algorithm based on entropy
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
This paper deals with packet classification in high-speed networks. It introduces a novel method for packet classification based on the amount of information stored in the ruleset. Basic principles of the algorithm based on the effort to reduce the amount of the necessary memory space and number of computational steps are presented together with analysis of the input rulesets.
[Security and privacy, Network security]
Fast regular expression matching in hardware using NFA-BDD combination
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
The development of Network Intrusion Detection Systems (NIDS) is nowadays a powerful solution to defend against various network security threats. There has been a lot of research effort devoted to hardware-based NIDS, because of (1) the massive amount of computation performed by regular expression matching algorithms and (2) the gigabit per second performance requirement of modern NIDS. Hardware-based NIDS take advantage of parallelization inherent in FPGAs, ASICs or network processors to support very high network speeds, while software approaches fail to do so.
[]
Improving PC-based OpenFlow switching performance
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
In this paper, we propose an architectural design to improve lookup performance of OpenFlow switching in Linux using a standard commodity network interface card based on the Intel 82599 Gigabit Ethernet controller. We describe our design and report our preliminary results that show packet switching throughput increasing up to 25 percent compared to the throughput of regular software-based OpenFlow switching.
[Networks, Network components, Routers, Intermediate nodes]
NFA split architecture for fast regular expression matching
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Many hardware architectures have been designed to accelerate regular expression matching in network security devices, but most of them can achieve high throughput only for strings or small sets of regular expressions. We propose new NFA Split architecture which reduces the amount of consumed FPGA resources in order to match larger set of regular expressions. New algorithm is introduced to find non-collision sets of states and determine part of nondeter-ministic automaton which can be mapped to the memory based architecture. For all analysed sets of regular expressions, the algorithm was able to find non-collision sets with 67.8% of states in average and reduces the amount of consumed flip-flops to 37.6% and look-up tables to 63.9% in average.
[Application specific processors, Hardware, Very large scale integration design, Application-specific VLSI designs]
Software-based implementations of updateable data structures for high-speed URL matching
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
URL matching is used in many network applications, including URL blacklisting, URL-based forwarding and URL shortening services. These applications need fast URL queries and updates, thus requiring an efficient updateable data structure. As the processing power of general-purpose multi-core processors increases, software-based approaches are better able to meet the speed requirements of URL matching. In this paper, we present our preliminary performance study of finite-automata- and hash-based URL matching implementations on commodity PCs. The impacts of the cache and memory allocation methods are discussed.
[]
Throughput of random arbitration for approximate matchings
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Modern switches and switching fabrics typically employ virtual output queues (VOQs) at network adapters, in order to mitigate head-of-line blocking. The core of the switch, often a crossbar, can either be bufferless or buffered. Previous research on random arbitration for bufferless crossbars found that the throughput for large switch sizes is bounded at 63% [1]. Although crossbars containing crosspoint buffers are shown to reach 100% throughput under uniform traffic, their scalability is restricted by the quadratic growth of the number of crosspoint buffers, and the size of each, which depends on the intra-switch (VOQ-crossbar) round trip time (RTT). In this paper, we study an alternative architecture [2], which can reduce buffer requirements, by (a) having a linear growth of the number of buffers, and (b) making the size of each independent of the RTT. As the scheduler in such an architecture may match multiple inputs to the same output at the same time, we refer to such matchings as approximate, as opposed to the exact matchings required in bufferless crossbars.
[Cross-computing tools and techniques, Performance, General and reference]
Efficient lookahead routing and header compression for multicasting in networks-on-chip
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
As technology advanced, Chip Multi-processor (CMP) architectures have emerged as a viable solution for designing processors. Networks-on-Chip (NOCs) provide a scalable communication method for CMP architectures as the number of cores is increasing. Although there has been significant research on NOC designs for unicast traffic, the research on the multicast router design is still in infancy stage. Considering that one-to-many (multicast) and one-to-all (broadcast) traffic are more common in CMP applications, it is important to design a router providing efficient multicasting. In this paper, we propose an efficient lookahead routing with limited area overhead for a recently proposed multicast routing algorithm, Recursive Partitioning Multicast (RPM) [17]. Also, we present a novel compression scheme for a multicast packet header that becomes a big overhead in large networks. Comprehensive simulation results show that with our route computation logic design, providing lookahead routing in the multicast router only costs less than 20% area overhead and this percentage keeps decreasing with larger network sizes. Compared with the basic lookahead routing design, our design can save area by over 50%. With header compression and lookahead multicast routing, the network performance is improved by 22% in a (16 x 16) network on average.
[Computer systems organization, Distributed architectures, Parallel architectures, Architectures, Interconnection architectures]
Energy-aware routing in hybrid optical network-on-chip for future multi-processor system-on-chip
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
With the development of Multi-Processor System-on-Chip (MP-SoC) in recent years, the intra-chip communication is becoming the bottleneck of the whole system. Current electronic network-on-chip (NoC) designs face serious challenges, such as bandwidth, latency and power consumption. Optical interconnection networks are a promising technology to overcome these problems. In this paper, we study the routing problem in optical NoCs with arbitrary network topologies. Traditionally, a minimum hop count routing policy is employed for electronic NoCs, as it minimizes both power consumption and latency. However, due to the special architecture of current optical NoC routers, such a minimum-hop path may not be energy-wise optimal. Using a detailed model of optical routers we reduce the energy-aware routing problem into a shortest-path problem, which can then be solved using one of the many well known techniques. By applying our approach to different popular topologies, we show that the energy consumed in data communication in an optical NoC can be significantly reduced. We also propose the use of optical burst switching (OBS) in optical NoCs to reduce control overhead, as well as an adaptive routing mechanism to reduce energy consumption without introducing extra latency. Our simulation results demonstrate the effectiveness of the proposed algorithms.
[]
Destination-based adaptive routing on 2D mesh networks
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
The choice of routing algorithm plays a vital role in the performance of on-chip interconnection networks. Adaptive routing is appealing because it offers better latency and throughput than oblivious routing, especially under non-uniform and bursty traffic. The performance of an adaptive routing algorithm is determined by its ability to accurately estimate congestion in the network. In this regard, maintaining global congestion information using a separate monitoring network offers better congestion visibility into distant parts of the network than solutions relying only on local congestion state. However, the main challenge in designing such routing schemes is to keep the logic and bandwidth overhead as low as possible to fit into the tight power, area and delay budgets of on-chip routers. In this paper, we propose a minimal destination-based adaptive routing strategy (DAR) where every node estimates the delay to every other node in the network, and routing decisions are based on these per-destination delay estimates. DAR outperforms Regional Congestion Awareness (RCA) [7], the best previously known adaptive routing algorithm that uses non-local congestion knowledge. This is because the per-destination delay estimates in DAR are more accurate and not corrupted by congestion on links outside the admissible routing paths to the destination. We show that DAR outperforms minimal adaptive routing by up to 65% and RCA by up to 41% in terms of latency on SPLASH-2 benchmarks. It also outperforms these algorithms in latency and throughput under synthetic traffic patterns on both 8x8 and 16x16 mesh topologies.
[Computer systems organization, Parallel architectures, Architectures, Interconnection architectures]
Range hash for regular expression pre-filtering
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Recently, major Internet carriers and vendors successfully tested high-speed backbone networks at 100-Gbps line speed to support rapid growth of the Internet traffic demands. In addition, traffic is getting more concentrated to points such as data centers, and demand for protecting such high-speed networks from attack traffic is increasing. Deep Packet Inspection (DPI) with Regular Expression (RegEx) detection is the de facto defense mechanism agains network intrusions. However, current RegEx detection systems cannot keep up with the upcoming high-speed line rate. The RegExes consist of three types of components, exact strings, character classes (CC), and repetitions. Exact string and repetition matching have been widely studied by RegEx research community for better performance. Yet, although more than 55% of RegExes in Snort signature set contain at least one CC, hardware based solutions that focus on CC detection is limited. In this paper we propose a new CC detection architecture called Range Hash that is suitable for high-speed, compact CC detection. Additionally, we propose a practical application of the Range Hash architecture where it can be used as a pre-filter for a Regular Expression detection system to increase overall RegEx detection performance. Based on our hardware prototype design which runs at 250MHz, Range Hash can reach to 100-Gbps CC detection throughput with today's FPGA chips.
[Security and privacy, Network security]
Packet scheduling for deep packet inspection on multi-core architectures
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Multi-core architectures are commonly used for network applications because the workload is highly parallelizable. Packet scheduling is a critical performance component of these applications and significantly impacts how well they scale. Deep packet inspection (DPI) applications are more complex than most network applications. This makes packet scheduling more difficult, but it can have a larger impact on performance. Also, packet latency and ordering requirements differ depending on whether the DPI application is deployed inline. Therefore, different packet scheduling tradeoffs can be made based on the deployment. In this paper, we evaluate three packet scheduling algorithms with the Protocol Analysis Module (PAM) as our DPI application using network traces acquired from production networks where intrusion prevention systems (IPS) are deployed. One of the packet scheduling algorithms we evaluate is commonly used in production applications; thus, it is useful for comparison. The other two are of our own design. Our results show that packet scheduling based on cache affinity is more important than trying to balance packets. More specifically, for the three network traces we tested, our cache affinity packet scheduler outperformed the other two schedulers increasing throughput by as much as 38%.
[Computer systems organization, Multiple instruction, multiple data, Parallel architectures, Architectures]
Axon: a flexible substrate for source-routed ethernet
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
This paper introduces the Axon, an Ethernet-compatible device for creating large-scale datacenter networks. Axons are inexpensive, practical devices that are demonstrated using prototype hardware. Functionally, Axons replace Ethernet switches and maintain full compatibility with existing Ethernet hosts. Between themselves, however, Axons transparently use source-routed Ethernet. This unlocks many benefits, such as improved network scalability, performance, and flexibility. In an Axon network, all state required to route a host's packets is placed in the local Axon---the Axon to which the host is directly connected. Therefore, regardless of the scale of the network, the route computation and storage needs of a single Axon device only need to scale with the demands of its locally-connected hosts. This is in stark contrast to conventional switched Ethernet, which requires routing resources proportional to the traffic that flows through the device. Scalability is also increased by eliminating the use of packet flooding for automatic location and address discovery. Further, source-routed Ethernet increases network flexibility by supporting different route selection strategies. For example, shortest-path routing could be employed, or longer paths selected to minimize congestion by balancing traffic across redundant links.
[Networks, Packet-switching networks, Network types]
Ensemble routing for datacenter networks
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
This paper describes Hash-Based Routing (HBR), an architecture that enhances Ethernet to support dynamic management for multipath networks in scalable datacenters. This work enhances HBR to support flow ensemble management for large-scale networks of arbitrary topology. Ensemble routing eliminates measurement and control for individual flows and instead manages using summary data thus providing a unique capability for reactive datacenter-wide network management. HBR provides seamless interoperability with Ethernet and supports the attachment of unmodified L2 hosts and devices including FCoE devices within converged fabrics. Simulation experiments demonstrate efficient multipath routing for a variety of scalable topologies. Optimized routing maintains efficiency in the presence of network faults and implements spatial Quality of Service to dynamically provision physical network hardware among co-hosted tenants or applications.
[Networks, Network architectures]
DOS: a scalable optical switch for datacenters
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
This paper discusses the architecture and performance studies of Datacenter Optical Switch (DOS) designed for scalable and high-throughput interconnections within a data center. DOS exploits wavelength routing characteristics of a switch fabric based on an Arrayed Waveguide Grating Router (AWGR) that allows contention resolution in the wavelength domain. Simulation results indicate that DOS exhibits lower latency and higher throughput even at high input loads compared with electronic switches or previously proposed optical switch architectures such as OSMOSIS [4, 5] and Data Vortex [6, 7]. Such characteristics, together with very high port count on a single switch fabric make DOS attractive for data center applications where the traffic patterns are known to be bursty with high temporary peaks [13]. DOS exploits the unique characteristics of the AWGR fabric to reduce the delay and complexity of arbitration. We present a detailed analysis of DOS using a cycle-accurate network simulator. The results show that the latency of DOS is almost independent of the number of input ports and does not saturate even at very high (approx 90%) input load. Furthermore, we show that even with 2 to 4 wavelengths, the performance of DOS is significantly better than an electrical switch network based on state-of-the-art flattened butterfly topology.
[Networks, Network components, Packet-switching networks, Routers, Intermediate nodes, Network types]
A new TCB cache to efficiently manage TCP sessions for web servers
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
TCP/IP, the most commonly used network protocol, consumes a significant portion of time in Internet servers. While a wide spectrum of studies has been done to reduce its processing overhead such as TOE and Direct Cache Access, most of them did studies solely from the per-packet perspective and concentrated on the packet memory access overhead. They ignored per-session data TCP Control Block (TCB), which poses a challenge in web servers with a large volume of concurrent sessions. In this paper, we start with challenge studies and show that the TCB data should be efficiently managed. We propose a new TCB cache addressed by session identifiers to address the challenge. We carefully design the TCB cache along two important axes: cache indexing and cache replacement policies. First, we study the performance of various hash functions and propose a new indexing scheme for the TCB cache by employing two Universal hash functions. We analyze session identifiers and choose some important bits as indexing bits to reduce hashing hardware complexity. Second, by leveraging characteristics of web sessions, we design a speculative cache replacement policy, which can effectively work on the TCB cache with two cache banks. Experimental results show that the new cache efficiently manages the per-session data. When it is used in TOEs or integrated into CPUs to manage the per-session data, TCP/IP processing time is significantly reduced, thus saving web server response time.
[Networks, Network protocols]
sNICh: efficient last hop networking in the data center
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Virtualization has fundamentally changed the data center network. The last hop of the network is no longer handled by a physical network switch, but rather is typically performed in software inside the server to switch among virtual machines hosted by that server. In this paper, we present the concept of a sNICh, which is a combination of a network interface card and switching accelerator for modern virtualized servers. The sNICh architecture exploits the proximity of the switching accelerator to the server by carefully dividing the network switching tasks between them. This division enables the sNICh to address the resource intensiveness of exclusively software-based approaches and the scalability limits of exclusively hardware-based approaches. Essentially, the sNICh hardware performs basic flow-based switching and the sNICh software handles flow setup based on packet filtering rules. The sNICh also minimizes I/O bus bandwidth utilization by transferring, whenever possible, inter-virtual machine traffic within the main memory. We also present a preliminary evaluation of this architecture using software emulation. We compare the performance of the sNICh with two existing software solutions in Xen, the Linux bridge and Open vSwitch. Our results show that the sNICh outperforms both of these existing solutions and also exhibits better scalability.
[Networks, Network protocols, Network components, Routers, Intermediate nodes, Network architectures]
An experimental evaluation of distributed rate limiting for cloud computing applications
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Pricing and load distribution in a cloud are difficult problems. In order to recover the construction costs of the data center, the owner must endeavour to have high utilization while maintaining performance levels for the users. Distributed Rate Limiting (DRL) is a mechanism that can be used to attack this problem. A mathematical framework and the convergence and stability properties of two DRL algorithms were examined in previous work. In this paper we build upon that work by evaluating the performance of these algorithms on a testbed against the results of a simulation carried out in previous work. We also evaluate the algorithms resilience to failure and propose the good-neighbours enhancement to improve its performance.
[Networks, Network management, Network services]
TnT: transparent network tracker for P2P applications
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Peer-to-peer (P2P) applications are voracious bandwidth consumers, and ISPs have no effective options for curbing their bandwidth consumption. The Transparent Network Tracker (TnT) is a network device that fills this void: it identifies and monitors P2P traffic on the wire to support applications that control it. In this paper, we describe our TnT prototype and an associated ISP tracker application.
[Networks, Network services]
Power optimization for multimedia transcoding on multicore servers
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
We design, implement and evaluate a power-efficient and traffic-aware transcoding system on multicore servers that appropriately adjusts the processor operating level. The system is capable of configuring the number of active cores and core frequency "on-the-fly" according to the varying traffic rate. Results on an AMD machine show that our system saves 51.0% power consumption compared to a native system without power-saving schemes. It also outperforms three other power-aware systems, CG [2] (clock gating), C-DVFS [3] (chip-wide DVFS) and Hybrid [1] (chip-wide DVFS + power-gating), by 19.5%, 10.5% and 5.5% reduction of power consumption, respectively.
[Design, Cross-computing tools and techniques, General and reference]
NetEx: efficient and cost-effective internet bulk content delivery
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
The Internet is witnessing explosive growth in traffic due to bulk content transfers, such as multimedia and software downloads, and online sharing of personal, commercial, and scientific data. Yet bulk data transfers remain very expensive and inefficient. As a result, huge amounts of digital data continue to be delivered outside of the Internet using hard drives, optical media or tapes. Meanwhile, large reserves of spare bandwidth lie unutilized in today's networks, where links are overprovisioned for peak load. We designed NetEx, a bulk transfer system that opportunistically exploits the excess capacities of network links to deliver bulk content cheaply and efficiently. Our results based on data from both a commercial tier-1 ISP and the Abilene network suggest that NetEx can considerably increase the capacity of the network, and at the same time it can provide good average performance to bulk transfers.
[Networks, Network services]
Evolution of cache replacement policies to track heavy-hitter flows
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Flow-based network traffic processing, that is, processing packets based on some state information associated to the flows to which the packets belong, is a key enabler for a variety of network services and applications. This form of stateful traffic processing is used in modern switches [1] and routers that contain flow tables to implement forwarding, firewalls, NAT, QoS, and collect measurements.
[Integrated circuits, Hardware, Dynamic memory, Semiconductor memory]
Load balancing packets on a tile-based massive multi-core processor with S-NUCA
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
In massive tile-based multi-core architectures, it is important that the execution of the packets of a particular flow takes place in a set of cores physically close to each other in order to minimize the average latency to the common data structures across the local caches of the different cores. An static NUCA implementation provides a substrate for a cost-effective implementation of a cache sharing mechanism. However, a careful mapping of the different data structures in the system's memory, along with a smart load-balancing mechanism of the packets to the different cores, is fundamental in order to avoid long latencies to remote data. This work proposes a methodology for load balancing packets to cores in an S-NUCA tile-based architecture with a large number of cores.
[]
Simple two-priority, low-jitter scheduler
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Many papers on emulations of Generalized Processor Sharing (GPS) have been published. The algorithms and their implementations are often very complex and/or generate a bursty output. In this paper, we present a simple two-priority scheduler that can be easily implemented in hardware, making it especially interesting for Networks on Chips (NoCs), and other applications dealing with stringent resource constraints.
[Communication hardware, interfaces and storage, Networks, Hardware]
TED: tool for testing and debugging uDAPL
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
User Direct Access Programming Library (uDAPL) defines a single set of user APIs for Remote Direct Memory Access (RDMA) capable transports. Developers of uDAPL have to write test programs for verification of APIs and for integrated testing of software stack along with underlying hardware. The tools available for testing uDAPL suffer from the following limitations: they do not provide control at API level, offer very little control of input parameters of APIs and provide limited flexibility vis-&agrave;-vis test cases that can be executed. This paper describes a new tool 'Test Environment for DAPL' (TED) that enables integrated testing and debugging of software stack and underlying hardware while providing more flexibility and control to user. It can be used over any implementation of uDAPL and is available as open source. In addition, this paper proposes a novel approach for flow control of RDMA operations. Since in RDMA operations responder side does not receive any completion, mechanisms generally rely on last byte of data buffer for notification of arrival of data. This scheme can fail if underlying transport does not ensure that data arrives in order. The proposed design ensures validity even over networks that do not guarantee in order arrival of data.
[]
Galois field hardware architectures for network coding
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
This paper presents and analyzes novel hardware designs for high-speed network coding. Our designs provide efficient methods to perform Galois field (GF) dot products and matrix inversions, which are important operations in network coding. Encoder designs that perform GF dot products and vary with respect to the number of messages combined, Galois field size, and input message size are implemented and analyzed to evaluate design tradeoffs. We investigate single cycle, multicycle, and pipelined designs with and without feedback mechanisms for encoding multiple sets of messages. The decoder is implemented as a multi-cycle design and performs GF matrix inversion followed by multiple GF dot products. Our designs are synthesized with a 65nm standard cell library and compared in terms of area, critical path delay, and throughput. Designs combining four messages achieve throughputs of more than 30 Gbps. Our designs can scale to achieve much higher throughput through the use of additional hardware.
[Communication hardware, interfaces and storage, Hardware]
Chimpp: a click-based programming and simulation environment for reconfigurable networking hardware
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Reconfigurable network hardware makes it easier to experiment with and prototype high-speed networking systems. However, these devices are still relatively hard to program; for example, requiring users to develop in Verilog or VHDL. Further, these devices are commonly designed to work with software on a host computer, requiring the co-development of these hardware and software components. We address this situation with Chimpp, a development environment for reconfigurable network hardware, modeled on the popular Click modular router system. Chimpp employs a modular approach to designing hardware-based packet-processing systems, featuring a simple configuration language similar to that of Click. We demonstrate this development environment by targeting the NetF-PGA platform. Chimpp can be combined with Click itself at the software layer for a highly modular, mixed hardware and software design framework. We also enable the integrated simulation of the hardware and software components of a network device together with other network devices using the OMNeT++ network simulator. The goal of Chimpp is to make experimentation easy by providing a toolbox of reusable, modular elements and a way to easily combine them. In contrast with some prior work, Chimpp avoids unnecessary restrictions on module interfaces and design styles. Rather, it is easy to add custom interfaces and to incorporate existing hardware modules. We describe our design and implementation of Chimpp, and provide initial evaluations showing how Chimpp makes it easier to implement, simulate, and modify a variety of packet-processing systems on the NetFPGA platform.
[Networks, Network components, Routers, Hardware validation, Intermediate nodes, Electronic design automation, Simulation and emulation, Hardware, Hardware description languages and compilation, Functional verification]
The case for hardware transactional memory in software packet processing
Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2010
Software packet processing is becoming more important to enable differentiated and rapidly-evolving network services. With increasing numbers of programmable processor and accelerator cores per network node, it is a challenge to support sharing and synchronization across them in a way that is scalable and easy-to-program. In this paper, we focus on parallel/threaded applications that have irregular control-flow and frequently-updated shared state that must be synchronized across threads. However, conventional lock-based synchronization is both difficult to use and also often results in frequent conservative serialization of critical sections. Alternatively, we propose that Transactional memory (TM) is a good match to software packet processing: it both (i) can allow the system to optimistically exploit parallelism between the processing of packets whenever it is safe to do so, and (ii) is easy-to-use for a programmer. With the NetFPGA [1] platform and four network packet processing applications that are threaded and share memory, we evaluate hardware support for TM (HTM) using the reconfigurable FPGA fabric. Relative to NetThreads [2], our two-processor four-way-multithreaded system with conventional lock-based synchronization, we find that adding HTM achieves 6%, 54% and 57% increases in packet throughput for three of four packet processing applications studied, due to reduced conservative serialization.
[Computer systems organization, Embedded and cyber-physical systems, Real-time systems, Multiple instruction, multiple data, Parallel architectures, Architectures]
CacheCard: caching static and dynamic content on the NIC
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
CacheCard is a NIC-based cache for static and dynamic web content in a way that allows for implementation on simple devices like NICs. It requires neither understanding of the way dynamic data is generated, nor execution of scripts on the cache. By monitoring file system activity and potential non-determinism incurred by scripts, we determine all data sources for specific requests. For instance, if a deterministic script opens a set of files or a database tables, these files and tables, as well as the script itself will be in the set of data sources for this URL. Caching the dynamic data is possible, since we can invalidate cache entries when any of the sources changes. Non-deterministic scripts that produce content based on time or random values are automatically recognised and flagged as non-cacheable. We implemented CacheCard on Intel IXP2400 network processors.
[]
Simplifying data path processing in next-generation routers
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Customizable packet processing is an important aspect of next-generation networks. Packet processing architectures using multi-core systems on a chip can be difficult to program. In our work, we propose a new packet processor design that simplifies packet processing by managing packet contexts in hardware. We show how such a design scales to large systems. Our results also show that the management of such a system is feasible with the proposed mapping algorithm.
[Networks, Computer systems organization, Network components, Routers, Intermediate nodes, Parallel architectures, Architectures]
Exploitation and threat analysis of open mobile devices
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
The increasingly open environment of mobile computing systems such as PDAs and smartphones brings rich applications and services to mobile users. Accompanied with this trend is the growing malicious activities against these mobile systems, such as information leakage, service stealing, and power exhaustion. Besides the threats posed against individual mobile users, these unveiled mobile devices also open the door for more serious damage such as disabling critical public cyber physical systems that are connected to the mobile/wireless infrastructure. The impact of such attacks, however, has not been fully recognized. In this work, we show that mobile devices, even with the state-of-the-art security mechanisms, are still vulnerable to a set of carefully crafted attacks. Taking Linux-based cell-phones as an example, we show that this vulnerability not only makes it possible to attack individual mobile devices such as accessing unauthorized resources, disabling predefined security mechanisms, and diverting phone calls, but also can be exploited to launch distributed denial-of-service attacks against critical public services such as 911. Using the open multi-class queuing network model, we analyze in detail the consequence of these attacks against the 911 service in a large region and also present some unique characteristics of these attacks. We further discuss potential countermeasures that can effectively mitigate or eliminate these attacks.
[]
Evaluating regular expression matching engines on network and general purpose processors
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
In recent years we have witnessed a proliferation of data structure and algorithm proposals for efficient deep packet inspection on memory based architectures. In parallel, we have observed an increasing interest in network processors as target architectures for high performance networking applications. In this paper we explore design alternatives in the implementation of regular expression matching architectures on network processors (NPs) and general purpose processors (GPPs). Specifically, we present a performance evaluation on an Intel IXP2800 NP, on an Intel Xeon GPP and on a multiprocessor system consisting of four AMD Opteron 850 cores. Our study shows how to exploit the Intel IXP2800 architectural features in order to maximize system throughput, identifies and evaluates algorithmic and architectural trade-offs and limitations, and highlights how the presence of caches affects the overall performances. We provide an implementation of our NP designs within the Open Network Laboratory (http://www.onl.wustl.edu).
[]
LaFA : lookahead finite automata for scalable regular expression detection
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Although Regular Expressions (RegExes) have been widely used in network security applications, their inherent complexity often limits the total number of RegExes that can be detected using a single chip for a reasonable throughput. This limit on the number of RegExes impairs the scalability of today's RegEx detection systems. The scalability of existing schemes is generally limited by the traditional per character state processing and state transition detection paradigm. The main focus of existing schemes is in optimizing the number of states and the required transitions, but not the suboptimal character-based detection method. Furthermore, the potential benefits of reduced number of operations and states using out-of-sequence detection methods have not been explored. In this paper, we propose Looka-head Finite Automata (LaFA) to perform scalable RegEx detection using very small amount of memory. LaFA's memory requirement is very small due to the following three areas of effort described in this paper: (1) Different parts of a RegEx, namely RegEx components, are detected using different detectors, each of which is specialized and optimized for the detection of a certain RegEx component. (2) We systematically reorder the RegEx component detection sequence, which provides us with new possibilities for memory optimization. (3) Many redundant states in classical finite automata are identified and eliminated in LaFA. Our simulations show that LaFA requires an order of magnitude less memory compared to today's state-of-the-art RegEx detection systems. A single commodity Field Programmable Gate Array (FPGA) chip can accommodate up to twenty-five thousand (25k) RegExes. Based on the throughput of our LaFA prototype on FPGA, we estimated that a 34-Gbps throughput can be achieved.
[Security and privacy, Network security]
An adaptive hash-based multilayer scheduler for L7-filter on a highly threaded hierarchical multi-core server
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Ubiquitous multi-core-based web servers and edge routers are increasingly popular in deploying computationally intensive Deep Packet Inspection (DPI) programs. Previous work has shown the benefits of connection locality-based scheduling on multi-core servers to improve L7-filter performance. However, we show that highly threaded hierarchical multi-core processors, such as the Sun Niagara 2 processor, accumulate imbalanced workload at each resource layer. This workload imbalance potentially offsets the benefits from connection locality. In addition, connection-locality-based load balance fails to work when network traffic is unevenly distributed. In this paper, we propose an adaptive hash-based multilayer scheduler for a highly threaded hierarchical Sun Niagara 2 server. Our scheduler maintains connection locality and adaptively adjusts the scheduling to balance the real time workload. The original Highest Random Weight (HRW) hash guarantees the connection locality but only balances the workload over the number of different connections. We enhance the original single layer HRW into a hierarchical "hash tree" scheduler to balance the connection workload in accordance with the hierarchical processor architecture. We then optimize our multilayer scheduler to adaptively adjust scheduling decisions based on service time at each level, further improving the system load balance. Our scheduler is shown to increase the system throughput by 59.2% compared to the previously proposed connection locality optimization.
[Computer systems organization, Multiple instruction, multiple data, Parallel architectures, Architectures]
A NFA-based programmable regular expression match engine
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
In this poster, we present a programmable hardware architecture to speed up the matching of regular expressions. The match engine is modeled as non-deterministic finite automata (NFA) with auxiliary hardware features to process repetition of sub-patterns without unrolling. The computation is table-driven and the system throughput is deterministic. The lookup tables are implemented using ternary content addressable memory (TCAM). The overall table size is approximately equal to the number of transition edges in the NFA. Incremental changes to the pattern set can be accommodated by modifying the contents of the lookup tables without reconfiguring the hardware.
[Computer systems organization, Embedded and cyber-physical systems, Real-time systems]
High throughput architecture for packet classification using FPGA
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
To avoid packet classification from being the performance bottleneck in network devices, one-chip solution hardware packet classifier based on HiCuts algorithm is designed and implemented in single chip of FPGA. The compact data structure and the optimized combination of memory organization with high degree parallel and pipeline architecture make the classifier running at very high speed. The simulation and implementation tests show our design reaches OC-768 throughput even for a large rule set with 26K rules while only consuming limited logic resource of the FPGA. This low cost one-chip hardware solution can effectively off-load data processing burden from the CPU of data path in network devices.
[Security and privacy, Network security]
OASis: towards extensible open-architecture services platforms
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
In this paper, we propose an extensible Open-Architecture Services platform (OASis) for high-performance network processing. OASis embraces recent advances of open technologies, including open source software, open system standards and open network architectures. Three programming models are proposed for target-specific processing modules: a multi-granularity packet processing model for network processing; a thread-isolated parallel programming model for service processing; and a message-based management model for centralized system administration. As an application example of OASis, a Unified Threat Management (UTM) prototype is implemented. This prototype provides multiple network security services, including stateful firewall, intrusion detection, and virus scanning. Experimental results show that, the OASis-UTM prototype can achieve 40Gbps stateful firewall performance together with 4--8Gbps intrusion detection and anti-virus performance on a 12U 14-slot ATCA platform.
[]
EINIC: an architecture for high bandwidth network I/O on multi-core processors
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
This paper proposes a new server architecture EINIC (Enhanced Integrated NIC) for multi-core processors to tackle the mismatch between network speed and host computational capacity. Similar to prior work, EINIC integrates a redesigned NIC onto a CPU. However, we extend the integrated NIC (INIC) to multicore platforms and examine its behaviors with the network receiving optimization. Additionally, by exploiting NICs proximity to CPUs, we also design an I/O-aware last level shared cache (LLC). Our I/O-aware design allows us to split the cache into an I/O cache and a general cache in a flexible way. It ameliorates cache interferences between network and non-network data. Our simulation results show that EINIC not only attacks the mismatch, but also ameliorates the cache interference.
[Communication hardware, interfaces and storage, Networks, Computer systems organization, Network architectures, Hardware, Other architectures, Architectures]
Accelerating OpenFlow switching with network processors
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
OpenFlow switching enables flexible management of enterprise network switches and experiments on regular network traffic. We present in this paper a complementary design to OpenFlow's existing reference designs. We apply network processor based acceleration cards to perform OpenFlow switching. We describe the design options and report our experiment results that show a 20% reduction on packet delay and the comparable packet forwarding throughput compared to conventional designs.
[Networks, Network protocols, Network components, Routers, Intermediate nodes]
Multiplexing endpoints of HCA to achieve scalability for MPI applications: design, implementation and performance evaluation with uDAPL
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
With an ever increasing demand for computing power, number of nodes to be deployed in a cluster based supercomputer is increasing. Limited hardware resources such as Endpoints on HCA of a high speed interconnect limit the scalability of a parallel application based on MPI that sets up reliable connections between every process pair using endpoints, prior to communication. In this paper, we propose a novel approach of multiplexing endpoints to extend scalability. We discuss critical design issues in connection management and data transfer routines with the multiplexing technique. Using this approach, we are able to scale up MPI applications with nearly equal or better performance with the same HCA.
[]
Micro Secure Socket Layer (MSSL) for micro server
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
In this paper, we propose Micro Secure Socket Layer (MSSL) for 8-bit flash micro controller that is about 1.3 Kbytes in code size. We have analyzed and compared various cryptographic protocols in TCP/IP stack for Micro Server to propose a simple secure layer based on simple handshake processing and encryption. Security implementation for Micro Server, which has very limited size of memory with a small processor, is very difficult and challenging task. However, security on the applications of ubiquitous sensors has become very important issues recently. Crackers can easily access to the sensor nodes or Micro Servers without security. Because the proposed MSSL is very small in code size, it can be implemented and is suitable for small sensors and Micro Server systems.
[]
A path combinational method for multiple pattern matching
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Multiple pattern matching architecture is critical for content inspection based network security applications, especially for high speed network or large pattern sets. This paper presents a method to optimize the potential memory usage for multiple string or regular expression matching by the idea of combining DFA's paths, named isomorphic path combination (IMPC). To achieve IMPC, a novel multiple pattern matching algorithm is proposed, which is based on Cached DFA (CDFA). Compared to extended AC algorithm based on DFA, our method on CDFA can reduce 78.6% states for Snort pattern set, which results in one of the most memory efficient methods. More important is that our method can be embedded to other algorithms as the optimization.
[Security and privacy, Network security]
A lock-free, cache-efficient shared ring buffer for multi-core architectures
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
We propose MCRingBuffer, a lock-free, cache-efficient shared ring buffer that provides fast data accesses among threads running in multi-core architectures. MCRingBuffer seeks to reduce the cost of inter-core communication by allowing concurrent lock-free data accesses and improving the cache locality of accessing control variables used for thread synchronization. Evaluation on an Intel Xeon multi-core machine shows that MCRingBuffer achieves a throughput gain of up to 4.9x over existing concurrent lock-free ring buffers. A motivating application of MCRingBuffer is parallel network traffic monitoring, in which MCRingBuffer facilitates multi-core architectures to process packets at line rate.
[Operating systems, Process synchronization, Contextual software domains, Software organization and properties, Software and its engineering, Process management]
Hash-based routing for scalable datacenters
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Most datacenter networks are based on specialized edge-core topologies, which are costly to build, difficult to maintain and consume too much power. We propose enhancements to layer-two (L2) Ethernet switches to enable multipath L2 routing in scalable datacenters. Our hash-based routing approach reuses and minimally extends hardware structures in high-volume switches, while exposing a powerful network management interface for multipath load balancing, QoS differentiation, and resilience to faults.
[]
Theoretic analysis of finite automata for memory-based pattern matching
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
In the midst of vastly numbered and quickly growing internet security threats, Network Intrusion Detection System (NIDS) [2] becomes more important to network security every day. Vital to effective NIDS is a multi-pattern matching engine which requires deterministic performance and adaptability to new threats [3]. Memory-based Deterministic Finite Automata (DFA) are ideal for pattern matching but have severe memory requirements [1] that make them difficult to implement. Many previous heuristic techniques have been proposed to reduce memory requirements, however in this paper, we aim to effectively understand the basic relationship between DFA characteristics and memory, in order to create minimal memory DFA implementations. We show what DFA characteristics either cause or reduce memory requirements, as well as how to optimize DFA to exploit those characteristics. Specifically, we introduce the concepts of State Independence and State Irregularity, which are DFA characteristics that can reduce memory waste and allow for memory reuse. Furthermore, we introduce DFA normalization which optimizes DFA to fully exploit these characteristics. Altogether this work serves as a source for how to extract and utilize DFA characteristics to create minimal memory implementations.
[]
Design and performance analysis of a DRAM-based statistics counter array architecture
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
The problem of maintaining efficiently a large number (say millions) of statistics counters that need to be updated at very high speeds (e.g. 40 Gb/s) has received considerable research attention in recent years. This problem arises in a variety of router management and data streaming applications where large arrays of counters are used to track various network statistics and implement various counting sketches. It proves too costly to store such large counter arrays entirely in SRAM while DRAM is viewed as too slow for providing wirespeed updates at such high speeds. In this paper, we propose a DRAM-based counter architecture that can effectively maintain wirespeed updates to large counter arrays. The proposed approach is based on the observation that modern commodity DRAM architectures, driven by aggressive performance roadmaps for consumer applications (e.g. video games), have advanced architecture features that can be exploited to make a DRAM-based solution practical. In particular, we propose a randomized DRAM architecture that can harness the performance of modern commodity DRAM offerings by interleaving counter updates to multiple memory banks. The proposed architecture makes use of a simple randomization scheme, a small cache, and small request queues to statistically guarantee a near-perfect load-balancing of counter updates to the DRAM banks. The statistical guarantee of the proposed scheme is proven using a novel combination of convex ordering and large deviation theory. Our proposed counter scheme can support arbitrary increments and decrements at wirespeed, and it can support different number representations, including both integer and floating point number representations.
[Networks, Network monitoring, Network services]
Motivating future interconnects: a differential measurement analysis of PCI latency
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Local interconnect architectures are at a cusp in which advances in throughput have come at the expense of power and latency. Moreover, physical limits imposed on dissipation and packaging mean that further advances will require a new approach to interconnect design. Although latency in networks has been the focus of the High-Performance Computing architect and of concern across the computer community, we illustrate how an evolution in the common PCI interconnect architecture has worsened latency by a factor of between 3 and 25 over earlier incarnations.
[]
Weighted random oblivious routing on torus networks
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Torus, mesh, and flattened butterfly networks have all been considered as candidate architectures for on-chip interconnection networks. In this paper, we study the problem of optimal oblivious routing for one of these architecture classes, namely, the torus network. We introduce a new closed-form oblivious routing algorithm called W2TURN that is worst-case throughput optimal for 2D-torus networks. W2TURN is based on a weighted random selection of paths that contain at most two turns. Restricting the maximum number of turns in routing paths to just two results in a simple deadlock-free implementation of W2TURN. In terms of average hop count, W2TURN outperforms the best previously known closed-form worst-case throughput optimal routing algorithm called IVAL [14]. We also provide another routing algorithm based on the weighted random selection of paths with at most two turns called I2TURN and show that it is equivalent to IVAL. However, I2TURN eliminates the need for loop removal at runtime and provides a closed-form analytical expression for evaluating the average hop count. The latter enables us to demonstrate analytically that W2TURN strictly outperforms IVAL (and I2TURN) in average hop count. Finally, we present a new optimal weighted random routing algorithm for rings called WRD (Weighted Random Direction). WRD provides a closed form expression for the the optimal distribution of traffic along the minimal and non-minimal directions in a ring topology to achieve minimum average hop count under maximum worst-case throughput.
[Theory of computation, Computer systems organization, Approximation algorithms analysis, Parallel architectures, Routing and network design problems, Design and analysis of algorithms, Architectures, Interconnection architectures]
Design of a scalable nanophotonic interconnect for future multicores
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
As communication-centric computing paradigm gathers momentum due to increased wire delays and excess power dissipation with technology scaling, researchers have focused their attention on developing alternate technology solutions for Network-on-Chips (NoCs) architectures. One potential solution is nanophotonics because of higher bandwidth, reduced power dissipation and increased wiring simplification. In this paper, we propose PROPEL, a balanced power and area-efficient on-chip photonic interconnect for future multicores. PROPEL overcomes two fundamental issues facing NoCs architectures, namely power dissipation and area overhead, by a combination of multiplexing techniques (wave-length and space) and by exploiting the recent advances in optical component design space. We also propose a scalable version of PROPEL, called E-PROPEL which can scale to 256 cores. Our results indicate that PROPEL and E-PROPEL are power, cost and area-effective networks when compared to competing on-chip optical topologies when the number of optical components and overall power loss in the network are considered. Simulation results on synthetic traffic indicate that PROPEL performs better (throughput and power) than electrical and optical topologies.
[Communication hardware, interfaces and storage, Integrated circuits, Interconnect, Hardware]
A novel 3D layer-multiplexed on-chip network
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Recently, a near-optimal oblivious routing algorithm for 3D mesh networks called Randomized Partially-Minimal (RPM) routing was proposed [12], which works by load-balancing traffic across vertical layers and routing minimally on each horizontal layer. It achieves optimal worst-case throughput when the network radix k is even and within a factor of 1/k2 of optimal when k is odd, and it achieves significantly lower latencies than Valiant routing [18], the best previously known optimal worst-case throughput algorithm. This paper presents a novel layer-multiplexed (LM) architecture for 3D on-chip networks that exploits the optimality of RPM together with the short inter-layer wiring delays enabled in 3D technology. The LM architecture replaces the one-layer-per-hop routing in a 3D mesh with simpler vertical demultiplexing and multiplexing structures. The proposed LM architecture can achieve the same worst-case throughput as a 3D mesh by adapting RPM routing to the LM architecture. However, the LM architecture consumes 27% less power, occupies 27% less area, attains 14.5% higher average throughput, and achieves 33% lower worst-case hop count for a symmetric 4x4x4 mesh topology. On an asymmetric 8 x 8 x 4 mesh, the LM architecture achieves comparable average-case throughput to a 3D mesh, but consumes 26% less power, takes up 27% less area and attains 20% lower worst-case hop count.
[Computer systems organization, Parallel architectures, Architectures, Interconnection architectures]
Divide and discriminate: algorithm for deterministic and fast hash lookups
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Exact and approximate membership lookups are among the most widely used primitives in a number of network applications. Hash tables are commonly used to implement these primitive functions as they provide O(1) operations at moderate load (table occupancy). However, at high load, collisions become prevalent in the table, which makes lookup highly non-deterministic and reduces the average performance. Slow and non-deterministic lookups are detrimental to the performance and scalability of modern platforms such as ASIC/FPGA and multi-core that use highly parallel compute and memory structures. To combat non-determinism and achieve high rate lookups, a recent series of papers employ compact on-chip memory that augments the main hash table and stores certain key information. Unfortunately, they require substantial on-chip memory space and bandwidth, and fail to provide 100% guarantee on lookup rate. In this paper, we solve this with a novel construction that requires 10-fold smaller on-chip memory and guarantees that all lookups require a single hash table access at near full load. The on-chip memory uses only between 1- and 2-bit per item and also needs a small number of accesses (between two and four) per lookup. This represents a substantial improvement over previous schemes and therefore can help realize highly scalable and deterministic lookup tables in modern parallel platforms.
[Security and privacy, Network security]
Range Tries for scalable address lookup
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
In this paper we introduce the Range Trie, a new multiway tree data structure for address lookup. Each Range Trie node maps to an address range [N<sub>a</sub>, N<sub>b</sub>) and performs multiple comparisons to determine the subrange an incoming address belongs to. Range Trie improves on the existing Range Trees allowing shorter comparisons than the address width. The maximum comparison length in a Range Trie node is [log<sub>2</sub> (N<sub>b</sub> -- N<sub>a</sub>)] bits. Address parts can be shared among multiple concurrent comparisons or even omitted. Addresses can be properly aligned to further reduce the required address bits per comparison. In so doing, Range Tries can store in a single tree node more address bounds to be compared. Given a memory bandwidth, more comparisons are performed in a single step reducing lookup latency, memory accesses per lookup, and overall memory requirements. Latency and memory size scale better than related works as the address width and the number of stored prefixes increase. Considering memory bandwidth of 256-bits per cycle, five to seven Range Trie levels are sufficient to store half a million IPv4 or IPv6 prefixes, while memory size is comparable and in many cases better than linear search. We describe a Range Trie hardware design and evaluate our approach in terms of performance, area cost and power consumption. Range Trie 90-nm ASIC implementations, storing 0.5 million IPv4 and IPv6 prefixes, perform over 500 million lookups per second (OC-3072) and consume 3.9 and 11.4 Watts respectively.
[Networks, Network components, Routers, Intermediate nodes]
Progressive hashing for packet processing using set associative memory
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
As the Internet grows, both the number of rules in packet filtering databases and the number of prefixes in IP lookup tables inside the router are growing. The packet processing engine is a critical part of the Internet router as it is used to perform packet forwarding (PF) and packet classification (PC). In both applications, processing has to be at wire speed. It is common to use hash-based schemes in packet processing engines; however, the downside of classic hashing techniques such as overflow and worst case memory access time, has to be dealt with. Implementing hash tables using set associative memory has the property that each bucket of a hash table can be searched in one memory cycle outperforming the conventional Ternary CAMs in terms of power and scalability. In this paper we present "Progressive Hashing" (PH), a general open addressing hash-based packet processing scheme for Internet routers using the set associative memory architecture. Our scheme is an extension of the multiple hashing scheme and is amendable to high-performance hardware implementation with low overflow and low memory access latency. We show by experimenting with real IP lookup tables and synthetic packet filtering databases that PH reduces the overflow over the multiple hashing. The proposed PH processing engine is estimated to achieve an average processing speed of 160 Gbps for the PC application and 320 Gbps for the PF application.
[Networks, Network components, Routers, Intermediate nodes]
SPC-FA: synergic parallel compact finite automaton to accelerate multi-string matching with low memory
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Deterministic Finite Automaton (DFA) is well-known for its constant matching speed in worst case, and widely used in multi-string matching, which is a critical technique in high performance Network Intrusion Detection System (NIDS) design. Existing DFA-based researches achieve high throughput at the expense of extremely high memory cost, so they fail to be used in situations like embedded systems where very tight memory resource is available. In this paper, we propose a memory-efficient multi-string matching acceleration scheme named Synergic Parallel Compact (SPC) Match Engine, which can provide a high matching speedup with no extra memory cost than the traditional DFA. Our scheme can be understood as consisting of k SPC-FAs, each of which can process one character from the input stream, causing achieving a constant speedup factor k with reduced memory occupation. Experimental evaluations with Snort and ClamAV rulesets show that a speedup of 9X can be practically achieved by a single SPC Match Engine instance with a reduced memory size than the up-to-date DFA-based compression approaches.
[Security and privacy, Network security]
Memory optimization for packet classification algorithms
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
We propose novel method how to reduce data structure size for the family of packet classification algorithms at the cost of additional pipelined processing with only small amount of logic resources. The reduction significantly decreases overhead given by the crossproduct nature of classification rules. Therefore the data structure can be compressed to 10% on average. As high compression ratio is achieved, fast on-chip memory can be used to store data structures and hardware architectures can process network traffic at significantly higher speed.
[Application specific processors, Hardware, Very large scale integration design, Application-specific VLSI designs]
ISP managed peer-to-peer
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Despite their widespread popularity, peer-to-peer (P2P) systems engender continuing controversy. To reduce P2P's high network cost, Internet Service Providers (ISPs) have installed network devices that detect and block P2P traffic. These devices angered subscribers because they also increased download times. For that reason, application developers have begun obfuscating their traffic to avoid ISP-detection. This "cat and mouse" game portends a broader shift. If ISPs remedy the relationship with P2P developers now, developers may cooperate with them to develop network-efficient protocols in the future. Our proposal makes a noteworthy contribution in this direction.
[Networks, Network protocols]
Interfacing to a virtualized network infrastructure through network service abstractions
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Virtualization is the base for a diversified next-generation network architecture design. Much work has been done on virtualization infrastructure, but it is still unclear how to easily instantiate a network slice that meets a high-level description of network functionality. Our work addresses this problem that occurs at the interface between network service providers and virtualized infrastructure providers. The proposed Service-based Network Virtualization System (SNVS), which is based on our previously developed network service architecture, provides a comprehensive and extensible interface to ease the development of new network services, protocols, and applications in virtualized networks.
[]
Implementing URL-based forwarding on a network processor-based router platform
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
We describe the implementation of a URL-based forwarding function on a network processor-based programmable router (NPR). URL-based forwarding is an important tool for overlay networks. This paper presents a data path for overlay networks and the effectiveness of a programmable router.
[]
Parallelization of Snort on a multi-core platform
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
We design and test a multithreaded Snort which uses flow pinning as a major optimization. The insights derived in improving Snort's performance will apply generally to any parallel networking application that uses flow pinning as an optimization.
[]
Testbed for evaluating worm containment systems
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Dangerous worms like CodeRed or Slammer can spread millions of probe packets in just seconds which can result in thousands of infected hosts and large losses. Fast and effective containment strategies are crucially important to protect the Internet Infrastructure. Toward this goal of fast and effective worm containment, different techniques have been presented such as address blacklisting and content filtering [3], anomaly detection [6] and signature-based detection [5]. Meanwhile recently developed worm models [1] enable us to develop a testbed to accurately and quickly evaluate the efficiency of these defense mechanisms. In this paper, we present a testbed which utilizes software agents to allow large scale simulation with individual host functionality. We utilize this testbed to evaluate our containment systems in terms of security and performance tradeoff.
[]
External storage middleware for wireless devices with limited resources
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
This paper introduces an external storage middleware, that offers a set of functions (API - Application Program Interface) to mobile applications and facilitates the transfer of files between a mobile device and external storage servers regardless of the available wireless network. The Middleware selects the best wireless service available. In addition, the files exchanged between the mobile device and the external storage server are encrypted to provide security when traveling through the network. As a use case, it was developed an automatic file swapper service for mobile devices. The service is running on the mobile device optimizing its available storage space. Our middleware was tested with the following wireless services: Wi-Fi, GPRS, MMS.
[Software system structures, Software architectures, Software organization and properties, Software and its engineering]
Designing high-speed packet processing tasks at arbitrary levels of abstraction: implementation and evaluation of a MIXMAP system
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Packet processing systems of forthcoming high-speed network nodes demand extremely high processing rates, but also modularity and easy adaptability due to new or evolving protocols and services. As the fixed architecture and instruction set of current network processors sometimes hinders an efficient implementation of processing tasks, we introduced the MIXMAP architecture [4] that is designed to offer programmability at multiple levels of abstraction. Now we describe the prototypical realization of this architecture showing its feasibility. Our results indicate that up to 170 million packets per second can be processed with this architecture using current FPGAs. By implementing packet processing tasks at register-transfer level and at software level, we validate the architecture's applicability and the benefits of implementing at an appropriate level of abstraction.
[Networks, Network components, Routers, Intermediate nodes]
SANS: a scalable architecture for network intrusion prevention with stateful frontend
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Inline stateful and deep inspection for intrusion prevention is becoming more challenging due to the increase in both the volume of network traffic and the complexity of the analysis requirements. In this work, we pursue a novel architectural approach, named SANS, which takes both the advantage of new generation network processors for packet-header-based processing and the advantage of commodity x86 platforms for packet payload data processing. A session table scheme is designed for the stateful frontend in SANS to achieve wire speed inline processing.
[Security and privacy, Network security]
A novel hybrid SRAM/DRAM memory architecture for fast packet buffers
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
This paper addresses the design of fast packet buffers for high speed Internet routers and switches. These buffers usually use a memory hierarchy that consist of expensive but fast SRAM and cheap but slow DRAM to meet both speed and capacity requirements. One challenge building these packet buffers is to provide worst-case bandwidth guarantees and fixed latencies, not to stall pipelines or to reduce throughput. My colleagues and I propose a novel packet buffer architecture along with a new memory management algorithm which reduces the amount of required SRAM compared to other architectures, e. g. by 73% for a 100 Gbps system using DDR3-DRAM. Furthermore, our architecture scales well with line rate.
[Networks, Network components, Routers, Intermediate nodes]
Binary search on levels using a Bloom filter for IPv6 address lookup
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
This paper proposes a new IP address lookup using a Bloom filter. The proposed algorithm is based on binary search on trie levels, and a Bloom filter pre-filters the levels which do not have matching nodes in performing the binary search on levels. Hence the number of memory access which affects the search performance is greatly reduced. Simulation result shows that an IPv6 address lookup can be performed with 1--3 memory accesses in average for an IPv6 routing data set with 1096 prefixes.
[Networks, Network components, Routers, Intermediate nodes]
A mobile healthcare system using IMS and the HL7 framework
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
The advent of Wireless Body-Area Sensor Networks (WBASNs) technologies enables the autonomic and remote collection of realtime physiological data related to the health status of patients with chronic diseases. At the same time the advances in wireless communication systems make possible the "anywhere, anytime" delivery of such data to medical staff and caregivers in order to allow them to easily monitor and quickly respond in emergencies. In this paper, we propose a system architecture that utilizes the IMS (IP Multimedia Subsystem) and the HL7 (Health Level Seven) technologies to implement a mobile and interoperable healthcare system to support WBASNs in a healthcare environment.
[Networks, Network protocols, Mobile networks, Wireless access networks, Network types]
An ultra high throughput and memory efficient pipeline architecture for multi-match packet classification without TCAMs
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
The emergence of new network applications like network intrusion detection system, packet-level accounting, and load-balancing requires packet classification to report all matched rules, instead of only the best matched rule. Although several schemes have been proposed recently to address the multi-match packet classification problem, most of them require either huge memory or expensive Ternary Content Addressable Memory (TCAM) to store the intermediate data structure, or suffer from steep performance degradation under certain types of classifiers. In this paper, we decompose the operation of multi-match packet classification from the complicated multi-dimensional search to several single-dimensional searches, and present an asynchronous pipeline architecture based on a signature tree structure to combine the intermediate results returned from single-dimensional searches. By spreading edges of the signature tree in multiple hash tables at different stages of the pipeline, the pipeline can achieve a high throughput via the inter-stage parallel access to hash tables. To exploit further intra-stage parallelism, two edge-grouping algorithms are designed to evenly divide the edges associated with each stage into multiple work-conserving hash tables with minimum overhead. Extensive simulation using realistic classifiers and traffic traces shows that the proposed pipeline architecture outperforms HyperCut and B2PC schemes in classification speed by at least one order of magnitude, while with a similar storage requirement. Particularly, with different types of classifiers of 4K rules, the proposed pipeline architecture is able to achieve a throughput between 19.5 Gbps and 91 Gbps.
[Networks, Network components, Routers, Intermediate nodes]
Co-match: fast and efficient packet inspection for multiple flows
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Packet inspection is widely employed in application-layer protocol analyzing systems to enable accurate protocol identification. Many existing systems, however, fail to meet the requirement of keeping up with wire speed in networking. There are two limitations: (1) software-based matching schemes are usually in a sequential manner which is slow and inefficient; (2) fast hardware-based matching schemes are inapplicable to network packet processing for lacking of intrinsic support for multiple flows. This paper proposes a novel approach for application-layer protocol identification called Co-Match, which combines software and hardware together to achieve fast and efficient signature matching for multiple flows. First, a grouping scheme is adopted to organize signatures into several matching sets. With this scheme, each packet is only matched against a subset of signatures, bringing about a remarkable improvement of matching speed in software. Second, an FPGA-based coprocessor is developed in order to support fast parallel regular expression matching for multiple flows in hardware. Moreover, a hardware-based flow-level traffic load balancer is employed to parallel multi-flow processing on multiple CPU cores. Experimental results show that our approach is efficient to handle multiple flows while system throughput can achieve the wire speed of Gigabit Ethernet links with moderate CPU usage.
[Security and privacy, Network security]
Experience with high-speed automated application-identification for network-management
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
AtoZ, an automatic traffic organizer, provides control of how network-resources are used by applications. It does this by combining the high-speed packet processing of the NetFPGA with an efficient method for application-behavior labeling. AtoZ can control network resources by prohibiting certain applications and controlling the resources available to others. We discuss deployment experience and use real traffic to illustrate how such an architecture enables several distinct features: high accuracy, high throughput, minimal delay, and efficient packet labeling --- all in a low-cost, robust configuration that works alongside the enterprise access-router.
[]
Software radio: a broad change in RF communications systems design
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
Software radio is a deceptively simple idea: Identify all the features that specialize an RF communications device to a particular waveform (e.g. GSM cell phone or FM walkie talkie), and implement these features in flexible software on a generic platform, rather than in fixed-function hardware. This change should provide significant advantages compared to legacy hardware radios: the ability to support multiple waveforms on the same device, to upgrade the waveforms on the device through software downloads, and to dynamically adapt modulation or other physical layer parameters to a wide range of channel conditions. However, taking full advantage of software radio turns out to require a broad change in communications systems. Affected hardware components include antennas, filters, A/D converters, and power amplifiers. Affected device-level software components include signal processing, timing control, inter-layer APIs, and security. The hardware architectures optimal for this software are not GPPs, DSPs or FPGAs, but an interesting hybrid among these approaches. At the network level, new MAC algorithms and topology management are needed to exploit the flexibility of individual nodes. In this talk I present a slice through these varied and interrelated systems and research challenges, taking a total systems view of software radio.
[]
Networking hardware: what drives innovation?
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
None
[]
Revisiting the internet hourglass: core strength vs. middle-age spread
Proceedings of the 5th ACM/IEEE Symposium on Architectures for Networking and Communications Systems
None
2009
The threat of commoditization poses a real challenge for service providers. Offering only a "plain vanilla" IP packet delivery service limits the options for competitive differentiation. Conversely, embedding additional functionality in the network carries a number of risks -- decreased robustness and increased complexity, for example. The key to addressing this challenge is the careful selection of appropriate functionality to embed in the network. Functions should be added to the network only when they offer value to a wide range of applications, and they should not inhibit the correct operation of applications that do not need them. This talk addresses the question of how novel, useful functions might be embedded "inside" the network, and how best to evaluate candidate functions for inclusion. For device designers, it is important to understand not only what functions are needed in the network today, but also which ones might provide the most benefit in the future. Because of the uncertainly about exactly what future networks will be expected to do, functions that are selected for inclusion in network devices must be as general as possible, and they should not interfere with the correct operation of the network when they are not needed. Some functions are best implemented as an overlay, leaving the essential network-layer functionality unaffected, while others will need assistance from the fast-path forwarding hardware. We will consider examples of various functions that have been or could be added to "core" networks, aiming to understand the tradeoffs both among different functions to add and among different implementation approaches.
[]
Softly defined networking
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Software Defined Networking (SDN) has been described as the hope and hype for the future of networking. Definitions vary, but one research direction is to separate the control plane from the data plane, introducing abstractions that can provide a global network view, a description of required behavior, and a model of packet forwarding. While the worthy goal is to address ossification of the Internet, the "S" for "software" in SDN perhaps unintentionally ossifies views of the respective roles of hardware and software. Specifically, it introduces an inbuilt assumption that there is relatively dumb switching hardware for high-speed packet forwarding, and relatively intelligent software running on processors for lesser-speed networking control. Programmable logic technology offers scope for 'soft hardware', with the potential to blur the distinctions between traditional roles. However, such technology must prove both its ability to deliver the necessary high performance and its ability to be programmed in a high-level manner. This talk will overview research that has been addressing these issues successfully, and will discuss its potential impact on the evolving view of SDN.
[Networks, Network components, Routers, Intermediate nodes]
On the feasibility of completely wireless datacenters
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Conventional datacenters, based on wired networks, entail high wiring costs, suffer from performance bottlenecks, and have low resilience to network failures. In this paper, we investigate a radically new methodology for building wire-free datacenters based on emerging 60GHz RF technology. We propose a novel rack design and a resulting network topology inspired by Cayley graphs that provide a dense interconnect. Our exploration of the resulting design space shows that wireless datacenters built with this methodology can potentially attain higher aggregate bandwidth, lower latency, and substantially higher fault tolerance than a conventional wired datacenter while improving ease of construction and maintenance.
[Network properties, Networks, Network structure, Mobile networks, Wireless access networks, Network types]
Popularity-driven coordinated caching in named data networking
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
The built-in caching capability of future Named Data Networking (NDN) promises to enable effective content distribution at a global scale without requiring special infrastructure. The aim of this work is to design efficient caching schemes in NDN to achieve better performance at both the network layer and application layer. With the specific objective of minimizing the inter-ISP (Internet Service Provider) traffic and average access latency, we first formulate the optimization problems for different objectives and then solve them to obtain the optimal replica placement. Then we develop popularity-driven caching schemes which dynamically place the replicas in the caches on the en-route path in a coordination fashion. Simulation results show that the performances of our caching algorithms are much closer to the optimum and outperform the widely used schemes in terms of the inter-ISP traffic and the average number of access hops. Finally, we thoroughly evaluate the impact of several important design issues such as network topology, cache size, access pattern and content popularity on the caching performance and demonstrate that the proposed schemes are effective, stable, scalable and with reasonably light overhead.
[Networks, Network architectures]
Cache-aware affinitization on commodity multicores for high-speed network flows
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
For a given TCP or UDP flow, protocol processing of incoming packets is performed on the core that receives the interrupt, while the user-space application which consumes the data may run on the same or a different core. If the cores are not the same, additional costs due to context switches, cache misses, and the movement of data between the caches of the cores may occur. The magnitude of this cost depends upon the processor affinity of the user-space process relative to the network stack. In this paper we present a prototype implementation of a tool which enables the application processing and protocol processing to occur on cores which share the lowest cache level. The Cache-Aware Affinity Deamon (CAAD) analyzes the topology of the die and the NIC characteristics and conveys information to the sender which allows the entire end-to-end path for each new flow to be be managed and controlled. This is done in a light-weight manner for both uni and bi-directional flows. Measurements show that for bulk data transfers using commodity multicore machines, the use of CAAD improves the overall TCP throughput by as much as 31%, and reduces the cache miss rate as much as 37.5%. GridFTP combined with CAAD improves the download time for big file transfers by up to 18%.
[Network properties, Wide area networks, Networks, Network protocols, Network range, Local area networks]
xOMB: extensible open middleboxes with commodity servers
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
This paper presents the design and implementation of an incrementally scalable architecture for middleboxes based on commodity servers and operating systems. xOMB, the eXtensible Open MiddleBox, employs general programmable network processing pipelines, with user-defined C++ modules responsible for parsing, transforming, and forwarding network flows. We implement three processing pipelines in xOMB, demonstrating good performance for load balancing, protocol acceleration, and application integration. In particular, our xOMB load balancing switch is able to match or outperform a commercial programmable switch and popular open-source reverse proxy while still providing a more flexible programming model.
[Networks, Network components, Public Internet, Network types]
NetBump: user-extensible active queue management with bumps on the wire
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Engineering large-scale data center applications built from thousands of commodity nodes requires both an underlying network that supports a wide variety of traffic demands, and low latency at microsecond timescales. Many ideas for adding innovative functionality to networks, especially active queue management strategies, require either modifying packets or performing alternative queuing to packets in-flight on the data plane. However, configuring packet queuing, marking, and dropping is challenging, since buffering in commercial switches and routers is not programmable. In this work, we present NetBump, a platform for experimenting with, evaluating, and deploying a wide variety of active queue management strategies to network data planes with minimal intrusiveness and at low latency. NetBump leaves existing switches and endhosts unmodified by acting as a "bump on the wire," examining, marking, and forwarding packets at line rate in tens of microseconds to implement a variety of virtual active queuing disciplines and congestion control mechanisms. We describe the design of NetBump, and use it to implement several network functions and congestion control protocols including DCTCP and 802.1Qau quantized congestion notification.
[Networks, Network management, Network services]
Fast longest prefix name lookup for content-centric network forwarding
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Longest-prefix name-based forwarding in Content-Centric Networking poses many significant challenges on design of routers and algorithms, because the name space is many orders of magnitude larger and significantly more complex than the IP address space. IP forwarding algorithms are no longer applicable and cannot reach the satisfactory performance. In this paper, we present a framework of fast longest-name-prefix lookup, based on a name space reduction scheme we proposed for content-centric networking. We implement the algorithm using fat tree and extensible hybrid data structures to speed up name lookup. Our evaluations demonstrate that we can achieve name lookup throughput as high as more than 37 Mpps on off-the-shelf general-purpose CPU platforms.
[Communication hardware, interfaces and storage, Networks, Hardware]
Hardware support for dynamic protocol stacks
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Most networking performance enhancements occur through specific static solutions, where the structure of the protocol stack remains unchanged. Instead, we focus on a flexible software and hardware co-design for the entire protocol stack. In this paper, we present EmbedNet, a System-on-Chip implementation of a flexible network architecture for the Future Internet, where parts of the protocol stack can be moved between software and hardware at runtime. This enables the construction of dynamic protocol stacks that use available resources optimally.
[Networks, Network architectures]
Low-latency modular packet header parser for FPGA
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Packet parsing is the basic operation performed at all points of the network infrastructure. Modern networks impose challenging requirements on the performance and configurability of packet parsing modules, however the high-speed parsers often use very large chip area. We propose novel architecture of pipelined packet parser, which in addition to high throughput (over 100 Gb/s) offers also low latency. Moreover, the latency to throughput ratio can be finely tuned to fit the particular application.
[Application specific processors, Hardware, Very large scale integration design, Application-specific VLSI designs]
M-DFA (multithreaded DFA): an algorithm for reduction of state transitions and acceleration of REGEXP matching
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
This paper proposes a multi-thread based regular expression (regexp) matching algorithm, M-DFA (multithreaded DFA), for parallel computer architectures such as multi-core processors and graphic processing units (GPU). At the thread level, one thread is designated to traverse the DFA of a possible matching path until its termination, and at the task level multiple threads concurrently match each input symbol in parallel. Given a set of regexps, the total number of (DFA) state transitions in M-DFA is significantly smaller than that of its traditional DFA counterpart. The significant saving of state transitions is contributed by elimination of backtracking transitions, which commonly occur to mapping of concurrent active states in NFA to DFA and other situations. Experimental result shows that the proposed algorithm achieves significant reduction on state and state transition. In addition, the proposed algorithm running on Nvidia&#174; GTX 480 is 35 times faster than the popular regexp library, RE2 performed on Intel Core i7 CPU.
[Security and privacy, Network security]
A new embedded platform for rapid development of network applications
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
None
[Computer systems organization, Embedded and cyber-physical systems, Real-time systems]
Structural compression of packet classification trees
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Most of state-of-the-art packet classification algorithms employ heuristics to trade off between classification speed and memory usage. However, intelligent heuristics often result in complex data structures in algorithm implementation. This brings difficulties to the deployment and optimization of packet classification algorithms. In this poster, a structural compression approach is presented for decision tree based packet classification algorithms. This approach exploits the similarity in real-life filter sets to achieve high compression ratio without loss of tree semantics.
[Networks, Network monitoring, Network management, Network services]
Toward fast NDN software forwarding lookup engine based on hash tables
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
In Named Data Networking (NDN), forwarding lookup is based on tokenized variable-length names instead of fixed-length host addresses, and therefore it requires a new approach for designing a fast packet forwarding lookup engine. In this paper, we propose a design of an NDN software forwarding lookup engine based on hash tables and evaluate its performance with different design options. With a good hash function and table design combined with Bloom filters and data prefetching, we demonstrate that our design reaches about 1.5MPPS with a single thread on an Intel 2.0GHz Xeon processor.
[Networks, Network components, Routers, Intermediate nodes, Network types]
Host-based multi-tenant technology for scalable data center networks
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
These days, various academic and industrial institutions are sharing the computing resources of cloud data centers. For the sake of security, data center networks need to be separated by institution or department. One conventional approach is using tag-based VLAN standardized in IEEE 802.1Q. However, this approach cannot accommodate scalable networks because of a limitation on the number of VLAN IDs. To address this problem, we propose HostVLAN, a novel multi-tenant technique for scalable networks. To provide logical isolated networks for individual tenants (e.g., academic and industrial institutions), end host servers deployed in a data center filter receiving network data and forward them to designated virtual machines on the basis of isolation information. To reduce the broadcast traffic for the protocols, ARP and DHCP, end host servers convert the broadcast data into unicast data. Unlike conventional approaches that work in cooperation with switches, HostVLAN provides multi-tenant environments at the end-host-server side. To build a HostVLAN-based network architecture, we extended three virtual network switches supported by KVM and Xen VMMs. The results of performance evaluation demonstrate that HostVLAN can be scaled up to large numbers of multitenant networks with little overhead.
[Networks, Network architectures]
Distributed adaptive routing for big-data applications running on data center networks
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
With the growing popularity of big-data applications, Data Center Networks increasingly carry larger and longer traffic flows. As a result of this increased flow granularity, static routing cannot efficiently load-balance traffic, resulting in an increased network contention and a reduced throughput. Unfortunately, while adaptive routing can solve this load-balancing problem, network designers refrain from using it, because it also creates out-of-order packet delivery that can significantly degrade the reliable transport performance of the longer flows. In this paper, we show that by throttling each flow bandwidth to half of the network link capacity, a distributed-adaptive-routing algorithm is able to converge to a non-blocking routing assignment within a few iterations, causing minimal out-of-order packet delivery. We present a Markov chain model for distributed-adaptive-routing in the context of Clos networks that provides an approximation for the expected convergence time. This model predicts that for full-link-bandwidth traffic, the convergence time is exponential with the network size, so out-of-order packet delivery is unavoidable for long messages. However, with half-rate traffic, the algorithm converges within a few iterations and exhibits weak dependency on the network size. Therefore, we show that distributed-adaptive-routing may be used to provide a scalable and non-blocking routing even for long flows on a rearrangeably-non-blocking Clos network under half-rate conditions. The proposed model is evaluated and approximately fits the abstract system simulation model. Hardware implementation guidelines are provided and evaluated using a detailed flit-level InfiniBand simulation model. These results directly apply to adaptive-routing systems designed and deployed in various fields.
[Networks, Packet-switching networks, Network types]
Efficient buffering and scheduling for a single-chip crosspoint-queued switch
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
The single-chip crosspoint-queued (CQ) switch is a self-sufficient switching architecture enabled by state-of-art ASIC technology. Unlike the legacy input-queued or output-queued switches, this kind of switch has all its buffers placed at the crosspoints of input and output lines. Scheduling is also performed inside the switching core, and does not rely on instantaneous communications with input or output line-cards. Compared with other legacy switching architectures, the CQ switch has the advantages of high throughput, minimal delay, low scheduling complexity, and no speedup requirement. However, since the crosspoint buffers are small and segregated, packets may be dropped as soon as one of them becomes full. Thus how to efficiently use the crosspoint buffers and decrease the packet drop rate remains a major problem that needs to be addressed. In this paper, we propose a novel chained structure for the CQ switch, which supports load balancing and deflection routing. We also design scheduling algorithms to maintain the correct packet order caused by multi-path switching. All these techniques require modest hardware modifications and memory speedup in the switching core, but can greatly boost the overall buffer utilization and reduce the packet drop rate, especially for large switches with small crosspoint buffers under bursty and non-uniform traffic.
[Networks, Network components, Packet-switching networks, Routers, Intermediate nodes, Network types]
Efficient traffic aware power management in multicore communications processors
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Multicore communications processors have become the main computing element in Internet routers and mobile base stations due to their flexibility and high processing capability. These processors are designed and equipped with enough resources to handle peak traffic loads. But network traffic varies significantly over time and peak traffic is observed very rarely. This variation in amount of traffic gives us an opportunity to save power during the low traffic times. Existing power management schemes are either too conservative or are unaware of traffic demands. We present a predictive power management scheme for communications or network processors. We use a traffic and load predictor to pro-actively change the number of active cores. Predictive power management provides more power efficiency than reactive schemes because it reduces the lag between load changes and changes in power adaptations since adaptations can be applied before the load changes. The proposed scheme also uses Dynamic Voltage and Frequency Scaling (DVFS) to change the frequency of the active cores to adapt to variation in traffic during the prediction interval. We perform experiments on real network traces and show that the proposed traffic aware scheme can save up to 40\% more power in communications processors as compared to traditional power management schemes.
[Computer systems organization, Architectures]
Software is the future of networking
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
In this talk, I'll revisit the role of Software in Software-Defined Networking and argue how not only control plane but also forwarding is becoming increasingly only a matter of software development. In short, I'll discuss how x86 is already on its way to transform the networking as we know it.
[Computer systems organization]
Attendre: mitigating ill effects of race conditions in openflow via queueing mechanism
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
None
[Networks, Network architectures]
Dynamic frequency scaling architecture for energy efficient router
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Recently, energy expenditures of the Internet have increased dramatically, raising energy issue of routers an urgent problem in relative research areas. In fact, much device surplus and redundancy are introduced during network planning for rarely appeared traffic peak hours and device failures, wasting energy most of the time. In this work, an energy-aware architecture is proposed for routers, which could trade system performance for energy savings while traffic is low by scaling frequencies of its inner components. We also explore multi-frequency modulation strategies to optimize the energy saving effect. The result shows that our prototype router could save about 40\% of its peak power consumption.
[Networks, Network architectures]
Extensible hierarchical simulation of network systems
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
The system architecture of a network system is of fundamental importance to the performance of computer networks. However, evaluating different architectural and algorithmic choices of network systems is usually difficult. This poster presents NetSysSim, a network system simulator implemented in SystemC. NetSysSim provides a hierarchical framework of different levels of abstraction. With SystemC's modular and timing based simulation, researchers can simulate any part of the system with the desired level of details. Our design of NetSysSim allows for performance evaluation of data plane architectures, including different queuing, scheduling or transmission schemes.
[Networks, Network components, Routers, Intermediate nodes]
FlowOS: a pure flow-based vision of network traffic
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
The original Internet architecture lacked the concept of a flow, and considered each traffic as a set of packets. In this short paper, we rethink this concept inside middlebox-based platform and handle each traffic as a whole block instead of packets. We design a whole system where each input packet matching some criteria is placed in a specific structure which is shared between all processing modules that interact in a parallel manner with this flow. Thus, this new design improves flexibility of traffic and also increases the flow processing performances.
[Networks, Network protocols]
Modular design of data vortex switch network
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
The Data Vortex switch architecture provides promising routing performance with scalability but requires complicated connections as its size increases. The modular design is proposed that allows a larger network to be formed from smaller Data Vortex units for flexible implementations. Routing performance is shown to be similar or improved.
[Communication hardware, interfaces and storage, Integrated circuits, Interconnect, Buses and high-speed links, Photonic and optical interconnect, Hardware]
PVNs: making virtualized network infrastructure usable
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Network virtualization is becoming a fundamental building block of future Internet architectures. Although the underlying network infrastructure needed to dynamically create and deploy custom virtual networks is rapidly taking shape (e.g., GENI), constructing and using a virtual network is still a challenging and labor intensive task, one best left to experts. In this paper, we present the concept of a Packaged Virtual Network (PVN), that enables normal users to easily download, deploy and use application-specific virtual networks. At the heart of our approach is a PVN Hypervisor that "runs" a PVN by allocating the virtual network resources needed by the PVN and then connecting the PVN's participants into the network on demand. To demonstrate our PVN approach, we implemented a multicast PVN that runs on the PVN hypervisor prototype using ProtoGENI as the underlying virtual network, allowing average users to create their own private multicast network.
[Networks, Network architectures]
Securing multi-core multi-threaded packet processors
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Modern routers use high-performance multi-core multi-threaded packet processing systems to implement protocol operations and to forward traffic. As the number of processor cores/threads increases, it becomes increasingly difficult to track their correct operation at runtime. In this paper, we discuss how to extent our existing monitoring scheme to support highly parallel environments.
[Networks, Network components, Routers, Intermediate nodes]
A hardware spinal decoder
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Spinal codes are a recently proposed capacity-achieving rateless code. While hardware encoding of spinal codes is straightforward, the design of an efficient, high-speed hardware decoder poses significant challenges. We present the first such decoder. By relaxing data dependencies inherent in the classic M-algorithm decoder, we obtain area and throughput competitive with 3GPP turbo codes as well as greatly reduced latency and complexity. The enabling architectural feature is a novel alpha-beta incremental approximate selection algorithm. We also present a method for obtaining hints which anticipate successful or failed decoding, permitting early termination and/or feedback-driven adaptation of the decoding parameters. We have validated our implementation in FPGA with on-air testing. Provisional hardware synthesis suggests that a near-capacity implementation of spinal codes can achieve a throughput of 12.5 Mbps in a 65 nm technology while using substantially less area than competitive 3GPP turbo code implementations.
[Communication hardware, interfaces and storage, Networks, Wireless devices, Mobile networks, Hardware, Wireless access networks, Network types]
Fast submatch extraction using OBDDs
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Network-based intrusion detection systems (NIDS) commonly use pattern languages to identify packets of interest. Similarly, security information and event management (SIEM) systems rely on pattern languages for real-time analysis of security alerts and event logs. Both NIDS and SIEM systems use pattern languages extended from regular expressions. One such extension, the submatch construct, allows the extraction of substrings from a string matching a pattern. Existing solutions for submatch extraction are based on non-deterministic finite automata (NFAs) or recursive backtracking. NFA-based algorithms are time-inefficient. Recursive backtracking algorithms perform poorly on pathological inputs generated by algorithmic complexity attacks. We propose a new approach for submatch extraction that uses ordered binary decision diagrams (OBDDs) to represent and operate pattern matching. Our evaluation using patterns from the Snort HTTP rule set and a commercial SIEM system shows that our approach achieves its ideal performance when patterns are combined. In the best case, our approach is faster than RE2 and PCRE by one to two orders of magnitude.
[Networks, Network monitoring, Network services]
LEAP: latency- energy- and area-optimized lookup pipeline
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Table lookups and other types of packet processing require so much memory bandwidth that the networking industry has long been a major consumer of specialized memories like TCAMs. Extensive research in algorithms for longest prefix matching and packet classification has laid the foundation for lookup engines relying on area- and power-efficient random access memories. Motivated by costs and semiconductor technology trends, designs from industry and academia implement multi-algorithm lookup pipelines by synthesizing multiple functions into hardware, or by adding programmability. In existing proposals, programmability comes with significant overhead. We build on recent innovations in computer architecture that demonstrate the efficiency and flexibility of dynamically synthesized accelerators. In this paper we propose LEAP, a latency- energy- and area- optimized lookup pipeline based on an analysis of various lookup algorithms. We compare to PLUG, which relies on von-Neumann-style programmable processing. We show that LEAP has equivalent flexibility by porting all lookup algorithms previously shown to work with PLUG. At the same time, LEAP reduces chip area by 1.5X, power consumption by 1.3X, and latency typically by 5X. Furthermore, programming LEAP is straight-forward; we demonstrate an intuitive Python-based API.
[Communication hardware, interfaces and storage, Computer systems organization, Hardware, Other architectures, Architectures]
Floating ground architecture: overcoming the one-hop boundary of current mobile internet
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
We propose the Floating Ground Architecture (FGA) for network mobility and ad hoc network convergence. Various factors, including excessive dependence on intelligence in the fixed network, result in the Internet having a de facto logical boundary one hop from the fixed network. To reduce these dependencies, FGA introduces a new logical layer, called Floating Ground, between the fixed network infrastructure and the mobile network, aiming to bridge these different types of network systems. Thanks to the effect of this buffer layer, the architecture: 1) optimizes routes in a deeply nested mobile router arrangement, 2) simplifies mobility event handling under frequent movement of the nodes, and 3) transparently introduces additional functionality with no additional intelligence on the infrastructure side. Through evaluation of our proposed architecture using an actual software implementation running via Direct Code Execution simulation, optimized routes are confirmed with three possible mobility scenarios, demonstrating the handoff duration is dramatically reduced in the short-distance movement scenario, which happens in 78.4%, at maximum, of the handoff events under actual taxi cabs movement in real world. Qualitative analysis of FGA shows it minimizes modification of the network components and existing standardized protocols, and is therefore more suitable for self-organized, distributed network extension than competitive approaches.
[Networks, Computer systems organization, Distributed architectures, Network architectures, Architectures]
ECOS: leveraging software-defined networks to support mobile application offloading
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Offloading has emerged as a promising idea to allow resource-constrained mobile devices to access intensive applications, without performance or energy costs, by leveraging external computing resources. This could be particularly useful in enterprise contexts where running line-of-business applications on mobile devices can enhance enterprise operations. However, we must address three practical roadblocks to make offloading amenable to adoption by enterprises: (i) ensuring privacy and trustworthiness of offload, (ii) decoupling offloading systems from their reliance on the availability of dedicated resources and (iii) accommodating offload at scale. We present the design and implementation of ECOS, an enterprise-centric offloading framework that leverages Software-Defined Networking to augment prior offloading proposals and address these limitations. ECOS functions as an application running at an enterprise-wide controller to allocate resources to mobile applications based on privacy and performance requirements, to ensure fairness, and to enforce security constraints. Experiments using a prototype based on Android and OpenFlow establish the effectiveness of our approach.
[]
On pending interest table in named data networking
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Internet has witnessed its paramount function transition from host-to-host communication to content dissemination. Named Data Networking (NDN) and Content-Centric Networking (CCN) emerge as a clean slate network architecture to embrace this shift. Pending Interest Table (PIT) in NDN/CCN keeps track of the Interest packets that are received but yet un-responded, which brings NDN/CCN significant features, such as communicating without the knowledge of source or destination, loop and packet loss detection, multipath routing, better security, etc. This paper presents a thorough study of PIT for the first time. Using an approximate, application-driven translation of current IP-generated trace to NDN trace, we firstly quantify the size and access frequencies of PIT. Evaluation results on a 20 Gbps gateway trace show that the corresponding PIT contains 1.5 M entries, and the lookup, insert and delete frequencies are 1.4 M/s, 0.9 M/s and 0.9 M/s, respectively. Faced with this challenging issue and to make PIT more scalable, we further propose a Name Component Encoding (NCE) solution to shrink PIT size and accelerate PIT access operations. By NCE, the memory consumption can be reduced by up to 87.44%, and the access performance significantly advanced, satisfying the access speed required by PIT. Moreover, PIT exhibits good scalability with NCE. At last, we propose to place PIT on (egress channel of) the outgoing line-cards of routers, which meets the NDN design and eliminates the cumbersome synchronization problem among multiple PITs on the line-cards.
[Networks, Network architectures]
Coexist: integrating content oriented publish/subscribe systems with ip
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
Content-Centric Networking (CCN) seeks to meet the content-centric needs of users. In this paper, we propose hybrid-COPSS, a hybrid content-centric architecture. We build on the previously proposed Content-Oriented Publish/Subscribe System (COPSS) to address incremental deployment of CCN and elegantly combine the functionality of content-centric networks with the efficiency of IP-based forwarding including IP multicast. Furthermore, we propose an approach for incremental deployment of caches in generic query/response CCN environments that optimizes latency and network load. To overcome the lack of inter-domain IP multicast, hybrid-COPSS uses COPSS multicast with shortcuts in the CCN overlay. Our hybrid approach would also be applicable to the Named Data Networking framework. To demonstrate the benefits of hybrid-COPSS, we use a multiplayer online gaming trace in our lab test-bed and microbenchmark the forwarding performance and queuing for both COPSS and hybrid-COPSS. A large scale trace-driven simulation (parameterized by the microbenchmark) on a representative ISP topology was used to evaluate the response latency and aggregate network load. Our results show that hybrid-COPSS performs better in terms of response latency in a single domain. In a multi-domain environment, hybrid-COPSS significantly reduces update latency and inter-domain traffic.
[Networks, Network architectures]
MCA 2 : multi-core architecture for mitigating complexity attacks
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
This paper takes advantage of the emerging multi-core computer architecture to design a general framework for mitigating network-based complexity attacks. In complexity attacks, an attacker carefully crafts "heavy" messages (or packets) such that each heavy message consumes substantially more resources than a normal message. Then, it sends a sufficient number of heavy messages to bring the system to a crawl at best. In our architecture, called MCA2---Multi-Core Architecture for Mitigating Complexity Attacks---cores quickly identify such suspicious messages and divert them to a fraction of the cores that are dedicated to handle all the heavy messages. This keeps the rest of the cores relatively unaffected and free to provide the legitimate traffic the same quality of service as if no attack takes place. We demonstrate the effectiveness of our architecture by examining cache-miss complexity attacks against Deep Packet Inspection (DPI) engines. For example, for Snort DPI engine, an attack in which 30% of the packets are malicious degrades the system throughput by over 50%, while with MCA2 the throughput drops by either 20% when no packets are dropped or by 10% in case dropping of heavy packets is allowed. At 60% malicious packets, the corresponding numbers are 70%, 40% and 23%.
[Networks, Network monitoring, Network management, Network services]
Malacoda: towards high-level compilation of network security applications on reconfigurable hardware
Proceedings of the eighth ACM/IEEE symposium on Architectures for networking and communications systems
None
2012
While the use of reconfigurable computing for tasks such as packet header processing or deep packet-inspection in high-speed networks has been widely studied, efforts to extend the technology to application-level processing have only recently been made. One issue that has prevented wider use of reconfigurable platforms in that context is the unfamiliar programming environment: Such systems commonly require expertise in computer architecture and digital logic design generally foreign to networking experts. To make the technology more accessible to potential users, we present the high-level domain-specific language Malacoda for application-level network processing and an associated compiler that automatically translates Malacoda descriptions into high-performance hardware blocks for insertion into an FPGA-based processing platform. We evaluate our approach on the use-case of a hardware-accelerated secure honeypot-in-a-box, programmed in Malacoda, and implemented on the NetFPGA 10G board. Results from a live-test of the system connected to a 10G Internet uplink complete the evaluation.
[High-level and register-transfer level synthesis, Electronic design automation, Hardware]
Programmable measurement architecture
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Measurement is at least half of network management. Many data centers require huge capital investments to build larger networks with higher link speeds; yet provide surprisingly little visibility into the network and traffic. Switch vendors often treat measurement as a second-class citizen, devoting most resources to control functions. Operators have limited control over what (not) to measure, and thus have to integrate incomplete measurement data from individual devices. Inspired by software-defined networking, we propose to design and build a new programmable measurement architecture that bridges the gap between operator's measurement requirements and device capabilities. We allow operators to flexibly program queries about the network state they need, provide generic and efficient primitives at many devices (hosts, switches, and reconfigurable devices), and automatically match the queries with the primitives. Our solutions have gained significant interests from both production data center operators and programmable switch vendors.
[Networks, Network architectures, Network services]
WASP: a software-defined communication layer for hybrid wireless networks
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
In this paper we introduce WASP, a general communication layer for hybrid wireless networks where multiple networks are used to complement each other. In our system, we capitalize on an infrastructure with a ubiquitous,wide-area network to help enable the creation of a local mobile ad-hocnetwork in an efficient, scalable, evolvable, and manageable way. In particular, in an architecture inspired by software-defined networking,we decouple the control plane and data plane in the mobile devices and shift the control plane to a centralized controller. The controller, reachable via the wide-area network, manages a collection of mobile devices by informing each device how to handle traffic based on neighbor information provided by the mobile devices. With this, a mobile ad-hoc network can help reduce the data burden on the ubiquitous network, and the ubiquitous network can help reduce the burden on the mobile devices. WASP can be used in different networks with different applications such as cellular and military networks. In this paper, we based our implementation on Android and tested on a collection of Google Nexus-4 devices to measure metrics such as battery consumption. We evaluate on an extended ns-3 simulation platform which we added the ability to run unmodified Android applications on the nodes within ns-3. Our experiments show that WASP scales better than traditional ad-hoc networks with only a minimal trade off of energy. Additionally, we show that a content distribution scheme using WASP on smart phones with cellular data plans significantly offloads bandwidth from the cellular infrastructure, and in turn reduces expensive data usage and energy usage.
[Networks, Mobile networks, Wireless access networks, Network types]
A packet-in message filtering mechanism for protection of control plane in openflow networks
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Protecting control planes in networking hardware from high rate packets is a critical issue for networks under operation. One common approach for conventional networking hardware is to offload expensive functions onto hard-wired offload engines as ASICs. OpenFlow networks are expected to provide greater network control flexibility by an open interface to the packet-forwarding plane and by centralized controllers. In OpenFlow networks, the approach for conventional networking hardware alone is inadequate because it restricts a certain amount of flexibility that OpenFlow is expected to provide. Therefore, we need a generic control plane protection mechanism in OpenFlow switches as a last resort. In this paper, we propose a mechanism to filter out Packet-In messages without dropping important ones for network control. Our proposed mechanism works simply. Switches record the values of packet header fields before sending Packet-In messages, which are specified by the controllers in advance, and filter out packets that have the same values as the recorded ones. We implemented and evaluated the proposed mechanism on a prototype software switch, concluding that it dramatically reduces CPU loads in the switches and passes important Packet-In messages for network control.
[Communication hardware, interfaces and storage, Networks, Hardware]
Faithful reproduction of network experiments
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
The proliferation of cloud computing has compelled the research community to rethink fundamental design aspects of networked systems. However, the tools commonly used to evaluate new ideas have not kept abreast of the latest developments. Common simulation and emulation frameworks fail to provide scalability, fidelity, reproducibility and execute unmodified code, all at the same time. We present SELENA, a Xen-based network emulation framework that offers fully reproducible experiments via its automation interface and supports the use of unmodified guest operating systems. This allows out-of-the-box compatibility with common applications and OS components, such as network stacks and filesystems. In order to faithfully emulate faster and larger networks, SELENA adopts the technique of time dilation and transparently slows down the passage of time for guest operating systems. This technique effectively virtualizes the availability of host's hardware resources and allows the replication of scenarios with increased I/O and computational demands. Users can directly control the trade-off between fidelity and running-times via intuitive tuning knobs. We evaluate the ability of SELENA to faithfully replicate the behavior of real systems and compare it against existing popular experimentation platforms. Our results suggest that SELENA can ac-curately model networks with aggregate link speeds of 44 Gbps or more, while improving by four times the execution time in comparison to ns3 and exhibits near-linear scaling properties.
[Transport protocols, Measurement, Networks, Cross-computing tools and techniques, Network protocols, Computing methodologies, Simulator / interpreter, Network types, Software architectures, Software system structures, Modeling and simulation, Public Internet, Performance, General and reference, Software organization and properties, Software and its engineering, Simulation evaluation]
DiFS: distributed flow scheduling for adaptive routing in hierarchical data center networks
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Data center networks leverage multiple parallel paths connecting end host pairs to offer high bisection bandwidth for cluster computing applications. However, state of the art routing protocols such as Equal Cost Multipath (ECMP) is load-oblivious due to static flow-to-link assignments. They may cause bandwidth loss due to flow collisions. Recently proposed centralized scheduling algorithm or host based adaptive routing that require network-wide condition information may suffer from scalability problems. In this paper, we present Distributed Flow Scheduling (DiFS) based Adaptive Routing for hierarchical data center networks, which is a localized and switch-only solution. DiFS allows switches to cooperate to avoid over-utilized links and find available paths without centralized control. DiFS is scalable and can react quickly to dynamic traffic, because it is independently executed on switches and requires no synchronization. DiFS provides global bounds of flow balance based on local optimization. Extensive experiments show that the aggregate throughput of DiFS using various traffic patterns is much better than that of ECMP, and is similar to or higher than those of two representative protocols that use network-wide optimization.
[Networks, Network protocols, Routing protocols, Network layer protocols]
Blender: upgrading tenant-based data center networking
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
This paper presents Blender, a framework that enables network operators to improve tenant performance by tailoring the network's behavior to tenant needs. Tenants may upgrade their provisioned portion of the network with specific features, such as multi-path routing, isolation, and failure recovery, without modifying hosted application code. Network operators may differentiate themselves based on upgrades they offer, creating new upgrades via a light-weight programming interface. Blender safely executes multiple tenants' selections simultaneously across a shared network infrastructure. We show that the Blender model can express and extend recently proposed network functionality on existing SDN networks. We use an OpenFlow-based prototype to quantify Blender's performance and potential for deployment at scale.
[Networks, Network architectures]
BCCC: an expandable network for data centers
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Many server-centric data center network topologies have been proposed recently due to their significant advantage in cost-efficiency and data center agility, such as BCube, FiConn and BCN. However, existing server-centric topologies are either not expandable or demanding prohibitive expansion cost. As the scale is increasing rapidly, the lack of expandability imposes a severe obstacle for data center upgrade. In this paper, we present a novel server-centric data center network topology called BCube Connected Crossbars (BCCC), which can provide good network performance and expandability using commodity off-the-shelf switches and commodity servers with only two NIC ports. BCCC can accommodate a large number of servers while keeping a very small network diameter, as a particular desirable property of BCCC is that its diameter increases only linearly to the network order, which is superior to most of existing server-centric networks, such as FiConn and BCN, whose diameters increase exponentially with network order. Additionally, we propose an effective addressing scheme and routing algorithms for BCCC. We also conduct comprehensive comparisons between BCCC and other popular server-centric networks. We show that BCCC has significant advantages over existing server-centric topologies in many important metrics, such as expandability, port utilization and network diameter.
[Network properties, Networks, Network structure]
Efficient and programmable ethernet switching with a NoC-enhanced FPGA
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Communications systems make heavy use of FPGAs; their programmability allows system designers to keep up with emerging protocols and their high-speed transceivers enable high bandwidth designs. While FPGAs are extensively used for packet parsing, inspection and classification, they have seen less use as the switch fabric between network ports. However, recent work has proposed embedding a network-on-chip (NoC) as a new "hard" resource on FPGAs and we show that by properly leveraging such a NoC one can create a very efficient yet still highly programmable network switch. We compare a NoC-based 16&#215;16 network switch for 10-Gigabit Ethernet traffic to a recent innovative FPGA-based switch fabric design. The NoC-based switch not only consumes 5.8&#215; less logic area, but also reduces latency by 8.1&#215;. We also show that using the FPGA's programmable interconnect to adjust the packet injection points into the NoC leads to significant performance improvements. A routing algorithm tailored to this application is shown to further improve switch performance and scalability. Overall, we show that an FPGA with a low-cost hard 64-node mesh NoC with 64-bit links can support a 16&#215;16 switch with up to 948 Gbps in aggregate bandwidth, roughly matching the transceiver bandwidth on the latest FPGAs.
[Networks, Packet-switching networks, Network components, Routers, Intermediate nodes, Network types]
Laying out interconnects on optical printed circuit boards
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Short distance optical interconnections, on-printed circuit boards, on-backplanes, and even on-chip, are a promising solution for replacing copper interconnections in future Data Center and HPC systems. Since photonic technology introduces new network building blocks, topology design for all the packaging levels should be reconsidered. This paper focuses on the on-board level of the packaging hierarchy, and proposes lay-out strategies for optical interconnection networks on optical printed circuit boards (OPCBs), based on direct topology families (tori, meshes and fully connected networks). We also describe a methodology for designing OPCBs given a set of input parameters, including building blocks specifications as well as traffic demands. The on-board topology design methodology generates all the feasible designs within the topology families examined, following our proposed OPCB lay-out approach, and selects the optimal designs based on specific optimization criteria.
[Network properties, Networks, Network structure, VLSI system specification and constraints, Hardware, Very large scale integration design]
Integration and QoS of multicast traffic in a server-rack fabric with 640 100g ports
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Flexible datacenters rely on high-bandwidth server-rack fabrics to allocate their distributed computing and storage resources anywhere,anyhow, and anytime demanded. We describe the multicast architecture of a distributed server-rack fabric, which is arranged around a spine-leaf topology and connects 640 Ethernet ports running at 100G. To cope with the immense fabric speed, we resort to hierarchical, tree-based replication, facilitated by specially commissioned fabric-end ports. At each (port-to-port) leg of the tree, a frame copy is forwarded after a request-grant admission phase and is ACKed by the receiver. To save on bandwidth, we use a packet cache in our input-queued switching-nodes, which replicates asynchronously forwarded frames thus tolerating the variable-delay in the admission phase. Because the cache has limited size, we loosely synchronize the multicast subflows to protect the cache from thrashing. We describe our policies for lossy classes, which segregate and provide fair treatment to multicast subflows. Finally, we show that industry-standard Level2 congestion control does not adapt well to one-to-many flows, and demonstrate that the methods that we implement achieve the best performance.
[Networks, Network architectures]
Marlin: a memory-based rack area network
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Disaggregation of hardware resources that are traditionally embedded within individual servers into separate resource pools is an emerging architectural trend in hyperscale data center design, as exemplified by Facebook's disaggregated rack architecture. This paper presents the design, implementation and evaluation of a PCIe-based rack area network system called Marlin, which is designed to support the communications needs of disaggregated racks. By virtue of being based on PCIe, Marlin presents a memory-based addressing model for both I/O device sharing among multiple hosts and inter-host communications, and as a result offers hardware- based remote direct memory access (HRDMA) as a first-class communications primitive between servers within a rack. Marlin supports socket-based communications for legacy network applications and cross-machine zero memory copying for applications designed specifically to take full advantage of Marlin. Empirical measurements on a fully operational Marlin prototype based on 4-lane Gen3 PCIe technology show that the one-way kernel-to-kernel latency is 8.5&#956;sec and the end-to- end sustainable TCP throughput is 19.6 Gbps.
[Networks, Network architectures]
Caesar: a content router for high-speed forwarding on content names
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Internet users are interested in content regardless of its location; however, the current client/server architecture still requires requests to be directed to a specific server. Information-centric networking (ICN) is a recent vein that relaxes this requirement through the use of name-based forwarding, where forwarding decisions are based on content names instead of IP addresses. Despite previous name-based forwarding strategies have been proposed, almost none have actually built a content router. To fill this gap, in this paper we design and prototype a content router called Caesar for high-speed forwarding on content names. Caesar introduces several innovative features, including (i) a longest-prefix matching algorithm based on a novel data structure called prefix Bloom filter; (ii) an incremental design which allows for easy integration with existing protocols and network equipment;(iii) a forwarding scheme where multiple line cards collaborate in a distributed fashion; and (iv) support for offloading packet processing to graphics processing units (GPUs). We build Caesar as an enterprise router, and show that every line card sustains up to 10 Gbps using a forwarding table with more than 10 million content prefixes. Distributed forwarding allows the forwarding table to grow even further, and to scale linearly with the number of line cards at the cost of only a few microseconds in the packet processing latency. GPU offloading, in turn, trades off a few milliseconds of latency for a large speedup in the forwarding rate.
[Networks, Network protocols, Network components, Packet-switching networks, Routers, Intermediate nodes, Network types]
Design patterns for tunable and efficient SSD-based indexes
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
A number of data-intensive systems require using random hash-based indexes of various forms, e.g., hash tables, Bloom filters, and locality sensitive hash tables. In this paper, we present general SSD optimization techniques that can be used to design a variety of such indexes while ensuring higher performance and easier tunability than specialized state-of-the-art approaches. We leverage two key SSD innovations: a) rearranging the data layout on the SSD to combine multiple read requests into one page read, and b) intelligently reordering requests to exploit inherent parallelism in the architecture of SSDs. We build three different indexes using these techniques, and we conduct extensive studies showing their superior performance, lower CPU/memory footprint, and tunability compared to state-of-the-art systems.
[Communication hardware, interfaces and storage, Networks, File systems management, Contextual software domains, Information systems, Information storage systems, Operating systems, Storage management, Memory management, Hardware, Software organization and properties, Software and its engineering]
CoRC: coordinated routing and caching for named data networking
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Named Data Networking (NDN) uses content names as routing entries, and thus the scalability of NDN routing is of primary concern. NDN allows in-network caching as a built-in functionality; however, if network nodes make caching decisions individually, duplicate copies of the same content may exist among nearby nodes. To address these problems, we propose Coordinated Routing and Caching (CoRC) that mitigates routing scalability and enhances the efficiency of the in-network storage. CoRC aligns the routing and caching mechanisms to manage the same content namespace for better performance. We evaluate CoRC (and its variants) with Vanilla NDN in terms of the cache hit ratio, hop count, and traffic load by running software routers on Amazon EC2. To demonstrate the feasibility of CoRC, we also implement and test the processing time of CoRC forwarding in Linux machines.
[Networks, Network protocols]
Secure remote sensing and communication using digital pufs
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Small form, mobile, and remote sensor network systems require secure and ultralow power data collection and communication solutions due to their energy constraints. The physical unclonable function (PUF) has emerged as a popular modern low power security primitive. However, current designs are analog in nature and susceptible to instability and difficult to integrate into existing circuitry. In this paper, we present the digital PUF which is stable in the same sense that digital logic is stable, has a very small footprint and very small timing overhead, and can be easily integrated into existing designs. We demonstrate the use of the digital PUF on two applications that are crucial for sensor networks: trusted remote sensing and logic obfuscation. We present our security analysis using standard randomness tests and confusion and diffusion analysis, and apply our new obfuscation approach on a set of standard design benchmarks.
[Integrated circuits, Security and privacy, Network security, Hardware]
Thermal-aware vacation and rate adaptation for network packet processing
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
As processor power density increases, thermal and power control becomes critical for packet processing on a processor. In "run-to-finish" applications, power consumption is stable and temperature simply rises to saturation point and then stabilizes. But, network applications feature ON/OFF execution pattern, which causes frequent temperature and power consumption changes in the processor. We propose a thermal aware scheduler, TrafficLight, which achieves power saving by employing vacation and rate adaptation techniques. We implement these through the idle states (C-state) provided by the OS in a CPU and show their effec-tiveness through experimental data. Then we build power, thermal and latency models based on the vacation queuing theory, which estimates the performance of our proposed techniques. Finally, we design, implement and evaluate an on-line algorithm to dynamically choose the proper pow-er/thermal management technique based on the traffic variation. The technique maintains the processor temperature below the temperature constraint and achieves power saving. To the best of our knowledge, this is the first work to provide the theoretical analysis as well as the experimental results for the vacation and rate adaptation schemes considering power, temperature and latency in the packet processing on a general purpose processor.
[Modeling and simulation, Computing methodologies, Model development and analysis, Modeling methodologies]
Fine-grained power scaling algorithms for energy efficient routers
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Energy efficient router is one of the most important and promising devices in the roadmap towards green communication and networking. In recent years, automatical power scaling adapting with real-time network traffic in a router has been proved to be practical on real hardware, which is an implementation under the traffic aware philosophy. In this paper, we further explore this direction, and present four real-time power scaling algorithms for the fine-grained energy management within a router. These algorithms are all based on the traffic aware philosophy. We first classify the traffic characteristics into three categories of the core router, access router and home router and analyze the differences among them. Then, we propose two design methodologies, periodical scaling and threshold scaling, and address four algorithms in details. Finally, we use real network traffic to evaluate these algorithms and draw the conclusions. The experiments on real traffic show that more than 40\% of the energy in a router can be saved by using proposed system-level power scaling methods. Based on those evaluations, we also find that three status modes with two working frequencies and a sleep in a router are enough to achieve near-optimal energy efficiency by using our algorithms, which indicates an easy and practical hardware modification.
[Networks, Network components, Packet-switching networks, Routers, Intermediate nodes, Network types]
Efficient software packet processing on heterogeneous and asymmetric hardware architectures
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Heterogeneous and asymmetric computing systems are composed by a set of different processing units, each with its own unique performance and energy characteristics. Still, the majority of current network packet processing frameworks targets only a single device (the CPU or some accelerator), leaving other processing resources idle. In this paper, we propose an adaptive scheduling approach that supports heterogeneous and asymmetric hardware, tailored for network packet processing applications. Our scheduler is able to respond quickly to dynamic performance fluctuations that occur at real-time, such as traffic bursts, application overloads and system changes. The experimental results show that our system is able to match the peak throughput of a diverse set of packet processing workloads, while consuming up to 3.5x less energy.
[Networks, Computer systems organization, Other architectures, Network services, Heterogeneous (hybrid) systems, Architectures]
A purely functional approach to packet processing
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Today's rapidly evolving network ecosystem, characterized by increasing traffic volumes, service heterogeneity and mutating cyber-threats, calls for new approaches to packet processing to address key issues such as scalability, flexibility, programmability and fast deployment. To this aim, this paper explores a new direction to packet processing by pushing forward functional programming principles in the definition of a ''software defined networking'' paradigm. This result is achieved by introducing PFQ-Lang, an extensible functional language which can be used to process, analyze and forward packets captured on modern multi-queue NICs (for example, it allows to quickly develop the early stage of monitoring applications). An implementation of PFQ-Lang, embedded into high level programming languages as an eDSL (embedded Domain Specific Language) is also presented. The proposed approach allows an easy development by leveraging the intuitive functional composition and, at the same time, allows to exploit multi-queue NICs and multi-core architectures to process high-speed network traffic. Experimental results are provided to prove that the presented implementation reaches line rate performance on a 10Gb line card. To demonstrate the effectiveness and expressiveness of PFQ-Lang, the paper also presents a few use-cases ranging from forwarding, firewalling and monitoring of real traffic.
[Networks, General programming languages, Network monitoring, Language types, Functional languages, Software notations and tools, Network management, Network services, Software and its engineering]
A scalable routing and admission control model in sdn-based networks
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
In this paper, we propose a scalable routing and admission control model for Software Defined Networks (SDN). We use pre-established multi-path (PMP) model to increase routing scalability and reduce admission control time.
[Networks, Network architectures]
High performance multi-field packet classification using bucket filtering and GPU processing
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
The literature review shows a trend to arbitrary number of multi-field packet classification is evolved from standard 5-tuple matching to support new applications like OpenFlow switch which processes upto 15 fields \cite{Yun:ISCAHPP13}. However, arbitrary number of multi-field packet classification becomes a great challenge regarding to performance, memory requirement, and update cost. In this paper, a high performance multi-field packet classification system is designed and implemented using bucket filtering and GPU processing.
[Networks, Network components, Routers, Intermediate nodes]
QoS aware dynamic power scaling algorithms for deploying energy efficient routers
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Energy efficient routers (EERs) are promising devices to achieve green communications for ISP to save energy and cost. However, deploying this kind of routers may introduce severe accumulated packet delay, especially for high-end optical routers. In this paper, we present three contributions to solve the above issue with dynamically balancing QoS and the energy consumption, while preserve the real deployment simple and flexible. First, we propose a QoS aware power scaling algorithm for single self-motivated EER. Second, we present a QoS aware open-loop deployment method by using a short-term traffic forecast model. This model can assist EERs to adapt their capacities with the information of the incoming network traffic along the traffic path. Third, we propose a QoS aware feedback deployment method for better energy efficiency by building local control systems between two adjacent EER pairs. We evaluate the above algorithms by performing simulations. The results show that our methods are energy efficieny while controlling the packet delay.
[Communication hardware, interfaces and storage, Networks, Hardware]
Network monitoring probe based on Xilinx Zynq
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
To provide reliable network and cloud services, it is necessary to perform precise monitoring and security analysis of cloud, ISP and local networks.Current SOHO (Small Office Home Office) devices have very limited resources and can not provide precise network security monitoring in local networks. Therefore we have designed small and low-power network probe which is able to analyse the network traffic at the application layer. The Xilinx Zynq enables to divide the task between hardware and software efficiently. The FPGA logic provides preprocessing (filtering) of data and the processor performs deep packet inspection to analyse application protocols. Moreover, the probe is ready to offload any time consuming operation (eg. regular expression matching) to the FPGA logic to increase processing speed.
[Computer systems organization, Embedded and cyber-physical systems, Real-time systems]
Network service quality rank: a network selection algorithm for heterogeneous wireless networks
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
High-speed wireless services have achieved remarkable rates of growth in recent years. In order to survive in this competitive market, high levels of service performance are an effective way to improve customer satisfaction and loyalty. This paper aims to identify the best service provider in a heterogeneous wireless network so that we differentiate the quality of service (QoS) and provide a framework for analytical performance evaluation. This problem is considered a ranking problem in Multi-Criteria Decision Making, and so we formulize a novel method to compute collaboration performance utility for each provider. The compromise ranking technique (called VIKOR) is used to aggregate all utility values on alternatives and computes the best level of service among providers. The experimental evaluation results demonstrate the computational efficacy of the solution approaches and derive managerial insights.
[Applied computing, Engineering, Physical sciences and engineering]
Toward terabyte-scale caching with SSD in a named data networking router
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Named Data Networking (NDN) routers can cache previously forwarded Data packets, and those can be reused when a matching Interest packet arrives. Unlike traditional IP routers and HTTP caches that exist as separate devices, designing a scalable NDN router is a new challenge because it should perform fast forwarding and massive-scale caching at the same time. This paper proposes a design of an NDN router with unique forwarding and caching mechanisms featuring terabyte-scale caching with solid-state drives (SSD) while still forwarding packets at line speed.
[Networks, Network components, Routers, Intermediate nodes, Network types]
Spectral clustering based regular expression grouping
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Regular expression matching has been playing an import role in today's network security systems with deep inspection function. However, compiling a set of regular expressions into one Deterministic Finite Automata (DFA) often leads to state explosion, which means huge or even impractical memory cost. Distributing regular expressions into several groups and building DFAs independently has been proved an efficient solution, but the previous grouping algorithms are either locally optimal or time-consuming. In this work, we proposed a new grouping method based on Spectral Clustering, which defines the similarity between regular expressions and then transforms grouping problem to clustering problem. Preliminary experiments illustrate that our grouping algorithm achieves efficient result with much less processing time.
[Security and privacy, Network security]
Change-point detection method on 100 Gb/s ethernet interface
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
This paper deals with hardware acceleration of statistical methods for detection of anomalies on 100 Gb/s Ethernet. The approach is demonstrated by implementing a sequential Non-Parametric Cumulative Sum (NP-CUSUM) procedure. We use high-level synthesis in combination with emerging software defined monitoring (SDM) methodology for rapid development of FPGA-based hardware-accelerated network monitoring applications. The implemented method offloads detection of network attacks and anomalies directly into an FPGA chip. The parallel nature of FPGA allows for simultaneous detection of various kinds of anomalies. Our results show that hardware acceleration of statistical methods using the SDM concept with high-level synthesis from C/C++ is possible and very promising for traffic analysis and anomaly detection in high-speed 100 Gb/s networks.
[Networks, Security and privacy, Network monitoring, Network security, Network services]
Superspreader detection system on NetFPGA platform
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
We propose a system to detect superspreaders based on combinations of FM sketch, Bloom filter and hash table. It first eliminates sources which are not potential superspreaders, then counts the number of connections to distinct destinations (fan-out) for remaining sources. The proposed system is implemented on NetFPGA platform. Our experiment results show that the system can detect superspreaders with higher fan-out and estimate their fan-outs accurately using small amount of memory.
[Networks, Network monitoring, Network services]
On reducing false positives of a bloom filter in trie-based algorithms
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Many IP address lookup approaches employ Bloom filters to obtain a high-speed search performance. Especially, the search performance of trie-based algorithms can be significantly improved by adding Bloom filters, because Bloom filters can determine whether a node exists in a trie without accessing the trie. The false positive rate of a Bloom filter must be reduced to enhance the lookup performance. One important characteristic of a trie is that all the ancestors of a node are also stored. The proposed IP lookup algorithm utilizes this characteristic in reducing the false positive rate of a Bloom filter without increasing the Bloom filter size. When a Bloom filter produces a positive result for a node of a trie, we propose to check whether the ancestors of the node are also positives. Because Bloom filters have no false negatives, the negative of the ancestor means that the positive of the node is false. Simulation results show that the false positive rate is reduced up to 67\% using the exact same amount of memory. The proposed approach can be applied to other trie-based algorithms employing Bloom filters.
[Networks, Network components, Routers, Intermediate nodes]
Static power reduction in caches using deterministic naps
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
We propose a technique that reduces static power consumption in caches with negligible hardware overhead and no performance penalties. Our proposed architecture achieves this by deterministically lowering the power state of cache lines that are guaranteed not to be accessed in the immediate future by exploiting in-flight cache access information. We simulated our architecture using the Simplescalar and Cacti toolsets, and observed up to 92% reduction in static power consumption in SPEC2006 benchmarks with no performance penalties and minimal hardware overhead.
[Integrated circuits, High-level and register-transfer level synthesis, Electronic design automation, Hardware, Semiconductor memory]
Secure and efficient key management protocol (SEKMP) for wireless sensor networks
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Wireless sensor networks (WSNs) are used in the many critical applications, such as, military, health, and civil applications. Sometimes such applications require that the WSNs to be randomly deployed in inaccessible terrains such as a remote territory. As a result, the sensors are left unattended and become a potential target for an adversary. Therefore, we propose a highly Secure and Efficient Key Management Protocol for WSN, called SEKMP. The proposed protocol (SEKMP) adapts a new key management approach by leveraging the advantages of asymmetric cryptography and employs them in a very efficient way for delivering the session key to sensor nodes.
[Networks, Security and privacy, Mobile networks, Wireless access networks, Cryptography, Network types, Public key (asymmetric) techniques, Public key encryption]
A digital PUF-based IP protection architecture for network embedded systems
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
In this paper we present an architecture for a secure embedded system that is resilient to tempering and code injection attacks and offers anti-piracy protection for the software and hardware Intellectual Property (IP). We incorporate digital Physical Unclonable Functions (PUFs) in an authentication mechanism at the machine code level. The digital PUFs are used to de-obfuscate, at run time, a firmware that's issued by a central authority with very little performance and resource overhead. Each PUF is unique to the hosting device, and at the same time can be reconfigured with new seeds. The reconfigurable digital PUFs (drPUFs) have much lower risks of side-channel attacks and vastly higher number of usable challenge-response pairs, while retaining the speed and ease to implementation of digital PUFs.
[Computer systems organization, Embedded and cyber-physical systems, Real-time systems]
PLWAH+: a bitmap index compressing scheme based on PLWAH
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Archiving of the Internet traffic is essential for analyzing network events in the field of network security and network forensics. The bitmap index is widely used to achieve fast searching in archival traffic data requiring a large storage space. As current state-of-art, WAH, PLWAH and COMPAX are proposed for compressing bitmap indexes. In this paper, a new bitmap index compression scheme, named PLWAH+ (Position List Word Aligned Hybrid Plus), is introduced, based on PLWAH. With less storage consumption, PLWAH+ is more suitable for indexing in large-scale and high-speed network traffic.
[Data compression, Data management systems, Data structures, Data layout, Information systems]
Impact of the end-system and affinities on the throughput of high-speed flows
Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems
None
2014
Network throughput is scaling "up" to higher data transfer rates while processors are scaling "out" to multiple cores. As a result, network adapter "offloads" and performance "tuning" have received a good deal of attention lately. However, much of this attention is focused on the "how" and not the "why" of performance efficiency. There are two types of efficiencies that we have found particularly intriguing: First, processor core "affinity," or "binding" is fundamentally the choice of which processor core or cores handle certain tasks in a network- or I/O-heavy application running on a MIMD machine. Second, Ethernet "pause frames" slightly violate the "end-to-end" nature of TCP/IP in order to perform link-to-link flow control. The goal of our research is to delve deeper into why these tuning suggestions and this offload exist, and how they affect the end-to-end performance and efficiency of a single, large TCP flow.
[Communication hardware, interfaces and storage, Networks, Network protocols, Hardware]
O3FA: A Scalable Finite Automata-based Pattern-Matching Engine for Out-of-Order Deep Packet Inspection
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
To match the signatures of malicious traffic across packet boundaries, network-intrusion detection (and prevention) systems (NIDS) typically perform pattern matching after flow reassembly or packet reordering. However, this may lead to the need for large packet buffers, making detection vulnerable to denial-of-service (DoS) attacks, whereby attackers exhaust the buffer capacity by sending long sequences of out-of-order packets. While researchers have proposed solutions for exact-match patterns, regular-expression matching on out-of-order packets is still an open problem. Specifically, a key challenge is the matching of complex sub-patterns (such as repetitions of wildcards matched at the boundary between packets). Our proposed approach leverages the insight that various segments matching the same repetitive sub-pattern are logically equivalent to the regular-expression matching engine, and thus, inter-changing them would not affect the final result. In this paper, we present O3FA, a new finite automata-based, deep packet-inspection engine to perform regular-expression matching on out-of-order packets without requiring flow reassembly. O3FA consists of a deterministic finite automaton (FA) coupled with a set of prefix-/suffix-FA, which allows processing out-of-order packets on the fly. We present our design, optimization, and evaluation for the O3FA engine. Our experiments show that our design requires 20x-4000x less buffer space than conventional buffering-and-reassembling schemes on various datasets and that it can process packets in real-time, i.e., without reassembly.
[Security and privacy, Intrusion/anomaly detection and malware mitigation, Intrusion detection systems]
Many-Field Packet Classification for Software-Defined Networking Switches
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
Packet classification is a core problem for OpenFlow-based software-defined networking switches, which required 38 packet header fields per flow to be examined against thousands of rules in a ruleset. With the trend of continue growing number of fields in a rule and the number of rules in rule set, it will be a great challenge to design a high performance packet classification solution with the capability to easy update new rule and fields. In this paper, we present a scalable many-field packet classification algorithm with varying rulesets and its prototype implementation on a graphics processing unit. The proposed algorithm constructs multiple lookup tables and merges partial lookup results for a small ruleset to accelerate the overall packet classification process by using effective bit positions in a ruleset with three selecting metrics: wildcard ratio, independence index, and diversity index. Those lookup tables made with effective bit positions are flat with a low rule replication ratio. Besides, they are adjustable to meet different implementation environments for a good performance scalability between different ruleset sizes. Our prototype on a single NVIDIA K20C GPU achieves 198 MPPS, 186 MPPS, 163 MPPS throughput for 1K, 32K, and 100K 15-field ruleset.
[Networks, Network architectures]
Memory-Efficient String Matching for Intrusion Detection Systems using a High-Precision Pattern Grouping Algorithm
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
The increasing complexity of cyber-attacks necessitates the design of more efficient hardware architectures for real-time Intrusion Detection Systems (IDSs). String matching is the main performance-demanding component of an IDS. An effective technique to design high-performance string matching engines is to partition the target set of strings into multiple subgroups and to use a parallel string matching hardware unit for each subgroup. This paper introduces a novel pattern grouping algorithm for heterogeneous bit-split string matching architectures. The proposed algorithm presents a reliable method to estimate the correlation between strings. The correlation factors are then used to find a preferred group for each string in a seed growing approach. Experimental results demonstrate that the proposed algorithm achieves an average of 41% reduction in memory consumption compared to the best existing approach found in the literature, while offering orders of magnitude faster execution time compared to an exhaustive search.
[Communication hardware, interfaces and storage, Document types, Networking hardware, Hardware, General and reference, Reference works]
High Throughput Forwarding for ICN with Descriptors and Locators
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
Application-defined and location-independent addressing is a founding principle of information centric networking (ICN) that is inherently difficult to realize if one also wants scalable routing and forwarding. We propose an ICN architecture, called TagNet, intended to combine expressive application-defined addressing with scalable routing and forwarding. TagNet features two independent delivery services: one with application-defined and possibly location-independent content descriptors, and one with network-defined host locators. In this paper we develop and evaluate specialized forwarding algorithms for TagNet. We then implement and combine these algorithms in a forwarding engine built on a general-purpose commodity CPU, and show experimentally that, thanks to the dual addressing, by descriptor or by locator, this engine can achieve a throughput of over 20Gbps with large forwarding tables corresponding to hundreds of millions of users.
[Networks, Network protocols, Data path algorithms, Network design principles, Naming and addressing, Network algorithms, Network architectures, Network layer protocols]
PFPSim: A Programmable Forwarding Plane Simulator
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
In this paper, we introduce PFPSim, a host-compiled simulator for early validation and analysis of packet processing applications on programmable forwarding plane architectures. The simulation model is automatically generated from a high-level description of the hardware/software architecture of the forwarding device and the behavioral description of the various modules in the architecture. Our high-level architectural description language is capable of defining many-core network processors as well as reconfigurable pipelines. The behavior of the fixed-function processing elements in the architecture is defined in C++. The code targeted for the processor cores, or reconfigurable pipeline stages, is compiled from P4, an emerging programming language for packet processing applications. Application developers can use PFPSim as a virtual prototype to simulate and debug their applications before hardware availability. Moreover, forwarding device architects can use PFPSim to evaluate the trade-offs between different hardware/software design decisions.
[Networks, Multicore architectures, Transaction-level verification, Simulation and emulation, Parallel architectures, Functional verification, Computer systems organization, Hardware validation, Hardware, Network simulations, Network performance evaluation, Architectures]
A Study of Speed Mismatches Between Communicating Virtual Machines
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
This work addresses an apparently simple but elusive problem that arises when doing high speed networking on Virtual Machines. When a VM and its peer (usually the hypervisor) process packets at different rates, the work required for synchronization (interrupts and "kicks") may reduce throughput well below the slowest of the two parties. The problem is not peculiar to VMs: I/O on magnetic tapes and rotating disks has similar issues. What is challenging with VM networking is the timescale at which interactions may occur: down to tens or hundreds of nanoseconds, versus the 1..100 milliseconds in mechanical I/O devices. In this paper we study the impact of producer/consumer synchronization on throughput and overall efficiency of the system; identify different operating regimes depending on the operating parameters; and validate the accuracy of our model on an actual prototype that resembles the operation of a VM and its hypervisor. Our goal, to be expanded in future work, is to use these findings to derive strategies that can provide good or optimal throughput while being cost effective, robust and practical, i.e., without unnecessarily keeping cores active all the time, or depending on precise timing measurements or unreasonable assumptions on the system's behaviour.
[Networks, Cross-computing tools and techniques, Communications management, Network protocols, Contextual software domains, Network protocol design, Operating systems, Software infrastructure, Virtual machines, Performance, General and reference, Software organization and properties, Software and its engineering]
BASEL (Buffer mAnagement SpEcification Language)
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
Buffering architectures and policies for their efficient management constitute one of the core ingredients of a network architecture. In this work we introduce a new specification language, BASEL, that allows to express virtual buffering architectures and management policies representing a variety of economic models. BASEL does not require the user to implement policies in a high-level language; rather, the entire buffering architecture and its policy are reduced to several comparators and simple functions. We show examples of buffer management policies in BASEL and demonstrate empirically the impact of various settings on performance.
[Networks, Cloud computing, Data path algorithms, Routers, Control path algorithms, Programming interfaces, Intermediate nodes, Reconfigurable computing, Network architectures, Bridges and switches, Programmable networks, Network performance analysis, Network services, Computer systems organization, Network components, Packet scheduling, Network algorithms, Network resources allocation, Other architectures, Network performance evaluation, Architectures]
Is Memory Disaggregation Feasible?: A Case Study with Spark SQL
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
This paper explores the feasibility of entirely disaggregated memory from compute and storage for a particular, widely deployed workload, Spark SQL analytics queries. We measure the empirical rate at which records are processed and calculate the effective memory bandwidth utilized based on the sizes of the columns accessed in the query. Our findings contradict conventional wisdom: not only is memory disaggregation possible under this workload, but achievable with already available, commercial network technology. Beyond this finding, we also recommend changes that can be made to Spark SQL to improve its ability to support memory disaggregation.
[Networks, Network protocols, Data path algorithms, Network design principles, Naming and addressing, Network algorithms, Network architectures, Network layer protocols]
Stick to the Script: Monitoring The Policy Compliance of SDN Data Plane
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
Software defined networks provide new opportunities for automating the process of network debugging. Many tools have been developed to verify the correctness of network configurations on the control plane. However, due to software bugs and hardware faults of switches, the correctness of control plane may not readily translate into that of data plane. To bridge this gap, we present VeriDP, which can monitor "whether actual forwarding behaviors are complying with network configurations". Given that policies are well-configured, operators can leverage VeriDP to monitor the correctness of the network data plane. In a nutshell, VeriDP lets switches tag packets that they forward, and report tags together with headers to the verification server before the packets leave the network. The verification server pre-computes all header-to-tag mappings based on the configuration, and checks whether the reported tags agree with the mappings. We prototype VeriDP with both software and hardware OpenFlow switches, and use emulation to show that VeriDP can detect common data plane fault including black holes and access violations, with a minimal impact on the data plane.
[Networks, Network monitoring, Network measurement, Network performance evaluation, Network services]
Links as a Service (LaaS): Guaranteed Tenant Isolation in the Shared Cloud
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
The most demanding tenants of shared clouds require complete isolation from their neighbors, in order to guarantee that their application performance is not affected by other tenants. Unfortunately, while shared clouds can offer an option whereby tenants obtain dedicated servers, they do not offer any network provisioning service, which would shield these tenants from network interference. In this paper, we introduce Links as a Service (LaaS), a new abstraction for cloud service that provides isolation of network links. Each tenant gets an exclusive set of links forming a virtual fat-tree, and is guaranteed to receive the exact same bandwidth and delay as if it were alone in the shared cloud. Consequently, each tenant can use the forwarding method that best ?ts its application. Under simple assumptions, we derive theoretical conditions for enabling LaaS without capacity over-provisioning in fat-trees. New tenants are only admitted in the network when they can be allocated hosts and links that maintain these conditions. LaaS is implementable with common network gear, tested to scale to large networks and provides full tenant isolation at the worst cost of a 10% reduction in the cloud utilization.
[Networks, Cloud computing, Software infrastructure, Virtual machines, Network services, Contextual software domains, Software organization and properties, Software and its engineering]
Optimizing VM live migration strategy based on migration time cost modeling
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
The live migration technology of virtual machine is very helpful for dynamic workload balance, server consolidation and fault tolerance in cloud computing environment. It is important to build live migration strategies which lead to low migration time, thus helping reduce migration cost while achieving migration goal. So we look into the topic of building a model to quantitatively predict live migration time. We thoroughly analyze the key parameters that affect the migration time and construct a live migration time cost model based on KVM. The evaluation of time cost model shows that the average prediction accuracy is above 90% in comparison with measured time. Based on time cost model, we propose 2 optimized live migration strategies for different application scenarios, one for load balance and fault tolerance, the other for server consolidation. The evaluation shows our optimized migration strategies can save 35%~50% of cost compared to the random migration strategy. We believe this should be the first comprehensive study of optimizing live migration strategy with migration time cost as a key factor.
[Networks, Cloud computing, Software infrastructure, Virtual machines, Network services, Contextual software domains, Software organization and properties, Software and its engineering]
Forwarding Strategies for Applications in Named Data Networking
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
Named Data Networking (NDN), an information-centric Internet architecture, introduces a new forwarding model, in which the forwarding plane can choose between multiple interfaces when forwarding a packet. While the forwarding module brings new opportunities it also introduces challenges when the application's performance or correctness is affected by a conflict between the application design and the assigned forwarding strategy. In this paper we demonstrate the impact of the forwarding strategy decision on the performance and correctness of NDN applications.
[Networks, Programming interfaces, Network architectures]
ParaRegex: Towards Fast Regular Expression Matching in Parallel
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
In this paper, we propose ParaRegex, a novel approach for fast parallel regular expression matching. ParaRegex is a framework that implements data-parallel regular expression matching for deterministic finite automaton based methods. Experimental evaluation shows that ParaRegex produces a fast matching engine with speeds of up to 6 times compared to sequential implementations on a commodity 8-thread workstation.
[Networks, Data path algorithms, Network algorithms, Deep packet inspection]
Minflate: Combining Rule Set Minimization with Jump-based Expansion for Fast Packet Classification
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
Network packet classification is a key functionality for packet filters and firewalls, and its performance is crucial for such systems to maintain a high packet throughput under heavy load situations. However, many existing packet filters employ slow classification algorithms which cannot provide the required lookup performance due to slow rule set traversal. In this work, we address this problem by providing a novel rule set transformation strategy called Minflate which combines the advantages of existing orthogonal transformation schemes by first minimizing a source rule set and then encoding decision trees into the minimized rule set. Our results show that the Minflate-generated rule sets are both small and can in many cases be traversed faster than rule sets transformed by existing techniques in isolation.
[Network properties, Networks, Security and privacy, Data path algorithms, Network manageability, Network algorithms, Systems security, Packet classification, Firewalls]
Toward Fabric: A Middleware Implementing High-level Description Languages on a Fabric-like Network
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
Many in the networking community believe that Software-Defined Networking, in which entire networks are managed centrally, has the potential to revolutionize the field. However, SDN faces several challenges that have prevented its wide-spread adoption. Current SDN technologies, such as OpenFlow, provide powerful and flexible APIs, but can be unreasonably complex for implementing nontrivial network control logic. The generality offered by these low-level abstractions impose no structure on the network, requiring programmers to herd switches themselves, with little guidance. Many researchers argue that SDNs must adopt more structured models, such as Fabric, with an intelligent edge and a fast but simple label-switched core. Our work draws heavily from these ideas. To that end, we propose ToF, a middleware architecture for implementing policies and behaviors from high-level network descriptions on top of a Fabric-like network. We have implemented a prototype using a combination of widely used technologies, such as MPLS, and our own proposed technologies. Based on our results, we reach near linear scalability with respect to the number of addresses routed over the network, all while introducing minimal performance overhead and requiring no changes to packet structure.
[Networks, Network design principles, Programming interfaces, Network architectures]
Virtual Network Functions Instantiation on SDN Switches for Policy-Aware Traffic Steering
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
Software-Defined Networking (SDN) provides the capability to steer traffic in a network to lower the management cost. Network Function Virtualization (NFV) gives the chance to implement network functions at the right time and the right place to increase operation flexibility. Together SDN and NFV show the potential to create an agile system with a low operations cost and a high customer satisfaction. However, the combination of SDN with NFV results in the redundant packet forwarding traffic inside SDN in order to forward packets based on the deployed network functions for a service chain. Besides, it also increase the computation requirement of a controller for possible packet header modifications and flow states management. In this paper, we propose to implement network functions on SDN switches to lower the traffic inside of SDN and the computation requirement of a SDN controller. We create network function modules for open virtual switches and make those functions to be managed by a controller with an algorithm to streamline the implemented service chains. Our results show that the proposed system can reduce about 2/3 of current network traffic compared to the current solutions without the modification of forwarding tables and packets.
[Networks, Network architectures]
Node configuration for the Aho-Corasick algorithm in Intrusion Detection Systems
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
In this paper, we analyze the performance and cost trade-off from selecting two representations of nodes when implementing the Aho-Corasick algorithm. This algorithm can be used for pattern matching in network-based intrusion detection systems such as Snort. Our analysis uses the Snort 2.9.7 rules set, which contains almost 26k patterns. Our methodology consists of code profiling and analysis, followed by the selection of a parameter to maximize a metric that combines clock cycles count and memory usage. The parameter determines which of two types of nodes is selected for each trie node. We show that it is possible to select the parameter to optimize the metric, which results in an improvement by up to 12&#215; compared with the single node-type case.
[Theory of computation, Security and privacy, Intrusion/anomaly detection and malware mitigation, Data structures design and analysis, Design and analysis of algorithms, Pattern matching, Intrusion detection systems]
A One-Way Proof-of-Work Protocol to Protect Controllers in Software-Defined Networks
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
Connection setup in software-defined networks (SDN) requires considerable amounts of processing, communication, and memory resources. Attackers can target SDN controllers with simple attacks to cause denial of service. We proposed a defense mechanism based on a proof-of-work protocol. The key characteristics of this protocol, namely its one-way operation, its requirement for freshness in proofs of work, its adjustable difficulty, its ability to work with multiple network providers, and its use of existing TCP/IP header fields, ensure that this approach can be used in practice.
[Security and privacy, Network security]
P4GPU: Accelerate Packet Processing of a P4 Program with a CPU-GPU Heterogeneous Architecture
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
The P4 language is an emerging domain-specific language for describing the data plane processing at a network device. P4 has been mapped to a wide range of forwarding devices including NPUs, programmable NICs and FPGAs, except for General Purpose Graphics Processing Unit (GPGPU) which is a salient parallel architecture for processing network flows. In this work, we design a heterogeneous architecture with both CPU and GPU as a P4 programming target, and present a toolset to map a P4 program onto the proposed architecture. Our evaluation reveals that a P4 program can render promising performance on such architecture by parallelizing its "match+action" engine with the GPGPU accelerator. The experiment results show that the auto-configured GPU kernels achieve scalable lookup and classification speeds: the prototype system can reach up to 580 Gbps for IP lookups (64-byte packets) and 60 million classifications per second for 4k firewall rules, respectively.
[Parsers, Networks, Multicore architectures, Single instruction, multiple data, Intermediate nodes, Context specific languages, Software notations and tools, Parallel architectures, Domain specific languages, Computer systems organization, Network components, Other architectures, Heterogeneous (hybrid) systems, Network performance evaluation, Architectures, Software and its engineering, Compilers]
Cache Sharing Using a Bloom Filter in Named Data Networking
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
In Named Data Networking (NDN), routers have caches to store frequently requested contents, and hence cache management scheme becomes a key factor for efficient content delivery. In this paper, we propose the sharing of cache summaries using a Bloom filter among neighboring routers for efficient content delivery and high cache utilization at NDN. When an Interest packet is received, a router can forward the Interest to a neighboring router which has the high potential of the requested content. The proposed scheme is evaluated by using ndnSIM, which is a NS-3 based named data networking simulator. Simulation results show that the summary sharing using our proposed method is beneficial in content diversity and average content delivery time.
[Networks, Network architectures]
Software Defined Networks-on-Chip for Multi/Many-Core Systems: A Performance Evaluation
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
By means of a management framework and programmable routing tables, Software Defined Network (SDN) architectures offer network's adaptability to today's computer systems. In Networks-on-Chip (NoC) based systems, management methods have been implemented as specific solutions unable to be reused in further designs. A Software Defined NoC (SDNoC) architecture will permit on-the-fly re / configuration and reduce Non-Recurring Engineering costs. In this paper, performance evaluations of a SDNoC through flit-accurate SystemC models are presented. We measure the average values of the configuration time (CT), global delay and throughput for various routing algorithms and packet injection rates.
[Networks, Computer systems organization, Multicore architectures, Embedded and cyber-physical systems, System on a chip, Parallel architectures, Network performance analysis, Network performance evaluation, Architectures]
NI + Router Microarchitecture for NoC-based Communication Systems
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
Modern communication systems are characterized by intensive computation signal processing algorithms. System-on-Chip implementations of these systems are generally based on Networks-on-Chip (NoC). The router and Network Interface (NI) are the main elements of the NoC, but the router is the architecture most discussed in the literature. Here, a NI + router microarchitecture is presented. Our router implementation outperforms the previous work in operational frequency by a 20%. The NI usually is assumed as a simple wrapper, although results in this work show that the NI can consume almost twice resources than the router. This indicates that further discussions must be carried out for the design of NoC-based communication systems.
[Communication hardware, interfaces and storage, Integrated circuits, Interconnect, Networks, End nodes, Network components, Routers, Network adapters, Intermediate nodes, Hardware]
On Data Plane Latency and Pseudo -TCP Congestion in Software-Defined Networking
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
None
[Networks, Circuit optimization, Logic synthesis, Electronic design automation, Electrical-level simulation, Hardware, Network measurement, Network performance analysis, Network performance evaluation, Timing analysis]
Evaluating Information-Centric Networks in Disconnected, Intermittent, and Low-Bandwidth Environments
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
This paper studies information dissemination in wireless ad hoc networks, using standard routing protocols, such as OLSR, as well as Information-Centric Networking. We performed simulations using NS-3 and ndnSIM with different node counts and transport protocols. Our simulations show that TCP performs better in lower hop count scenarios, while NDN performs better in higher hop count scenarios.
[Networks, Ad hoc networks, Network simulations, Network performance evaluation, Network types, Mobile ad hoc networks]
Enterprise LTE and WiFi Interworking System and A Proposed Network Selection Solution
Proceedings of the 2016 Symposium on Architectures for Networking and Communications Systems
None
2016
With a bandwidth reservation mechanism, we propose that LTE can assist existing WiFi networks to improve the Quality of Experience (QoE) of wireless communication in enterprise and meanwhile increase the available spectrum. To address the associated network selection problem between WiFi and LTE, in this paper based on the 3GPP standard Access Network Discovery and Selection Function (ANDSF) framework, a context-aware solution named Extended Dynamic Enterprise ANDSF (EDE-ANDSF) is presented. It can select interfaces according to real time network conditions and cater for specific enterprise requirements.
[Network properties, Networks, Network components, Mobile networks, Network dynamics, Network architectures, Wireless access networks, Network types]
